{"1": "1. Geiger, A., Lenz, P., Urtasun, R.: Are we ready for autonomous driving? the kitti vision benchmark suite. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2012) 2. Scharstein, D., Szeliski, R.: A taxonomy and evaluation of dense two-frame stereo  correspondence algorithms. Int. J. Comp. Vis. 47(1-3) (April 2002) 7-42  3. Hirschmuller, H.: Stereo processing by semiglobal matching and mutual informa- tion. IEEE Trans. Pattern Anal. Mach. Intell. 30(2) (February 2008) 328-341 4. Kendall, A., Martirosyan, H., Dasgupta, S., Henry, P., Kennedy, R., Bachrach, A., Bry, A.: End-to-end learning of geometry and context for deep stereo regression. In: Proc. IEEE Int. Conf. Comp. Vis. (Oct 2017)  5. Shi, X., Chen, Z., Wang, H., Yeung, D.Y., Wong, W.k., Woo, W.c.: Convolutional lstm network: A machine learning approach for precipitation nowcasting. In: Proc. Adv. Neural Inf. Process. Syst. NIPS\u201915, Cambridge, MA, USA, MIT Press (2015) 802-810  6. Janai, J., Gney, F., Behl, A., Geiger, A.: Computer vision for autonomous vehicles:  Problems, datasets and state-of-the-art. Arxiv (2017)  7. \u02c7Zbontar, J., LeCun, Y.: Stereo matching by training a convolutional neural network to compare image patches. J. Mach. Learn. Res. 17(1) (January 2016) 2287-2318 8. Luo, W., Schwing, A.G., Urtasun, R.: E\ufb03cient deep learning for stereo matching.  In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (June 2016) 5695-5703  9. Seki, A., Pollefeys, M.: Sgm-nets: Semi-global matching with neural networks. In:  Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2017)  10. Mayer, N., Ilg, E., Husser, P., Fischer, P., Cremers, D., Dosovitskiy, A., Brox, T.: A large dataset to train convolutional networks for disparity, optical \ufb02ow, and scene \ufb02ow estimation. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (June 2016) 11. Pang, J., Sun, W., Ren, J.S., Yang, C., Yan, Q.: Cascade residual learning: A two- stage convolutional neural network for stereo matching. In: International Conf. on Computer Vision - Workshop on Geometry Meets Deep Learning. (2017)  12. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.  In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (June 2016) 770-778  13. Garg, R., Kumar, B.V., Carneiro, G., Reid, I.: Unsupervised cnn for single view depth estimation: Geometry to the rescue. In: Proc. Eur. Conf. Comp. Vis. (2016) 740-756  14. Godard, C., Mac Aodha, O., Brostow, G.J.: Unsupervised monocular depth esti- mation with left-right consistency. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2017)  15. Zhou, T., Brown, M., Snavely, N., Lowe, D.G.: Unsupervised learning of depth and ego-motion from video. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2017) 16. Xie, J., Girshick, R., Farhadi, A. In: Deep3D: Fully Automatic 2D-to-3D Video Conversion with Deep Convolutional Neural Networks. Springer International Pub- lishing, Cham (2016) 842-857  17. Zhong, Y., Dai, Y., Li, H.: Self-supervised learning for stereo matching with self-  improving ability. In: arXiv:1709.00930. (2017)  18. Wang, C., Buenaposada, J.M., Zhu, R., Lucey, S.: Learning Depth from Monocular  Videos using Direct Methods. ArXiv e-prints (November 2017)  19. Luo, Y., Ren, J., Lin, M., Pang, J., Sun, W., Li, H., Lin, L.: Single View Stereo  Matching. ArXiv e-prints (March 2018)  20. Bengio, Y., Simard, P., Frasconi, P.: Learning long-term dependencies with gradi-  ent descent is di\ufb03cult. Trans. Neur. Netw. 5(2) (March 1994) 157-166   Open-World Stereo Video Matching with Deep RNNReferences  1. Geiger, A., Lenz, P., Urtasun, R.: Are we ready for autonomous driving? the kitti vision benchmark suite. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2012) 2. Scharstein, D., Szeliski, R.: A taxonomy and evaluation of dense two-frame stereo  correspondence algorithms. Int. J. Comp. Vis. 47(1-3) (April 2002) 7-42  3. Hirschmuller, H.: Stereo processing by semiglobal matching and mutual informa- tion. IEEE Trans. Pattern Anal. Mach. Intell. 30(2) (February 2008) 328-341 4. Kendall, A., Martirosyan, H., Dasgupta, S., Henry, P., Kennedy, R., Bachrach, A., Bry, A.: End-to-end learning of geometry and context for deep stereo regression. In: Proc. IEEE Int. Conf. Comp. Vis. (Oct 2017)  5. Shi, X., Chen, Z., Wang, H., Yeung, D.Y., Wong, W.k., Woo, W.c.: Convolutional lstm network: A machine learning approach for precipitation nowcasting. In: Proc. Adv. Neural Inf. Process. Syst. NIPS\u201915, Cambridge, MA, USA, MIT Press (2015) 802-810  6. Janai, J., Gney, F., Behl, A., Geiger, A.: Computer vision for autonomous vehicles:  Problems, datasets and state-of-the-art. Arxiv (2017)  7. \u02c7Zbontar, J., LeCun, Y.: Stereo matching by training a convolutional neural network to compare image patches. J. Mach. Learn. Res. 17(1) (January 2016) 2287-2318 8. Luo, W., Schwing, A.G., Urtasun, R.: E\ufb03cient deep learning for stereo matching.  In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (June 2016) 5695-5703  9. Seki, A., Pollefeys, M.: Sgm-nets: Semi-global matching with neural networks. In:  Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2017)  10. Mayer, N., Ilg, E., Husser, P., Fischer, P., Cremers, D., Dosovitskiy, A., Brox, T.: A large dataset to train convolutional networks for disparity, optical \ufb02ow, and scene \ufb02ow estimation. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (June 2016) 11. Pang, J., Sun, W., Ren, J.S., Yang, C., Yan, Q.: Cascade residual learning: A two- stage convolutional neural network for stereo matching. In: International Conf. on Computer Vision - Workshop on Geometry Meets Deep Learning. (2017)  12. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.  In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (June 2016) 770-778  13. Garg, R., Kumar, B.V., Carneiro, G., Reid, I.: Unsupervised cnn for single view depth estimation: Geometry to the rescue. In: Proc. Eur. Conf. Comp. Vis. (2016) 740-756  14. Godard, C., Mac Aodha, O., Brostow, G.J.: Unsupervised monocular depth esti- mation with left-right consistency. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2017)  15. Zhou, T., Brown, M., Snavely, N., Lowe, D.G.: Unsupervised learning of depth and ego-motion from video. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2017) 16. Xie, J., Girshick, R., Farhadi, A. In: Deep3D: Fully Automatic 2D-to-3D Video Conversion with Deep Convolutional Neural Networks. Springer International Pub- lishing, Cham (2016) 842-857  17. Zhong, Y., Dai, Y., Li, H.: Self-supervised learning for stereo matching with self-  improving ability. In: arXiv:1709.00930. (2017)  18. Wang, C., Buenaposada, J.M., Zhu, R., Lucey, S.: Learning Depth from Monocular  Videos using Direct Methods. ArXiv e-prints (November 2017)  19. Luo, Y., Ren, J., Lin, M., Pang, J., Sun, W., Li, H., Lin, L.: Single View Stereo  Matching. ArXiv e-prints (March 2018)  20. Bengio, Y., Simard, P., Frasconi, P.: Learning long-term dependencies with gradi-  ent descent is di\ufb03cult. Trans. Neur. Netw. 5(2) (March 1994) 157-166   16  Y. Zhong, H. Li and Y. Dai  21. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Comput. 9(8)  (November 1997) 1735-1780  22. Fragkiadaki, K., Levine, S., Felsen, P., Malik, J.: Recurrent network models for human dynamics. In: Proc. IEEE Int. Conf. Comp. Vis., Washington, DC, USA, IEEE Computer Society (2015) 4346-4354  23. Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P.: Image quality assessment: from error visibility to structural similarity. IEEE Trans. Image Proc. 13(4) (April 2004) 600-612  24. Scharstein, D., Pal, C.: Learning conditional random fields for stereo. In: Proc.  IEEE Conf. Comp. Vis. Patt. Recogn. (June 2007) 1-8  25. Hirschmller, H., Scharstein, D.: Evaluation of cost functions for stereo matching.  In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn., IEEE Computer Society (2007)  26. Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A.: The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2016)  27. Yamaguchi, K., McAllester, D., Urtasun, R.: E\ufb03cient joint segmentation, occlusion labeling, stereo and \ufb02ow estimation. In: Proc. Eur. Conf. Comp. Vis. (2014)"}