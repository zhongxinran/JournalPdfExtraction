{"1": "1. Tzeng, E., Ho\ufb00man, J., Saenko, K., Darrell, T.: Adversarial discriminative domain  adaptation. CVPR (2017)  2. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,  Courville, A., Bengio, Y.: Generative adversarial nets. In: NIPS. (2014)  3. Panareda Busto, P., Gall, J.: Open set domain adaptation. In: ICCV. (2017) 4. Gebru, T., Ho\ufb00man, J., Fei-Fei, L.: Fine-grained recognition in the wild: A multi-  task domain adaptation approach. In: ICCV. (2017)  5. Zhang, Y., David, P., Gong, B.: Curriculum domain adaptation for semantic seg-  mentation of urban scenes. In: ICCV. (2017)  6. Gholami, B., (Oggi) Rudovic, O., Pavlovic, V.: Punda: Probabilistic unsupervised In: ICCV.  domain adaptation for knowledge transfer across visual categories. (2017)  7. Maria Carlucci, F., Porzi, L., Caputo, B., Ricci, E., Rota Bulo, S.: Autodial:  Automatic domain alignment layers. In: ICCV. (2017)  8. Yan, H., Ding, Y., Li, P., Wang, Q., Xu, Y., Zuo, W.: Mind the class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation. In: CVPR. (2017)  9. Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D.: Unsupervised pixel-level domain adaptation with generative adversarial networks. CVPR (2017) 10. Herath, S., Harandi, M., Porikli, F.: Learning an invariant hilbert space for domain  adaptation. In: CVPR. (2017)  11. Koniusz, P., Tas, Y., Porikli, F.: Domain adaptation by mixture of alignments of  second- or higher-order scatter tensors. In: CVPR. (2017)  12. Sankaranarayanan, S., Balaji, Y., Castillo, C.D., Chellappa, R.: Generate to adapt:  Aligning domains using generative adversarial networks. CVPR (2018)  13. Patel, V.M., Gopalan, R., Li, R., Chellappa, R.: Visual domain adaptation: A  survey of recent advances. IEEE Signal Process. Mag. (2015)  14. Csurka, G.: Domain adaptation for visual applications: A comprehensive survey.  arXiv preprint arXiv:1702.05374 (2017)  15. Saenko, K., Kulis, B., Fritz, M., Darrell, T.: Adapting visual category models to  new domains. In: ECCV. (2010)  16. Tzeng, E., Ho\ufb00man, J., Zhang, N., Saenko, K., Darrell, T.: Deep domain confusion:  Maximizing for domain invariance. CoRR (2014)  17. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic  segmentation. In: CVPR, IEEE Computer Society (2015)  18. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,  Courville, A., Bengio, Y.: Generative adversarial nets. In: NIPS. (2014)  19. Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V.: Domain-adversarial training of neural networks. JMLR (2016)  20. Tzeng, E., Ho\ufb00man, J., Darrell, T., Saenko, K.: Simultaneous deep transfer across  domains and tasks. ICCV (2015)  21. Liu, M.Y., Tuzel, O.: Coupled generative adversarial networks. In: NIPS. (2016) 22. Ghifary, M., Kleijn, W.B., Zhang, M., Balduzzi, D., Li, W.: Deep reconstruction- classification networks for unsupervised domain adaptation. In: ECCV. (2016) 23. Isola, P., Zhu, J., Zhou, T., Efros, A.A.: Image-to-image translation with condi-  tional adversarial networks. CVPR (2017)   Domain transfer through deep activation matchingReferences  1. Tzeng, E., Ho\ufb00man, J., Saenko, K., Darrell, T.: Adversarial discriminative domain  adaptation. CVPR (2017)  2. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,  Courville, A., Bengio, Y.: Generative adversarial nets. In: NIPS. (2014)  3. Panareda Busto, P., Gall, J.: Open set domain adaptation. In: ICCV. (2017) 4. Gebru, T., Ho\ufb00man, J., Fei-Fei, L.: Fine-grained recognition in the wild: A multi-  task domain adaptation approach. In: ICCV. (2017)  5. Zhang, Y., David, P., Gong, B.: Curriculum domain adaptation for semantic seg-  mentation of urban scenes. In: ICCV. (2017)  6. Gholami, B., (Oggi) Rudovic, O., Pavlovic, V.: Punda: Probabilistic unsupervised In: ICCV.  domain adaptation for knowledge transfer across visual categories. (2017)  7. Maria Carlucci, F., Porzi, L., Caputo, B., Ricci, E., Rota Bulo, S.: Autodial:  Automatic domain alignment layers. In: ICCV. (2017)  8. Yan, H., Ding, Y., Li, P., Wang, Q., Xu, Y., Zuo, W.: Mind the class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation. In: CVPR. (2017)  9. Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D.: Unsupervised pixel-level domain adaptation with generative adversarial networks. CVPR (2017) 10. Herath, S., Harandi, M., Porikli, F.: Learning an invariant hilbert space for domain  adaptation. In: CVPR. (2017)  11. Koniusz, P., Tas, Y., Porikli, F.: Domain adaptation by mixture of alignments of  second- or higher-order scatter tensors. In: CVPR. (2017)  12. Sankaranarayanan, S., Balaji, Y., Castillo, C.D., Chellappa, R.: Generate to adapt:  Aligning domains using generative adversarial networks. CVPR (2018)  13. Patel, V.M., Gopalan, R., Li, R., Chellappa, R.: Visual domain adaptation: A  survey of recent advances. IEEE Signal Process. Mag. (2015)  14. Csurka, G.: Domain adaptation for visual applications: A comprehensive survey.  arXiv preprint arXiv:1702.05374 (2017)  15. Saenko, K., Kulis, B., Fritz, M., Darrell, T.: Adapting visual category models to  new domains. In: ECCV. (2010)  16. Tzeng, E., Ho\ufb00man, J., Zhang, N., Saenko, K., Darrell, T.: Deep domain confusion:  Maximizing for domain invariance. CoRR (2014)  17. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic  segmentation. In: CVPR, IEEE Computer Society (2015)  18. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,  Courville, A., Bengio, Y.: Generative adversarial nets. In: NIPS. (2014)  19. Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V.: Domain-adversarial training of neural networks. JMLR (2016)  20. Tzeng, E., Ho\ufb00man, J., Darrell, T., Saenko, K.: Simultaneous deep transfer across  domains and tasks. ICCV (2015)  21. Liu, M.Y., Tuzel, O.: Coupled generative adversarial networks. In: NIPS. (2016) 22. Ghifary, M., Kleijn, W.B., Zhang, M., Balduzzi, D., Li, W.: Deep reconstruction- classification networks for unsupervised domain adaptation. In: ECCV. (2016) 23. Isola, P., Zhu, J., Zhou, T., Efros, A.A.: Image-to-image translation with condi-  tional adversarial networks. CVPR (2017)   16  Haoshuo Huang, Qixing Huang and Philipp Kr\u00a8ahenb\u00a8uhl  24. Sangkloy, P., Lu, J., Fang, C., Yu, F., Hays, J.: Scribbler: Controlling deep image  synthesis with sketch and color. CVPR (2017)  25. Karacan, L., Akata, Z., Erdem, A., Erdem, E.: Learning to generate images of  outdoor scenes from attributes and semantic layouts. CoRR (2016)  26. Yoo, D., Kim, N., Park, S., Paek, A.S., Kweon, I.S.: Pixel-level domain transfer.  In: ECCV. (2016)  ICLR (2017)  27. Taigman, Y., Polyak, A., Wolf, L.: Unsupervised cross-domain image generation.  28. Shrivastava, A., Pfister, T., Tuzel, O., Susskind, J., Wang, W., Webb, R.: Learning from simulated and unsupervised images through adversarial training. CVPR (2017)  29. Zhu, J.Y., Park, T., Isola, P., Efros, A.A.: Unpaired image-to-image translation  using cycle-consistent adversarial networks. ICCV (2017)  30. Yi, Z., Zhang, H., Tan, P., Gong, M.: Dualgan: Unsupervised dual learning for  image-to-image translation. ICCV (2017)  31. Ho\ufb00man, J., Tzeng, E., Park, T., Zhu, J., Isola, P., Saenko, K., Efros, A.A., Darrell,  T.: Cycada: Cycle-consistent adversarial domain adaptation. ICML (2018)  32. Levinkov, E., Fritz, M.: Sequential bayesian model update under structured scene  prior for semantic road scenes labeling. In: ICCV. (2013)  33. Ho\ufb00man, J., Wang, D., Yu, F., Darrell, T.: Fcns in the wild: Pixel-level adversarial  and constraint-based adaptation. CoRR abs/1612.02649 (2016)  34. Ros, G., Stent, S., Alcantarilla, P.F., Watanabe, T.: Training constrained deconvo- lutional networks for road scene semantic segmentation. CoRR abs/1604.01545 (2016)  35. Chen, Y.H., Chen, W.Y., Chen, Y.T., Tsai, B.C., Frank Wang, Y.C., Sun, M.: No more discrimination: Cross city adaptation of road scene segmenters. In: ICCV. (2017)  36. Glorot, X., Bengio, Y.: Understanding the di\ufb03culty of training deep feedforward  neural networks. In: AIStats. (2010)  37. Li, Y., Wang, N., Shi, J., Liu, J., Hou, X.: Revisiting batch normalization for  practical domain adaptation. ICLR (2017)  38. Mao, X., Li, Q., Xie, H., Lau, R.Y.K., Wang, Z.: Multi-class generative adversarial  networks with the L2 loss function. CoRR (2016)  39. LeCun, Y., Bottou, L., Bengio, Y., Ha\ufb00ner, P.: Gradient-based learning applied to  document recognition. Proceedings of the IEEE (1998)  40. Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y.: Reading digits In: NIPS Deep Learning  in natural images with unsupervised feature learning. Workshop. (2011)  41. Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Roth, S., Schiele, B.: The cityscapes dataset for semantic urban scene understanding. In: CVPR. (2016)  42. Paszke, A., Chaurasia, A., Kim, S., Culurciello, E.: Enet: A deep neural network  architecture for real-time semantic segmentation. CoRR (2016)  43. Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A.: The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes. In: CVPR. (2016)  44. Long, M., Wang, J., Jordan, M.I.: Deep transfer learning with joint adaptation  networks. ICML (2016)  45. Yu, F., Koltun, V., Funkhouser, T.: Dilated residual networks. In: CVPR. (2017)"}