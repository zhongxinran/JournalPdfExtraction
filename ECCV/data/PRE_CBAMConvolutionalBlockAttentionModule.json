{"1": "1. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database. In: Proc. of Computer Vision and Pattern Recognition (CVPR). (2009) 1, 7  2. Krizhevsky, A., Hinton, G.: Learning multiple layers of features from tiny images  1  3. Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\u00e1r, P., Zitnick, C.L.: Microsoft coco: Common objects in context. In: Proc. of European Conf. on Computer Vision (ECCV). (2014) 1, 13  4. LeCun, Y., Bottou, L., Bengio, Y., Ha\ufb00ner, P.: Gradient-based learning applied to  document recognition. Proceedings of the IEEE 86(11) (1998) 2278-2324 1  5. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proc. of Computer Vision and Pattern Recognition (CVPR). (2016) 1, 3, 6, 7, 9, 10, 13, 14  6. Zagoruyko, S., Komodakis, N.: Wide residual networks.  arXiv preprint  arXiv:1605.07146 (2016) 1, 3, 6, 9, 10  7. Xie, S., Girshick, R., Doll\u00e1r, P., Tu, Z., He, K.: Aggregated residual transformations for deep neural networks. arXiv preprint arXiv:1611.05431 (2016) 1, 2, 3, 6, 9, 10 8. Szegedy, C., Io\ufb00e, S., Vanhoucke, V., Alemi, A.A.: Inception-v4, inception-resnet and the impact of residual connections on learning. In: Proc. of Association for the Advancement of Artificial Intelligence (AAAI). (2017) 1, 3  9. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014) 1, 3, 14  10. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., In: Proc. of  Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. Computer Vision and Pattern Recognition (CVPR). (2015) 1, 3  11. Chollet, F.: Xception: Deep learning with depthwise separable convolutions. arXiv  preprint arXiv:1610.02357 (2016) 2, 3  12. Mnih, V., Heess, N., Graves, A., et al.: Recurrent models of visual attention.\" advances in neural information processing systems. In: Proc. of Neural Information Processing Systems (NIPS). (2014) 2  13. Ba, J., Mnih, V., Kavukcuoglu, K.: Multiple object recognition with visual atten-  14. Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly learning  tion. (2014) 2  to align and translate. (2014) 2  15. Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., Bengio, Y.: Show, attend and tell: Neural image caption generation with visual attention. (2015) 2  16. Gregor, K., Danihelka, I., Graves, A., Rezende, D.J., Wierstra, D.: Draw: A recur-  rent neural network for image generation. (2015) 2  17. Jaderberg, M., Simonyan, K., Zisserman, A., et al.: Spatial transformer networks.  In: Proc. of Neural Information Processing Systems (NIPS). (2015) 2  18. Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.: Grad- cam: Visual explanations from deep networks via gradient-based localization. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2017) 618-626 2, 10, 12  19. Krizhevsky, A., Sutskever, I., Hinton, G.E.:  Imagenet classification with deep convolutional neural networks. In: Proc. of Neural Information Processing Systems (NIPS). (2012) 3   Convolutional Block Attention ModuleReferences  1. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database. In: Proc. of Computer Vision and Pattern Recognition (CVPR). (2009) 1, 7  2. Krizhevsky, A., Hinton, G.: Learning multiple layers of features from tiny images3. Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\u00e1r, P., Zitnick, C.L.: Microsoft coco: Common objects in context. In: Proc. of European Conf. on Computer Vision (ECCV). (2014) 1, 13  4. LeCun, Y., Bottou, L., Bengio, Y., Ha\ufb00ner, P.: Gradient-based learning applied to  document recognition. Proceedings of the IEEE 86(11) (1998) 2278-2324 1  5. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proc. of Computer Vision and Pattern Recognition (CVPR). (2016) 1, 3, 6, 7, 9, 10, 13, 14  6. Zagoruyko, S., Komodakis, N.: Wide residual networks.  arXiv preprint  arXiv:1605.07146 (2016) 1, 3, 6, 9, 10  7. Xie, S., Girshick, R., Doll\u00e1r, P., Tu, Z., He, K.: Aggregated residual transformations for deep neural networks. arXiv preprint arXiv:1611.05431 (2016) 1, 2, 3, 6, 9, 10 8. Szegedy, C., Io\ufb00e, S., Vanhoucke, V., Alemi, A.A.: Inception-v4, inception-resnet and the impact of residual connections on learning. In: Proc. of Association for the Advancement of Artificial Intelligence (AAAI). (2017) 1, 3  9. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014) 1, 3, 14  10. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., In: Proc. of  Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. Computer Vision and Pattern Recognition (CVPR). (2015) 1, 3  11. Chollet, F.: Xception: Deep learning with depthwise separable convolutions. arXiv  preprint arXiv:1610.02357 (2016) 2, 3  12. Mnih, V., Heess, N., Graves, A., et al.: Recurrent models of visual attention.\" advances in neural information processing systems. In: Proc. of Neural Information Processing Systems (NIPS). (2014) 2  13. Ba, J., Mnih, V., Kavukcuoglu, K.: Multiple object recognition with visual atten-  14. Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly learning  tion. (2014) 2  to align and translate. (2014) 2  15. Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., Bengio, Y.: Show, attend and tell: Neural image caption generation with visual attention. (2015) 2  16. Gregor, K., Danihelka, I., Graves, A., Rezende, D.J., Wierstra, D.: Draw: A recur-  rent neural network for image generation. (2015) 2  17. Jaderberg, M., Simonyan, K., Zisserman, A., et al.: Spatial transformer networks.  In: Proc. of Neural Information Processing Systems (NIPS). (2015) 2  18. Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.: Grad- cam: Visual explanations from deep networks via gradient-based localization. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2017) 618-626 2, 10, 12  19. Krizhevsky, A., Sutskever, I., Hinton, G.E.:  Imagenet classification with deep convolutional neural networks. In: Proc. of Neural Information Processing Systems (NIPS). (2012) 3   16  Woo, Park, Lee, Kweon  20. Han, D., Kim, J., Kim, J.: Deep pyramidal residual networks. In: Proc. of Computer  Vision and Pattern Recognition (CVPR). (2017) 3  21. Huang, G., Liu, Z., Weinberger, K.Q., van der Maaten, L.: Densely connected  convolutional networks. arXiv preprint arXiv:1608.06993 (2016) 3  22. Szegedy, C., Vanhoucke, V., Io\ufb00e, S., Shlens, J., Wojna, Z.: Rethinking the incep- tion architecture for computer vision. In: Proc. of Computer Vision and Pattern Recognition (CVPR). (2016) 3  23. Itti, L., Koch, C., Niebur, E.: A model of saliency-based visual attention for rapid scene analysis. In: IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI). (1998) 3 24. Rensink, R.A.: The dynamic representation of scenes. In: Visual cognition 7.1-3.  (2000) 3  25. Corbetta, M., Shulman, G.L.: Control of goal-directed and stimulus-driven atten-  tion in the brain. In: Nature reviews neuroscience 3.3. (2002) 3  26. Larochelle, H., Hinton, G.E.: Learning to combine foveal glimpses with a third- In: Proc. of Neural Information Processing Systems  order boltzmann machine. (NIPS). (2010) 3  27. Wang, F., Jiang, M., Qian, C., Yang, S., Li, C., Zhang, H., Wang, X., Tang, X.: Residual attention network for image classification. arXiv preprint arXiv:1704.06904 (2017) 3, 4  28. Hu, J., Shen, L., Sun, G.: Squeeze-and-excitation networks.  arXiv preprint  arXiv:1709.01507 (2017) 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14  29. Chen, L., Zhang, H., Xiao, J., Nie, L., Shao, J., Chua, T.S.: Sca-cnn: Spatial and channel-wise attention in convolutional networks for image captioning. In: Proc. of Computer Vision and Pattern Recognition (CVPR). (2017) 4  30. Sanghyun, W., Soonmin, H., So, K.I.: Stairnet: Top-down semantic aggregation for accurate one shot detection. In: Proc. of Winter Conference on Applications of Computer Vision (WACV). (2018) 4, 13, 14  31. Park, J., Woo, S., Lee, J.Y., Kweon, I.S.: Bam: Bottleneck attention module. In:  Proc. of British Machine Vision Conference (BMVC). (2018) 4  32. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks.  In: Proc. of European Conf. on Computer Vision (ECCV). (2014) 4  33. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.: Learning deep fea- tures for discriminative localization. In: Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on, IEEE (2016) 2921-2929 5  34. Zagoruyko, S., Komodakis, N.: Paying more attention to attention: Improving the In: ICLR.  performance of convolutional neural networks via attention transfer. (2017) 6  35. Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., An- dreetto, M., Adam, H.: Mobilenets: E\ufb03cient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861 (2017) 6, 10, 11, 13, 14  36. : Pytorch. http://pytorch.org/ Accessed: 2017-11-08. 6 37. He, K., Zhang, X., Ren, S., Sun, J.: Identity mappings in deep residual networks.  In: Proc. of European Conf. on Computer Vision (ECCV). (2016) 7  38. Huang, G., Sun, Y., Liu, Z., Sedra, D., Weinberger, K.Q.: Deep networks with stochastic depth. In: Proc. of European Conf. on Computer Vision (ECCV). (2016) 7  39. Bell, S., Lawrence Zitnick, C., Bala, K., Girshick, R.: Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks. In: Proc. of Computer Vision and Pattern Recognition (CVPR). (2016) 13   Convolutional Block Attention Module40. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y., Berg, A.C.: Ssd: Single shot multibox detector. In: Proc. of European Conf. on Computer Vision (ECCV). (2016) 13, 14  41. Chen, X., Gupta, A.: An implementation of faster rcnn with study for region  sampling. arXiv preprint arXiv:1702.02138 (2017) 13  42. Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object de- tection with region proposal networks. In: Proc. of Neural Information Processing Systems (NIPS). (2015) 13, 14"}