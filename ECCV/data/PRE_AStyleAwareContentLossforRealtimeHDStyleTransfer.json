{"1": "1. Bautista, M.A., Sanakoyeu, A., Tikhoncheva, E., Ommer, B.: Cliquecnn: Deep unsupervised exemplar learning. In: Advances in Neural Information Processing Systems. pp. 3846-3854 (2016)  2. Che, T., Li, Y., Jacob, A.P., Bengio, Y., Li, W.: Mode regularized generative  adversarial networks. arXiv preprint arXiv:1612.02136 (2016)  3. Chen, D., Yuan, L., Liao, J., Yu, N., Hua, G.: Stylebank: An explicit representation  for neural image style transfer. In: Proc. CVPR (2017)  4. Chen, T.Q., Schmidt, M.: Fast patch-based style transfer of arbitrary style. arXiv  preprint arXiv:1612.04337 (2016)  5. Collomosse, J., Bui, T., Wilber, M.J., Fang, C., Jin, H.: Sketching with style: Visual search with sketches and aesthetic context. In: The IEEE International Conference on Computer Vision (ICCV) (Oct 2017)  6. Dumoulin, V., Shlens, J., Kudlur, M.: A learned representation for artistic style.  Proc. of ICLR (2017) 7. Engstrom, L.: Fast  transfer/ (2016), commit 55809f4e  style  transfer. https://github.com/lengstrom/fast-style-  8. Esser, P., Sutter, E., Ommer, B.: A variational u-net for conditional appearance and shape generation. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (July 2018)  9. Fernie, E.: Art History and its Methods: A critical anthology. Phaidon, London  (1995), p. 361  10. Frigo, O., Sabater, N., Delon, J., Hellier, P.: Split and match: Example-based adap- tive patch sampling for unsupervised style transfer. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 553-561 (2016) 11. Gatys, L.A., Ecker, A.S., Bethge, M.: Texture synthesis and the controlled gen- eration of natural stimuli using convolutional neural networks. arXiv preprint arXiv:1505.07376 12 (2015)  12. Gatys, L.A., Ecker, A.S., Bethge, M.: Image style transfer using convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on. pp. 2414-2423. IEEE (2016)  13. Gatys, L.A., Ecker, A.S., Bethge, M., Hertzmann, A., Shechtman, E.: Control- ling perceptual factors in neural style transfer. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)  14. Ghiasi, G., Lee, H., Kudlur, M., Dumoulin, V., Shlens, J.: Exploring the struc- ture of a real-time, arbitrary neural artistic stylization network. arXiv preprint arXiv:1705.06830 (2017)  15. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In: Advances in neural information processing systems. pp. 2672-2680 (2014)  16. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016)  17. Hertzmann, A., Jacobs, C.E., Oliver, N., Curless, B., Salesin, D.H.: Image analo- gies. In: Proceedings of the 28th annual conference on Computer graphics and interactive techniques. pp. 327-340. ACM (2001)  18. Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S.: Gans trained by a two time-scale update rule converge to a local nash equilibrium. In: Advances in Neural Information Processing Systems. pp. 6629-6640 (2017)   A Style-Aware Content Loss for Real-time HD Style TransferReferences  1. Bautista, M.A., Sanakoyeu, A., Tikhoncheva, E., Ommer, B.: Cliquecnn: Deep unsupervised exemplar learning. In: Advances in Neural Information Processing Systems. pp. 3846-3854 (2016)  2. Che, T., Li, Y., Jacob, A.P., Bengio, Y., Li, W.: Mode regularized generative  adversarial networks. arXiv preprint arXiv:1612.02136 (2016)  3. Chen, D., Yuan, L., Liao, J., Yu, N., Hua, G.: Stylebank: An explicit representation  for neural image style transfer. In: Proc. CVPR (2017)  4. Chen, T.Q., Schmidt, M.: Fast patch-based style transfer of arbitrary style. arXiv  preprint arXiv:1612.04337 (2016)  5. Collomosse, J., Bui, T., Wilber, M.J., Fang, C., Jin, H.: Sketching with style: Visual search with sketches and aesthetic context. In: The IEEE International Conference on Computer Vision (ICCV) (Oct 2017)  6. Dumoulin, V., Shlens, J., Kudlur, M.: A learned representation for artistic style.  Proc. of ICLR (2017) 7. Engstrom, L.: Fast  transfer/ (2016), commit 55809f4e  style  transfer. https://github.com/lengstrom/fast-style-  8. Esser, P., Sutter, E., Ommer, B.: A variational u-net for conditional appearance and shape generation. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (July 2018)  9. Fernie, E.: Art History and its Methods: A critical anthology. Phaidon, London  (1995), p. 361  10. Frigo, O., Sabater, N., Delon, J., Hellier, P.: Split and match: Example-based adap- tive patch sampling for unsupervised style transfer. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 553-561 (2016) 11. Gatys, L.A., Ecker, A.S., Bethge, M.: Texture synthesis and the controlled gen- eration of natural stimuli using convolutional neural networks. arXiv preprint arXiv:1505.07376 12 (2015)  12. Gatys, L.A., Ecker, A.S., Bethge, M.: Image style transfer using convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on. pp. 2414-2423. IEEE (2016)  13. Gatys, L.A., Ecker, A.S., Bethge, M., Hertzmann, A., Shechtman, E.: Control- ling perceptual factors in neural style transfer. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)  14. Ghiasi, G., Lee, H., Kudlur, M., Dumoulin, V., Shlens, J.: Exploring the struc- ture of a real-time, arbitrary neural artistic stylization network. arXiv preprint arXiv:1705.06830 (2017)  15. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In: Advances in neural information processing systems. pp. 2672-2680 (2014)  16. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016)  17. Hertzmann, A., Jacobs, C.E., Oliver, N., Curless, B., Salesin, D.H.: Image analo- gies. In: Proceedings of the 28th annual conference on Computer graphics and interactive techniques. pp. 327-340. ACM (2001)  18. Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S.: Gans trained by a two time-scale update rule converge to a local nash equilibrium. In: Advances in Neural Information Processing Systems. pp. 6629-6640 (2017)   16  A. Sanakoyeu, D. Kotovenko, S. Lang, and B. Ommer  19. Hinton, sionality 504-507 http://science.sciencemag.org/content/313/5786/504  Salakhutdinov, with  G.E., of  (2006).  Reducing  dimen- 313(5786), https://doi.org/10.1126/science.1127647,  networks.  Science  neural  R.R.:  data  the  20. Huang, X., Belongie, S.: Arbitrary style transfer in real-time with adaptive instance  normalization. In: ICCV (2017)  21. Jing, Y., Liu, Y., Yang, Y., Feng, Z., Yu, Y., Song, M.: Stroke controllable fast style transfer with adaptive receptive fields. arXiv preprint arXiv:1802.07101 (2018) 22. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and super-resolution. In: European Conference on Computer Vision. pp. 694-711. Springer (2016)  23. Karayev, S., Trentacoste, M., Han, H., Agarwala, A., Darrell, T., Hertzmann, A., Winnemoeller, H.: Recognizing image style. arXiv preprint arXiv:1311.3715 (2013) 24. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint  arXiv:1412.6980 (2014)  25. Li, C., Wand, M.: Precomputed real-time texture synthesis with markovian gen- erative adversarial networks. In: European Conference on Computer Vision. pp. 702-716. Springer (2016)  26. Li, Y., Fang, C., Yang, J., Wang, Z., Lu, X., Yang, M.H.: Diversified texture syn- thesis with feed-forward networks. In: IEEE Conference on Computer Vision and Pattern Recognition (2017)  27. Li, Y., Fang, C., Yang, J., Wang, Z., Lu, X., Yang, M.H.: Universal style transfer via feature transforms. In: Advances in Neural Information Processing Systems. pp. 385-395 (2017)  28. Liao, J., Yao, Y., Yuan, L., Hua, G., Kang, S.B.: Visual attribute transfer through  deep image analogy. arXiv preprint arXiv:1705.01088 (2017)  29. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 3431-3440 (2015)  30. Luan, F., Paris, S., Shechtman, E., Bala, K.: Deep photo style transfer. In: IEEE  Conference on Computer Vision and Pattern Recognition (CVPR) (2017)  31. Mahendran, A., Vedaldi, A.: Understanding deep image representations by invert- ing them. In: Proceedings of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) (2015)  32. Mao, H., Cheung, M., She, J.: Deepart: Learning joint representations of visual arts. In: Proceedings of the 2017 ACM on Multimedia Conference. pp. 1183-1191. ACM (2017)  33. Odena, A., Dumoulin, V., Olah, C.: Deconvolution and checkerboard artifacts. Dis- till (2016). https://doi.org/10.23915/distill.00003, http://distill.pub/2016/deconv- checkerboard  34. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115(3), 211-252 (2015). https://doi.org/10.1007/s11263-015-0816-y 35. Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X.: Im- proved techniques for training gans. In: Advances in Neural Information Processing Systems. pp. 2234-2242 (2016)  36. Shen, F., Yan, S., Zeng, G.: Meta networks for neural style transfer. arXiv preprint  arXiv:1709.04111 (2017)  37. Shih, Y., Paris, S., Barnes, C., Freeman, W.T., Durand, F.: Style transfer for headshot portraits. ACM Transactions on Graphics (TOG) 33(4), 148 (2014)   A Style-Aware Content Loss for Real-time HD Style Transfer38. Shih, Y., Paris, S., Durand, F., Freeman, W.T.: Data-driven hallucination of dif- ferent times of day from a single outdoor photo. ACM Transactions on Graphics (TOG) 32(6), 200 (2013)  39. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014)  40. Ulyanov, D., Lebedev, V., Vedaldi, A., Lempitsky, V.S.: Texture networks: Feed- forward synthesis of textures and stylized images. In: ICML. pp. 1349-1357 (2016) 41. Ulyanov, D., Vedaldi, A., Lempitsky, V.: Improved texture networks: Maximizing quality and diversity in feed-forward stylization and texture synthesis. In: Proc. CVPR (2017)  42. Wang, H., Liang, X., Zhang, H., Yeung, D.Y., Xing, E.P.: Zm-net: Real-time zero-  shot image manipulation network. arXiv preprint arXiv:1703.07255 (2017)  43. Wang, X., Gupta, A.: Unsupervised learning of visual representations using videos.  arXiv preprint arXiv:1505.00687 (2015)  44. Wang, X., Oxholm, G., Zhang, D., Wang, Y.F.: Multimodal transfer: A hierarchical deep convolutional neural network for fast artistic style transfer. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (July 2017) 45. Wilber, M.J., Fang, C., Jin, H., Hertzmann, A., Collomosse, J., Belongie, S.: Bam! the behance artistic media dataset for recognition beyond photography. In: The IEEE International Conference on Computer Vision (ICCV) (Oct 2017)  46. Wilmot, P., Risser, E., Barnes, C.: Stable and controllable neural texture synthesis and style transfer using histogram losses. arXiv preprint arXiv:1701.08893 (2017) 47. Zhou, B., Lapedriza, A., Xiao, J., Torralba, A., Oliva, A.: Learning deep features for scene recognition using places database. In: Advances in neural information processing systems. pp. 487-495 (2014)  48. Zhu, J.Y., Park, T., Isola, P., Efros, A.A.: Unpaired image-to-image translation using cycle-consistent adversarial networks. In: IEEE International Conference on Computer Vision (2017)"}