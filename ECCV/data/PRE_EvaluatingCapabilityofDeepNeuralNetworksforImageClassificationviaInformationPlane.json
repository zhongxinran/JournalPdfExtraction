{"1": "1. Alex Graves, Abdel-rahman Mohamed, and Geo\ufb00rey Hinton. Speech recognition with deep recurrent neural networks. In Acoustics, Speech and Signal Processing (icassp), 2013 IEEE International Conference on, pages 6645-6649. IEEE, 2013. 2. Alex Krizhevsky, Ilya Sutskever, and Geo\ufb00rey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Pro- cessing Systems, pages 1097-1105, 2012.  3. William Lotter, Gabriel Kreiman, and David Cox. Deep predictive coding networks for video prediction and unsupervised learning. arXiv preprint arXiv:1605.08104, 2016.  4. David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershel- vam, Marc Lanctot, et al. Mastering the game of go with deep neural networks and tree search. Nature, 529(7587):484-489, 2016.  5. Xiang Zhang and Yann LeCun. Text understanding from scratch. arXiv preprint  arXiv:1502.01710, 2015.  6. Naftali Tishby and Noga Zaslavsky. Deep learning and the information bottleneck principle. In Information Theory Workshop (ITW), 2015 IEEE, pages 1-5. IEEE, 2015.  7. Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural  networks via information. arXiv preprint arXiv:1703.00810, 2017.  8. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for  large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.  9. Naftali Tishby, Fernando C Pereira, and William Bialek. The information bottle-  neck method. arXiv preprint physics/0004057, 2000.  10. Gal Chechik, Amir Globerson, Naftali Tishby, and Yair Weiss. Information bot- tleneck for gaussian variables. Journal of Machine Learning Research, 6(Jan):165- 188, 2005.  11. DJ Strouse and David J Schwab. The deterministic information bottleneck. Neural  computation, 29(6):1611-1630, 2017.  12. Ohad Shamir, Sivan Sabato, and Naftali Tishby. Learning and generalization with the information bottleneck. Theoretical Computer Science, 411(29-30):2696-2711, 2010.  13. Susanne Still, William Bialek, and L\u00b4eon Bottou. Geometric clustering using the In Advances in Neural Information Processing  information bottleneck method. systems, pages 1165-1172, 2004.  14. Alexander A Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy. Deep vari-  ational information bottleneck. arXiv preprint arXiv:1612.00410, 2016.  15. Artemy Kolchinsky, Brendan D Tracey, and David H Wolpert. Nonlinear informa-  tion bottleneck. arXiv preprint arXiv:1705.02436, 2017.  16. Jaesik Choi Thann T. Nguyen. Layer-wise learning of stochastic neural networks  with information bottleneck. arXiv preprint arXiv:1712.01272, 2018.  17. Alessandro Achille and Stefano Soatto.  Information dropout: Learning optimal representations through noisy computation. IEEE Transactions on Pattern Anal- ysis and Machine Intelligence, 2018.  18. Maxim Raginsky, Alexander Rakhlin, Matthew Tsao, Yihong Wu, and Aolin Xu. Information-theoretic analysis of stability and bias of learning algorithms. In In- formation Theory Workshop (ITW), 2016 IEEE, pages 26-30. IEEE, 2016.  19. Christopher M Bishop. Pattern Recognition and Machine Learning. springer, 2006.   Using IB to evaluate capability of DNNsReferences  1. Alex Graves, Abdel-rahman Mohamed, and Geo\ufb00rey Hinton. Speech recognition with deep recurrent neural networks. In Acoustics, Speech and Signal Processing (icassp), 2013 IEEE International Conference on, pages 6645-6649. IEEE, 2013. 2. Alex Krizhevsky, Ilya Sutskever, and Geo\ufb00rey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Pro- cessing Systems, pages 1097-1105, 2012.  3. William Lotter, Gabriel Kreiman, and David Cox. Deep predictive coding networks for video prediction and unsupervised learning. arXiv preprint arXiv:1605.08104, 2016.  4. David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershel- vam, Marc Lanctot, et al. Mastering the game of go with deep neural networks and tree search. Nature, 529(7587):484-489, 2016.  5. Xiang Zhang and Yann LeCun. Text understanding from scratch. arXiv preprint  arXiv:1502.01710, 2015.  6. Naftali Tishby and Noga Zaslavsky. Deep learning and the information bottleneck principle. In Information Theory Workshop (ITW), 2015 IEEE, pages 1-5. IEEE, 2015.  7. Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural  networks via information. arXiv preprint arXiv:1703.00810, 2017.  8. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for  large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.  9. Naftali Tishby, Fernando C Pereira, and William Bialek. The information bottle-  neck method. arXiv preprint physics/0004057, 2000.  10. Gal Chechik, Amir Globerson, Naftali Tishby, and Yair Weiss. Information bot- tleneck for gaussian variables. Journal of Machine Learning Research, 6(Jan):165- 188, 2005.  11. DJ Strouse and David J Schwab. The deterministic information bottleneck. Neural  computation, 29(6):1611-1630, 2017.  12. Ohad Shamir, Sivan Sabato, and Naftali Tishby. Learning and generalization with the information bottleneck. Theoretical Computer Science, 411(29-30):2696-2711, 2010.  13. Susanne Still, William Bialek, and L\u00b4eon Bottou. Geometric clustering using the In Advances in Neural Information Processing  information bottleneck method. systems, pages 1165-1172, 2004.  14. Alexander A Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy. Deep vari-  ational information bottleneck. arXiv preprint arXiv:1612.00410, 2016.  15. Artemy Kolchinsky, Brendan D Tracey, and David H Wolpert. Nonlinear informa-  tion bottleneck. arXiv preprint arXiv:1705.02436, 2017.  16. Jaesik Choi Thann T. Nguyen. Layer-wise learning of stochastic neural networks  with information bottleneck. arXiv preprint arXiv:1712.01272, 2018.  17. Alessandro Achille and Stefano Soatto.  Information dropout: Learning optimal representations through noisy computation. IEEE Transactions on Pattern Anal- ysis and Machine Intelligence, 2018.  18. Maxim Raginsky, Alexander Rakhlin, Matthew Tsao, Yihong Wu, and Aolin Xu. Information-theoretic analysis of stability and bias of learning algorithms. In In- formation Theory Workshop (ITW), 2016 IEEE, pages 26-30. IEEE, 2016.  19. Christopher M Bishop. Pattern Recognition and Machine Learning. springer, 2006."}