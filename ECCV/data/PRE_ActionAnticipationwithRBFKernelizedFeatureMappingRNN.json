{"1": "1. Bengio, Y., Ducharme, R., Vincent, P., Jauvin, C.: A neural probabilistic language model.  Journal of machine learning research 3(Feb), 1137-1155 (2003) 4  2. Dix, A.: Human-computer interaction. In: Encyclopedia of database systems, pp. 1327-1331.  Springer (2009) 1  3. Duan, L.Y., Xu, M., Chua, T.S., Tian, Q., Xu, C.S.: A mid-level representation framework for semantic sports video analysis. In: 2003 ACM International Conference on Multimedia. pp. 33-44. ACM (2003) 1  4. Ekin, A., Tekalp, A.M., Mehrotra, R.: Automatic soccer video analysis and summarization.  IEEE Transactions on Image processing 12(7), 796-807 (2003) 1  5. Enzweiler, M., Gavrila, D.M.: Integrated pedestrian classification and orientation estimation. In: 2010 IEEE Conference on Computer Vision and Pattern Recognition. pp. 982-989 (2010) 1  6. Fan, Z., Lin, T., Zhao, X., Jiang, W., Xu, T., Yang, M.: An online approach for gesture recognition toward real-world applications. In: Zhao, Y., Kong, X., Taubman, D. (eds.) Image and Graphics. pp. 262-272. Springer International Publishing, Cham (2017) 10  7. Felsen, P., Agrawal, P., Malik, J.: What will happen next? forecasting player moves in sports  videos. In: 2017 IEEE International Conference on Computer Vision (2017) 4  8. Fouhey, D.F., Zitnick, C.L.: Predicting object dynamics in scenes. In: 2014 IEEE Conference on Computer Vision and Pattern Recognition. pp. 2027-2034 (2014). https://doi.org/10.1109/CVPR.2014.260 4   14  Y. Shi et al.  5 Conclusions  The proposed RNN which uses a very few parameters outperforms state-of-the-art al- gorithms on action anticipation task. Our extensive experiments indicates the model\u2019s ability to produce accurate prediction of future features only observing a fraction of the features. Furthermore, our RNN model is fast and consumes fraction of the mem- ory which makes it suitable for real-time execution on mobile devices. Proposed fea- ture mapping RNN can be trained with and without lables to generate future features. Our feature generator does not use class level annotations of video data. Therefore, in principle, we can increase the robustness of the model utilizing large amount of available unlabelled data. The fact that the model is able to generate valid results us- ing very few parameters provides strong proofs for the existence of inner-correlation between deep features, which is a characteristic that can have implications on many related problems such as video tracking, image translation, and metric learning.  In addition, by appending a RBF layer to the RNN, we observe significant improve- ment in prediction accuracy. However, it was also noted that over-fitting occurs when the model is implemented with too many kernel RBFs. To fully explore functional ca- pacity of RBF function, in future studies, we aim to implement kernel RBFs on fully connected layer of popular deep CNN models such as ResNet [13], AlexNet [24] and DenseNet [15].  In conclusion, proposed RBF kernalized feature mapping RNN demonstrates the power of parameter sharing and RBF functions in a challenging sequence learning task of video action anticipation.  References  1. Bengio, Y., Ducharme, R., Vincent, P., Jauvin, C.: A neural probabilistic language model.  Journal of machine learning research 3(Feb), 1137-1155 (2003) 4  2. Dix, A.: Human-computer interaction. In: Encyclopedia of database systems, pp. 1327-1331.  Springer (2009) 1  3. Duan, L.Y., Xu, M., Chua, T.S., Tian, Q., Xu, C.S.: A mid-level representation framework for semantic sports video analysis. In: 2003 ACM International Conference on Multimedia. pp. 33-44. ACM (2003) 1  4. Ekin, A., Tekalp, A.M., Mehrotra, R.: Automatic soccer video analysis and summarization.  IEEE Transactions on Image processing 12(7), 796-807 (2003) 1  5. Enzweiler, M., Gavrila, D.M.: Integrated pedestrian classification and orientation estimation. In: 2010 IEEE Conference on Computer Vision and Pattern Recognition. pp. 982-989 (2010) 1  6. Fan, Z., Lin, T., Zhao, X., Jiang, W., Xu, T., Yang, M.: An online approach for gesture recognition toward real-world applications. In: Zhao, Y., Kong, X., Taubman, D. (eds.) Image and Graphics. pp. 262-272. Springer International Publishing, Cham (2017) 10  7. Felsen, P., Agrawal, P., Malik, J.: What will happen next? forecasting player moves in sports  videos. In: 2017 IEEE International Conference on Computer Vision (2017) 4  8. Fouhey, D.F., Zitnick, C.L.: Predicting object dynamics in scenes. In: 2014 IEEE Conference on Computer Vision and Pattern Recognition. pp. 2027-2034 (2014). https://doi.org/10.1109/CVPR.2014.260 4   Feature Mapping RNN9. Gandhi, T., Trivedi, M.M.: Image based estimation of pedestrian orientation for improving path prediction. In: 2008 IEEE Intelligent Vehicles Symposium. pp. 506-511 (2008) 1 10. Gao, J., Yang, Z., Nevatia, R.: Red: Reinforced encoder-decoder networks for action antici-  pation. arXiv preprint arXiv:1707.04818 (2017) 3  11. Gong, H., Sim, J., Likhachev, M., Shi, J.: Multi-hypothesis motion planning for visual object tracking. In: 2011 IEEE International Conference on Computer Vision. pp. 619-626 (Nov 2011). https://doi.org/10.1109/ICCV.2011.6126296 4  12. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In: Advances in neural information processing systems. pp. 2672-2680 (2014) 3, 7  13. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: 2016 IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016) 4, 14 14. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation 9(8), 1735-  1780 (1997) 4  15. Huang, G., Liu, Z., van der Maaten, L., Weinberger, K.Q.: Densely connected convolutional networks. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (2017) 14  16. Jain, A., Singh, A., Koppula, H.S., Soh, S., Saxena, A.: Recurrent neural networks for driver activity anticipation via sensory-fusion architecture. In: 2016 IEEE International Conference on Robotics and Automation. pp. 3118-3125 (2016) 3, 10  17. Jhuang, H., Gall, J., Zuffi, S., Schmid, C., Black, M.J.: Towards understanding action recog- nition. In: 2013 IEEE International Conference on Computer Vision. pp. 3192-3199 (Dec 2013) 8  18. Keller, C.G., Gavrila, D.M.: Will the pedestrian cross? a study on pedestrian path prediction. 2014 IEEE Transactions on Intelligent Transportation Systems 15(2), 494-506 (2014) 1 19. Kitani, K.M., Ziebart, B.D., Bagnell, J.A., Hebert, M.: Activity Forecasting, pp. 201-214.  Springer Berlin Heidelberg, Berlin, Heidelberg (2012) 4  20. Kong, Y., Kit, D., Fu, Y.: A discriminative model with multiple temporal scales for action  prediction, pp. 596-611 (2014) 3  21. Kooij, J.F.P., Schneider, N., Flohr, F., Gavrila, D.M.: Context-based pedestrian path predic- tion. In: 2014 European Conference on Computer Vision. pp. 618-633. Springer (2014) 1 22. Kooij, J.F.P., Schneider, N., Flohr, F., Gavrila, D.M.: Context-Based Pedestrian Path Predic-  tion, pp. 618-633. Springer International Publishing, Cham (2014) 4  23. Koppula, H.S., Saxena, A.: Anticipating human activities using object affordances for re- active robotic response. IEEE Transactions on Pattern Analysis and Machine Intelligence 38(1), 14-29 (Jan 2016). https://doi.org/10.1109/TPAMI.2015.2430335 1, 3  24. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Pereira, F., Burges, C.J.C., Bottou, L., Weinberger, K.Q. (eds.) Ad- vances in Neural Information Processing Systems 25, pp. 1097-1105. Curran Associates, Inc. (2012) 14  25. Lampert, C.H.: Predicting the future behavior of a time-varying probability distribution. In: 2015 IEEE Conference on Computer Vision and Pattern Recognition. pp. 942-950 (2015). https://doi.org/10.1109/CVPR.2015.7298696 4  26. Laviers, K., Sukthankar, G., Aha, D.W., Molineaux, M., Darken, C., et al.: Improving of- fensive performance through opponent modeling. In: 2009 AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (2009) 10  27. Li, K., Fu, Y.: Prediction of human activity by discovering temporal sequence patterns. 2014 IEEE transactions on pattern analysis and machine intelligence 36(8), 1644-1657 (2014) 3 28. Ma, S., Sigal, L., Sclaroff, S.: Learning activity progression in lstms for activity detection and early detection. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition. pp. 1942-1950 (2016). https://doi.org/10.1109/CVPR.2016.214 1, 10   16  Y. Shi et al.  29. Ma, S., Sigal, L., Sclaroff, S.: Learning activity progression in lstms for activity detection and early detection. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition. pp. 1942-1950 (2016) 3  30. MacKenzie, I.S.: Fitts\u2019 law as a research and design tool in human-computer interaction.  Human-computer interaction 7(1), 91-139 (1992) 1  31. Mahmud, T., Hasan, M., Roy-Chowdhury, A.K.: Joint prediction of activity labels and start- ing times in untrimmed videos. In: 2017 IEEE International Conference on Computer Vision. pp. 5784-5793 (2017) 4  32. Mobahi, H., Collobert, R., Weston, J.: Deep learning from temporal coherence in video. In:  2009 International Conference on Machine Learning. pp. 737-744. ACM (2009) 4  33. Newell, A., Card, S.K.: The prospects for psychological science in human-computer interac-  tion. Human-computer interaction 1(3), 209-242 (1985) 1  34. Ranzato, M., Szlam, A., Bruna, J., Mathieu, M., Collobert, R., Chopra, S.: Video (language) modeling: a baseline for generative models of natural videos. CoRR abs/1412.6604 (2014) 4  35. Ryoo, M.S.: Human activity prediction: Early recognition of ongoing activities from stream- ing videos. In: 2011 International Conference on Computer Vision. pp. 1036-1043 (Nov 2011). https://doi.org/10.1109/ICCV.2011.6126349 3, 8, 9, 10  36. Ryoo, M.S., Aggarwal, J.K.: Spatio-temporal relationship match: Video structure compari- son for recognition of complex human activities. In: 2009 IEEE International Conference on Computer Vision. pp. 1593-1600 (2009). https://doi.org/10.1109/ICCV.2009.5459361 3  M.S.,  J.K.: 37. Ryoo, test Description http://cvrc.ece.utexas.edu/SDHA2010/Human Interaction.html (2010) 8  UT-Interaction  Aggarwal,  Semantic  Human  Dataset,  on  of  Activities  ICPR  con- (SDHA).  38. Ryoo, M., Chen, C.C., Aggarwal, J., Roy-Chowdhury, A.: An overview of contest on seman- tic description of human activities (sdha) 2010. In: Recognizing Patterns in Signals, Speech, Images and Videos, pp. 270-285. Springer (2010) 10  39. Sadegh Aliakbarian, M., Sadat Saleh, F., Salzmann, M., Fernando, B., Petersson, L., An- dersson, L.: Encouraging lstms to anticipate actions very early. In: 2017 IEEE International Conference on Computer Vision (Oct 2017) 1, 3, 8, 9, 10  40. Saito, M., Matsumoto, E., Saito, S.: Temporal generative adversarial nets with singular value clipping. In: 2017 IEEE International Conference on Computer Vision. vol. 2, p. 5 (2017) 4 41. Singh, G., Saha, S., Sapienza, M., Torr, P., Cuzzolin, F.: Online real time multiple spatiotem-  poral action localisation and prediction (2017) 10  42. Soomro, K., Idrees, H., Shah, M.: Online localization and prediction of actions and interac-  tions. CoRR abs/1612.01194 (2016) 1, 3, 10  43. Soomro, K., Idrees, H., Shah, M.: Predicting the where and what of actors and actions through online action localization. In: 2016 IEEE Conference on Computer Vision and Pat- tern Recognition. pp. 2648-2657 (2016) 3, 10  44. Soomro, K., Zamir, A.R., Shah, M.: UCF101: A dataset of 101 human actions classes from  videos in the wild. CoRR abs/1212.0402 (2012) 8  45. Srivastava, N., Mansimov, E., Salakhudinov, R.: Unsupervised learning of video represen- tations using lstms. In: 2015 International Conference on Machine Learning. pp. 843-852 (2015) 4  46. Suard, F., Rakotomamonjy, A., Bensrhair, A., Broggi, A.: Pedestrian detection using infrared images and histograms of oriented gradients. In: 2006 IEEE Intelligent Vehicles Symposium. pp. 206-212. IEEE (2006) 1  47. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the inception ar- chitecture for computer vision. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition. pp. 2818-2826 (2016). https://doi.org/10.1109/CVPR.2016.308 4, 9   Feature Mapping RNN48. Tulyakov, S., Liu, M.Y., Yang, X., Kautz, J.: Mocogan: Decomposing motion and content  for video generation. arXiv preprint arXiv:1707.04993 (2017) 4  49. Vondrick, C., Pirsiavash, H., Torralba, A.: Anticipating visual representations from unlabeled video. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition. pp. 98-106 (2016) 1, 2, 3  50. Vu, T.H., Olsson, C., Laptev, I., Oliva, A., Sivic, J.: Predicting Actions from Static Scenes,  pp. 421-436. Springer International Publishing, Cham (2014) 3  51. Walker, J., Gupta, A., Hebert, M.: Patch to the future: Unsupervised visual prediction. In: 2014 IEEE Conference on Computer Vision and Pattern Recognition. pp. 3302-3309 (2014). https://doi.org/10.1109/CVPR.2014.416 4  52. Walker, J., Gupta, A., Hebert, M.: Dense optical \ufb02ow prediction from a static image. In: 2015 IEEE International Conference on Computer Vision. pp. 2443-2451 (Dec 2015). https://doi.org/10.1109/ICCV.2015.281 4  53. Walker, J., Marino, K., Gupta, A., Hebert, M.: The pose knows: Video forecasting by gener- ating pose futures. In: 2017 IEEE International Conference on Computer Vision. pp. 3352- 3361 (2017) 4  54. Xie, D., Todorovic, S., Zhu, S.C.: Inferring dark matter and dark energy from videos. In: 2013 IEEE International Conference on Computer Vision. pp. 2224-2231 (Dec 2013). https://doi.org/10.1109/ICCV.2013.277 4  55. Yu, G., Yuan, J., Liu, Z.: Predicting human activities using spatio-temporal structure of in-  terest points. In: 2012 ACM International Conference on Multimedia (2012) 3  56. Zhong, D., Chang, S.F.: Structure analysis of sports video using domain models. In: 2001  IEEE International Conference on Multimedia & Expo. Citeseer (2001) 1"}