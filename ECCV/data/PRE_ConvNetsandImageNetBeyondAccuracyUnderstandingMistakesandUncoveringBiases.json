{"1": "1. Lecun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document  recognition. In: Proceedings of the IEEE. (1998)   ImageNet Beyond Accuracy(a)  (b)  Fig. 10: (a) Images from the Internet classified as Traffic Light for a ResNet-101. (b) Explanation path of a ResNet-101 for a test sample of the Basketball class. Note that the first feature to appear includes the writing on the jersey and then the basket ball.  persons are more represented in this class in comparison to the other classes. A similar phenomenon has also been noted in the context of textual data. [45, 19]. We defer further investigations on this to future studies.  Remark. We have focused on racial biases because a human can easily spot them. In fact, we have found similar biases where pictures displaying Asians dressed in red are very often classified as ping-pong ball. However, we hypothesize the biases of the model are numerous and diverse. For example, we also have found that the model often predicts the class traffic light for images of a blue sky with street lamps as depicted in Figure 10a. In any case, model criticism has proven effective in uncovering the undesirable hidden biases learned by the model.  4 Conclusion  Through human studies and explanations, we have proven that the performance of SOTA models on Imagenet is underestimated. This leaves little room for improvement and calls for new large-scale benchmarks involving for example multi-label annotations. We have also improved our understanding of adversarial examples from the perspective of the end-user and positioned model criticism as a valuable tool for uncovering un- desirable biases. These results open an exciting perspective on designing explanations and automating bias detection in vision models. Our study suggests that more research in these topics will be necessary to sustain the use of machine learning as a general purpose technology and to achieve new breakthroughs in image classification.  References  1. Lecun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document  recognition. In: Proceedings of the IEEE. (1998)   14  Stock and Cisse  2. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1. (2012)  3. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: ImageNet: A Large-Scale Hier-  archical Image Database. In: CVPR09. (2009)  4. Perronnin, F., S\u00b4anchez, J., Mensink, T.: Improving the fisher kernel for large-scale image classification. In: Proceedings of the 11th European Conference on Computer Vision: Part IV. (2010)  5. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. 2016 IEEE  Conference on Computer Vision and Pattern Recognition (CVPR) (2016)  6. Huang, G., Liu, Z., Weinberger, K.Q.: Densely connected convolutional networks. CoRR  7. Girshick, R.: Fast r-cnn.  In: Proceedings of the 2015 IEEE International Conference on  Computer Vision (ICCV). ICCV \u201915 (2015)  8. He, K., Gkioxari, G., Doll\u00b4ar, P., Girshick, R.B.: Mask R-CNN. CoRR abs/1703.06870  (2016)  (2017)  9. Insafutdinov, E., Pishchulin, L., Andres, B., Andriluka, M., Schiele, B.: Deepercut: A deeper, stronger, and faster multi-person pose estimation model. CoRR abs/1605.03170 (2016) 10. Bulat, A., Tzimiropoulos, G.: Human pose estimation via convolutional part heatmap regres-  11. Gehring, J., Auli, M., Grangier, D., Yarats, D., Dauphin, Y.N.: Convolutional sequence to  12. Wang, Y., Deng, X., Pu, S., Huang, Z.: Residual convolutional CTC networks for automatic  13. Zhang, H., Ciss\u00b4e, M., Dauphin, Y.N., Lopez-Paz, D.: mixup: Beyond empirical risk mini-  sion. CoRR (2016)  sequence learning. CoRR (2017)  speech recognition. CoRR (2017)  mization. CoRR (2017)  14. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. CoRR (2014) 15. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.J., Fergus, R.:  Intriguing properties of neural networks. CoRR (2013)  16. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial examples.  (2014)  17. Ciss\u00b4e, M., Adi, Y., Neverova, N., Keshet, J.: Houdini: Fooling deep structured visual and speech recognition models with adversarial examples. In: Advances in Neural Informa- tion Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA, USA. (2017)  18. Ritter, S., Barrett, D.G.T., Santoro, A., Botvinick, M.M.: Cognitive psychology for deep neu- ral networks: A shape bias case study. In: Proceedings of the 34th International Conference on Machine Learning. Proceedings of Machine Learning Research (2017)  19. Bolukbasi, T., Chang, K., Zou, J.Y., Saligrama, V., Kalai, A.: Man is to computer program-  mer as woman is to homemaker? debiasing word embeddings. CoRR (2016)  20. Kim, B., Khanna, R., Koyejo, O.O.: Examples are not enough, learn to criticize! criticism for int=erpretability. In: Advances in Neural Information Processing Systems 29. (2016)  21. Karpathy, A.: What  i  learned from competing against a convnet on imagenet,  http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet- on-imagenet/  22. Goodfellow, I., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial examples. In:  International Conference on Learning Representations. (2015)  23. Tabacof, P., Valle, E.: Exploring the space of adversarial images. CoRR (2015) 24. Fawzi, A., Fawzi, O., Frossard, P.: Analysis of classifiers\u2019 robustness to adversarial pertur-  bations. CoRR (2015)   ImageNet Beyond Accuracy25. Shaham, U., Yamada, Y., Negahban, S.: Understanding adversarial training: Increasing local  stability of neural nets through robust optimization. CoRR (2015)  26. Fawzi, A., Moosavi-Dezfooli, S., Frossard, P.: Robustness of classifiers: from adversarial to  random noise. CoRR (2016)  27. Papernot, N., McDaniel, P.D., Wu, X., Jha, S., Swami, A.: Distillation as a defense to adver- sarial perturbations against deep neural networks. 2016 IEEE Symposium on Security and Privacy (SP) (2016)  28. Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N.: Parseval networks: Improving robustness to adversarial examples. In: Proceedings of the 34th International Conference on Machine Learning. (2017)  29. Kurakin, A., Boneh, D., Tramr, F., Goodfellow, I., Papernot, N., McDaniel, P.: Ensemble  adversarial training: Attacks and defenses. (2018)  30. Guo, C., Rana, M., Ciss\u00b4e, M., van der Maaten, L.: Countering adversarial images using input  31. Moosavi-Dezfooli, S., Fawzi, A., Frossard, P.: Deepfool: a simple and accurate method to  transformations. CoRR (2017)  fool deep neural networks. CoRR (2015)  32. Kurakin, A., Goodfellow, I.J., Bengio, S.: Adversarial examples in the physical world. CoRR  33. Simon, H.A., Newell, A.: Human problem solving: The state of the theory in 1970 (1972) 34. Aamodt, A., Plaza, E.: Case-based reasoning; foundational issues, methodological varia-  tions, and system approaches. AI COMMUNICATIONS (1994)  35. Bichindaritz, I., Marling, C.: Case-based reasoning in the health sciences: What\u2019s next?  (2016)  (2006)  36. Kim, B., Rudin, C., Shah, J.A.: The bayesian case model: A generative approach for case- based reasoning and prototype classification. In: Advances in Neural Information Processing Systems 27. (2014)  37. Gelman, A.: Bayesian data analysis using r. (2006) 38. Gretton, A., Borgwardt, K.M., Rasch, M., Sch\u00a8olkopf, B., Smola, A.J.: A kernel method for the two-sample-problem. In: Proceedings of the 19th International Conference on Neural Information Processing Systems. NIPS\u201906 (2006)  39. Badanidiyuru, A., Mirzasoleiman, B., Karbasi, A., Krause, A.: Streaming submodular maxi- mization: Massive data summarization on the \ufb02y. In: Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. (2014)  40. Lipton, Z.C.: The mythos of model interpretability. CoRR (2016) 41. Samek, W., Wiegand, T., Muller, K.: Explainable artificial intelligence: Understanding, vi-  sualizing and interpreting deep learning models. CoRR (2017)  42. Montavon, G., Samek, W., Muller, K.: Methods for interpreting and understanding deep  43. Dong, Y., Su, H., Zhu, J., Bao, F.: Towards interpretable deep neural networks by leveraging  neural networks. CoRR (2017)  adversarial examples. CoRR (2017)  44. Ribeiro, M.T., Singh, S., Guestrin, C.: \u201dwhy should i trust you?\u201d: Explaining the predictions of any classifier. In: Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. (2016)  45. Paperno, D., Marelli, M., Tentori, K., Baroni, M.: Corpus-based estimates of word associ- ation predict biases in judgment of word co-occurrence likelihood. Cognitive Psychology (2014)"}