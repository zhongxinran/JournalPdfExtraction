{"1": "1. Krizhevsky, A., Sutskever, I., Hinton, G.E.:  Imagenet classification with deep convolutional neural networks. In: Conference on Neural Information Processing Systems. (2012)  2. Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K.: Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 0.5 mb model size. arXiv preprint arXiv:1602.07360 (2016)  3. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014)  4. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: IEEE Conference on Computer Vision and Pattern Recognition. (2016) 770-778 5. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115(3) (2015) 211-252  6. Lowe, D.G.: Distinctive image features from scale-invariant keypoints. Interna-  tional Journal of Computer Vision (IJCV) 60(2) (2004) 91-110  7. Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detec- tion with region proposal networks. In: Advances in Neural Information Processing System. (2015) 91-99  8. Itti, L., Koch, C., Niebur, E.: A model of saliency-based visual attention for rapid scene analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence 20(11) (1998) 1254-1259  9. Mnih, V., Heess, N., Graves, A.: Recurrent models of visual attention. In: Advances  in Neural Information Processing System. (2014) 2204-2212  10. Ba, J., Mnih, V., Kavukcuoglu, K.: Multiple object recognition with visual atten-  tion. arXiv preprint arXiv:1412.7755 (2014)  11. Eslami, S.A., Heess, N., Weber, T., Tassa, Y., Szepesvari, D., Hinton, G.E., et al.: Attend, infer, repeat: Fast scene understanding with generative models. In: Ad- vances in Neural Information Processing Systems. (2016) 3225-3233  12. Fu, J., Zheng, H., Mei, T.: Look closer to see better: Recurrent attention convo- lutional neural network for fine-grained image recognition. In: Conf. on Computer Vision and Pattern Recognition. (2017)  13. Jaderberg, M., Simonyan, K., Zisserman, A., et al.: Spatial transformer networks.  In: Advances in Neural Information Processing System. (2015) 2017-2025  14. Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y.: Deformable convo- lutional networks. In: IEEE Conference on Computer Vision and Pattern Recog- nition. (2017) 764-773  15. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.: Learning deep features In: IEEE Conference on Computer Vision and  for discriminative localization. Pattern Recognition, IEEE (2016) 2921-2929  16. Li, J., Chen, Y., Cai, L., Davidson, I., Ji, S.: Dense Transformer Networks.  arXiv:1705.08881 [cs, stat] (May 2017) arXiv: 1705.08881.  17. Zheng, H., Fu, J., Mei, T., Luo, J.: Learning multi-attention convolutional neural network for fine-grained image recognition. In: IEEE International Conference on Computer Vision (ICCV). (2017)  18. Xiao, T., Xu, Y., Yang, K., Zhang, J., Peng, Y., Zhang, Z.: The application of two- level attention models in deep convolutional neural network for fine-grained image classification. In: IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2015) 842-850   Learning to Zoom: a Saliency-Based Sampling Layer for Neural NetworksReferences  1. Krizhevsky, A., Sutskever, I., Hinton, G.E.:  Imagenet classification with deep convolutional neural networks. In: Conference on Neural Information Processing Systems. (2012)  2. Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K.: Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 0.5 mb model size. arXiv preprint arXiv:1602.07360 (2016)  3. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014)  4. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: IEEE Conference on Computer Vision and Pattern Recognition. (2016) 770-778 5. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115(3) (2015) 211-252  6. Lowe, D.G.: Distinctive image features from scale-invariant keypoints. Interna-  tional Journal of Computer Vision (IJCV) 60(2) (2004) 91-110  7. Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detec- tion with region proposal networks. In: Advances in Neural Information Processing System. (2015) 91-99  8. Itti, L., Koch, C., Niebur, E.: A model of saliency-based visual attention for rapid scene analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence 20(11) (1998) 1254-1259  9. Mnih, V., Heess, N., Graves, A.: Recurrent models of visual attention. In: Advances  in Neural Information Processing System. (2014) 2204-2212  10. Ba, J., Mnih, V., Kavukcuoglu, K.: Multiple object recognition with visual atten-  tion. arXiv preprint arXiv:1412.7755 (2014)  11. Eslami, S.A., Heess, N., Weber, T., Tassa, Y., Szepesvari, D., Hinton, G.E., et al.: Attend, infer, repeat: Fast scene understanding with generative models. In: Ad- vances in Neural Information Processing Systems. (2016) 3225-3233  12. Fu, J., Zheng, H., Mei, T.: Look closer to see better: Recurrent attention convo- lutional neural network for fine-grained image recognition. In: Conf. on Computer Vision and Pattern Recognition. (2017)  13. Jaderberg, M., Simonyan, K., Zisserman, A., et al.: Spatial transformer networks.  In: Advances in Neural Information Processing System. (2015) 2017-2025  14. Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y.: Deformable convo- lutional networks. In: IEEE Conference on Computer Vision and Pattern Recog- nition. (2017) 764-773  15. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.: Learning deep features In: IEEE Conference on Computer Vision and  for discriminative localization. Pattern Recognition, IEEE (2016) 2921-2929  16. Li, J., Chen, Y., Cai, L., Davidson, I., Ji, S.: Dense Transformer Networks.  arXiv:1705.08881 [cs, stat] (May 2017) arXiv: 1705.08881.  17. Zheng, H., Fu, J., Mei, T., Luo, J.: Learning multi-attention convolutional neural network for fine-grained image recognition. In: IEEE International Conference on Computer Vision (ICCV). (2017)  18. Xiao, T., Xu, Y., Yang, K., Zhang, J., Peng, Y., Zhang, Z.: The application of two- level attention models in deep convolutional neural network for fine-grained image classification. In: IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2015) 842-850   16  A. Recasens  , P. Kellnhofer  , S.Stent, W. Matusik and A.Torralba  \u2217  \u2217  19. Rosenfeld, A., Ullman, S.: Visual concept recognition and localization via iterative introspection. In: Asian Conference on Computer Vision (ACCV), Springer (2016) 264-279  20. Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.: Grad- cam: Visual explanations from deep networks via gradient-based localization. In: IEEE Conference on Computer Vision and Pattern Recognition. (2017) 618-626  21. Khosla  \u2217  \u2217  , A., Krafka  , K., Kellnhofer, P., Kannan, H., Bhandarkar, S., Matusik, W., Torralba, A.: Eye tracking for everyone. In: IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, USA (June 2016) indicates equal contribution.  \u2217  22. Wang, S., Luo, L., Zhang, N., Li, J.: AutoScaler: Scale-Attention Networks for  Visual Correspondence. In: British Machine Vision Conference (BMVC). (2017)  23. Rubinstein, M., Gutierrez, D., Sorkine, O., Shamir, A.: A comparative study of image retargeting. In: ACM Transactions on Graphics (TOG). Volume 29., ACM (2010) 160  24. Wolf, L., Guttmann, M., Cohen-Or, D.: Non-homogeneous content-driven video- retargeting. In: IEEE International Conference on Computer Vision (ICCV), IEEE (2007) 1-6  25. Karni, Z., Freedman, D., Gotsman, C.: Energy-based image deformation.  In: Computer Graphics Forum. Volume 28., Wiley Online Library (2009) 1257-1268 26. Kaufmann, P., Wang, O., Sorkine-Hornung, A., Sorkine-Hornung, O., Smolic, A., Gross, M.: Finite element image warping. In: Computer Graphics Forum. Vol- ume 32., Wiley Online Library (2013) 31-39  27. Chen, R., Freedman, D., Karni, Z., Gotsman, C., Liu, L.: Content-aware image resizing by quadratic programming. In: Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE (2010) 1-8  28. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large- scale hierarchical image database. In: IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2009) 248-255  29. Van Horn, G., Mac Aodha, O., Song, Y., Shepard, A., Adam, H., Perona, P., Be- longie, S.: The inaturalist challenge 2017 dataset. arXiv preprint arXiv:1707.06642 (2017)  30. Zhou, B., Khosla, A., A., L., Oliva, A., Torralba, A.: Learning Deep Features for Discriminative Localization. IEEE Conference on Computer Vision and Pattern Recognition (2016)  31. Szegedy, C., Vanhoucke, V., Io\ufb00e, S., Shlens, J., Wojna, Z.: Rethinking the incep- tion architecture for computer vision. In: Proceedings of the IEEE conference on computer vision and pattern recognition. (2016) 2818-2826  32. Wah, C., Branson, S., Welinder, P., Perona, P., Belongie, S.: The caltech-ucsd  birds-200-2011 dataset. (2011)  33. Li, Z., Yang, Y., Liu, X., Zhou, F., Wen, S., Xu, W.: Dynamic computational time  for visual attention. arXiv preprint arXiv:1703.10332 (2017)"}