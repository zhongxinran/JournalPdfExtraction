{"1": "1. Aalen, O., Borgan, O., Gjessing, H.: Survival and event history analysis: a process point of view. Springer Science and Business Media (2008), http- s://doi.org/10.1162/neco.1997.9.8.1735  2. Baccouche, M., Mamalet, F., Wolf, C., Garcia, C., Baskurt, A.: Action classifica- tion in soccer videos with long short-term memory recurrent neural networks. In: ICANN. pp. 154-159 (2010)  3. Borji, A., Sihite, D.N., Itti, L.: Probabilistic learning of task-specific visual atten-  tion. In: CVPR. pp. 470-477 (2012)  4. Cho, K., van Merrienboer, B., Bahdanau, D., Bengio, Y.: On the properties of neural machine translation: Encoder-decoder approaches. In: Proceedings of SSST@EMNLP. pp. 103-111 (2014), http://aclweb.org/anthology/W/W14/W14- 4012.pdf  5. Du, N., Dai, H., Trivedi, R., Upadhyay, U., Gomez-Rodriguez, M., Song, L.: Re- current marked temporal point processes: Embedding event history to vector. In: Proceedings of the 22nd ACM SIGKDD International Conference. pp. 1555-1564 (2016)  6. Einhauser, W., Spain, M., Perona, P.: Objects predict fixations better than early  saliency. Journal of Vision 8(14), 18.1 (2008)  7. Elman, J.L.: Finding structure in time. Cognitive Science 14(2), 179-211 (1990) 8. Fathi, A., Li, Y., Rehg, J.M.: Learning to recognize daily actions using gaze. In:  ECCV. pp. 314-327 (2012)  9. Fathi, A., Ren, X., Rehg, J.M.: Learning to recognize objects in egocentric activi-  10. Girshick,  ties. In: CVPR. pp. 3281-3288 (2011) R-CNN.  R.B.: http://arxiv.org/abs/1504.08083  Fast  CoRR  abs/1504.08083  (2015),  11. Graves, A.: Generating sequences with recurrent neural networks. CoRR ab-  s/1308.0850 (2013), http://arxiv.org/abs/1308.0850  12. Hawkes, G., A.: Spectra of some self-exciting and mutually exciting point processes.  Springer Science and Business Media (1971), https://doi:10.2307/2334319  13. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Computation  9(8), 1735-1780 (1997)  14. Itti, L., Koch, C., Niebur, E.: A model of saliency-based visual attention for rapid scene analysis. IEEE Trans. Pattern Anal. Mach. Intell. 20(11), 1254-1259 (1998) 15. Jang, Y., Song, Y., Yu, Y., Kim, Y., Kim, G.: TGIF-QA: toward spatio-temporal  reasoning in visual question answering. In: CVPR. pp. 1359-1367 (2017)  16. Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R.B., Guadar- rama, S., Darrell, T.: Ca\ufb00e: Convolutional architecture for fast feature embedding. In: ACMMM. pp. 675-678 (2014), http://doi.acm.org/10.1145/2647868.2654889  17. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep con-  volutional neural networks. In: NIPS. pp. 1106-1114 (2012)  18. Lehman, A., O\u2019Rourke, N., Hatcher, L., stepanski, E.: Jmp for basic univariate and multivariate statistics: Methods for researchers and social scientists second edition p. 123 (2005)  19. Li, Y., Ye, Z., Rehg, J.M.: Delving into egocentric actions. In: CVPR. pp. 287-295  (2015)  20. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S.E., Fu, C., Berg, A.C.:  SSD: single shot multibox detector. In: ECCV. pp. 21-37 (2016)   Egocentric Activity Prediction via Event Modulated AttentionReferences  1. Aalen, O., Borgan, O., Gjessing, H.: Survival and event history analysis: a process point of view. Springer Science and Business Media (2008), http- s://doi.org/10.1162/neco.1997.9.8.1735  2. Baccouche, M., Mamalet, F., Wolf, C., Garcia, C., Baskurt, A.: Action classifica- tion in soccer videos with long short-term memory recurrent neural networks. In: ICANN. pp. 154-159 (2010)  3. Borji, A., Sihite, D.N., Itti, L.: Probabilistic learning of task-specific visual atten-  tion. In: CVPR. pp. 470-477 (2012)  4. Cho, K., van Merrienboer, B., Bahdanau, D., Bengio, Y.: On the properties of neural machine translation: Encoder-decoder approaches. In: Proceedings of SSST@EMNLP. pp. 103-111 (2014), http://aclweb.org/anthology/W/W14/W14- 4012.pdf  5. Du, N., Dai, H., Trivedi, R., Upadhyay, U., Gomez-Rodriguez, M., Song, L.: Re- current marked temporal point processes: Embedding event history to vector. In: Proceedings of the 22nd ACM SIGKDD International Conference. pp. 1555-1564 (2016)  6. Einhauser, W., Spain, M., Perona, P.: Objects predict fixations better than early  saliency. Journal of Vision 8(14), 18.1 (2008)  7. Elman, J.L.: Finding structure in time. Cognitive Science 14(2), 179-211 (1990) 8. Fathi, A., Li, Y., Rehg, J.M.: Learning to recognize daily actions using gaze. In:  ECCV. pp. 314-327 (2012)  9. Fathi, A., Ren, X., Rehg, J.M.: Learning to recognize objects in egocentric activi-  10. Girshick,  ties. In: CVPR. pp. 3281-3288 (2011) R-CNN.  R.B.: http://arxiv.org/abs/1504.08083  Fast  CoRR  abs/1504.08083  (2015),  11. Graves, A.: Generating sequences with recurrent neural networks. CoRR ab-  s/1308.0850 (2013), http://arxiv.org/abs/1308.0850  12. Hawkes, G., A.: Spectra of some self-exciting and mutually exciting point processes.  Springer Science and Business Media (1971), https://doi:10.2307/2334319  13. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Computation  9(8), 1735-1780 (1997)  14. Itti, L., Koch, C., Niebur, E.: A model of saliency-based visual attention for rapid scene analysis. IEEE Trans. Pattern Anal. Mach. Intell. 20(11), 1254-1259 (1998) 15. Jang, Y., Song, Y., Yu, Y., Kim, Y., Kim, G.: TGIF-QA: toward spatio-temporal  reasoning in visual question answering. In: CVPR. pp. 1359-1367 (2017)  16. Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R.B., Guadar- rama, S., Darrell, T.: Ca\ufb00e: Convolutional architecture for fast feature embedding. In: ACMMM. pp. 675-678 (2014), http://doi.acm.org/10.1145/2647868.2654889  17. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep con-  volutional neural networks. In: NIPS. pp. 1106-1114 (2012)  18. Lehman, A., O\u2019Rourke, N., Hatcher, L., stepanski, E.: Jmp for basic univariate and multivariate statistics: Methods for researchers and social scientists second edition p. 123 (2005)  19. Li, Y., Ye, Z., Rehg, J.M.: Delving into egocentric actions. In: CVPR. pp. 287-295  (2015)  20. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S.E., Fu, C., Berg, A.C.:  SSD: single shot multibox detector. In: ECCV. pp. 21-37 (2016)   16  Yang Shen et al.  21. Liu, Y., Yan, J., Ouyang, W.: Quality aware network for set to set recognition. In:  22. Ma, M., Fan, H., Kitani, K.M.: Going deeper into first-person activity recognition.  CVPR. pp. 4694-4703 (2017)  In: CVPR. pp. 1894-1903 (2016)  23. Mnih, V., Heess, N., Graves, A., Kavukcuoglu, K.: Recurrent models of visu- al attention. In: NIPS. pp. 2204-2212 (2014), http://papers.nips.cc/paper/5542- recurrent-models-of-visual-attention  24. Moltisanti, D., Wray, M., Mayol-Cuevas, W.W., Damen, D.: Trespassing the boundaries: Labeling temporal bounds for object interactions in egocentric video. In: ICCV. pp. 2905-2913 (2017)  25. Ng, J.Y., Hausknecht, M.J., Vijayanarasimhan, S., Vinyals, O., Monga, R., Toderi- ci, G.: Beyond short snippets: Deep networks for video classification. In: CVPR. pp. 4694-4702 (2015)  26. Poleg, Y., Ephrat, A., Peleg, S., Arora, C.: Compact CNN for indexing egocentric  27. Ryoo, M.S., Rothrock, B., Matthies, L.H.: Pooled motion features for first-person  videos. In: WACV. pp. 1-9 (2016)  videos. In: CVPR. pp. 896-904 (2015)  28. Singh, S., Arora, C., Jawahar, C.V.: First person action recognition using deep  learned descriptors. In: CVPR. pp. 2620-2628 (2016)  29. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neu- ral networks. In: NIPS. pp. 3104-3112 (2014), http://papers.nips.cc/paper/5346- sequence-to-sequence-learning-with-neural-networks  30. Xiao, S., Yan, J., Yang, X., Zha, H., Chu, S.M.: Modeling the intensity function of point process via recurrent neural networks. In: AAAI. pp. 1597-1603 (2017), http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14391  31. Zhang, M., Ma, K.T., Lim, J., Zhao, Q., Feng, J.: Deep future gaze: Gaze antici- pation on egocentric videos using adversarial networks. In: CPVR. pp. 3539-3548 (2017)  32. Zhou, Y., Ni, B., Hong, R., Yang, X., Tian, Q.: Cascaded interactional targeting  network for egocentric video analysis. In: CVPR. pp. 1904-1913 (2016)  33. Zhu, X., Jia, X., Wong, K.K.: Pixel-level hand detection with shape-aware struc-  tured forests. In: ACCV. pp. 64-78 (2014)"}