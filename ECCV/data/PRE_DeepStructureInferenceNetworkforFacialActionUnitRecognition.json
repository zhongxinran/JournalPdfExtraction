{"1": "1. Bakkes, S., Tan, C.T., Pisan, Y.: Personalised gaming. JCT 3 (2012) 2. Chu, X., Ouyang, W., Wang, X., et al.: Crf-cnn: Modeling structured information in human pose estimation. In: Advances in Neural Information Processing Systems. pp. 316-324 (2016)  3. Deng, Z., Vahdat, A., Hu, H., Mori, G.: Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition. In: IEEE CVPR. pp. 4772-4781 (2016)  4. DeVault, D., Artstein, R., Benn, G., Dey, T., Fast, E., Gainer, A., Morency, L.P.: A virtual human interviewer for healthcare decision support. AAMAS (2014)  5. Ekman, P., Friesen, W., Hager, J.: Facs manual. a human face (2002) 6. Eleftheriadis, S., Rudovic, O., Pantic, M.: Multi-conditional latent variable model  for joint facial action unit detection. In: IEEE ICCV. pp. 3792-3800 (2015)  7. Fabian Benitez-Quiroz, C., Wang, Y., Martinez, A.M.: Recognition of action units in the wild with deep nets and a new global-local loss. In: IEEE ICCV (Oct 2017) 8. Jaiswal, S., Valstar, M.: Deep learning the dynamic appearance and shape of facial action units. In: Applications of Computer Vision (WACV), 2016 IEEE Winter Conference on. pp. 1-8. IEEE (2016)  9. Kapoor, A., Burleson, W., Picard, R.W.: Automatic prediction of frustration.  IJHCS 65(8), 724-736 (2007)  10. Kazemi, V., Sullivan, J.: One millisecond face alignment with an ensemble of re-  gression trees. In: IEEE CVPR. pp. 1867-1874 (2014)  11. Kulkarni, K., Corneanu, C.A., Ofodile, I., Escalera, S., Baro, X., Hyniewska, S., Allik, J., Anbarjafari, G.: Automatic recognition of deceptive facial expressions of emotion. arXiv preprint arXiv:1707.04061 (2017)  12. Li, W., Abtahi, F., Zhu, Z.: Action unit detection with region adaptation, multi- labeling learning and optimal temporal fusing. In: IEEE CVPR. pp. 6766-6775 (2017)  13. Mavadati, S.M., Mahoor, M.H., Bartlett, K., Trinh, P., Cohn, J.F.: Disfa: A sponta- neous facial action intensity database. IEEE Transactions on A\ufb00ective Computing 4(2), 151-160 (2013)  14. Parkhi, O.M., Vedaldi, A., Zisserman, A.: Deep face recognition. In: British Ma-  chine Vision Conference (2015)  15. Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.: Grad- cam: Visual explanations from deep networks via gradient-based localization. See https://arxiv. org/abs/1610.02391 v3 7(8) (2016)  16. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014)  17. Taigman, Y., Yang, M., Ranzato, M., Wolf, L.: Deepface: Closing the gap to human- level performance in face verification. In: IEEE CVPR. pp. 1701-1708 (2014) 18. Vinciarelli, A., Pantic, M., Bourlard, H.: Social signal processing: Survey of an  emerging domain. IVC 27(12), 1743-1759 (2009)  19. Walecki, R., Rudovic, O., Pavlovic, V., Schuller, B., Pantic, M.: Deep structured learning for facial action unit intensity estimation. In: IEEE CVPR. pp. 5709-5718 (2017)  20. Wang, Z., Li, Y., Wang, S., Ji, Q.: Capturing global semantic relationships for  facial action unit recognition. In: IEEE ICCV. pp. 3304-3311 (2013)  21. Wu, Y., Ji, Q.: Constrained joint cascade regression framework for simultaneous facial action unit recognition and facial landmark detection. In: IEEE CVPR. pp. 3400-3408 (2016)   Deep Structure Inference NetworkReferences  1. Bakkes, S., Tan, C.T., Pisan, Y.: Personalised gaming. JCT 3 (2012) 2. Chu, X., Ouyang, W., Wang, X., et al.: Crf-cnn: Modeling structured information in human pose estimation. In: Advances in Neural Information Processing Systems. pp. 316-324 (2016)  3. Deng, Z., Vahdat, A., Hu, H., Mori, G.: Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition. In: IEEE CVPR. pp. 4772-4781 (2016)  4. DeVault, D., Artstein, R., Benn, G., Dey, T., Fast, E., Gainer, A., Morency, L.P.: A virtual human interviewer for healthcare decision support. AAMAS (2014)  5. Ekman, P., Friesen, W., Hager, J.: Facs manual. a human face (2002) 6. Eleftheriadis, S., Rudovic, O., Pantic, M.: Multi-conditional latent variable model  for joint facial action unit detection. In: IEEE ICCV. pp. 3792-3800 (2015)  7. Fabian Benitez-Quiroz, C., Wang, Y., Martinez, A.M.: Recognition of action units in the wild with deep nets and a new global-local loss. In: IEEE ICCV (Oct 2017) 8. Jaiswal, S., Valstar, M.: Deep learning the dynamic appearance and shape of facial action units. In: Applications of Computer Vision (WACV), 2016 IEEE Winter Conference on. pp. 1-8. IEEE (2016)  9. Kapoor, A., Burleson, W., Picard, R.W.: Automatic prediction of frustration.  IJHCS 65(8), 724-736 (2007)  10. Kazemi, V., Sullivan, J.: One millisecond face alignment with an ensemble of re-  gression trees. In: IEEE CVPR. pp. 1867-1874 (2014)  11. Kulkarni, K., Corneanu, C.A., Ofodile, I., Escalera, S., Baro, X., Hyniewska, S., Allik, J., Anbarjafari, G.: Automatic recognition of deceptive facial expressions of emotion. arXiv preprint arXiv:1707.04061 (2017)  12. Li, W., Abtahi, F., Zhu, Z.: Action unit detection with region adaptation, multi- labeling learning and optimal temporal fusing. In: IEEE CVPR. pp. 6766-6775 (2017)  13. Mavadati, S.M., Mahoor, M.H., Bartlett, K., Trinh, P., Cohn, J.F.: Disfa: A sponta- neous facial action intensity database. IEEE Transactions on A\ufb00ective Computing 4(2), 151-160 (2013)  14. Parkhi, O.M., Vedaldi, A., Zisserman, A.: Deep face recognition. In: British Ma-  chine Vision Conference (2015)  15. Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.: Grad- cam: Visual explanations from deep networks via gradient-based localization. See https://arxiv. org/abs/1610.02391 v3 7(8) (2016)  16. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014)  17. Taigman, Y., Yang, M., Ranzato, M., Wolf, L.: Deepface: Closing the gap to human- level performance in face verification. In: IEEE CVPR. pp. 1701-1708 (2014) 18. Vinciarelli, A., Pantic, M., Bourlard, H.: Social signal processing: Survey of an  emerging domain. IVC 27(12), 1743-1759 (2009)  19. Walecki, R., Rudovic, O., Pavlovic, V., Schuller, B., Pantic, M.: Deep structured learning for facial action unit intensity estimation. In: IEEE CVPR. pp. 5709-5718 (2017)  20. Wang, Z., Li, Y., Wang, S., Ji, Q.: Capturing global semantic relationships for  facial action unit recognition. In: IEEE ICCV. pp. 3304-3311 (2013)  21. Wu, Y., Ji, Q.: Constrained joint cascade regression framework for simultaneous facial action unit recognition and facial landmark detection. In: IEEE CVPR. pp. 3400-3408 (2016)   16  Ciprian Corneanu , Meysam Madadi, and Sergio Escalera  22. Zeng, J., Chu, W.S., De la Torre, F., Cohn, J.F., Xiong, Z.: Confidence preserving machine for facial action unit detection. In: IEEE ICCV. pp. 3622-3630 (2015) 23. Zhang, X., Mahoor, M.H.: Task-dependent multi-task multiple kernel learning for  facial action unit detection. Pattern Recognition 51, 187-196 (2016)  24. Zhang, X., Yin, L., Cohn, J.F., Canavan, S., Reale, M., Horowitz, A., Liu, P., Girard, J.M.: Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database. Image and Vision Computing 32(10), 692-706 (2014)  25. Zhao, K., Chu, W.S., De la Torre, F., Cohn, J.F., Zhang, H.: Joint patch and multi-label learning for facial action unit detection. In: IEEE CVPR. pp. 2207- 2216 (2015)  26. Zhao, K., Chu, W.S., Zhang, H.: Deep region and multi-label learning for facial  action unit detection. In: IEEE CVPR. pp. 3391-3399 (2016)  27. Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V., Su, Z., Du, D., Huang, C., Torr, P.H.: Conditional random fields as recurrent neural networks. In: IEEE CVPR. pp. 1529-1537 (2015)  28. Zhong, L., Liu, Q., Yang, P., Huang, J., Metaxas, D.N.: Learning multiscale active facial patches for expression analysis. IEEE Transactions on Cybernetics 45(8), 1499-1510 (2015)"}