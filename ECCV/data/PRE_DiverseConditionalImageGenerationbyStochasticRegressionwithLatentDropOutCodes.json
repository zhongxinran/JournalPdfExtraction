{"1": "1. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,  Courville, A., Bengio, Y.: Generative adversarial nets. In: NIPS. (2014)  2. Sohn, K., Lee, H., Yan, X.: Learning structured output representation using deep  conditional generative models. In: NIPS. (2015)  3. Mirza, M., Osindero, S.: Conditional generative adversarial nets. arXiv preprint  arXiv:1411.1784 (2014)  4. Zhu, J.Y., Zhang, R., Pathak, D., Darrell, T., Efros, A.A., Wang, O., Shechtman,  E.: Toward multimodal image-to-image translation. In: NIPS. (2017)  5. Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A.: Image-to-image translation with con-  ditional adversarial networks. In: CVPR. (2017)  6. Chen, Q., Koltun, V.: Photographic image synthesis with cascaded refinement  networks. In: ICCV. (2017)  7. Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., Lee, H.: Generative  adversarial text to image synthesis. In: ICML. (2016)  8. Zhang, H., Xu, T., Li, H., Zhang, S., Huang, X., Wang, X., Metaxas, D.: Stack- gan: Text to photo-realistic image synthesis with stacked generative adversarial networks. In: ICCV. (2017)  9. Wang, X., Gupta, A.: Generative image modeling using style and structure adver-  sarial networks. In: ECCV. (2016)  10. Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., Efros, A.A.:  f: Feature  learning by inpainting. In: CVPR. (2016)  11. Ledig, C., Theis, L., Husz\u00b4ar, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., et al.: Photo-realistic single image super- resolution using a generative adversarial network. arXiv preprint arXiv:1609.04802 (2016)  12. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer  and super-resolution. In: ECCV. (2016)  13. Dosovitskiy, A., Brox, T.: Generating images with perceptual similarity metrics based on deep networks. In: Advances in Neural Information Processing Systems. (2016) 658-666  14. Guzman-Rivera, A., Batra, D., Kohli, P.: Multiple choice learning: Learning to  produce multiple structured outputs. In: NIPS. (2012)  15. Li, Y., Fang, C., Yang, J., Wang, Z., Lu, X., Yang, M.H.: Diversified texture  synthesis with feed-forward networks. (2017)  16. Liu, C., Shum, H.Y., Freeman, W.T.: Face hallucination: Theory and practice.  17. Hays, J., Efros, A.A.: Scene completion using millions of photographs. In: SIG-  IJCV (2007)  GRAPH. (2007)  ICCV. (1999)  SIGGRAPH. (2001)  ICLR (2018)  18. Efros, A.A., Leung, T.K.: Texture synthesis by non-parametric sampling.  In:  19. Efros, A.A., Freeman, W.T.: Image quilting for texture synthesis and transfer. In:  20. Bansal, A., Sheikh, Y., Ramanan, D.: Pixelnn: Example-based image synthesis.  21. Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.: Dropout: a simple way to prevent neural networks from overfitting. JMLR (2014) 22. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.: Object detectors  emerge in deep scene cnns. In: ICLR. (2015)   Diverse conditional image generation by stochastic regressionReferences  1. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,  Courville, A., Bengio, Y.: Generative adversarial nets. In: NIPS. (2014)  2. Sohn, K., Lee, H., Yan, X.: Learning structured output representation using deep  conditional generative models. In: NIPS. (2015)  3. Mirza, M., Osindero, S.: Conditional generative adversarial nets. arXiv preprint  arXiv:1411.1784 (2014)  4. Zhu, J.Y., Zhang, R., Pathak, D., Darrell, T., Efros, A.A., Wang, O., Shechtman,  E.: Toward multimodal image-to-image translation. In: NIPS. (2017)  5. Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A.: Image-to-image translation with con-  ditional adversarial networks. In: CVPR. (2017)  6. Chen, Q., Koltun, V.: Photographic image synthesis with cascaded refinement  networks. In: ICCV. (2017)  7. Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., Lee, H.: Generative  adversarial text to image synthesis. In: ICML. (2016)  8. Zhang, H., Xu, T., Li, H., Zhang, S., Huang, X., Wang, X., Metaxas, D.: Stack- gan: Text to photo-realistic image synthesis with stacked generative adversarial networks. In: ICCV. (2017)  9. Wang, X., Gupta, A.: Generative image modeling using style and structure adver-  sarial networks. In: ECCV. (2016)  10. Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., Efros, A.A.:  f: Feature  learning by inpainting. In: CVPR. (2016)  11. Ledig, C., Theis, L., Husz\u00b4ar, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., et al.: Photo-realistic single image super- resolution using a generative adversarial network. arXiv preprint arXiv:1609.04802 (2016)  12. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer  and super-resolution. In: ECCV. (2016)  13. Dosovitskiy, A., Brox, T.: Generating images with perceptual similarity metrics based on deep networks. In: Advances in Neural Information Processing Systems. (2016) 658-666  14. Guzman-Rivera, A., Batra, D., Kohli, P.: Multiple choice learning: Learning to  produce multiple structured outputs. In: NIPS. (2012)  15. Li, Y., Fang, C., Yang, J., Wang, Z., Lu, X., Yang, M.H.: Diversified texture  synthesis with feed-forward networks. (2017)  16. Liu, C., Shum, H.Y., Freeman, W.T.: Face hallucination: Theory and practice.  17. Hays, J., Efros, A.A.: Scene completion using millions of photographs. In: SIG-  IJCV (2007)  GRAPH. (2007)  ICCV. (1999)  SIGGRAPH. (2001)  ICLR (2018)  18. Efros, A.A., Leung, T.K.: Texture synthesis by non-parametric sampling.  In:  19. Efros, A.A., Freeman, W.T.: Image quilting for texture synthesis and transfer. In:  20. Bansal, A., Sheikh, Y., Ramanan, D.: Pixelnn: Example-based image synthesis.  21. Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.: Dropout: a simple way to prevent neural networks from overfitting. JMLR (2014) 22. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.: Object detectors  emerge in deep scene cnns. In: ICLR. (2015)   16  Y. He, B. Schiele and M. Fritz  23. Bau, D., Zhou, B., Khosla, A., Oliva, A., Torralba, A.: Network dissection: Quan-  tifying interpretability of deep visual representations. In: CVPR. (2017)  24. Rumelhart, D.E., Hinton, G.E., Williams, R.J.: Learning representations by back-  propagating errors. Nature (1986)  25. Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadar- rama, S., Darrell, T.: Ca\ufb00e: Convolutional architecture for fast feature embedding. In: ACM Multimedia. (2014)  26. Parkhi, O.M., Vedaldi, A., Zisserman, A., Jawahar, C.: Cats and dogs. In: CVPR.  (2012)  27. Bansal, A., Chen, X., Russell, B., Ramanan, A.G., et al.: Pixelnet: Representation of the pixels, by the pixels, and for the pixels. arXiv preprint arXiv:1702.06506 (2017)  28. Learned-Miller, E., Huang, G.B., RoyChowdhury, A., Li, H., Hua, G.: Labeled faces in the wild: A database for studying face recognition in unconstrained envi- ronments. Advances in Face Detection and Facial Image Analysis (2016)  29. Zhang, K., Zhang, Z., Li, Z., Qiao, Y.: Joint face detection and alignment using multitask cascaded convolutional networks. IEEE Signal Processing Letters (2016) 30. Zhang, Z., Luo, P., Loy, C.C., Tang, X.: Facial landmark detection by deep multi-  31. Kingma, D., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint  task learning. In: ECCV. (2014)  arXiv:1412.6980 (2014)  32. Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P.: Image quality assessment:  from error visibility to structural similarity. TIP (2004)  33. Zhang, L., Zhang, L., Mou, X., Zhang, D.: Fsim: A feature similarity index for  image quality assessment. TIP (2011)  34. Wang, X., Fouhey, D., Gupta, A.: Designing deep networks for surface normal  estimation. In: CVPR  35. Wen, Y., Zhang, K., Li, Z., Qiao, Y.: A discriminative feature learning approach  for deep face recognition. In: ECCV. (2016) 36. Oh, S.J., Fritz, M., Schiele, B.: Adversarial  protection-a game theory perspective. In: ICCV. (2017)  image perturbation for privacy"}