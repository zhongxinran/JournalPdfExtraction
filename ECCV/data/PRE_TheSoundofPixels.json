{"1": "1. Arandjelovic, R., Zisserman, A.: Look, listen and learn. In: 2017 IEEE International  Conference on Computer Vision (ICCV). pp. 609-617. IEEE (2017)  2. Arandjelovi\u00b4c, R., Zisserman, A.: Objects  that  sound.  arXiv preprint  arXiv:1712.06651 (2017)  3. Aytar, Y., Vondrick, C., Torralba, A.: Soundnet: Learning sound representations from unlabeled video. In: Advances in Neural Information Processing Systems. pp. 892-900 (2016)  4. Belouchrani, A., Abed-Meraim, K., Cardoso, J.F., Moulines, E.: A blind source separation technique using second-order statistics. IEEE Transactions on signal processing 45(2), 434-444 (1997)  5. Bregman, A.S.: Auditory scene analysis: The perceptual organization of sound.  MIT press (1994)  6. Cardoso, J.F.: Infomax and maximum likelihood for blind source separation. IEEE  Signal processing letters 4(4), 112-114 (1997)  7. Chandna, P., Miron, M., Janer, J., G\u00b4omez, E.: Monoaural audio source separation  using deep convolutional neural networks. In: ICLVASS. pp. 258-266 (2017)  8. Cichocki, A., Zdunek, R., Phan, A.H., Amari, S.i.: Nonnegative matrix and tensor factorizations: applications to exploratory multi-way data analysis and blind source separation. John Wiley & Sons (2009)  9. Comon, P., Jutten, C.: Handbook of Blind Source Separation: Independent com-  ponent analysis and applications. Academic press (2010)  10. Doersch, C., Gupta, A., Efros, A.A.: Unsupervised visual representation learning by context prediction. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 1422-1430 (2015)  11. Ephrat, A., Mosseri,  I., Lang, O., Dekel, T., Wilson, K., Hassidim, A., Freeman, W.T., Rubinstein, M.: Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation. arXiv preprint arXiv:1804.03619 (2018)  12. Gabbay, A., Ephrat, A., Halperin, T., Peleg, S.: Seeing through noise: Speaker separation and enhancement using visually-derived speech. arXiv preprint arXiv:1708.06767 (2017)  13. Gan, C., Gong, B., Liu, K., Su, H., Guibas, L.J.: Geometry-guided CNN for self-  supervised video representation learning (2018)  14. Haykin, S., Chen, Z.: The cocktail party problem. Neural computation 17(9), 1875-  1902 (2005)  15. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016)  16. Hershey, J.R., Chen, Z., Le Roux, J., Watanabe, S.: Deep clustering: Discriminative embeddings for segmentation and separation. In: Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on. pp. 31-35. IEEE (2016)  17. Hershey, J.R., Movellan, J.R.: Audio vision: Using audio-visual synchrony (eds.) Ad- to locate vances Information Processing Systems 12, pp. 813-819. MIT Press (2000), http://papers.nips.cc/paper/1686-audio-vision-using-audio-visual- synchrony-to-locate-sounds.pdf  In: Solla, S.A., Leen, T.K., M\u00a8uller, K.  sounds. in Neural   The Sound of PixelsReferences  1. Arandjelovic, R., Zisserman, A.: Look, listen and learn. In: 2017 IEEE International  Conference on Computer Vision (ICCV). pp. 609-617. IEEE (2017)  2. Arandjelovi\u00b4c, R., Zisserman, A.: Objects  that  sound.  arXiv preprint  arXiv:1712.06651 (2017)  3. Aytar, Y., Vondrick, C., Torralba, A.: Soundnet: Learning sound representations from unlabeled video. In: Advances in Neural Information Processing Systems. pp. 892-900 (2016)  4. Belouchrani, A., Abed-Meraim, K., Cardoso, J.F., Moulines, E.: A blind source separation technique using second-order statistics. IEEE Transactions on signal processing 45(2), 434-444 (1997)  5. Bregman, A.S.: Auditory scene analysis: The perceptual organization of sound.  MIT press (1994)  6. Cardoso, J.F.: Infomax and maximum likelihood for blind source separation. IEEE  Signal processing letters 4(4), 112-114 (1997)  7. Chandna, P., Miron, M., Janer, J., G\u00b4omez, E.: Monoaural audio source separation  using deep convolutional neural networks. In: ICLVASS. pp. 258-266 (2017)  8. Cichocki, A., Zdunek, R., Phan, A.H., Amari, S.i.: Nonnegative matrix and tensor factorizations: applications to exploratory multi-way data analysis and blind source separation. John Wiley & Sons (2009)  9. Comon, P., Jutten, C.: Handbook of Blind Source Separation: Independent com-  ponent analysis and applications. Academic press (2010)  10. Doersch, C., Gupta, A., Efros, A.A.: Unsupervised visual representation learning by context prediction. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 1422-1430 (2015)  11. Ephrat, A., Mosseri,  I., Lang, O., Dekel, T., Wilson, K., Hassidim, A., Freeman, W.T., Rubinstein, M.: Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation. arXiv preprint arXiv:1804.03619 (2018)  12. Gabbay, A., Ephrat, A., Halperin, T., Peleg, S.: Seeing through noise: Speaker separation and enhancement using visually-derived speech. arXiv preprint arXiv:1708.06767 (2017)  13. Gan, C., Gong, B., Liu, K., Su, H., Guibas, L.J.: Geometry-guided CNN for self-  supervised video representation learning (2018)  14. Haykin, S., Chen, Z.: The cocktail party problem. Neural computation 17(9), 1875-  1902 (2005)  15. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016)  16. Hershey, J.R., Chen, Z., Le Roux, J., Watanabe, S.: Deep clustering: Discriminative embeddings for segmentation and separation. In: Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on. pp. 31-35. IEEE (2016)  17. Hershey, J.R., Movellan, J.R.: Audio vision: Using audio-visual synchrony (eds.) Ad- to locate vances Information Processing Systems 12, pp. 813-819. MIT Press (2000), http://papers.nips.cc/paper/1686-audio-vision-using-audio-visual- synchrony-to-locate-sounds.pdf  In: Solla, S.A., Leen, T.K., M\u00a8uller, K.  sounds. in Neural   16  Hang Zhao et al.  18. Hershey, S., Chaudhuri, S., Ellis, D.P., Gemmeke, J.F., Jansen, A., Moore, R.C., Plakal, M., Platt, D., Saurous, R.A., Seybold, B., et al.: Cnn architectures for large- scale audio classification. In: Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on. pp. 131-135. IEEE (2017)  19. Izadinia, H., Saleemi, I., Shah, M.: Multimodal analysis for identification and seg- mentation of moving-sounding objects. IEEE Transactions on Multimedia 15(2), 378-390 (2013)  20. Jayaraman, D., Grauman, K.: Learning image representations tied to ego-motion. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 1413-1421 (2015)  21. Kidron, E., Schechner, Y.Y., Elad, M.: Pixels that sound. In: Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recog- nition (CVPR\u201905) - Volume 1 - Volume 01. pp. 88-95. CVPR \u201905, IEEE Computer Society, Washington, DC, USA (2005). https://doi.org/10.1109/CVPR.2005.274, http://dx.doi.org/10.1109/CVPR.2005.274  22. Larsson, G., Maire, M., Shakhnarovich, G.: Colorization as a proxy task for visual  understanding. In: CVPR. vol. 2, p. 8 (2017)  23. Logan, B., et al.: Mel frequency cepstral coe\ufb03cients for music modeling. In: ISMIR.  vol. 270, pp. 1-11 (2000)  24. Ma, W.C., Chu, H., Zhou, B., Urtasun, R., Torralba, A.: Single image intrinsic  decomposition without a single intrinsic image. In: ECCV (2018)  25. McDermott, J.H.: The cocktail party problem. Current Biology 19(22), R1024-  R1027 (2009)  26. Mesaros, A., Heittola, T., Diment, A., Elizalde, B., Ankit Shah, e.a.: Dcase 2017 challenge setup: Tasks, datasets and baseline system. In: DCASE 2017 - Workshop on Detection and Classification of Acoustic Scenes and Events (2017)  27. Nagrani, A., Albanie, S., Zisserman, A.: Seeing voices and hearing faces: Cross-  modal biometric matching. arXiv preprint arXiv:1804.00326 (2018)  28. Ngiam, J., Khosla, A., Kim, M., Nam, J., Lee, H., Ng, A.Y.: Multimodal deep learning. In: Proceedings of the 28th International Conference on International Conference on Machine Learning. pp. 689-696. ICML\u201911 (2011)  29. Owens, A., Efros, A.A.: Audio-visual scene analysis with self-supervised multisen-  sory features. arXiv preprint arXiv:1804.03641 (2018)  30. Owens, A., Isola, P., McDermott, J., Torralba, A., Adelson, E.H., Freeman, W.T.: Visually indicated sounds. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2405-2413 (2016)  31. Owens, A., Wu, J., McDermott, J.H., Freeman, W.T., Torralba, A.: Ambient sound provides supervision for visual learning. In: European Conference on Computer Vision. pp. 801-816. Springer (2016)  32. Pathak, D., Girshick, R., Doll\u00b4ar, P., Darrell, T., Hariharan, B.: Learning features  by watching objects move. In: Proc. CVPR. vol. 2 (2017)  33. Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., Efros, A.A.: Context en- coders: Feature learning by inpainting. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2536-2544 (2016)  34. Ra\ufb00el, C., McFee, B., Humphrey, E.J., Salamon, J., Nieto, O., Liang, D., Ellis, D.P., Ra\ufb00el, C.C.: mir eval: A transparent implementation of common mir metrics. In: In Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR. Citeseer (2014)  35. Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedi- cal image segmentation. In: International Conference on Medical image computing and computer-assisted intervention. pp. 234-241. Springer (2015)   The Sound of Pixels36. R. de Sa, V.: Learning classification with unlabeled data. In: Advances In Neural  Information Processing Systems. pp. 112-119 (1993)  37. Senocak, A., Oh, T.H., Kim, J., Yang, M.H., Kweon, I.S.: Learning to localize  sound source in visual scenes. arXiv preprint arXiv:1803.03849 (2018)  38. Shu, Z., Yumer, E., Hadap, S., Sunkavalli, K., Shechtman, E., Samaras, D.: Neural face editing with intrinsic image disentangling. arXiv preprint arXiv:1704.04131 (2017)  39. Simpson, A.J., Roma, G., Plumbley, M.D.: Deep karaoke: Extracting vocals from musical mixtures using a convolutional deep neural network. In: International Con- ference on Latent Variable Analysis and Signal Separation. pp. 429-436. Springer (2015)  40. Smaragdis, P., Brown, J.C.: Non-negative matrix factorization for polyphonic mu- sic transcription. In: Applications of Signal Processing to Audio and Acoustics, 2003 IEEE Workshop on. pp. 177-180. IEEE (2003)  41. Vincent, E., Gribonval, R., F\u00b4evotte, C.: Performance measurement in blind audio source separation. IEEE transactions on audio, speech, and language processing 14(4), 1462-1469 (2006)  42. Virtanen, T.: Monaural sound source separation by nonnegative matrix factoriza- tion with temporal continuity and sparseness criteria. IEEE transactions on audio, speech, and language processing 15(3), 1066-1074 (2007)  43. Vondrick, C., Pirsiavash, H., Torralba, A.: Generating videos with scene dynamics. In: Advances In Neural Information Processing Systems. pp. 613-621 (2016) 44. Vondrick, C., Shrivastava, A., Fathi, A., Guadarrama, S., Murphy, K.: Tracking  emerges by colorizing videos. arXiv preprint arXiv:1806.09594 (2018)  45. Wang, D., Chen, J.: Supervised speech separation based on deep learning: an  overview. arXiv preprint arXiv:1708.07524 (2017)  46. Wang, X., Gupta, A.: Unsupervised learning of visual representations using videos.  In: ICCV. pp. 2794-2802 (2015)  47. Zhao, H., Gallo, O., Frosio, I., Kautz, J.: Loss functions for image restoration with neural networks. IEEE Transactions on Computational Imaging 3(1), 47-57 (2017) 48. Zhao, M., Li, T., Abu Alsheikh, M., Tian, Y., Zhao, H., Torralba, A., Katabi, D.: Through-wall human pose estimation using radio signals. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 7356-7365 (2018)  49. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.: Learning deep fea- tures for discriminative localization. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2921-2929 (2016)  50. Zhou, B., Zhao, H., Puig, X., Fidler, S., Barriuso, A., Torralba, A.: Scene parsing  through ADE20K dataset. In: Proc. CVPR (2017)  51. Zhou, Y., Wang, Z., Fang, C., Bui, T., Berg, T.L.: Visual to sound: Generating natural sound for videos in the wild. arXiv preprint arXiv:1712.01393 (2017) 52. Zibulevsky, M., Pearlmutter, B.A.: Blind source separation by sparse decomposi-  tion in a signal dictionary. Neural computation 13(4), 863-882 (2001)"}