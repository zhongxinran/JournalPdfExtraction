{"1": "1. Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Lawrence Zitnick, C., Parikh,  D.: Vqa: Visual question answering. In: ICCV. pp. 2425-2433 (2015)  2. Dai, B., Zhang, Y., Lin, D.: Detecting visual relationships with deep relational  networks. In: CVPR (2017)  3. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J.M., Parikh, D.,  Batra, D.: Visual dialog. In: CVPR (2017)  4. Everingham, M., Van Gool, L., Williams, C., Winn, J., Zisserman, A.: The pascal visual object classes challenge 2012 results. In: See http://www. pascal-network. org/challenges/VOC/voc2012/workshop/index. html. vol. 5 (2012)  5. Gao, X., Xiao, B., Tao, D., Li, X.: A survey of graph edit distance. Pattern Analysis  and Applications 13(1), 113-129 (2010) 6. Girshick, R.: Fast r-cnn. In: CVPR (2015) 7. Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accu-  rate object detection and semantic segmentation. In: CVPR (2014)  8. He, K., Gkioxari, G., Doll\u00b4ar, P., Girshick, R.: Mask r-cnn. In: ICCV (2017) 9. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.  In: CVPR (2016)  In: CVPR (2018)  10. Hu, H., Gu, J., Zhang, Z., Dai, J., Wei, Y.: Relation networks for object detection.  11. Johnson, J., Hariharan, B., van der Maaten, L., Fei-Fei, L., Zitnick, C.L., Girshick, R.: CLEVR: a diagnostic dataset for compositional language and elementary visual reasoning. In: CVPR (2017)  12. Johnson, J., Krishna, R., Stark, M., Li, L.J., Shamma, D.A., Bernstein, M., Fei-Fei,  L.: Image retrieval using scene graphs. In: CVPR (2015)  13. Kipf, T.N., Welling, M.: Semi-supervised classification with graph convolutional  networks. In: ICLR (2017)  14. Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalan- tidis, Y., Li, L.J., Shamma, D.A., et al.: Visual genome: Connecting language and vision using crowdsourced dense image annotations. IJCV 123(1), 32-73 (2017)  15. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep con-  volutional neural networks. In: NIPS (2012)  16. Ladicky, L., Russell, C., Kohli, P., Torr, P.H.: Graph cut based inference with  co-occurrence statistics. In: ECCV (2010)  17. Li, Y., Ouyang, W., Wang, X.: Vip-cnn: A visual phrase reasoning convolutional  neural network for visual relationship detection. In: CVPR (2017)  18. Li, Y., Ouyang, W., Zhou, B., Wang, K., Wang, X.: Scene graph generation from  objects, phrases and region captions. In: ICCV (2017)  19. Liang, X., Lee, L., Xing, E.P.: Deep variation-structured reinforcement learning  for visual relationship and attribute detection. In: CVPR (2017)  20. Lin, C.L.: Hardness of approximating graph transformation problem. In: Interna- tional Symposium on Algorithms and Computation. pp. 74-82. Springer (1994) 21. Lin, T.Y., Doll\u00b4ar, P., Girshick, R., He, K., Hariharan, B., Belongie, S.: Feature  pyramid networks for object detection. In: CVPR (2017)  22. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y., Berg, A.C.:  SSD: Single shot multibox detector. In: ECCV (2016)  23. Lu, C., Krishna, R., Bernstein, M., Fei-Fei, L.: Visual relationship detection with  language priors. In: ECCV (2016)  24. Lu, J., Yang, J., Batra, D., Parikh, D.: Neural baby talk. In: CVPR (2018)   Graph R-CNNReferences  1. Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Lawrence Zitnick, C., Parikh,  D.: Vqa: Visual question answering. In: ICCV. pp. 2425-2433 (2015)  2. Dai, B., Zhang, Y., Lin, D.: Detecting visual relationships with deep relational  networks. In: CVPR (2017)  3. Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J.M., Parikh, D.,  Batra, D.: Visual dialog. In: CVPR (2017)  4. Everingham, M., Van Gool, L., Williams, C., Winn, J., Zisserman, A.: The pascal visual object classes challenge 2012 results. In: See http://www. pascal-network. org/challenges/VOC/voc2012/workshop/index. html. vol. 5 (2012)  5. Gao, X., Xiao, B., Tao, D., Li, X.: A survey of graph edit distance. Pattern Analysis  and Applications 13(1), 113-129 (2010) 6. Girshick, R.: Fast r-cnn. In: CVPR (2015) 7. Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accu-  rate object detection and semantic segmentation. In: CVPR (2014)  8. He, K., Gkioxari, G., Doll\u00b4ar, P., Girshick, R.: Mask r-cnn. In: ICCV (2017) 9. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.  In: CVPR (2016)  In: CVPR (2018)  10. Hu, H., Gu, J., Zhang, Z., Dai, J., Wei, Y.: Relation networks for object detection.  11. Johnson, J., Hariharan, B., van der Maaten, L., Fei-Fei, L., Zitnick, C.L., Girshick, R.: CLEVR: a diagnostic dataset for compositional language and elementary visual reasoning. In: CVPR (2017)  12. Johnson, J., Krishna, R., Stark, M., Li, L.J., Shamma, D.A., Bernstein, M., Fei-Fei,  L.: Image retrieval using scene graphs. In: CVPR (2015)  13. Kipf, T.N., Welling, M.: Semi-supervised classification with graph convolutional  networks. In: ICLR (2017)  14. Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalan- tidis, Y., Li, L.J., Shamma, D.A., et al.: Visual genome: Connecting language and vision using crowdsourced dense image annotations. IJCV 123(1), 32-73 (2017)  15. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep con-  volutional neural networks. In: NIPS (2012)  16. Ladicky, L., Russell, C., Kohli, P., Torr, P.H.: Graph cut based inference with  co-occurrence statistics. In: ECCV (2010)  17. Li, Y., Ouyang, W., Wang, X.: Vip-cnn: A visual phrase reasoning convolutional  neural network for visual relationship detection. In: CVPR (2017)  18. Li, Y., Ouyang, W., Zhou, B., Wang, K., Wang, X.: Scene graph generation from  objects, phrases and region captions. In: ICCV (2017)  19. Liang, X., Lee, L., Xing, E.P.: Deep variation-structured reinforcement learning  for visual relationship and attribute detection. In: CVPR (2017)  20. Lin, C.L.: Hardness of approximating graph transformation problem. In: Interna- tional Symposium on Algorithms and Computation. pp. 74-82. Springer (1994) 21. Lin, T.Y., Doll\u00b4ar, P., Girshick, R., He, K., Hariharan, B., Belongie, S.: Feature  pyramid networks for object detection. In: CVPR (2017)  22. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y., Berg, A.C.:  SSD: Single shot multibox detector. In: ECCV (2016)  23. Lu, C., Krishna, R., Bernstein, M., Fei-Fei, L.: Visual relationship detection with  language priors. In: ECCV (2016)  24. Lu, J., Yang, J., Batra, D., Parikh, D.: Neural baby talk. In: CVPR (2018)   16  Yang and Lu et al.  25. Nair, V., Hinton, G.E.: Rectified linear units improve restricted boltzmann ma-  chines. In: ICML (2010)  26. Newell, A., Deng, J.: Pixels to graphs by associative embedding. In: NIPS (2017) 27. Oliva, A., Torralba, A.: The role of context in object recognition. Trends in cogni-  tive sciences 11(12), 520-527 (2007)  28. Parikh, D., Zitnick, C.L., Chen, T.: From appearance to context-based recognition:  Dense labeling in small images. In: CVPR (2008)  29. Peyre, J., Laptev, I., Schmid, C., Sivic, J.: Weakly-supervised learning of visual  30. Rabinovich, A., Vedaldi, A., Galleguillos, C., Wiewiora, E., Belongie, S.: Objects  relations. In: ICCV (2017)  in context. In: ICCV (2007)  31. Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: Unified,  real-time object detection. In: CVPR (2016)  32. Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object de-  tection with region proposal networks. In: NIPS (2015)  33. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014)  34. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: CVPR (2015) 35. Teney, D., Liu, L., Hengel, A.v.d.: Graph-structured representations for visual ques-  36. Veli\u02c7ckovi\u00b4c, P., Cucurull, G., Casanova, A., Romero, A., Li`o, P., Bengio, Y.: Graph  37. Wang, P., Wu, Q., Shen, C., Dick, A., van den Hengel, A.: Fvqa: Fact-based visual  tion answering. In: CVPR (2017)  attention networks. In: ICLR (2018)  question answering. PAMI (2017)  38. Wang, P., Wu, Q., Shen, C., van den Hengel, A.: The vqa-machine: Learning how to use existing vision algorithms to answer new questions. In: CVPR (2017) 39. Wu, Q., Shen, C., Wang, P., Dick, A., van den Hengel, A.: Image captioning and vi- sual question answering based on attributes and external knowledge. PAMI (2017) 40. Xu, D., Zhu, Y., Choy, C.B., Fei-Fei, L.: Scene graph generation by iterative mes-  sage passing. In: CVPR (2017)  41. Yang, J., Lu, J., Batra, D., Parikh, D.: A faster pytorch implementation of faster  r-cnn. https://github.com/jwyang/faster-rcnn.pytorch (2017)  42. Zellers, R., Yatskar, M., Thomson, S., Choi, Y.: Neural motifs: Scene graph parsing  with global context. In: CVPR (2018)  43. Zhang, H., Kyaw, Z., Chang, S.F., Chua, T.S.: Visual translation embedding net-  work for visual relation detection. In: CVPR (2017)  44. Zhang, H., Kyaw, Z., Yu, J., Chang, S.F.: Ppr-fcn: weakly supervised visual relation  detection via parallel pairwise r-fcn (2017)  45. Zhang, J., Elhoseiny, M., Cohen, S., Chang, W., Elgammal, A.: Relationship pro-  posal networks. In: CVPR (2017)  46. Zhuang, B., Liu, L., Shen, C., Reid, I.: Towards context-aware interaction recog-  nition for visual relationship detection. In: ICCV (2017)"}