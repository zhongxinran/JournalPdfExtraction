{"1": "1. Bach, S., Binder, A., Montavon, G., Klauschen, F., M\u00a8uller, K.R., Samek, W.: On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. PloS one 10(7), e0130140 (2015)  2. Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D.: Unsupervised pixel-level domain adaptation with generative adversarial networks. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). vol. 1, p. 7 (2017)  3. Fong, R.C., Vedaldi, A.: Interpretable explanations of black boxes by meaningful  perturbation. arXiv preprint arXiv:1704.03296 (2017)  4. Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V.: Domain-adversarial training of neural networks. The Journal of Machine Learning Research 17(1), 2096-2030 (2016)  5. Gatys, L.A., Ecker, A.S., Bethge, M.: A neural algorithm of artistic style. arXiv  preprint arXiv:1508.06576 (2015)  6. Gatys, L.A., Ecker, A.S., Bethge, M.: Image style transfer using convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on. pp. 2414-2423. IEEE (2016)  7. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial  examples. arXiv preprint arXiv:1412.6572 (2014)  8. Goodman, B., Flaxman, S.: European union regulations on algorithmic decision- making and a\u201d right to explanation\u201d. arXiv preprint arXiv:1606.08813 (2016) 9. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and super-resolution. In: European Conference on Computer Vision. pp. 694-711. Springer (2016)  10. Larsen, A.B.L., S\u00f8nderby, S.K., Larochelle, H., Winther, O.: Autoencoding beyond  pixels using a learned similarity metric. arXiv preprint arXiv:1512.09300 (2015)  11. LeCun, Y., Bottou, L., Bengio, Y., Ha\ufb00ner, P.: Gradient-based learning applied to  document recognition. Proceedings of the IEEE 86(11), 2278-2324 (1998)  12. Liu, M.Y., Breuel, T., Kautz, J.: Unsupervised image-to-image translation net- works. In: Advances in Neural Information Processing Systems. pp. 700-708 (2017) 13. Liu, M.Y., Tuzel, O.: Coupled generative adversarial networks. In: Advances in  neural information processing systems. pp. 469-477 (2016)  14. Liu, Z., Luo, P., Wang, X., Tang, X.: Deep learning face attributes in the wild. In: Proceedings of International Conference on Computer Vision (ICCV) (2015) 15. Maaten, L.v.d., Hinton, G.: Visualizing data using t-sne. Journal of machine learn-  ing research 9(Nov), 2579-2605 (2008)  16. Montavon, G., Lapuschkin, S., Binder, A., Samek, W., M\u00a8uller, K.R.: Explaining nonlinear classification decisions with deep taylor decomposition. Pattern Recog- nition 65, 211-222 (2017)  17. Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 (2015)  18. Rudin, L.I., Osher, S., Fatemi, E.: Nonlinear total variation based noise removal  algorithms. Physica D: nonlinear phenomena 60(1-4), 259-268 (1992)  19. Samek, W., Binder, A., Montavon, G., Lapuschkin, S., M\u00a8uller, K.R.: Evaluating the visualization of what a deep neural network has learned. IEEE transactions on neural networks and learning systems 28(11), 2660-2673 (2017)   ExplainGAN: Model Explanation via TransformationsReferences  1. Bach, S., Binder, A., Montavon, G., Klauschen, F., M\u00a8uller, K.R., Samek, W.: On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. PloS one 10(7), e0130140 (2015)  2. Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D.: Unsupervised pixel-level domain adaptation with generative adversarial networks. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). vol. 1, p. 7 (2017)  3. Fong, R.C., Vedaldi, A.: Interpretable explanations of black boxes by meaningful  perturbation. arXiv preprint arXiv:1704.03296 (2017)  4. Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V.: Domain-adversarial training of neural networks. The Journal of Machine Learning Research 17(1), 2096-2030 (2016)  5. Gatys, L.A., Ecker, A.S., Bethge, M.: A neural algorithm of artistic style. arXiv  preprint arXiv:1508.06576 (2015)  6. Gatys, L.A., Ecker, A.S., Bethge, M.: Image style transfer using convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on. pp. 2414-2423. IEEE (2016)  7. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial  examples. arXiv preprint arXiv:1412.6572 (2014)  8. Goodman, B., Flaxman, S.: European union regulations on algorithmic decision- making and a\u201d right to explanation\u201d. arXiv preprint arXiv:1606.08813 (2016) 9. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and super-resolution. In: European Conference on Computer Vision. pp. 694-711. Springer (2016)  10. Larsen, A.B.L., S\u00f8nderby, S.K., Larochelle, H., Winther, O.: Autoencoding beyond  pixels using a learned similarity metric. arXiv preprint arXiv:1512.09300 (2015)  11. LeCun, Y., Bottou, L., Bengio, Y., Ha\ufb00ner, P.: Gradient-based learning applied to  document recognition. Proceedings of the IEEE 86(11), 2278-2324 (1998)  12. Liu, M.Y., Breuel, T., Kautz, J.: Unsupervised image-to-image translation net- works. In: Advances in Neural Information Processing Systems. pp. 700-708 (2017) 13. Liu, M.Y., Tuzel, O.: Coupled generative adversarial networks. In: Advances in  neural information processing systems. pp. 469-477 (2016)  14. Liu, Z., Luo, P., Wang, X., Tang, X.: Deep learning face attributes in the wild. In: Proceedings of International Conference on Computer Vision (ICCV) (2015) 15. Maaten, L.v.d., Hinton, G.: Visualizing data using t-sne. Journal of machine learn-  ing research 9(Nov), 2579-2605 (2008)  16. Montavon, G., Lapuschkin, S., Binder, A., Samek, W., M\u00a8uller, K.R.: Explaining nonlinear classification decisions with deep taylor decomposition. Pattern Recog- nition 65, 211-222 (2017)  17. Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 (2015)  18. Rudin, L.I., Osher, S., Fatemi, E.: Nonlinear total variation based noise removal  algorithms. Physica D: nonlinear phenomena 60(1-4), 259-268 (1992)  19. Samek, W., Binder, A., Montavon, G., Lapuschkin, S., M\u00a8uller, K.R.: Evaluating the visualization of what a deep neural network has learned. IEEE transactions on neural networks and learning systems 28(11), 2660-2673 (2017)   16  P. Samangouei, A. Saeedi, L. Nakagawa, and N. Silberman  20. Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.: Grad- cam: Visual explanations from deep networks via gradient-based localization. See https://arxiv. org/abs/1610.02391 v3 7(8) (2016)  21. Shrikumar, A., Greenside, P., Kundaje, A.: Learning important features through  propagating activation di\ufb00erences. arXiv preprint arXiv:1704.02685 (2017)  22. Shrikumar, A., Greenside, P., Shcherbina, A., Kundaje, A.: Not just a black box: Learning important features through propagating activation di\ufb00erences. arXiv preprint arXiv:1605.01713 (2016)  23. Simonyan, K., Vedaldi, A., Zisserman, A.: Deep inside convolutional networks: visualising image classification models and saliency maps (2014). arXiv preprint arXiv:1312.6034 (2013)  24. Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M.: Striving for simplic-  ity: The all convolutional net. arXiv preprint arXiv:1412.6806 (2014)  25. Sundararajan, M., Taly, A., Yan, Q.: Axiomatic attribution for deep networks.  arXiv preprint arXiv:1703.01365 (2017)  26. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fer- gus, R.: Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199 (2013)  27. Wattenberg, M., Vigas, F., Johnson, I.: How to use t-sne e\ufb00ectively. Distill (2016). https://doi.org/10.23915/distill.00002, http://distill.pub/2016/misread-tsne 28. Xiao, H., Rasul, K., Vollgraf, R.: Fashion-mnist: a novel image dataset for bench-  marking machine learning algorithms (2017)  29. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks.  In: European conference on computer vision. pp. 818-833. Springer (2014)  30. Zhu, J.Y., Park, T., Isola, P., Efros, A.A.: Unpaired image-to-image translation us- ing cycle-consistent adversarial networks. arXiv preprint arXiv:1703.10593 (2017)"}