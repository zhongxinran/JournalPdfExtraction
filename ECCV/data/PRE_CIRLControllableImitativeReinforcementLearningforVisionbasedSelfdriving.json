{"1": "1. Abbeel, P., Coates, A., Quigley, M., Ng, A.Y.: An application of reinforcement learning to aerobatic helicopter \ufb02ight. In: Advances in neural information processing systems. pp. 1-8 (2007)  2. Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Monfort, M., Muller, U., Zhang, J., et al.: End to end learning for self-driving cars. arXiv preprint arXiv:1604.07316 (2016)  3. Cao, Q., Lin, L., Shi, Y., Liang, X., Li, G.: Attention-aware face hallucination via deep  reinforcement learning. arXiv preprint arXiv:1708.03132 (2017)  4. Codevilla, F., M\u00a8uller, M., Dosovitskiy, A., L\u00b4opez, A., Koltun, V.: End-to-end driving via  conditional imitation learning. arXiv preprint arXiv:1710.02410 (2017)  5. Dosovitskiy, A., Koltun, V.: Learning to act by predicting the future. arXiv preprint  arXiv:1611.01779 (2016)  6. Dosovitskiy, A., Ros, G., Codevilla, F., L\u00b4opez, A., Koltun, V.: Carla: An open urban driving  simulator. arXiv preprint arXiv:1711.03938 (2017)  7. Endo, G., Morimoto, J., Matsubara, T., Nakanishi, J., Cheng, G.: Learning cpg-based biped locomotion with a policy gradient method: Application to a humanoid robot. The Interna- tional Journal of Robotics Research 27(2), 213-228 (2008)  8. Franke, U.: Autonomous driving. Computer Vision in Vehicle Technology (2017) 9. Han, J., Yang, L., Zhang, D., Chang, X., Liang, X.: Reinforcement cutting-agent learning for video object segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 9080-9089 (2018)  10. Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., Meger, D.: Deep reinforcement  learning that matters. arXiv preprint arXiv:1709.06560 (2017)  11. Hester, T., Vecerik, M., Pietquin, O., Lanctot, M., Schaul, T., Piot, B., Sendonaris, A., Dulac- Arnold, G., Osband, I., Agapiou, J., et al.: Learning from demonstrations for real world reinforcement learning. arXiv preprint arXiv:1704.03732 (2017)  12. Ho, J., Ermon, S.: Generative adversarial imitation learning. In: Advances in Neural Infor-  mation Processing Systems. pp. 4565-4573 (2016)  13. Hou, Y., Hornauer, S., Zipser, K.: Fast recurrent fully convolutional networks for direct per-  ception in autonomous driving. arXiv preprint arXiv:1711.06459 (2017)  14. Jie, Z., Liang, X., Feng, J., Jin, X., Lu, W., Yan, S.: Tree-structured reinforcement learning for sequential object localization. In: Advances in Neural Information Processing Systems. pp. 127-135 (2016)  15. Kim, J., Canny, J.: Interpretable learning for self-driving cars by visualizing causal attention.  ICCV (2017)  16. Latzke, T., Behnke, S., Bennewitz, M.: Imitative reinforcement learning for soccer playing  robots. In: Robot Soccer World Cup. pp. 47-58. Springer (2006)  17. Li, Y., Song, J., Ermon, S.: Infogail: Interpretable imitation learning from visual demonstra- tions. In: Advances in Neural Information Processing Systems. pp. 3815-3825 (2017) 18. Liang, X., Hu, Z., Zhang, H., Gan, C., Xing, E.P.: Recurrent topic-transition gan for visual  paragraph generation. In: ICCV (2017)  19. Liang, X., Lee, L., Xing, E.P.: Deep variation-structured reinforcement learning for visual relationship and attribute detection. In: Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. pp. 4408-4417. IEEE (2017)  20. Liang, X., Zhou, H., Xing, E.: Dynamic-structured semantic propagation network. In: Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 752-761 (2018)   Imitative Reinforcement Learning for Self-drivingReferences  1. Abbeel, P., Coates, A., Quigley, M., Ng, A.Y.: An application of reinforcement learning to aerobatic helicopter \ufb02ight. In: Advances in neural information processing systems. pp. 1-8 (2007)  2. Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Monfort, M., Muller, U., Zhang, J., et al.: End to end learning for self-driving cars. arXiv preprint arXiv:1604.07316 (2016)  3. Cao, Q., Lin, L., Shi, Y., Liang, X., Li, G.: Attention-aware face hallucination via deep  reinforcement learning. arXiv preprint arXiv:1708.03132 (2017)  4. Codevilla, F., M\u00a8uller, M., Dosovitskiy, A., L\u00b4opez, A., Koltun, V.: End-to-end driving via  conditional imitation learning. arXiv preprint arXiv:1710.02410 (2017)  5. Dosovitskiy, A., Koltun, V.: Learning to act by predicting the future. arXiv preprint  arXiv:1611.01779 (2016)  6. Dosovitskiy, A., Ros, G., Codevilla, F., L\u00b4opez, A., Koltun, V.: Carla: An open urban driving  simulator. arXiv preprint arXiv:1711.03938 (2017)  7. Endo, G., Morimoto, J., Matsubara, T., Nakanishi, J., Cheng, G.: Learning cpg-based biped locomotion with a policy gradient method: Application to a humanoid robot. The Interna- tional Journal of Robotics Research 27(2), 213-228 (2008)  8. Franke, U.: Autonomous driving. Computer Vision in Vehicle Technology (2017) 9. Han, J., Yang, L., Zhang, D., Chang, X., Liang, X.: Reinforcement cutting-agent learning for video object segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 9080-9089 (2018)  10. Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., Meger, D.: Deep reinforcement  learning that matters. arXiv preprint arXiv:1709.06560 (2017)  11. Hester, T., Vecerik, M., Pietquin, O., Lanctot, M., Schaul, T., Piot, B., Sendonaris, A., Dulac- Arnold, G., Osband, I., Agapiou, J., et al.: Learning from demonstrations for real world reinforcement learning. arXiv preprint arXiv:1704.03732 (2017)  12. Ho, J., Ermon, S.: Generative adversarial imitation learning. In: Advances in Neural Infor-  mation Processing Systems. pp. 4565-4573 (2016)  13. Hou, Y., Hornauer, S., Zipser, K.: Fast recurrent fully convolutional networks for direct per-  ception in autonomous driving. arXiv preprint arXiv:1711.06459 (2017)  14. Jie, Z., Liang, X., Feng, J., Jin, X., Lu, W., Yan, S.: Tree-structured reinforcement learning for sequential object localization. In: Advances in Neural Information Processing Systems. pp. 127-135 (2016)  15. Kim, J., Canny, J.: Interpretable learning for self-driving cars by visualizing causal attention.  ICCV (2017)  16. Latzke, T., Behnke, S., Bennewitz, M.: Imitative reinforcement learning for soccer playing  robots. In: Robot Soccer World Cup. pp. 47-58. Springer (2006)  17. Li, Y., Song, J., Ermon, S.: Infogail: Interpretable imitation learning from visual demonstra- tions. In: Advances in Neural Information Processing Systems. pp. 3815-3825 (2017) 18. Liang, X., Hu, Z., Zhang, H., Gan, C., Xing, E.P.: Recurrent topic-transition gan for visual  paragraph generation. In: ICCV (2017)  19. Liang, X., Lee, L., Xing, E.P.: Deep variation-structured reinforcement learning for visual relationship and attribute detection. In: Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. pp. 4408-4417. IEEE (2017)  20. Liang, X., Zhou, H., Xing, E.: Dynamic-structured semantic propagation network. In: Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 752-761 (2018)   16  X. Liang, T. Wang, L. Yang and E. Xing  21. Lillicrap, T.P., Hunt, J.J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., Wierstra, D.:  Continuous control with deep reinforcement learning. ICLR (2016)  22. Mnih, V., Badia, A.P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D., Kavukcuoglu, K.: Asynchronous methods for deep reinforcement learning. In: International Conference on Machine Learning. pp. 1928-1937 (2016)  23. Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Riedmiller, M., Fidjeland, A.K., Ostrovski, G., et al.: Human-level control through deep reinforcement learning. Nature 518(7540), 529 (2015)  24. Muller, U., Ben, J., Cosatto, E., Flepp, B., Cun, Y.L.: Off-road obstacle avoidance through end-to-end learning. In: Advances in neural information processing systems. pp. 739-746 (2006)  25. Paden, B., \u02c7C\u00b4ap, M., Yong, S.Z., Yershov, D., Frazzoli, E.: A survey of motion planning and control techniques for self-driving urban vehicles. IEEE Transactions on Intelligent Vehicles 1(1), 33-55 (2016)  26. Plappert, M., Houthooft, R., Dhariwal, P., Sidor, S., Chen, R.Y., Chen, X., Asfour, T., Abbeel, P., Andrychowicz, M.: Parameter space noise for exploration. arXiv preprint arXiv:1706.01905 (2017)  27. Pomerleau, D.A.: Alvinn: An autonomous land vehicle in a neural network. In: Advances in  neural information processing systems. pp. 305-313 (1989)  28. Sallab, A.E., Abdou, M., Perot, E., Yogamani, S.: Deep reinforcement learning framework  for autonomous driving. Electronic Imaging 2017(19), 70-76 (2017)  29. Santana, E., Hotz, G.: Learning a driving simulator. arXiv preprint arXiv:1608.01230 (2016) 30. Shalev-Shwartz, S., Shammah, S., Shashua, A.: Safe, multi-agent, reinforcement learning for  autonomous driving. arXiv preprint arXiv:1610.03295 (2016)  31. Silver, D., Bagnell, J.A., Stentz, A.: Learning from demonstration for autonomous naviga- tion in complex unstructured terrain. The International Journal of Robotics Research 29(12), 1565-1592 (2010)  32. Sutton, R.S., Barto, A.G.: Introduction to reinforcement learning, vol. 135. MIT press Cam-  bridge (1998)  bridge (1998)  33. Sutton, R.S., Barto, A.G.: Reinforcement learning: An introduction, vol. 1. MIT press Cam-  34. Ve\u02c7cer\u00b4\u0131k, M., Hester, T., Scholz, J., Wang, F., Pietquin, O., Piot, B., Heess, N., Roth\u00a8orl, T., Lampe, T., Riedmiller, M.: Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards. arXiv preprint arXiv:1707.08817 (2017)  35. Xu, H., Gao, Y., Yu, F., Darrell, T.: End-to-end learning of driving models from large-scale  video datasets. CVPR (2017)  36. Yang, L., Liang, X., Xing, E.: Unsupervised real-to-virtual domain unification for end-to-end  highway driving. arXiv preprint arXiv:1801.03458 (2018)  37. You, Y., Pan, X., Wang, Z., Lu, C.: Virtual to real reinforcement learning for autonomous  driving. arXiv preprint arXiv:1704.03952 (2017)  38. Zhang, J., Cho, K.: Query-efficient imitation learning for end-to-end simulated driving. In:  AAAI. pp. 2891-2897 (2017)  39. Zhang, L., Lin, L., Liang, X., He, K.: Is faster r-cnn doing well for pedestrian detection? In:  European Conference on Computer Vision. pp. 443-457 (2016)  40. Zhu, Y., Mottaghi, R., Kolve, E., Lim, J.J., Gupta, A., Fei-Fei, L., Farhadi, A.: Target-driven visual navigation in indoor scenes using deep reinforcement learning. In: Robotics and Au- tomation (ICRA), 2017 IEEE International Conference on. pp. 3357-3364 (2017)  41. Ziebart, B.D., Maas, A.L., Dey, A.K., Bagnell, J.A.: Navigate like a cabbie: Probabilistic reasoning from observed context-aware behavior. In: Proceedings of the 10th international conference on Ubiquitous computing. pp. 322-331 (2008)"}