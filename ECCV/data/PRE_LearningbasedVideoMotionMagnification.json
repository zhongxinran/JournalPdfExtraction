{"1": "1. Balakrishnan, G., Durand, F., Guttag, J.: Detecting pulse from head motions in  video. In: IEEE Conf. on Comput. Vis. and Pattern Recognit. (2013)  2. Bau, D., Zhou, B., Khosla, A., Oliva, A., Torralba, A.: Network dissection: Quan- tifying interpretability of deep visual representations. In: IEEE Conf. on Comput. Vis. and Pattern Recognit. (2017)  3. Cha, Y.J., Chen, J., B\u00a8uy\u00a8uk\u00a8ozt\u00a8urk, O.: Output-only computer vision based damage detection using phase-based optical \ufb02ow and unscented kalman filters. Engineering Structures 132, 300-313 (2017)  4. Elgharib, M.A., Hefeeda, M., Durand, F., Freeman, W.T.: Video magnification in presence of large motions. In: IEEE Conf. on Comput. Vis. and Pattern Recognit. (2015)  5. Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A.: The pascal visual object classes (voc) challenge. Int. J. of Comput. Vis. 88(2), 303-338 (Jun 2010)  6. Freeman, W.T., Adelson, E.H.: The design and use of steerable filters. IEEE Trans.  Pattern Anal. Mach. Intell. 13(9), 891-906 (1991)  7. Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A.: Image-to-image translation with condi- tional adversarial networks. In: IEEE Conf. on Comput. Vis. and Pattern Recognit. (2017)  8. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and  super-resolution. In: Eur. Conf. on Comput. Vis. Springer (2016)  9. Jones, M.J., Poggio, T.: Multidimensional morphable models: A framework for representing and matching object classes. Int. J. of Comput. Vis. 29(2), 107-131 (1998)  10. Kalantari, N.K., Wang, T.C., Ramamoorthi, R.: Learning-based view synthesis for light field cameras. ACM Trans. Graph. (SIGGRAPH Asia) 35(6), 193-10 (2016) 11. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint  arXiv:1412.6980 (2014)  12. Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\u00b4ar, P., Zitnick, C.L.: Microsoft coco: Common objects in context. In: Eur. Conf. on Comput. Vis. Springer (2014)  13. Liu, C., Torralba, A., Freeman, W.T., Durand, F., Adelson, E.H.: Motion magni-  fication. ACM Trans. Graph. (SIGGRAPH) 24(3), 519-526 (2005)  14. Liu, Z., Yeh, R.A., Tang, X., Liu, Y., Agarwala, A.: Video Frame Synthesis using  Deep Voxel Flow. In: IEEE Int. Conf. on Comput. Vis. (2017)  15. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic segmentation. In: IEEE Conf. on Comput. Vis. and Pattern Recognit. (2015) 16. Mathieu, M., Couprie, C., LeCun, Y.: Deep multi-scale video prediction beyond  mean square error. Int. Conf. on Learn. Representations (2016)  17. Niklaus, S., Mai, L., Liu, F.: Video Frame Interpolation via Adaptive Convolution.  IEEE Conf. on Comput. Vis. and Pattern Recognit. (2017)  18. Niklaus, S., Mai, L., Liu, F.: Video Frame Interpolation via Adaptive Separable  Convolution. In: IEEE Int. Conf. on Comput. Vis. (2017)  19. Odena, A., Dumoulin, V., Olah, C.: Deconvolution and checkerboard artifacts.  Distill 1(10), e3 (2016)  20. Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 (2015)   Learning-based Video Motion MagnificationReferences  1. Balakrishnan, G., Durand, F., Guttag, J.: Detecting pulse from head motions in  video. In: IEEE Conf. on Comput. Vis. and Pattern Recognit. (2013)  2. Bau, D., Zhou, B., Khosla, A., Oliva, A., Torralba, A.: Network dissection: Quan- tifying interpretability of deep visual representations. In: IEEE Conf. on Comput. Vis. and Pattern Recognit. (2017)  3. Cha, Y.J., Chen, J., B\u00a8uy\u00a8uk\u00a8ozt\u00a8urk, O.: Output-only computer vision based damage detection using phase-based optical \ufb02ow and unscented kalman filters. Engineering Structures 132, 300-313 (2017)  4. Elgharib, M.A., Hefeeda, M., Durand, F., Freeman, W.T.: Video magnification in presence of large motions. In: IEEE Conf. on Comput. Vis. and Pattern Recognit. (2015)  5. Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A.: The pascal visual object classes (voc) challenge. Int. J. of Comput. Vis. 88(2), 303-338 (Jun 2010)  6. Freeman, W.T., Adelson, E.H.: The design and use of steerable filters. IEEE Trans.  Pattern Anal. Mach. Intell. 13(9), 891-906 (1991)  7. Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A.: Image-to-image translation with condi- tional adversarial networks. In: IEEE Conf. on Comput. Vis. and Pattern Recognit. (2017)  8. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and  super-resolution. In: Eur. Conf. on Comput. Vis. Springer (2016)  9. Jones, M.J., Poggio, T.: Multidimensional morphable models: A framework for representing and matching object classes. Int. J. of Comput. Vis. 29(2), 107-131 (1998)  10. Kalantari, N.K., Wang, T.C., Ramamoorthi, R.: Learning-based view synthesis for light field cameras. ACM Trans. Graph. (SIGGRAPH Asia) 35(6), 193-10 (2016) 11. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint  arXiv:1412.6980 (2014)  12. Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\u00b4ar, P., Zitnick, C.L.: Microsoft coco: Common objects in context. In: Eur. Conf. on Comput. Vis. Springer (2014)  13. Liu, C., Torralba, A., Freeman, W.T., Durand, F., Adelson, E.H.: Motion magni-  fication. ACM Trans. Graph. (SIGGRAPH) 24(3), 519-526 (2005)  14. Liu, Z., Yeh, R.A., Tang, X., Liu, Y., Agarwala, A.: Video Frame Synthesis using  Deep Voxel Flow. In: IEEE Int. Conf. on Comput. Vis. (2017)  15. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic segmentation. In: IEEE Conf. on Comput. Vis. and Pattern Recognit. (2015) 16. Mathieu, M., Couprie, C., LeCun, Y.: Deep multi-scale video prediction beyond  mean square error. Int. Conf. on Learn. Representations (2016)  17. Niklaus, S., Mai, L., Liu, F.: Video Frame Interpolation via Adaptive Convolution.  IEEE Conf. on Comput. Vis. and Pattern Recognit. (2017)  18. Niklaus, S., Mai, L., Liu, F.: Video Frame Interpolation via Adaptive Separable  Convolution. In: IEEE Int. Conf. on Comput. Vis. (2017)  19. Odena, A., Dumoulin, V., Olah, C.: Deconvolution and checkerboard artifacts.  Distill 1(10), e3 (2016)  20. Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 (2015)   16  T. Oh et al.  21. Sajjadi, M.S., Sch\u00a8olkopf, B., Hirsch, M.: EnhanceNet: Single image super-resolution through automated texture synthesis. In: IEEE Int. Conf. on Comput. Vis. (2017) 22. Srivastava, N., Mansimov, E., Salakhudinov, R.: Unsupervised learning of video  representations using lstms. In: Int. Conf. on Mach. Learn. (2015)  23. Villegas, R., Yang, J., Hong, S., Lin, X., Lee, H.: Decomposing motion and content for natural video sequence prediction. In: Int. Conf. on Learn. Representations (2017)  24. Wadhwa, N., Rubinstein, M., Durand, F., Freeman, W.T.: Phase-based video mo-  tion processing. ACM Trans. Graph. (SIGGRAPH) 32(4), 80 (2013)  25. Wadhwa, N., Rubinstein, M., Durand, F., Freeman, W.T.: Riesz pyramids for fast phase-based video magnification. In: IEEE Int. Conf. on Comput. Photogr. (2014) 26. Wang, T., Zhu, J., Kalantari, N.K., Efros, A.A., Ramamoorthi, R.: Light field video capture using a learning-based hybrid imaging system. ACM Trans. Graph. (SIGGRAPH) 36(4), 133:1-133:13 (2017)  27. Wu, H.Y., Rubinstein, M., Shih, E., Guttag, J., Durand, F., Freeman, W.: Eulerian video magnification for revealing subtle changes in the world. ACM Trans. Graph. (SIGGRAPH) 31(4), 65-8 (2012)  28. Zhang, Y., Pintea, S.L., van Gemert, J.C.: Video Acceleration Magnification. In:  IEEE Conf. on Comput. Vis. and Pattern Recognit. (2017)"}