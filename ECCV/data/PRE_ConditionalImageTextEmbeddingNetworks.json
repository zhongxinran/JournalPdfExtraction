{"1": "1. Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D.:  VQA: Visual Question Answering. In: ICCV (2015)  2. Babenko, B., Branson, S., Belongie, S.: Similarity metrics for categorization: from  monolithic to category specific. In: ICCV (2009)  3. Chen, K., Kovvuri, R., Gao, J., Nevatia, R.: MSRC: Multimodal spatial regression  with semantic context for phrase grounding. In: ICMR (2017)  4. Chen, K., Kovvuri, R., Nevatia, R.: Query-guided regression network with context  policy for phrase grounding. In: ICCV (2017)  5. Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A.: The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results. http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html (2012)  6. Fang, H., Gupta, S., Iandola, F., Srivastava, R., Deng, L., Dollar, P., Gao, J., He, X., Mitchell, M., Platt, J., Zitnick, L., Zweig, G.: From captions to visual concepts and back. In: CVPR (2015)  7. Fukui, A., Park, D.H., Yang, D., Rohrbach, A., Darrell, T., Rohrbach, M.: Multi- modal compact bilinear pooling for visual question answering and visual grounding. In: EMNLP (2016)  8. Girshick, R.: Fast r-cnn. In: ICCV (2015) 9. Gordo, A., Almazan, J., Revaud, J., Larlus, D.: Deep image retrieval: Learning  global representations for image search. In: ECCV (2016)  10. Hu, R., Xu, H., Rohrbach, M., Feng, J., Saenko, K., Darrell, T.: Natural language  object retrieval. In: CVPR (2016)  11. Io\ufb00e, S., Szegedy, C.: Batch normalization: Accelerating deep network training by  reducing internal covariate shift. In: ICML (2015)  12. Johnson, J., Karpathy, A., Fei-Fei, L.: Densecap: Fully convolutional localization  networks for dense captioning. In: CVPR (2016)  13. Johnson, J., Krishna, R., Stark, M., Li, L.J., Shamma, D.A., Bernstein, M., Fei-Fei,  L.: Image retrieval using scene graphs. In: CVPR (2015)  14. Karpathy, A., Fei-Fei, L.: Deep visual-semantic alignments for generating image  descriptions. In: CVPR (2015)  15. Kazemzadeh, S., Ordonez, V., Matten, M., Berg, T.: Referitgame: Referring to  objects in photographs of natural scenes. In: EMNLP (2014)  16. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: Interna-  tional Conference for Learning Representations (2015)  17. Klein, B., Lev, G., Sadeh, G., Wolf, L.: Associating neural word embeddings with  deep image representations using fisher vector. In: CVPR (2015)  18. Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalan- tidis, Y., Li, L.J., Shamma, D.A., Bernstein, M., Fei-Fei, L.: Visual genome: Con- necting language and vision using crowdsourced dense image annotations. IJCV (2017)  19. Liu, C., Mao, J., Sha, F., Yuille, A.: Attention correctness in neural image cap-  20. Liu, J., Wang, L., Yang, M.H.: Referring expression generation and comprehension  21. Luo, R., Shakhnarovich, G.: Comprehension-guided referring expressions. In:  tioning. In: AAAI (2017)  via attributes. In: ICCV (2017)  CVPR (2017)   Conditional Image-Text Embedding NetworksReferences  1. Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D.:  VQA: Visual Question Answering. In: ICCV (2015)  2. Babenko, B., Branson, S., Belongie, S.: Similarity metrics for categorization: from  monolithic to category specific. In: ICCV (2009)  3. Chen, K., Kovvuri, R., Gao, J., Nevatia, R.: MSRC: Multimodal spatial regression  with semantic context for phrase grounding. In: ICMR (2017)  4. Chen, K., Kovvuri, R., Nevatia, R.: Query-guided regression network with context  policy for phrase grounding. In: ICCV (2017)  5. Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A.: The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results. http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html (2012)  6. Fang, H., Gupta, S., Iandola, F., Srivastava, R., Deng, L., Dollar, P., Gao, J., He, X., Mitchell, M., Platt, J., Zitnick, L., Zweig, G.: From captions to visual concepts and back. In: CVPR (2015)  7. Fukui, A., Park, D.H., Yang, D., Rohrbach, A., Darrell, T., Rohrbach, M.: Multi- modal compact bilinear pooling for visual question answering and visual grounding. In: EMNLP (2016)  8. Girshick, R.: Fast r-cnn. In: ICCV (2015) 9. Gordo, A., Almazan, J., Revaud, J., Larlus, D.: Deep image retrieval: Learning  global representations for image search. In: ECCV (2016)  10. Hu, R., Xu, H., Rohrbach, M., Feng, J., Saenko, K., Darrell, T.: Natural language  object retrieval. In: CVPR (2016)  11. Io\ufb00e, S., Szegedy, C.: Batch normalization: Accelerating deep network training by  reducing internal covariate shift. In: ICML (2015)  12. Johnson, J., Karpathy, A., Fei-Fei, L.: Densecap: Fully convolutional localization  networks for dense captioning. In: CVPR (2016)  13. Johnson, J., Krishna, R., Stark, M., Li, L.J., Shamma, D.A., Bernstein, M., Fei-Fei,  L.: Image retrieval using scene graphs. In: CVPR (2015)  14. Karpathy, A., Fei-Fei, L.: Deep visual-semantic alignments for generating image  descriptions. In: CVPR (2015)  15. Kazemzadeh, S., Ordonez, V., Matten, M., Berg, T.: Referitgame: Referring to  objects in photographs of natural scenes. In: EMNLP (2014)  16. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: Interna-  tional Conference for Learning Representations (2015)  17. Klein, B., Lev, G., Sadeh, G., Wolf, L.: Associating neural word embeddings with  deep image representations using fisher vector. In: CVPR (2015)  18. Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalan- tidis, Y., Li, L.J., Shamma, D.A., Bernstein, M., Fei-Fei, L.: Visual genome: Con- necting language and vision using crowdsourced dense image annotations. IJCV (2017)  19. Liu, C., Mao, J., Sha, F., Yuille, A.: Attention correctness in neural image cap-  20. Liu, J., Wang, L., Yang, M.H.: Referring expression generation and comprehension  21. Luo, R., Shakhnarovich, G.: Comprehension-guided referring expressions. In:  tioning. In: AAAI (2017)  via attributes. In: ICCV (2017)  CVPR (2017)   16  B. A. Plummer et al .  22. Mao, J., Huang, J., Toshev, A., Camburu, O., Yuille, A., Murphy, K.: Generation  and comprehension of unambiguous object descriptions. In: CVPR (2016)  23. Mikolov, T., Chen, K., Corrado, G., Dean, J.: E\ufb03cient estimation of word repre-  sentations in vector space. arXiv:1301.3781 (2013)  24. Plummer, B.A., Mallya, A., Cervantes, C.M., Hockenmaier, J., Lazebnik, S.: Phrase localization and visual relationship detection with comprehensive image-language cues. In: ICCV (2017)  25. Plummer, B.A., Wang, L., Cervantes, C.M., Caicedo, J.C., Hockenmaier, J., Lazeb- nik, S.: Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models. IJCV 123(1), 74-93 (2017)  26. Radenovi, F., Tolias, G., Chum, O.: Cnn image retrieval learns from bow: Unsu-  pervised fine-tuning with hard examples. In: ECCV (2016)  27. Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: Towards real-time object  detection with region proposal networks. In: NIPS (2015)  28. Rohrbach, A., Rohrbach, M., Hu, R., Darrell, T., Schiele, B.: Grounding of textual  phrases in images by reconstruction. In: ECCV (2016)  29. Tommasi, T., Mallya, A., Plummer, B.A., Lazebnik, S., Berg, A.C., Berg, T.L.:  Solving visual madlibs with multiple cues. In: BMVC (2016)  30. Veit, A., Belongie, S., Karaletsos, T.: Conditional similarity networks. In: CVPR  31. Wang, L., Li, Y., Lazebnik, S.: Learning deep structure-preserving image-text em-  (2017)  beddings. In: CVPR (2016)  32. Wang, L., Li, Y., Lazebnik, S.: Learning two-branch neural networks for image-text  33. Wang, M., Azab, M., Kojima, N., Mihalcea, R., Deng, J.: Structured matching for  matching tasks. arXiv:1704.03470 (2017)  phrase localization. In: ECCV (2016)  34. Xu, K., Ba, J., Kiros, R., Courville, A., Salakhutdinov, R., Zemel, R., Bengio, Y.: Show, attend and tell: Neural image caption generation with visual attention. In: ICML (2015)  35. Yeh, R.A., Xiong, J., mei W. Hwu, W., Do, M.N., Schwing, A.G.: Interpretable and globally optimal prediction for textual grounding using image concepts. In: NIPS (2017)  36. Yu, L., Poirson, P., Yang, S., Berg, A.C., Berg, T.L.: Modeling context in referring  expressions. In: ECCV (2016)  37. Zhang, Y., Yuan, L., Guo, Y., He, Z., Huang, I.A., Lee, H.: Discriminative bimodal networks for visual localization and detection with natural language queries. In: CVPR (2017)  38. Zitnick, C.L., Doll\u00b4ar, P.: Edge boxes: Locating object proposals from edges. In:  ECCV (2014)"}