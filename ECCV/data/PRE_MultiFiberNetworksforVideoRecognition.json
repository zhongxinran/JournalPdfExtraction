{"1": "1. Carreira, J., Zisserman, A.: Quo vadis, action recognition? a new model and the In: 2017 IEEE Conference on Computer Vision and Pattern  kinetics dataset. Recognition (CVPR), IEEE (2017) 4724-4733  2. Tran, D., Wang, H., Torresani, L., Ray, J., LeCun, Y., Paluri, M.: A closer arXiv preprint  look at spatiotemporal convolutions for action recognition. arXiv:1711.11248 (2017)  3. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. (2016) 770-778  4. Girshick, R.: Fast r-cnn. arXiv preprint arXiv:1504.08083 (2015) 5. Chen, L.C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L.: Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. arXiv preprint arXiv:1606.00915 (2016)  6. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large- scale video classification with convolutional neural networks. In: Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. (2014) 1725-1732 7. Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M.: Learning spatiotem- poral features with 3d convolutional networks. In: Computer Vision (ICCV), 2015 IEEE International Conference on, IEEE (2015) 4489-4497  8. Xie, S., Sun, C., Huang, J., Tu, Z., Murphy, K.: Rethinking spatiotemporal feature  learning for video understanding. arXiv preprint arXiv:1712.04851 (2017)  9. Hara, K., Kataoka, H., Satoh, Y.: Can spatiotemporal 3d cnns retrace the history of 2d cnns and imagenet. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA. (2018) 18-22  10. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014)  11. Shou, Z., Wang, D., Chang, S.F.: Temporal action localization in untrimmed videos  via multi-stage cnns. In: CVPR. (2016)  12. Shou, Z., Chan, J., Zareian, A., Miyazawa, K., Chang, S.F.: Cdc: Convolutional- de-convolutional networks for precise temporal action localization in untrimmed videos. In: CVPR. (2017)  13. Simonyan, K., Zisserman, A.: Two-stream convolutional networks for action recog- nition in videos. In: Advances in neural information processing systems. (2014) 568-576  14. Feichtenhofer, C., Pinz, A., Zisserman, A.: Convolutional two-stream network IEEE Conference on Computer Vision and  fusion for video action recognition. Pattern Recognition (CVPR) (2016)  15. Ng, J.Y.H., Hausknecht, M., Vijayanarasimhan, S., Vinyals, O., Monga, R., Toderici, G.: Beyond short snippets: Deep networks for video classification. In: Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, IEEE (2015) 4694-4702  16. Wang, L., Li, W., Li, W., Van Gool, L.: Appearance-and-relation networks for  video classification. arXiv preprint arXiv:1711.09125 (2017)  17. Tran, A., Cheong, L.F.: Two-stream \ufb02ow-guided convolutional attention networks for action recognition. International Conference on Computer Vision (2017) 18. Wu, C.Y., Zaheer, M., Hu, H., Manmatha, R., Smola, A.J., Kr\u00a8ahenb\u00a8uhl, P.: Com-  pressed video action recognition. arXiv preprint arXiv:1712.00636 (2017)   Multi-Fiber NetworksReferences  1. Carreira, J., Zisserman, A.: Quo vadis, action recognition? a new model and the In: 2017 IEEE Conference on Computer Vision and Pattern  kinetics dataset. Recognition (CVPR), IEEE (2017) 4724-4733  2. Tran, D., Wang, H., Torresani, L., Ray, J., LeCun, Y., Paluri, M.: A closer arXiv preprint  look at spatiotemporal convolutions for action recognition. arXiv:1711.11248 (2017)  3. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. (2016) 770-778  4. Girshick, R.: Fast r-cnn. arXiv preprint arXiv:1504.08083 (2015) 5. Chen, L.C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L.: Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. arXiv preprint arXiv:1606.00915 (2016)  6. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large- scale video classification with convolutional neural networks. In: Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. (2014) 1725-1732 7. Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M.: Learning spatiotem- poral features with 3d convolutional networks. In: Computer Vision (ICCV), 2015 IEEE International Conference on, IEEE (2015) 4489-4497  8. Xie, S., Sun, C., Huang, J., Tu, Z., Murphy, K.: Rethinking spatiotemporal feature  learning for video understanding. arXiv preprint arXiv:1712.04851 (2017)  9. Hara, K., Kataoka, H., Satoh, Y.: Can spatiotemporal 3d cnns retrace the history of 2d cnns and imagenet. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA. (2018) 18-22  10. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014)  11. Shou, Z., Wang, D., Chang, S.F.: Temporal action localization in untrimmed videos  via multi-stage cnns. In: CVPR. (2016)  12. Shou, Z., Chan, J., Zareian, A., Miyazawa, K., Chang, S.F.: Cdc: Convolutional- de-convolutional networks for precise temporal action localization in untrimmed videos. In: CVPR. (2017)  13. Simonyan, K., Zisserman, A.: Two-stream convolutional networks for action recog- nition in videos. In: Advances in neural information processing systems. (2014) 568-576  14. Feichtenhofer, C., Pinz, A., Zisserman, A.: Convolutional two-stream network IEEE Conference on Computer Vision and  fusion for video action recognition. Pattern Recognition (CVPR) (2016)  15. Ng, J.Y.H., Hausknecht, M., Vijayanarasimhan, S., Vinyals, O., Monga, R., Toderici, G.: Beyond short snippets: Deep networks for video classification. In: Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, IEEE (2015) 4694-4702  16. Wang, L., Li, W., Li, W., Van Gool, L.: Appearance-and-relation networks for  video classification. arXiv preprint arXiv:1711.09125 (2017)  17. Tran, A., Cheong, L.F.: Two-stream \ufb02ow-guided convolutional attention networks for action recognition. International Conference on Computer Vision (2017) 18. Wu, C.Y., Zaheer, M., Hu, H., Manmatha, R., Smola, A.J., Kr\u00a8ahenb\u00a8uhl, P.: Com-  pressed video action recognition. arXiv preprint arXiv:1712.00636 (2017)   16  Y. Chen, Y. Kalantidis, J. Li, S. Yan and J. Feng  19. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large- scale video classification with convolutional neural networks. In: CVPR. (2014) 20. Kay, W., Carreira, J., Simonyan, K., Zhang, B., Hillier, C., Vijayanarasimhan, S., Viola, F., Green, T., Back, T., Natsev, P., et al.: The kinetics human action video dataset. arXiv preprint arXiv:1705.06950 (2017)  21. Shou, Z., Gao, H., Zhang, L., Miyazawa, K., Chang, S.F.: Autoloc: Weakly-  supervised temporal action localization in untrimmed videos. In: ECCV. (2018)  22. Shou, Z., Pan, J., Chan, J., Miyazawa, K., Mansour, H., Vetro, A., Giro-i Nieto, X., Chang, S.F.: Online detection of action start in untrimmed, streaming videos. In: ECCV. (2018)  23. Tran, D., Ray, J., Shou, Z., Chang, S.F., Paluri, M.: Convnet architecture search for spatiotemporal feature learning. arXiv preprint arXiv:1708.05038 (2017) 24. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D.,  Vanhoucke, V., Rabinovich, A., et al.: Going deeper with convolutions  25. Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., An- dreetto, M., Adam, H.: Mobilenets: E\ufb03cient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861 (2017)  26. Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.C.: Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmenta- tion. arXiv preprint arXiv:1801.04381 (2018)  27. Zhang, X., Zhou, X., Lin, M., Sun, J.: Shu\ufb04enet: An extremely e\ufb03cient convolu- tional neural network for mobile devices. arXiv preprint arXiv:1707.01083 (2017) 28. Xie, S., Girshick, R., Doll\u00b4ar, P., Tu, Z., He, K.: Aggregated residual transformations for deep neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, IEEE (2017) 5987-5995  29. Ahmed, K., Torresani, L.: Maskconnect: Connectivity learning by gradient descent.  In: European Conference on Computer Vision (ECCV). (2018)  30. Chollet, F.: Xception: Deep learning with depthwise separable convolutions. arXiv  preprint (2017) 1610-02357  31. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep con- volutional neural networks. In: Advances in neural information processing systems. (2012) 1097-1105  32. Chen, Y., Li, J., Xiao, H., Jin, X., Yan, S., Feng, J.: Dual path networks. Advances in Neural Information Processing Systems. (2017) 4470-4478  In:  33. Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao, T., Xu, B., Zhang, C., Zhang, Z.: Mxnet: A \ufb02exible and e\ufb03cient machine learning library for hetero- geneous distributed systems. arXiv preprint arXiv:1512.01274 (2015)  34. Soomro, K., Zamir, A.R., Shah, M.: Ucf101: A dataset of 101 human actions classes  from videos in the wild. arXiv preprint arXiv:1212.0402 (2012)  35. Kuehne, H., Jhuang, H., Garrote, E., Poggio, T., Serre, T.: Hmdb: a large video database for human motion recognition. In: Computer Vision (ICCV), 2011 IEEE International Conference on, IEEE (2011) 2556-2563  36. Paszke, A., Gross, S., Chintala, S., Chanan, G.: Pytorch (2017) 37. Feichtenhofer, C., Pinz, A., Wildes, R.P.: Spatiotemporal multiplier networks for In: 2017 IEEE Conference on Computer Vision and  video action recognition. Pattern Recognition (CVPR), IEEE (2017) 7445-7454  38. Wang, L., Xiong, Y., Wang, Z., Qiao, Y., Lin, D., Tang, X., Van Gool, L.: Tem- poral segment networks: Towards good practices for deep action recognition. In: European Conference on Computer Vision, Springer (2016) 20-36"}