{"1": "1. Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghe- mawat, S., Irving, G., Isard, M., et al.: Tensor\ufb02ow: A system for large-scale machine learning. In: OSDI. vol. 16, pp. 265-283 (2016)  2. Aditya, S., Yang, Y., Baral, C., Aloimonos, Y., Ferm\u00a8uller, C.: Image understanding using vision and reasoning through scene description graph. Computer Vision and Image Understanding (2017)  3. Albrecht, J.S., Hwa, R.: Regression for machine translation evaluation at the sen-  tence level. Machine Translation 22(1-2), 1 (2008)  4. Anderson, P., Fernando, B., Johnson, M., Gould, S.: Spice: Semantic propositional image caption evaluation. In: European Conference on Computer Vision. pp. 382- 398. Springer (2016)  5. Banerjee, S., Lavie, A.: Meteor: An automatic metric for mt evaluation with im- proved correlation with human judgments. In: Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summa- rization. pp. 65-72 (2005)  6. Bojar, O., Graham, Y., Kamran, A., Stanojevi\u00b4c, M.: Results of the wmt16 met- rics shared task. In: Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers. vol. 2, pp. 199-231 (2016)  7. Bojar, O., Helcl, J., Kocmi, T., Libovick`y, J., Musil, T.: Results of the wmt17 neural mt training task. In: Proceedings of the Second Conference on Machine Translation. pp. 525-533 (2017)  8. Chen, X., Fang, H., Lin, T.Y., Vedantam, R., Gupta, S., Doll\u00b4ar, P., Zitnick, C.L.: Microsoft coco captions: Data collection and evaluation server. arXiv preprint arXiv:1504.00325 (2015)  9. Corston-Oliver, S., Gamon, M., Brockett, C.: A machine learning approach to the automatic evaluation of machine translation. In: Proceedings of the 39th Annual Meeting on Association for Computational Linguistics. pp. 148-155. Association for Computational Linguistics (2001)  10. Denkowski, M., Lavie, A.: Meteor universal: Language specific translation evalua- tion for any target language. In: Proceedings of the ninth workshop on statistical machine translation. pp. 376-380 (2014)  11. Elliott, D., Keller, F.: Comparing automatic evaluation measures for image de- scription. In: Proceedings of the 52nd Annual Meeting of the Association for Com- putational Linguistics (Volume 2: Short Papers). vol. 2, pp. 452-457 (2014) 12. Fang, H., Gupta, S., Iandola, F., Srivastava, R., Deng, L., Doll\u00b4ar, P., Gao, J., He, X., Mitchell, M., Platt, J., et al.: From captions to visual concepts and back (2015) 13. Gim\u00b4enez, J., M`arquez, L.: Linguistic features for automatic evaluation of heteroge- nous mt systems. In: Proceedings of the Second Workshop on Statistical Machine Translation. pp. 256-264. Association for Computational Linguistics (2007) 14. Glorot, X., Bengio, Y.: Understanding the di\ufb03culty of training deep feedforward neural networks. In: Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics. pp. 249-256 (2010)  15. Guzm\u00b4an, F., Joty, S., M`arquez, L., Nakov, P.: Pairwise neural machine translation evaluation. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). vol. 1, pp. 805-814 (2015)  16. Guzm\u00b4an, F., Joty, S., M`arquez, L., Nakov, P.: Machine translation evaluation with  neural networks. Computer Speech & Language 45, 180-200 (2017)   NNEval: Neural Network based Evaluation Metric for Image CaptioningReferences  1. Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghe- mawat, S., Irving, G., Isard, M., et al.: Tensor\ufb02ow: A system for large-scale machine learning. In: OSDI. vol. 16, pp. 265-283 (2016)  2. Aditya, S., Yang, Y., Baral, C., Aloimonos, Y., Ferm\u00a8uller, C.: Image understanding using vision and reasoning through scene description graph. Computer Vision and Image Understanding (2017)  3. Albrecht, J.S., Hwa, R.: Regression for machine translation evaluation at the sen-  tence level. Machine Translation 22(1-2), 1 (2008)  4. Anderson, P., Fernando, B., Johnson, M., Gould, S.: Spice: Semantic propositional image caption evaluation. In: European Conference on Computer Vision. pp. 382- 398. Springer (2016)  5. Banerjee, S., Lavie, A.: Meteor: An automatic metric for mt evaluation with im- proved correlation with human judgments. In: Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summa- rization. pp. 65-72 (2005)  6. Bojar, O., Graham, Y., Kamran, A., Stanojevi\u00b4c, M.: Results of the wmt16 met- rics shared task. In: Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers. vol. 2, pp. 199-231 (2016)  7. Bojar, O., Helcl, J., Kocmi, T., Libovick`y, J., Musil, T.: Results of the wmt17 neural mt training task. In: Proceedings of the Second Conference on Machine Translation. pp. 525-533 (2017)  8. Chen, X., Fang, H., Lin, T.Y., Vedantam, R., Gupta, S., Doll\u00b4ar, P., Zitnick, C.L.: Microsoft coco captions: Data collection and evaluation server. arXiv preprint arXiv:1504.00325 (2015)  9. Corston-Oliver, S., Gamon, M., Brockett, C.: A machine learning approach to the automatic evaluation of machine translation. In: Proceedings of the 39th Annual Meeting on Association for Computational Linguistics. pp. 148-155. Association for Computational Linguistics (2001)  10. Denkowski, M., Lavie, A.: Meteor universal: Language specific translation evalua- tion for any target language. In: Proceedings of the ninth workshop on statistical machine translation. pp. 376-380 (2014)  11. Elliott, D., Keller, F.: Comparing automatic evaluation measures for image de- scription. In: Proceedings of the 52nd Annual Meeting of the Association for Com- putational Linguistics (Volume 2: Short Papers). vol. 2, pp. 452-457 (2014) 12. Fang, H., Gupta, S., Iandola, F., Srivastava, R., Deng, L., Doll\u00b4ar, P., Gao, J., He, X., Mitchell, M., Platt, J., et al.: From captions to visual concepts and back (2015) 13. Gim\u00b4enez, J., M`arquez, L.: Linguistic features for automatic evaluation of heteroge- nous mt systems. In: Proceedings of the Second Workshop on Statistical Machine Translation. pp. 256-264. Association for Computational Linguistics (2007) 14. Glorot, X., Bengio, Y.: Understanding the di\ufb03culty of training deep feedforward neural networks. In: Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics. pp. 249-256 (2010)  15. Guzm\u00b4an, F., Joty, S., M`arquez, L., Nakov, P.: Pairwise neural machine translation evaluation. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). vol. 1, pp. 805-814 (2015)  16. Guzm\u00b4an, F., Joty, S., M`arquez, L., Nakov, P.: Machine translation evaluation with  neural networks. Computer Speech & Language 45, 180-200 (2017)   16  Naeha Sharif, Lyndon White, Mohammed Bennamoun, Syed Afaq Ali Shah  17. Hodosh, M., Hockenmaier, J.: Focused evaluation for image description with binary forced-choice tasks. In: Proceedings of the 5th Workshop on Vision and Language. pp. 19-28 (2016)  18. Hodosh, M., Young, P., Hockenmaier, J.: Framing image description as a rank- ing task: Data, models and evaluation metrics. Journal of Artificial Intelligence Research 47, 853-899 (2013)  19. Karpathy, A., Fei-Fei, L.: Deep visual-semantic alignments for generating image de- scriptions. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 3128-3137 (2015)  20. Karpathy, A., Joulin, A., Fei-Fei, L.F.: Deep fragment embeddings for bidirectional image sentence mapping. In: Advances in neural information processing systems. pp. 1889-1897 (2014)  21. Kilickaya, M., Erdem, A., Ikizler-Cinbis, N., Erdem, E.: Re-evaluating automatic  metrics for image captioning. arXiv preprint arXiv:1612.07600 (2016)  22. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint  arXiv:1412.6980 (2014)  23. Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalantidis, Y., Li, L.J., Shamma, D.A., et al.: Visual genome: Connecting language and vision using crowdsourced dense image annotations. International Journal of Computer Vision 123(1), 32-73 (2017)  24. Kulesza, A., Shieber, S.M.: A learning approach to improving sentence-level mt evaluation. In: Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation. pp. 75-84 (2004)  25. Kulkarni, G., Premraj, V., Ordonez, V., Dhar, S., Li, S., Choi, Y., Berg, A.C., Berg, T.L.: Babytalk: Understanding and generating simple image descriptions. IEEE Transactions on Pattern Analysis and Machine Intelligence 35(12), 2891- 2903 (2013)  26. Kusner, M., Sun, Y., Kolkin, N., Weinberger, K.: From word embeddings to doc- ument distances. In: International Conference on Machine Learning. pp. 957-966 (2015)  27. Lin, C.Y.: Rouge: A package for automatic evaluation of summaries. Text Summa-  rization Branches Out (2004)  28. Liu, S., Zhu, Z., Ye, N., Guadarrama, S., Murphy, K.: Improved image captioning via policy gradient optimization of spider. arXiv preprint arXiv:1612.00370 (2016) 29. Lu, J., Xiong, C., Parikh, D., Socher, R.: Knowing when to look: Adaptive attention via a visual sentinel for image captioning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). vol. 6 (2017)  30. Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Distributed repre- sentations of words and phrases and their compositionality. In: Advances in neural information processing systems. pp. 3111-3119 (2013)  31. van Miltenburg, E., Elliott, D.: Room for improvement in automatic image de-  scription: an error analysis. arXiv preprint arXiv:1704.04198 (2017) regularization,  Feature  invariance.  32. Ng, A.Y.: tional Conference York, http://doi.acm.org/10.1145/1015330.1015435  l1 selection, In: Proceedings on Machine Learning.  (2004).  USA  NY,  vs. of pp.  l2 the Twenty-first 78-.  rota- International ICML \u201904, ACM, New https://doi.org/10.1145/1015330.1015435,  and  33. Papineni, K., Roukos, S., Ward, T., Zhu, W.J.: Bleu: a method for automatic evaluation of machine translation. In: Proceedings of the 40th annual meeting on association for computational linguistics. pp. 311-318. Association for Computa- tional Linguistics (2002)   NNEval: Neural Network based Evaluation Metric for Image Captioning34. Plummer, B.A., Wang, L., Cervantes, C.M., Caicedo, J.C., Hockenmaier, J., Lazeb- nik, S.: Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models. In: Computer Vision (ICCV), 2015 IEEE International Conference on. pp. 2641-2649. IEEE (2015)  35. \u02c7Reh\u02dau\u02c7rek, R., Sojka, P.: Software Framework for Topic Modelling with Large the LREC 2010 Workshop on New Chal- Corpora. lenges for NLP Frameworks. pp. 45-50. ELRA, Valletta, Malta (May 2010), http://is.muni.cz/publication/884893/en  In: Proceedings of  36. Tillmann, C., Vogel, S., Ney, H., Zubiaga, A., Sawaf, H.: Accelerated dp based search for statistical translation. In: Fifth European Conference on Speech Com- munication and Technology (1997)  37. Vedantam, R., Lawrence Zitnick, C., Parikh, D.: Cider: Consensus-based image description evaluation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 4566-4575 (2015)  38. Vinyals, O., Toshev, A., Bengio, S., Erhan, D.: Show and tell: A neural image caption generator. In: Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on. pp. 3156-3164. IEEE (2015)  39. Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., Bengio, Y.: Show, attend and tell: Neural image caption generation with visual attention. In: International Conference on Machine Learning. pp. 2048-2057 (2015) 40. Yao, T., Pan, Y., Li, Y., Qiu, Z., Mei, T.: Boosting image captioning with at-  tributes. OpenReview 2(5), 8 (2016)  41. You, Q., Jin, H., Luo, J.: Image captioning at will: A versatile scheme for e\ufb00ectively injecting sentiments into image descriptions. arXiv preprint arXiv:1801.10121 (2018)  42. You, Q., Jin, H., Wang, Z., Fang, C., Luo, J.: Image captioning with semantic attention. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4651-4659 (2016)  43. Young, P., Lai, A., Hodosh, M., Hockenmaier, J.: From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions. Transactions of the Association for Computational Linguistics 2, 67-78 (2014) 44. Zhang, Y., Vogel, S.: Significance tests of automatic machine translation evaluation  metrics. Machine Translation 24(1), 51-65 (2010)"}