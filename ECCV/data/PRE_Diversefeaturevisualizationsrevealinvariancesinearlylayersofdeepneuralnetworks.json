{"1": "1. Adelson, E.H., Bergen, perception of motion. https://doi.org/10.1364/JOSAA.2.000284  Spatiotemporal J. Opt. Soc. Am. A 2(2),  J.R.:  energy models  284-299  for  the (1985).  2. Berkes, P., Wiskott, L.: Slow feature analysis yields a rich repertoire of complex  cell properties. Journal of vision 5(6), 9-9 (2005)  3. Bethge, M., Gerwinn, S., Macke, J.H.: Unsupervised learning of a steerable basis for invariant image representations. In: Human Vision and Electronic Imaging XII. vol. 6492, p. 64920C. International Society for Optics and Photonics (2007)  4. Cadena, S.A., Denield, G.H., Walker, E.Y., Gatys, L.A., Tolias, A.S., Bethge, M., Ecker, A.S.: Deep convolutional models improve predictions of macaque v1 responses to natural images. bioRxiv (2017). https://doi.org/10.1101/201764 5. Cadieu, C.F., Hong, H., Yamins, D.L., Pinto, N., Ardila, D., Solomon, E.A., Ma- jaj, N.J., DiCarlo, J.J.: Deep neural networks rival the representation of primate IT cortex for core visual object recognition. PLoS computational biology 10(12), e1003963 (2014), 00152  6. Erhan, D., Bengio, Y., Courville, A., Vincent, P.: Visualizing higher-layer features of a deep network. Tech. Rep. 1341, University of Montreal (Jun 2009), also pre- sented at the ICML 2009 Workshop on Learning Feature Hierarchies, Montr\u00e9al, Canada.  7. Gatys, L., Ecker, A.S., Bethge, M.: Texture synthesis using convolutional neural networks. In: Advances in Neural Information Processing Systems. pp. 262-270 (2015)  8. Gatys, L.A., Ecker, A.S., Bethge, M.: Image style transfer using convolutional neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2414-2423 (2016)  9. Goodfellow, I., Lee, H., Le, Q.V., Saxe, A., Ng, A.Y.: Measuring invariances in deep networks. In: Advances in neural information processing systems. pp. 646- 654 (2009)  10. G\u00fc\u00e7l\u00fc, U., van Gerven, M.A.J.: Deep neural networks reveal a gradient in the com- plexity of neural representations across the ventral stream. Journal of Neuroscience 35(27), 10005-10014 (2015). https://doi.org/10.1523/JNEUROSCI.5023-14.2015 11. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016)  12. Hubel, D.H., Wiesel, T.N.: Receptive ields, binocular interaction and functional architecture in the cat\u2019s visual cortex. The Journal of physiology 160(1), 106 (1962), 09139  13. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint  arXiv:1412.6980 (2014)  14. Kriegeskorte, N.: Deep neural networks: A new framework for modeling biological vision and brain information processing. Annual Review of Vision Science 1(1), 417-446 (2015). https://doi.org/10.1146/annurev-vision-082114-035447  15. Lies, J.P., H\u00e4fner, R.M., Bethge, M.: Slowness and sparseness have diverging efects on complex cell learning. PLoS computational biology 10(3), e1003468 (2014) 16. Mahendran, A., Vedaldi, A.: Understanding deep image representations by invert- ing them. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 5188-5196 (2015)   Diverse feature visualizations of early layers of CNNsReferences  1. Adelson, E.H., Bergen, perception of motion. https://doi.org/10.1364/JOSAA.2.000284  Spatiotemporal J. Opt. Soc. Am. A 2(2),  J.R.:  energy models  284-299  for  the (1985).  2. Berkes, P., Wiskott, L.: Slow feature analysis yields a rich repertoire of complex  cell properties. Journal of vision 5(6), 9-9 (2005)  3. Bethge, M., Gerwinn, S., Macke, J.H.: Unsupervised learning of a steerable basis for invariant image representations. In: Human Vision and Electronic Imaging XII. vol. 6492, p. 64920C. International Society for Optics and Photonics (2007)  4. Cadena, S.A., Denield, G.H., Walker, E.Y., Gatys, L.A., Tolias, A.S., Bethge, M., Ecker, A.S.: Deep convolutional models improve predictions of macaque v1 responses to natural images. bioRxiv (2017). https://doi.org/10.1101/201764 5. Cadieu, C.F., Hong, H., Yamins, D.L., Pinto, N., Ardila, D., Solomon, E.A., Ma- jaj, N.J., DiCarlo, J.J.: Deep neural networks rival the representation of primate IT cortex for core visual object recognition. PLoS computational biology 10(12), e1003963 (2014), 00152  6. Erhan, D., Bengio, Y., Courville, A., Vincent, P.: Visualizing higher-layer features of a deep network. Tech. Rep. 1341, University of Montreal (Jun 2009), also pre- sented at the ICML 2009 Workshop on Learning Feature Hierarchies, Montr\u00e9al, Canada.  7. Gatys, L., Ecker, A.S., Bethge, M.: Texture synthesis using convolutional neural networks. In: Advances in Neural Information Processing Systems. pp. 262-270 (2015)  8. Gatys, L.A., Ecker, A.S., Bethge, M.: Image style transfer using convolutional neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2414-2423 (2016)  9. Goodfellow, I., Lee, H., Le, Q.V., Saxe, A., Ng, A.Y.: Measuring invariances in deep networks. In: Advances in neural information processing systems. pp. 646- 654 (2009)  10. G\u00fc\u00e7l\u00fc, U., van Gerven, M.A.J.: Deep neural networks reveal a gradient in the com- plexity of neural representations across the ventral stream. Journal of Neuroscience 35(27), 10005-10014 (2015). https://doi.org/10.1523/JNEUROSCI.5023-14.2015 11. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016)  12. Hubel, D.H., Wiesel, T.N.: Receptive ields, binocular interaction and functional architecture in the cat\u2019s visual cortex. The Journal of physiology 160(1), 106 (1962), 09139  13. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint  arXiv:1412.6980 (2014)  14. Kriegeskorte, N.: Deep neural networks: A new framework for modeling biological vision and brain information processing. Annual Review of Vision Science 1(1), 417-446 (2015). https://doi.org/10.1146/annurev-vision-082114-035447  15. Lies, J.P., H\u00e4fner, R.M., Bethge, M.: Slowness and sparseness have diverging efects on complex cell learning. PLoS computational biology 10(3), e1003468 (2014) 16. Mahendran, A., Vedaldi, A.: Understanding deep image representations by invert- ing them. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 5188-5196 (2015)   16  SA Cadena, MA Weis, LA Gatys. M Bethge, AS Ecker  17. Mahendran, A., Vedaldi, A.: Visualizing deep convolutional neural networks using natural pre-images. International Journal of Computer Vision 120(3), 233-255 (2016)  18. Nguyen, A., Clune, J., Bengio, Y., Dosovitskiy, A., Yosinski, J.: Plug & play gen- erative networks: Conditional iterative generation of images in latent space. In: CVPR. vol. 2, p. 7 (2017)  19. Nguyen, A., Dosovitskiy, A., Yosinski, J., Brox, T., Clune, J.: Synthesizing the preferred inputs for neurons in neural networks via deep generator networks. In: Advances in Neural Information Processing Systems. pp. 3387-3395 (2016)  20. Nguyen, A., Yosinski, J., Clune, J.: Deep neural networks are easily fooled: High conidence predictions for unrecognizable images. In: The IEEE Conference on Computer Vision and Pattern Recognition (June 2015)  21. Nguyen, A.M., Yosinski, J., Clune, J.: Multifaceted feature visualization: Uncover- ing the diferent types of features learned by each neuron in deep neural networks. Visualization for Deep Learning workshop, ICML (2016)  22. Olah, C., Mordvintsev, A., Schubert, L.: Feature visualization. Distill (2017).  https://doi.org/10.23915/distill.00007  23. van den Oord, A., Kalchbrenner, N., Espeholt, L., Vinyals, O., Graves, A., et al.: Conditional image generation with pixelcnn decoders. In: Advances in Neural In- formation Processing Systems. pp. 4790-4798 (2016)  24. Oord, A.v.d., Kalchbrenner, N., Kavukcuoglu, K.: Pixel recurrent neural networks.  arXiv preprint arXiv:1601.06759 (2016)  25. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115(3), 211-252 (2015). https://doi.org/10.1007/s11263-015-0816-y 26. Rust, N.C., Schwartz, O., Movshon, J.A., Simoncelli, E.P.: Spatiotemporal ele-  ments of macaque v1 receptive ields. Neuron 46(6), 945-956 (2005)  27. Salimans, T., Karpathy, A., Chen, X., Kingma, D.P., Bulatov, Y.: Pixelcnn++: A pixelcnn implementation with discretized logistic mixture likelihood and other modiications. In: Submitted to ICLR 2017 (2016) deep preprint  28. Simonyan, K., Zisserman, A.: Very arXiv  arXiv:1409.1556  for (2014),  convolutional  recognition.  networks  large-scale image http://arxiv.org/abs/1409.1556  29. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fer- gus, R.: Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199 (2013)  30. Theis, L., Bethge, M.: Generative image modeling using spatial lstms. In: Advances  in Neural Information Processing Systems. pp. 1927-1935 (2015)  31. Theis, L., Hosseini, R., Bethge, M.: Mixtures of conditional gaussian scale mixtures  applied to multiscale image representations. PloS one 7(7), e39857 (2012)  32. Wei, D., Zhou, B., Torrabla, A., Freeman, W.: Understanding intra-class knowledge  inside cnn. arXiv preprint arXiv:1507.02379 (2015)  33. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks.  In: European conference on computer vision. pp. 818-833. Springer (2014)"}