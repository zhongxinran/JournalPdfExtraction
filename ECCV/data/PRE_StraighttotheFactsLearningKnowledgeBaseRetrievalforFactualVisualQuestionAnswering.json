{"1": "1. Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalantidis, Y., Li, L.J., Shamma, D.A., et al.: Visual genome: Connecting language and vision using crowdsourced dense image annotations. IJCV (2017)  2. Ren, M., Kiros, R., Zemel, R.: Exploring models and data for image question  answering. In: NIPS. (2015)  3. Zhu, Y., Groth, O., Bernstein, M., Fei-Fei, L.: Visual7W: Grounded Question  Answering in Images. In: CVPR. (2016)  4. Malinowski, M., Fritz, M.: Towards a visual turing challenge. In: NIPS. (2014) 5. Johnson, J., Hariharan, B., van der Maaten, L., Fei-Fei, L., Zitnick, C.L., Girshick, R.: Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. In: CVPR. (2017)  6. Jabri, A., Joulin, A., van der Maaten, L.: Revisiting Visual Question Answering  Baselines. In: ECCV. (2016)  7. Yu, L., Park, E., Berg, A., Berg, T.: Visual Madlibs: Fill in the blank image  generation and question answering. In: ICCV. (2015)  8. Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D.:  VQA: Visual Question Answering. In: ICCV. (2015)  9. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., Parikh, D.: Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In: CVPR. (2017)  10. Gao, H., Mao, J., Zhou, J., Huang, Z., Wang, L., Xu, W.: Are you talking to a machine? Dataset and Methods for Multilingual Image Question Answering. In: NIPS. (2015)  11. Malinowski, M., Fritz, M.: A Multi-World Approach to Question Answering about  Real-World Scenes based on Uncertain Input. In: NIPS. (2014)  12. Malinowski, M., Rohrbach, M., Fritz, M.: Ask your neurons: A neural-based ap-  proach to answering questions about images. In: ICCV. (2015)  13. Hu, R., Andreas, J., Rohrbach, M., Darrell, T., Saenko, K.: Learning to reason: End-to-end module networks for visual question answering. CoRR, abs/1704.05526 3 (2017)  14. Wang, P., Wu, Q., Shen, C., Dick, A., v. d. Hengel, A.: Fvqa: Fact-based visual  question answering. TPAMI (2018)  15. Tandon, N., de Melo, G., Suchanek, F., Weikum, G.: Webchild: Harvesting and  organizing commonsense knowledge from the web. In: WSDM. (2014)  16. Auer, S., Bizer, C., Kobilarov, G., Lehmann, J., Cyganiak, R., Ives, Z.: Dbpedia:  A nucleus for a web of open data. In: ISWC/ASWC. (2007)  17. Speer, R., Chin, J., Havasi, C.: Conceptnet 5.5: An open multilingual graph of  general knowledge. In: AAAI. (2017)  18. Lu, J., Yang, J., Batra, D., Parikh, D.: Hierarchical question-image co-attention  for visual question answering. In: NIPS. (2016)  19. Yang, Z., He, X., Gao, J., Deng, L., Smola, A.: Stacked attention networks for  image question answering. In: CVPR. (2016)  20. Andreas, J., Rohrbach, M., Darrell, T., Klein, D.: Deep compositional question  answering with neural module networks. In: CVPR. (2016)  21. Das, A., Agrawal, H., Zitnick, C.L., Parikh, D., Batra, D.: Human attention in visual question answering: Do humans and deep networks look at the same regions? In: EMNLP. (2016)   Learning Knowledge Base Retrieval for Factual Visual Question AnsweringReferences  1. Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalantidis, Y., Li, L.J., Shamma, D.A., et al.: Visual genome: Connecting language and vision using crowdsourced dense image annotations. IJCV (2017)  2. Ren, M., Kiros, R., Zemel, R.: Exploring models and data for image question  answering. In: NIPS. (2015)  3. Zhu, Y., Groth, O., Bernstein, M., Fei-Fei, L.: Visual7W: Grounded Question  Answering in Images. In: CVPR. (2016)  4. Malinowski, M., Fritz, M.: Towards a visual turing challenge. In: NIPS. (2014) 5. Johnson, J., Hariharan, B., van der Maaten, L., Fei-Fei, L., Zitnick, C.L., Girshick, R.: Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. In: CVPR. (2017)  6. Jabri, A., Joulin, A., van der Maaten, L.: Revisiting Visual Question Answering  Baselines. In: ECCV. (2016)  7. Yu, L., Park, E., Berg, A., Berg, T.: Visual Madlibs: Fill in the blank image  generation and question answering. In: ICCV. (2015)  8. Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D.:  VQA: Visual Question Answering. In: ICCV. (2015)  9. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., Parikh, D.: Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In: CVPR. (2017)  10. Gao, H., Mao, J., Zhou, J., Huang, Z., Wang, L., Xu, W.: Are you talking to a machine? Dataset and Methods for Multilingual Image Question Answering. In: NIPS. (2015)  11. Malinowski, M., Fritz, M.: A Multi-World Approach to Question Answering about  Real-World Scenes based on Uncertain Input. In: NIPS. (2014)  12. Malinowski, M., Rohrbach, M., Fritz, M.: Ask your neurons: A neural-based ap-  proach to answering questions about images. In: ICCV. (2015)  13. Hu, R., Andreas, J., Rohrbach, M., Darrell, T., Saenko, K.: Learning to reason: End-to-end module networks for visual question answering. CoRR, abs/1704.05526 3 (2017)  14. Wang, P., Wu, Q., Shen, C., Dick, A., v. d. Hengel, A.: Fvqa: Fact-based visual  question answering. TPAMI (2018)  15. Tandon, N., de Melo, G., Suchanek, F., Weikum, G.: Webchild: Harvesting and  organizing commonsense knowledge from the web. In: WSDM. (2014)  16. Auer, S., Bizer, C., Kobilarov, G., Lehmann, J., Cyganiak, R., Ives, Z.: Dbpedia:  A nucleus for a web of open data. In: ISWC/ASWC. (2007)  17. Speer, R., Chin, J., Havasi, C.: Conceptnet 5.5: An open multilingual graph of  general knowledge. In: AAAI. (2017)  18. Lu, J., Yang, J., Batra, D., Parikh, D.: Hierarchical question-image co-attention  for visual question answering. In: NIPS. (2016)  19. Yang, Z., He, X., Gao, J., Deng, L., Smola, A.: Stacked attention networks for  image question answering. In: CVPR. (2016)  20. Andreas, J., Rohrbach, M., Darrell, T., Klein, D.: Deep compositional question  answering with neural module networks. In: CVPR. (2016)  21. Das, A., Agrawal, H., Zitnick, C.L., Parikh, D., Batra, D.: Human attention in visual question answering: Do humans and deep networks look at the same regions? In: EMNLP. (2016)   16  Medhini Narasimhan and Alexander G. Schwing  22. Fukui, A., Park, D.H., Yang, D., Rohrbach, A., Darrell, T., Rohrbach, M.: Multi- modal compact bilinear pooling for visual question answering and visual grounding. In: EMNLP. (2016)  23. Shih, K.J., Singh, S., Hoiem, D.: Where to look: Focus regions for visual question  answering. In: CVPR. (2016)  24. Xu, H., Saenko, K.: Ask, attend and answer: Exploring question-guided spatial  attention for visual question answering. In: ECCV. (2016)  25. Schwartz, I., Schwing, A.G., Hazan, T.: High-Order Attention Models for Visual  Question Answering. In: NIPS. (2017)  26. Ben-younes, H., Cadene, R., Cord, M., Thome, N.: Mutan: Multimodal tucker  fusion for visual question answering. In: ICCV. (2017)  27. Ma, L., Lu, Z., Li, H.: Learning to answer questions from image using convolutional  neural network. In: AAAI. (2016)  28. Jain, U., Zhang, Z., Schwing, A.G.: Creativity: Generating Diverse Questions using  Variational Autoencoders. In: CVPR. (2017)  29. Xiong, C., Merity, S., Socher, R.: Dynamic memory networks for visual and textual  question answering. In: ICML. (2016)  30. Kim, J.H., Kwak, S.W.L.D.H., Heo, M.O., Kim, J., Ha, J.W., Zhang, B.T.: Mul-  timodal residual learning for visual qa. In: NIPS. (2016)  31. Zitnick, C.L., Agrawal, A., Antol, S., Mitchell, M., Batra, D., Parikh, D.: Measuring machine intelligence through visual question answering. AI Magazine (2016) 32. Zhou, B., Tian, Y., Sukhbataar, S., Szlam, A., Fergus, R.: Simple baseline for  visual question answering. In: arXiv:1512.02167. (2015)  33. Wu, Q., Shen, C., van den Hengel, A., Wang, P., Dick, A.: Image captioning and visual question answering based on attributes and their related external knowledge. In: arXiv:1603.02814. (2016)  34. Jain, U., Lazebnik, S., Schwing, A.G.: Two can play this Game: Visual Dialog with Discriminative Question Generation and Answering. In: CVPR. (2018) 35. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014)  36. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet Large Scale Visual Recognition Challenge. IJCV (2015)  37. Zettlemoyer, L.S., M.Collins: Learning to map sentences to logical form: Structured  classification with probabilistic categorial grammars. In: UAI. (2005)  38. Zettlemoyer, L.S., M.Collins: Learning context-dependent mappings from sen-  tences to logical form. In: ACL. (2005)  39. Berant, J., Chou, A., Frostig, R., Liang, P.: Semantic Parsing on Freebase from  Question-Answer Pairs. In: EMNLP. (2013)  40. Cai, Q., Yates, A.: Large-scale Semantic Parsing via Schema Matching and Lexicon  Extension. In: ACL. (2013)  41. Liang, P., Jordan, M.I., Klein, D.: Learning dependency-based compositional se-  mantics. In: Computational Linguistics. (2013)  42. Kwiatkowski, T., Choi, E., Artzi, Y., Zettlemoyer, L.: Scaling semantic parsers  with on-the-\ufb02y ontology matching. In: EMNLP. (2013)  43. Berant, J., Liang, P.: Semantic parsing via paraphrasing. In: ACL. (2014) 44. Fader, A., Zettlemoyer, L., Etzioni, O.: Open question answering over curated and  extracted knowledge bases. In: KDD. (2014)  45. Yih, W., Chang, M.W., He, X., Gao, J.: Semantic parsing via staged query graph generation: Question answering with knowledge base. In: ACL-IJCNLP. (2015)   Learning Knowledge Base Retrieval for Factual Visual Question Answering46. Reddy, S., T\u00a8ackstr\u00a8om, O., Collins, M., Kwiatkowski, T., Das, D., Steedman, M., Lapata, M.: Transforming dependency structures to logical forms for semantic parsing. In: ACL. (2016)  47. Xiao, C., Dymetman, M., Gardent, C.: Sequence-based structured prediction for  semantic parsing. In: ACL. (2016)  48. Unger, C., B\u00a8uhmann, L., Lehmann, J., Ngomo, A.C.N., Gerber, D., Cimiano, P.:  Template-based question answering over RDF data. In: WWW. (2012)  49. Kolomiyets, O., Moens, M.F.: A survey on question answering technology from an  information retrieval perspective. In: Information Sciences. (2011)  50. Yao, X., Durme, B.V.:  Information extraction over structured data: Question  answering with Freebase. In: ACL. (2014)  51. Bordes, A., Chopra, S., Weston, J.: Question answering with sub-graph embed-  dings. In: EMNLP. (2014)  52. Bordes, A., Weston, J., Usunier, N.: Open question answering with weakly super-  vised embedding models. In: ECML. (2014)  53. Dong, L., Wei, F., Zhou, M., Xu, K.: Question answering over freebase with multi-  column convolutional neural networks. In: ACL. (2015)  54. Bordes, A., Usunier, N., Chopra, S., Weston, J.: Large-scale simple question an-  swering with memory networks. In: ICLR. (2015)  55. Zhu, Y., Zhang, C., R\u00b4e, C., Fei-Fei, L.: Building a large-scale multimodal Knowl-  edge Base for Visual Question Answering. In: CoRR. (2015)  56. Wu, Q., Wang, P., Shen, C., van den Hengel, A., Dick, A.: Ask Me Anything: Free-form Visual Question Answering Based on Knowledge from External Sources. In: CVPR. (2016)  57. Wang, P., Wu, Q., Shen, C., van den Hengel, A., Dick, A.: Explicit Knowledge-  based Reasoning for Visual Question Answering. In: IJCAI. (2017)  58. Krishnamurthy, J., Kollar, T.: Jointly learning to parse and perceive: Connecting  natural language to the physical world. In: ACL. (2013)  59. Narasimhan, K., Yala, A., Barzilay, R.: Improving information extraction by ac-  quiring external evidence with reinforcement learning. In: EMNLP. (2016)  60. Wu, Q., Wang, P., Shen, C., Dick, A., van den Hengel, A.: Ask me anything: Free-form visual question answering based on knowledge from external sources. In: CVPR. (2016)  61. Wang, P., Wu, Q., Shen, C., Dick, A., Van Den Henge, A.: Explicit knowledge-  based reasoning for visual question answering. In: IJCAI. (2017)  62. Pennington, J., Socher, R., Manning, C.D.: Glove: Global vectors for word repre-  sentation. In: EMNLP. (2014)  63. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Computation  (1997)  In: CVPR. (2016)  64. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.  65. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale  hierarchical image database. In: CVPR. (2009)  66. Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object  detection with region proposal networks. In: NIPS. (2015)  67. Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\u00b4ar, P., Zitnick, C. Lawrence, e.D., Pajdla, T., Schiele, B., Tuytelaars, T.: Microsoft coco: Common objects in context. In: ECCV. (2014)  68. Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., Torralba, A.: Places: A 10 million  image database for scene recognition. TPAMI (2017)   18  Medhini Narasimhan and Alexander G. Schwing  69. Mallya, A., Lazebnik, S.: Learning models for actions and person-object interac-  tions with transfer to question answering. In: ECCV. (2016)  70. Chao, Y.W., Wang, Z., He, Y., Wang, J., Deng, J.: Hico: A benchmark for recog-  nizing human-object interactions in images. In: ICCV. (2015)  71. Andriluka, M., Pishchulin, L., Gehler, P., Schiele, B.: 2d human pose estimation:  New benchmark and state of the art analysis. In: CVPR. (2014)  72. Tsochantaridis, I., Joachims, T., Hofmann, T., Altun, Y.: Large Margin Methods  for Structured and Interdependent Output Variables. JMLR (2005)"}