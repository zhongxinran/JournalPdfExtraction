{"1": "1. Aksoy, E.E., Abramov, A., D\u00a8orr, J., Ning, K., Dellen, B., W\u00a8org\u00a8otter, F.: Learning the semantics of object-action relations by observation. The International Journal of Robotics Research 30(10), 1229-1249 (2011)  2. Andriluka, M., Pishchulin, L., Gehler, P., Schiele, B.: 2d human pose estimation: New benchmark and state of the art analysis. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (June 2014)  3. Ba, J., Mnih, V., Kavukcuoglu, K.: Multiple object recognition with visual atten-  tion. In: arXiv preprint arXiv:1412.7755 (2014)  4. Boyer, T.W., Maouene, J., Sethuraman, N.: Attention to body-parts varies with visual preference and verb-e\ufb00ector associations. Cognitive Processing (2017) 5. Chao, Y.W., Wang, Z., He, Y., Wang, J., Deng, J.: Hico: A benchmark for recog-  nizing human-object interactions in images. In: ICCV (2015)  6. Delaitre, V., Laptev, I., Sivic, J.: Recognizing human actions in still images: a  study of bag-of-features and part-based representations. In: BMVC (2010)  7. Denil, M., Bazzani, L., Larochelle, H., de Freitas, N.: Learning where to attend with deep architectures for image tracking. Neural computation 24(8), 2151-2184 (2012)  8. Desai, C., Ramanan, D., Fowlkes, C.: Discriminative models for static human-  object interactions. In: CVPR\u2019w (2010)  9. Fang, H.S., Xie, S., Tai, Y.W., Lu, C.: RMPE: Regional multi-person pose estima-  10. Girdhar, R., Ramanan, D.: Attentional pooling for action recognition. In: NIPS  11. Gkioxari, G., Girshick, R., Malik, J.: Actions and attributes from wholes and parts.  tion. In: ICCV (2017)  (2017)  In: ICCV (2015)  12. Gkioxari, G., Hariharan, B., Girshick, R., Malik, J.: R-cnns for pose estimation  and action detection. In: arXiv preprint arXiv:1406.5212 (2014)  13. Gkioxari, G., Girshick, R., Doll\u00b4ar, P., He, K.: Detecting and recognizing human-  object intaractions. In: arXiv preprint arXiv:1704.07333 (2017)  14. Gkioxari, G., Girshick, R., Malik, J.: Contextual action recognition with r* cnn.  15. Goferman, S., Zelnik-Manor, L., Tal, A.: Context-aware saliency detection. TPAMI  In: ICCV (2015)  34(10), 1915-1926 (2012)  ICCV (2009)  9(8), 1735-1780 (1997)  (2007)  16. Han, D., Bo, L., Sminchisescu, C.: Selection and context for action recognition. In:  17. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.  arXiv preprint arXiv:1512.03385 (2015)  18. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation  19. Hou, X., Zhang, L.: Saliency detection: A spectral residual approach. In: CVPR  20. Hu, J.F., Zheng, W.S., Lai, J., Gong, S., Xiang, T.: Recognising human-object  interaction via exemplar based modelling. In: ICCV (2013)  21. Ikizler, N., Cinbis, R.G., Pehlivan, S., Duygulu, P.: Recognizing actions from still  images. In: ICPR (2008)  22. Itti, L., Koch, C., Niebur, E.: A model of saliency-based visual attention for rapid  scene analysis. TPAMI 20(11), 1254-1259 (1998)   Pairwise Body-Part AttentionReferences  1. Aksoy, E.E., Abramov, A., D\u00a8orr, J., Ning, K., Dellen, B., W\u00a8org\u00a8otter, F.: Learning the semantics of object-action relations by observation. The International Journal of Robotics Research 30(10), 1229-1249 (2011)  2. Andriluka, M., Pishchulin, L., Gehler, P., Schiele, B.: 2d human pose estimation: New benchmark and state of the art analysis. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (June 2014)  3. Ba, J., Mnih, V., Kavukcuoglu, K.: Multiple object recognition with visual atten-  tion. In: arXiv preprint arXiv:1412.7755 (2014)  4. Boyer, T.W., Maouene, J., Sethuraman, N.: Attention to body-parts varies with visual preference and verb-e\ufb00ector associations. Cognitive Processing (2017) 5. Chao, Y.W., Wang, Z., He, Y., Wang, J., Deng, J.: Hico: A benchmark for recog-  nizing human-object interactions in images. In: ICCV (2015)  6. Delaitre, V., Laptev, I., Sivic, J.: Recognizing human actions in still images: a  study of bag-of-features and part-based representations. In: BMVC (2010)  7. Denil, M., Bazzani, L., Larochelle, H., de Freitas, N.: Learning where to attend with deep architectures for image tracking. Neural computation 24(8), 2151-2184 (2012)  8. Desai, C., Ramanan, D., Fowlkes, C.: Discriminative models for static human-  object interactions. In: CVPR\u2019w (2010)  9. Fang, H.S., Xie, S., Tai, Y.W., Lu, C.: RMPE: Regional multi-person pose estima-  10. Girdhar, R., Ramanan, D.: Attentional pooling for action recognition. In: NIPS  11. Gkioxari, G., Girshick, R., Malik, J.: Actions and attributes from wholes and parts.  tion. In: ICCV (2017)  (2017)  In: ICCV (2015)  12. Gkioxari, G., Hariharan, B., Girshick, R., Malik, J.: R-cnns for pose estimation  and action detection. In: arXiv preprint arXiv:1406.5212 (2014)  13. Gkioxari, G., Girshick, R., Doll\u00b4ar, P., He, K.: Detecting and recognizing human-  object intaractions. In: arXiv preprint arXiv:1704.07333 (2017)  14. Gkioxari, G., Girshick, R., Malik, J.: Contextual action recognition with r* cnn.  15. Goferman, S., Zelnik-Manor, L., Tal, A.: Context-aware saliency detection. TPAMI  In: ICCV (2015)  34(10), 1915-1926 (2012)  ICCV (2009)  9(8), 1735-1780 (1997)  (2007)  16. Han, D., Bo, L., Sminchisescu, C.: Selection and context for action recognition. In:  17. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.  arXiv preprint arXiv:1512.03385 (2015)  18. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation  19. Hou, X., Zhang, L.: Saliency detection: A spectral residual approach. In: CVPR  20. Hu, J.F., Zheng, W.S., Lai, J., Gong, S., Xiang, T.: Recognising human-object  interaction via exemplar based modelling. In: ICCV (2013)  21. Ikizler, N., Cinbis, R.G., Pehlivan, S., Duygulu, P.: Recognizing actions from still  images. In: ICPR (2008)  22. Itti, L., Koch, C., Niebur, E.: A model of saliency-based visual attention for rapid  scene analysis. TPAMI 20(11), 1254-1259 (1998)   16  H.S. Fang and J. Cao and Y.W. Tai and C. Lu  23. Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadar- rama, S., Darrell, T.: Ca\ufb00e: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.5093 (2014)  24. Khan, F.S., Anwer, R.M., van de Weijer, J., Bagdanov, A.D., Lopez, A.M., Fels- berg, M.: Coloring action recognition in still images. IJCV 105(3), 205-221 (2013) 25. Larochelle, H., Hinton, G.E.: Learning to combine foveal glimpses with a third-  order boltzmann machine. In: NIPS (2010)  26. Liu, J., Kuipers, B., Savarese, S.: Recognizing human actions by attributes. In:  CVPR (2011)  27. Liu, J., Wang, G., Hu, P., Duan, L.Y., Kot, A.C.: Global context-aware attention  lstm networks for 3d action recognition. In: CVPR (2017)  28. Maji, S., Bourdev, L., Malik, J.: Action recognition from a distributed representa-  tion of pose and appearance. In: CVPR (2011)  29. Mallya, A., Lazebnik, S.: Learning models for actions and person-object interac-  tions with transfer to question answering. In: ECCV (2016)  30. Maron, O., Lozano-P\u00b4erez, T.: A framework for multiple-instance learning (1998) 31. Mnih, V., Heess, N., Graves, A., et al.: Recurrent models of visual attention. In:  NIPS (2014)  32. Prest, A., Schmid, C., Ferrari, V.: Weakly supervised learning of interactions be-  tween humans and objects. TPAMI 34(3), 601-614 (2012)  33. Ramanathan, V., Li, C., Deng, J., Han, W., Li, Z., Gu, K., Song, Y., Bengio, S., Rosenberg, C., Fei-Fei, L.: Learning semantic relationships for better action retrieval in images. In: CVPR (2015)  34. Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object de-  tection with region proposal networks. In: NIPS (2015)  35. Ro, T., Friggel, A., Lavie, N.: Attentional biases for faces and body parts. Visual  Cognition 15(3), 322-348 (2007)  36. Sharma, G., Jurie, F., Schmid, C.: Expanded parts model for human attribute and  action recognition in still images. In: CVPR (2013)  37. Sharma, S., Kiros, R., Salakhutdinov, R.: Action recognition using visual attention  38. Shih, K.J., Singh, S., Hoiem, D.: Where to look: Focus regions for visual question  (2015)  answering. In: CVPR (2016)  39. Song, S., Lan, C., Xing, J., Zeng, W., Liu, J.: An end-to-end spatio-temporal attention model for human action recognition from skeleton data. In: AAAI (2017) 40. Thurau, C., Hlav\u00b4ac, V.: Pose primitive based human action recognition in videos  or still images. In: CVPR (2008)  41. Wang, H., Kl\u00a8aser, A., Schmid, C., Liu, C.L.: Action recognition by dense trajecto-  ries. In: CVPR (2011)  (2013)  42. Wang, H., Schmid, C.: Action recognition with improved trajectories. In: ICCV  43. Wang, Y., Jiang, H., Drew, M.S., Li, Z.N., Mori, G.: Unsupervised discovery of  action classes. In: CVPR (2006)  44. W\u00a8org\u00a8otter, F., Aksoy, E.E., Kr\u00a8uger, N., Piater, J., Ude, A., Tamosiunaite, M.: A simple ontology of manipulation actions based on hand-object relations. IEEE Transactions on Autonomous Mental Development 5(2), 117-134 (2013)  45. Xiao, T., Xu, Y., Yang, K., Zhang, J., Peng, Y., Zhang, Z.: The application of two-level attention models in deep convolutional neural network for fine-grained image classification. In: CVPR (2015)   Pairwise Body-Part Attention46. Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A.C., Salakhutdinov, R., Zemel, R.S., Bengio, Y.: Show, attend and tell: Neural image caption generation with visual attention. In: ICML. vol. 14 (2015)  47. Yang, W., Wang, Y., Mori, G.: Recognizing human actions from still images with  48. Yang, Y., Fermuller, C., Aloimonos, Y.: Detection of manipulation action conse-  latent poses. In: CVPR (2010)  quences (mac). In: CVPR (2013)  49. Yang, Z., He, X., Gao, J., Deng, L., Smola, A.: Stacked attention networks for  image question answering. In: CVPR (2016)  50. Yao, B., Fei-Fei, L.: Grouplet: A structured image representation for recognizing  human and object interactions. In: CVPR (2010)  51. Yao, B., Fei-Fei, L.: Modeling mutual context of object and human pose in human-  object interaction activities. In: CVPR (2010)  52. Yao, B., Fei-Fei, L.: Action recognition with exemplar based 2.5 d graph matching.  In: ECCV (2012)  53. Yao, B., Jiang, X., Khosla, A., Lin, A.L., Guibas, L., Fei-Fei, L.: Human action recognition by learning bases of action attributes and parts. In: ICCV (2011) 54. Yao, B., Khosla, A., Fei-Fei, L.: Combining randomization and discrimination for  fine-grained image categorization. In: CVPR (2011)  55. You, Q., Jin, H., Wang, Z., Fang, C., Luo, J.: Image captioning with semantic  attention. In: CVPR (2016)"}