{"1": "1. Luc, P., Neverova, N., Couprie, C., Verbeek, J., LeCun, Y.: Predicting deeper into  the future of semantic segmentation. In: ICCV. (2017)  2. Sutton, R., Barto, A.: Reinforcement learning: An introduction. MIT Press (1998) 3. Mathieu, M., Couprie, C., LeCun, Y.: Deep multi-scale video prediction beyond  mean square error. In: ICLR. (2016)  4. Ranzato, M., Szlam, A., Bruna, J., Mathieu, M., Collobert, R., Chopra, S.: Video (language) modeling: a baseline for generative models of natural videos. arXiv 1412.6604 (2014)  5. Srivastava, N., Mansimov, E., Salakhutdinov, R.: Unsupervised learning of video  representations using LSTMs. In: ICML. (2015)  6. Kalchbrenner, N., van den Oord, A., Simonyan, K., Danihelka, I., Vinyals, O.,  Graves, A., Kavukcuoglu, K.: Video pixel networks. In: ICML. (2017)  7. Shalev-Shwartz, S., Ben-Zrihem, N., Cohen, A., Shashua, A.: Long-term planning  by short-term prediction. arXiv 1602.01580 (2016)  8. Shalev-Shwartz, S., Shashua, A.: On the sample complexity of end-to-end training  vs. semantic abstraction training. arXiv 1604.06915 (2016)  9. He, K., Gkioxari, G., Doll\u00b4ar, P., Girshick, R.: Mask R-CNN. In: ICCV. (2017) 10. Kokkinos, I.: Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory. In: CVPR. (2017)  11. Villegas, R., Yang, J., Hong, S., Lin, X., Lee, H.: Decomposing motion and content  for natural video sequence prediction. In: ICLR. (2017)  12. Villegas, R., Yang, J., Zou, Y., Sohn, S., Lin, X., Lee, H.: Learning to generate  long-term future via hierarchical prediction. In: ICML. (2017)  13. Walker, J., Doersch, C., Gupta, A., Hebert, M.: An uncertain future: Forecasting  from static images using variational autoencoders. In: ECCV. (2016)  14. Lan, T., Chen, T.C., Savarese, S.: A hierarchical representation for future action  prediction. In: ECCV. (2014)  15. Kitani, K., Ziebart, B., Bagnell, J., Hebert, M.: Activity forecasting. In: ECCV.  (2012)  (2017)  16. Lee, N., Choi, W., Vernaza, P., Choy, C., Torr, P., Chandraker, M.: DESIRE: distant future prediction in dynamic scenes with interacting agents. In: CVPR. (2017)  17. Dosovitskiy, A., Koltun, V.: Learning to act by predicting the future. In: ICLR.  18. Vondrick, C., Pirsiavash, H., Torralba, A.: Anticipating the future by watching  unlabeled video. In: CVPR. (2016)  19. Jin, X., Xiao, H., Shen, X., Yang, J., Lin, Z., Chen, Y., Jie, Z., Feng, J., Yan, S.: Predicting scene parsing and motion dynamics in the future. In: NIPS. (2017) 20. Romera-Paredes, B., Torr, P.: Recurrent instance segmentation. In: ECCV. (2016) 21. Bai, M., Urtasun, R.: Deep watershed transform for instance segmentation. In:  CVPR. (2017)  In: ECCV. (2016)  22. Pinheiro, P., Lin, T.Y., Collobert, R., Doll\u00b4ar, P.: Learning to refine object segments.  23. Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object  detection with region proposal networks. In: NIPS. (2015)  24. Lin, T.Y., Doll\u00b4ar, P., Girshick, R., He, K., Hariharan, B., Belongie, S.: Feature  pyramid networks for object detection. In: CVPR. (2017)   Predicting Future Instance SegmentationReferences  1. Luc, P., Neverova, N., Couprie, C., Verbeek, J., LeCun, Y.: Predicting deeper into  the future of semantic segmentation. In: ICCV. (2017)  2. Sutton, R., Barto, A.: Reinforcement learning: An introduction. MIT Press (1998) 3. Mathieu, M., Couprie, C., LeCun, Y.: Deep multi-scale video prediction beyond  mean square error. In: ICLR. (2016)  4. Ranzato, M., Szlam, A., Bruna, J., Mathieu, M., Collobert, R., Chopra, S.: Video (language) modeling: a baseline for generative models of natural videos. arXiv 1412.6604 (2014)  5. Srivastava, N., Mansimov, E., Salakhutdinov, R.: Unsupervised learning of video  representations using LSTMs. In: ICML. (2015)  6. Kalchbrenner, N., van den Oord, A., Simonyan, K., Danihelka, I., Vinyals, O.,  Graves, A., Kavukcuoglu, K.: Video pixel networks. In: ICML. (2017)  7. Shalev-Shwartz, S., Ben-Zrihem, N., Cohen, A., Shashua, A.: Long-term planning  by short-term prediction. arXiv 1602.01580 (2016)  8. Shalev-Shwartz, S., Shashua, A.: On the sample complexity of end-to-end training  vs. semantic abstraction training. arXiv 1604.06915 (2016)  9. He, K., Gkioxari, G., Doll\u00b4ar, P., Girshick, R.: Mask R-CNN. In: ICCV. (2017) 10. Kokkinos, I.: Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory. In: CVPR. (2017)  11. Villegas, R., Yang, J., Hong, S., Lin, X., Lee, H.: Decomposing motion and content  for natural video sequence prediction. In: ICLR. (2017)  12. Villegas, R., Yang, J., Zou, Y., Sohn, S., Lin, X., Lee, H.: Learning to generate  long-term future via hierarchical prediction. In: ICML. (2017)  13. Walker, J., Doersch, C., Gupta, A., Hebert, M.: An uncertain future: Forecasting  from static images using variational autoencoders. In: ECCV. (2016)  14. Lan, T., Chen, T.C., Savarese, S.: A hierarchical representation for future action  prediction. In: ECCV. (2014)  15. Kitani, K., Ziebart, B., Bagnell, J., Hebert, M.: Activity forecasting. In: ECCV.  (2012)  (2017)  16. Lee, N., Choi, W., Vernaza, P., Choy, C., Torr, P., Chandraker, M.: DESIRE: distant future prediction in dynamic scenes with interacting agents. In: CVPR. (2017)  17. Dosovitskiy, A., Koltun, V.: Learning to act by predicting the future. In: ICLR.  18. Vondrick, C., Pirsiavash, H., Torralba, A.: Anticipating the future by watching  unlabeled video. In: CVPR. (2016)  19. Jin, X., Xiao, H., Shen, X., Yang, J., Lin, Z., Chen, Y., Jie, Z., Feng, J., Yan, S.: Predicting scene parsing and motion dynamics in the future. In: NIPS. (2017) 20. Romera-Paredes, B., Torr, P.: Recurrent instance segmentation. In: ECCV. (2016) 21. Bai, M., Urtasun, R.: Deep watershed transform for instance segmentation. In:  CVPR. (2017)  In: ECCV. (2016)  22. Pinheiro, P., Lin, T.Y., Collobert, R., Doll\u00b4ar, P.: Learning to refine object segments.  23. Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: towards real-time object  detection with region proposal networks. In: NIPS. (2015)  24. Lin, T.Y., Doll\u00b4ar, P., Girshick, R., He, K., Hariharan, B., Belongie, S.: Feature  pyramid networks for object detection. In: CVPR. (2017)   16  Luc, Couprie, LeCun and Verbeek  25. Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Roth, S., Schiele, B.: The Cityscapes dataset for semantic urban scene understanding. In: CVPR. (2016)  26. Lin, T., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J., Perona, P., Ramanan, D., Doll\u00b4ar, P., Zitnick, C.: Microsoft COCO: common objects in context. In: ECCV. (2014)  27. Yang, A., Wright, J., Ma, Y., Sastry, S.: Unsupervised segmentation of natural  images via lossy data compression. CVIU 110(2) (2008) 212-225  28. Parntofaru, C., Hebert, M.: A comparison of image segmentation algorithms. Tech-  nical Report CMU-RI-TR-05-40, Carnegie Mellon University (2005)  29. Martin, D., Fowlkes, C., Tal, D., Malik, J.: A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In: ICCV. (2001)  30. Meil\u02c7a, M.: Comparing clusterings: An axiomatic view. In: ICML. (2005) 31. Yu, F., Koltun, V.: Multi-scale context aggregation by dilated convolutions. In:  ICLR. (2016)  32. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,  Courville, A., Bengio, Y.: Generative adversarial nets. In: NIPS. (2014) 33. Kingma, D., Welling, M.: Auto-encoding variational Bayes. In: ICLR. (2014) 34. Gkioxari, G., Malik, J.: Finding action tubes. In: CVPR. (2015)"}