{"1": "1. Cao, C., Liu, X., Yang, Y., Yu, Y., Wang, J., Wang, Z., Huang, Y., Wang, L., Huang, C., Xu, W., et al.: Look and think twice: Capturing top-down visual at- tention with feedback convolutional neural networks. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 2956-2964 (2015)  2. Chen, Y., Li, J., Xiao, H., Jin, X., Yan, S., Feng, J.: Dual path networks. arXiv  preprint arXiv:1707.01629 (2017)  3. Cheng, B., Wei, Y., Shi, H., Feris, R., Xiong, J., Huang, T.: Revisiting rcnn: On  awakening the classification power of faster rcnn. In: ECCV (2018)   14  Xiaolin Zhang et al.  attention maps. Also, we find it is helpful to share the second and third layers of B1 and B2. By removing the shared setting, the localization error rate will increase from 35.31% to 36.31%.  E\ufb00ect of the auxiliary supervision We propose to use the self-produced guidance maps as a pixel-level auxiliary supervision to encourage the classification network to learn better localization maps using SPG-C. Thus, we remove SPG-C to test whether SPG-C in\ufb02uence the classification network. After removing SPG-C, the performance becomes worse with the Top-1 error rate of 36.06% on ILSVRC validation set when providing ground-truth labels. This reveals that the proposed self-produced guidance maps is e\ufb00ective to improve the quality of the localization maps by adding auxiliary supervision with SPG-C. It is notable that, the localization performance with only using SPG-B is still better than the plain version. So, the branches in SPG-B can also contribute to the improvement of localization accuracy.  5 Conclusions  In this paper, we proposed the Self-produced Guidance approach for locating target object regions given only image-level labels. The proposed approach can generate high-quality self-produced guidance maps for encouraging the classifi- cation network to learn pixel-level correlations. Thereby, the networks can detect much more object regions for localization. Extensive experiments show the pro- posed method can detect more object regions and outperform the state-of-the-art localization methods.  Acknowledgement  Xiaolin Zhang (No. 201606180026) is partially supported by the Chinese Schol- arship Council. This work is partially supported by IBM-ILLINOIS Center for Cognitive Computing Systems Research (C3SR) - a research collaboration as part of the IBM AI Horizons Network. We acknowledge the Data to Decisions CRC (D2D CRC) and the Cooperative Research Centres Programme for funding this research.  References  1. Cao, C., Liu, X., Yang, Y., Yu, Y., Wang, J., Wang, Z., Huang, Y., Wang, L., Huang, C., Xu, W., et al.: Look and think twice: Capturing top-down visual at- tention with feedback convolutional neural networks. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 2956-2964 (2015)  2. Chen, Y., Li, J., Xiao, H., Jin, X., Yan, S., Feng, J.: Dual path networks. arXiv  preprint arXiv:1707.01629 (2017)  3. Cheng, B., Wei, Y., Shi, H., Feris, R., Xiong, J., Huang, T.: Revisiting rcnn: On  awakening the classification power of faster rcnn. In: ECCV (2018)   Self-produced Guidance for Weakly-supervised Object Localization4. Diba, A., Sharma, V., Pazandeh, A., Pirsiavash, H., Van Gool, L.: Weakly super-  vised cascaded convolutional networks. arXiv preprint (2017)  5. Dong, X., Meng, D., Ma, F., Yang, Y.: A dual-network progressive approach to  weakly supervised object detection. In: ACM Multimedia (2017)  6. Dong, X., Zheng, L., Ma, F., Yang, Y., Meng, D.: Few-example object detection  with model communication. arXiv preprint arXiv:1706.08249 (2017)  7. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016)  8. He, S., Jiao, J., Zhang, X., Han, G., Lau, R.W.: Delving into salient object subitiz- ing and detection. In: 2017 IEEE International Conference on Computer Vision (ICCV). pp. 1059-1067. IEEE (2017)  9. Hou, Q., Cheng, M.M., Hu, X., Borji, A., Tu, Z., Torr, P.: Deeply supervised salient object detection with short connections. In: Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. pp. 5300-5309. IEEE (2017) 10. Jiang, H., Wang, J., Yuan, Z., Wu, Y., Zheng, N., Li, S.: Salient object detection: A discriminative regional feature integration approach. In: IEEE CVPR. pp. 2083- 2090 (2013)  11. Jie, Z., Wei, Y., Jin, X., Feng, J., Liu, W.: Deep self-taught learning for weakly  supervised object localization. In: IEEE CVPR (2018)  12. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep con-  volutional neural networks. In: NIPS. pp. 1097-1105 (2012)  13. Liang, X., Liu, S., Wei, Y., Liu, L., Lin, L., Yan, S.: Towards computational baby learning: A weakly-supervised approach for object detection. In: IEEE ICCV. pp. 999-1007 (2015)  14. Lin, M., Chen, Q., Yan, S.: Network in network. ICLR (2013) 15. Lin, T.Y., Doll\u00b4ar, P., Girshick, R., He, K., Hariharan, B., Belongie, S.: Feature  pyramid networks for object detection. In: CVPR. vol. 1, p. 4 (2017)  16. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y., Berg, A.C.: Ssd: Single shot multibox detector. In: European conference on computer vision. pp. 21-37. Springer (2016)  17. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic  segmentation. In: IEEE CVPR (2015)  18. Luo, Y., Guan, T., Pan, H., Wang, Y., Yu, J.: Accurate localization for mobile device using a multi-planar city model. In: Pattern Recognition (ICPR), 2016 23rd International Conference on. pp. 3733-3738. IEEE (2016)  19. Luo, Y., Zheng, Z., Zheng, L., Tao, G., Junqing, Y., Yang, Y.: Macro-micro adver-  sarial network for human parsing. In: ECCV (2018)  20. Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: Unified, real-time object detection. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 779-788 (2016)  21. Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detec- tion with region proposal networks. In: Advances in neural information processing systems. pp. 91-99 (2015)  22. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115(3), 211-252 (2015). https://doi.org/10.1007/s11263-015-0816-y 23. Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y.: Overfeat: Integrated recognition, localization and detection using convolutional networks. International Conference on Learning Representations (2014)   16  Xiaolin Zhang et al.  24. Simonyan, K., Vedaldi, A., Zisserman, A.: Deep inside convolutional net- works: Visualising image classification models and saliency maps. arXiv preprint arXiv:1312.6034 (2013)  25. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. International Conference on Learning Representations (2015)  26. Singh, K.K., Lee, Y.J.: Hide-and-seek: Forcing a network to be meticulous for weakly-supervised object and action localization. arXiv preprint arXiv:1704.04232 (2017)  27. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. arXiv preprint arXiv:1409.4842 (2014)  28. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: IEEE CVPR. pp. 1-9 (2015)  29. Szegedy, C., Vanhoucke, V., Io\ufb00e, S., Shlens, J., Wojna, Z.: Rethinking the incep- tion architecture for computer vision. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2818-2826 (2016)  30. Uijlings, J.R., van de Sande, K.E., Gevers, T., Smeulders, A.W.: Selective search  for object recognition. IJCV 104(2), 154-171 (2013)  31. Wah, C., Branson, S., Welinder, P., Perona, P., Belongie, S.: The Caltech-UCSD Birds-200-2011 Dataset. Tech. Rep. CNS-TR-2011-001, California Institute of Technology (2011)  32. Wei, Y., Feng, J., Liang, X., Cheng, M.M., Zhao, Y., Yan, S.: Object region min- ing with adversarial erasing: A simple classification to semantic segmentation ap- proach. In: IEEE CVPR (2018)  33. Wei, Y., Liang, X., Chen, Y., Jie, Z., Xiao, Y., Zhao, Y., Yan, S.: Learning to  segment with image-level annotations. Pattern Recognition (2016)  34. Wei, Y., Liang, X., Chen, Y., Shen, X., Cheng, M.M., Feng, J., Zhao, Y., Yan, S.: Stc: A simple to complex framework for weakly-supervised semantic segmentation. IEEE TPAMI (2016)  35. Wei, Y., Shen, Z., Cheng, B., Shi, H., Xiong, J., Feng, J., Huang, T.: Ts2c: Tight box mining with surrounding segmentation context for weakly supervised object detection. In: ECCV (2018)  36. Wei, Y., Xiao, H., Shi, H., Jie, Z., Feng, J., Huang, T.S.: Revisiting dilated convo- lution: A simple approach for weakly-and semi-supervised semantic segmentation. In: IEEE CVPR. pp. 7268-7277 (2018)  37. Xiao, H., Wei, Y., Liu, Y., Zhang, M., Feng, J.: Transferable semi-supervised se-  mantic segmentation. In: AAAI (2018)  38. Xie, S., Tu, Z.: Holistically-nested edge detection. In: Proceedings of the IEEE  international conference on computer vision. pp. 1395-1403 (2015)  39. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks.  In: European conference on computer vision. pp. 818-833. Springer (2014)  40. Zhang, H., Kyaw, Z., Yu, J., Chang, S.F.: Ppr-fcn: Weakly supervised visual rela-  tion detection via parallel pairwise r-fcn. In: IEEE ICCV (2017)  41. Zhang, J., Lin, Z., Brandt, J., Shen, X., Sclaro\ufb00, S.: Top-down neural attention by excitation backprop. In: European Conference on Computer Vision. pp. 543-559. Springer (2016)  42. Zhang, Q., Jiao, J., Cao, Y., Lau, R.W.: Task-driven webpage saliency. In: ECCV  (2018)  43. Zhang, X., Wei, Y., Feng, J., Yang, Y., Huang, T.: Adversarial complementary  learning for weakly supervised object localization. In: IEEE CVPR (2018)   Self-produced Guidance for Weakly-supervised Object Localization44. Zhou, B., Khosla, A., A., L., Oliva, A., Torralba, A.: Learning Deep Features for  Discriminative Localization. IEEE CVPR (2016)  45. Zhu, J., Mao, J., Yuille, A.L.: Learning from weakly supervised data by the expec-  tation loss svm (e-svm) algorithm. In: NIPS. pp. 1125-1133 (2014)"}