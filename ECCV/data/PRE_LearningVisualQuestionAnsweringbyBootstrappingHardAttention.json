{"1": "1. C\u00b8 ukur, T., Nishimoto, S., Huth, A.G., Gallant, J.L.: Attention during natural vision warps semantic representation across the human brain. Nature neuroscience 16(6) (2013) 763  2. Sheinberg, D.L., Logothetis, N.K.: Noticing familiar objects in real world scenes: the role of temporal cortical neurons in natural vision. Journal of Neuroscience 21(4) (2001) 1340-1350  3. Simons, D.J., Rensink, R.A.: Change blindness: Past, present, and future. Trends  in cognitive sciences 9(1) (2005) 16-20  4. Mack, A., Rock, I.: Inattentional blindness. Volume 33. MIT press Cambridge,  MA (1998)  5. Simons, D.J., Chabris, C.F.: Gorillas in our midst: Sustained inattentional blind-  ness for dynamic events. Perception 28(9) (1999) 1059-1074  6. Malinowski, M., Fritz, M.: A multi-world approach to question answering about real-world scenes based on uncertain input. In: Advances in Neural Information Processing Systems (NIPS). (2014)  7. Agrawal, A., Batra, D., Parikh, D., Kembhavi, A.: Don\u2019t just assume; look arXiv preprint  and answer: Overcoming priors for visual question answering. arXiv:1712.00377 (2017)  8. Xu, H., Saenko, K.: Ask, attend and answer: Exploring question-guided spatial  attention for visual question answering. arXiv:1511.05234 (2015)  9. Yang, Z., He, X., Gao, J., Deng, L., Smola, A.: Stacked attention networks for image question answering. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (2016)  10. Fukui, A., Park, D.H., Yang, D., Rohrbach, A., Darrell, T., Rohrbach, M.: Multi- modal compact bilinear pooling for visual question answering and visual ground- ing. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). (2016)  11. Perez, E., Strub, F., De Vries, H., Dumoulin, V., Courville, A.: Film: Visual reasoning with a general conditioning layer. In: Proceedings of the Conference on Artificial Intelligence (AAAI). (2018)  12. Kazemi, V., Elqursh, A.: Show, ask, attend, and answer: A strong baseline for  visual question answering. arXiv preprint arXiv:1704.03162 (2017)  13. Teney, D., Anderson, P., He, X., Hengel, A.v.d.: Tips and tricks for visual question answering: Learnings from the 2017 challenge. arXiv preprint arXiv:1708.02711 (2017)  14. Ilievski, I., Yan, S., Feng, J.: A focused dynamic attention model for visual question  answering. arXiv:1604.01485 (2016)  15. Mnih, V., Heess, N., Graves, A., et al.: Recurrent models of visual attention. In:  Advances in neural information processing systems. (2014) 2204-2212  16. Gulcehre, C., Chandar, S., Cho, K., Bengio, Y.: Dynamic neural turing machine with soft and hard addressing schemes. arXiv preprint arXiv:1607.00036 (2016)  17. Bengio, Y., L\u00b4eonard, N., Courville, A.:  ents through stochastic neurons for conditional computation. arXiv:1308.3432 (2013)  Estimating or propagating gradi- arXiv preprint  18. Jang, E., Gu, S., Poole, B.: Categorical reparameterization with gumbel-softmax.  arXiv preprint arXiv:1611.01144 (2016)  19. Maddison, C.J., Mnih, A., Teh, Y.W.: The concrete distribution: A continuous  relaxation of discrete random variables. arXiv preprint arXiv:1611.00712 (2016)   Learning Visual Question Answering by Bootstrapping Hard AttentionReferences  1. C\u00b8 ukur, T., Nishimoto, S., Huth, A.G., Gallant, J.L.: Attention during natural vision warps semantic representation across the human brain. Nature neuroscience 16(6) (2013) 763  2. Sheinberg, D.L., Logothetis, N.K.: Noticing familiar objects in real world scenes: the role of temporal cortical neurons in natural vision. Journal of Neuroscience 21(4) (2001) 1340-1350  3. Simons, D.J., Rensink, R.A.: Change blindness: Past, present, and future. Trends  in cognitive sciences 9(1) (2005) 16-20  4. Mack, A., Rock, I.: Inattentional blindness. Volume 33. MIT press Cambridge,  MA (1998)  5. Simons, D.J., Chabris, C.F.: Gorillas in our midst: Sustained inattentional blind-  ness for dynamic events. Perception 28(9) (1999) 1059-1074  6. Malinowski, M., Fritz, M.: A multi-world approach to question answering about real-world scenes based on uncertain input. In: Advances in Neural Information Processing Systems (NIPS). (2014)  7. Agrawal, A., Batra, D., Parikh, D., Kembhavi, A.: Don\u2019t just assume; look arXiv preprint  and answer: Overcoming priors for visual question answering. arXiv:1712.00377 (2017)  8. Xu, H., Saenko, K.: Ask, attend and answer: Exploring question-guided spatial  attention for visual question answering. arXiv:1511.05234 (2015)  9. Yang, Z., He, X., Gao, J., Deng, L., Smola, A.: Stacked attention networks for image question answering. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (2016)  10. Fukui, A., Park, D.H., Yang, D., Rohrbach, A., Darrell, T., Rohrbach, M.: Multi- modal compact bilinear pooling for visual question answering and visual ground- ing. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). (2016)  11. Perez, E., Strub, F., De Vries, H., Dumoulin, V., Courville, A.: Film: Visual reasoning with a general conditioning layer. In: Proceedings of the Conference on Artificial Intelligence (AAAI). (2018)  12. Kazemi, V., Elqursh, A.: Show, ask, attend, and answer: A strong baseline for  visual question answering. arXiv preprint arXiv:1704.03162 (2017)  13. Teney, D., Anderson, P., He, X., Hengel, A.v.d.: Tips and tricks for visual question answering: Learnings from the 2017 challenge. arXiv preprint arXiv:1708.02711 (2017)  14. Ilievski, I., Yan, S., Feng, J.: A focused dynamic attention model for visual question  answering. arXiv:1604.01485 (2016)  15. Mnih, V., Heess, N., Graves, A., et al.: Recurrent models of visual attention. In:  Advances in neural information processing systems. (2014) 2204-2212  16. Gulcehre, C., Chandar, S., Cho, K., Bengio, Y.: Dynamic neural turing machine with soft and hard addressing schemes. arXiv preprint arXiv:1607.00036 (2016)  17. Bengio, Y., L\u00b4eonard, N., Courville, A.:  ents through stochastic neurons for conditional computation. arXiv:1308.3432 (2013)  Estimating or propagating gradi- arXiv preprint  18. Jang, E., Gu, S., Poole, B.: Categorical reparameterization with gumbel-softmax.  arXiv preprint arXiv:1611.01144 (2016)  19. Maddison, C.J., Mnih, A., Teh, Y.W.: The concrete distribution: A continuous  relaxation of discrete random variables. arXiv preprint arXiv:1611.00712 (2016)   16  M. Malinowski, C. Doersch, A. Santoro and P. Battaglia  20. Olah, C., Satyanarayan, A., Johnson, I., Carter, S., Schubert, L., Ye, K., Mordv-  intsev, A.: The building blocks of interpretability. Distill (2018)  21. Oliva, A., Torralba, A., Castelhano, M.S., Henderson, J.M.: Top-down control In: Image processing, 2003. icip 2003.  of visual attention in object detection. proceedings. 2003 international conference on. Volume 1., IEEE (2003) I-253 22. Ren, M., Kiros, R., Zemel, R.: Image question answering: A visual semantic em- bedding model and a new dataset. In: Advances in Neural Information Processing Systems (NIPS). (2015)  23. Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D.: Vqa: Visual question answering. In: Proceedings of the IEEE International Con- ference on Computer Vision (ICCV). (2015)  24. Malinowski, M., Rohrbach, M., Fritz, M.: Ask your neurons: A deep learning approach to visual question answering. International Journal of Computer Vision (IJCV) 125(1-3) (2017) 110-135  25. Santoro, A., Raposo, D., Barrett, D.G., Malinowski, M., Pascanu, R., Battaglia, In: P., Lillicrap, T.: A simple neural network module for relational reasoning. Advances in Neural Information Processing Systems (NIPS). (2017) 4974-4983 26. Wang, X., Girshick, R., Gupta, A., He, K.: Non-local neural networks. arXiv  preprint arXiv:1711.07971 (2017)  27. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser,  L., Polosukhin, I.: Attention is all you need. In: Advances in Neural Information Processing Systems. (2017) 6000-6010  28. Shaw, P., Uszkoreit, J., Vaswani, A.: Self-attention with relative position repre-  sentations. arXiv preprint arXiv:1803.02155 (2018)  29. Malinowski, M., Fritz, M.: Towards a visual turing challenge. In: Learning Seman-  tics (NIPS workshop). (2014)  30. Malinowski, M., Fritz, M.: Hard to cheat: A turing test based on answering ques-  tions about images. AAAI Workshop: Beyond the Turing Test (2015)  31. Malinowski, M.: Towards holistic machines: From visual recognition to question  answering about real-world images. PhD Thesis (2017)  32. Geman, D., Geman, S., Hallonquist, N., Younes, L.: Visual turing test for computer In: Proceedings of the National Academy of Sciences, National  vision systems. Academy of Sciences (2015)  33. Gao, H., Mao, J., Zhou, J., Huang, Z., Wang, L., Xu, W.: Are you talking to a machine? dataset and methods for multilingual image question answering. In: Advances in Neural Information Processing Systems (NIPS). (2015)  34. Johnson, J., Hariharan, B., van der Maaten, L., Fei-Fei, L., Zitnick, C.L., Girshick, R.: Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. In: Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, IEEE (2017) 1988-1997  35. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., Parikh, D.: Making the v in vqa matter: Elevating the role of image understanding in visual question answering. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (2017)  36. Harnad, S.: The symbol grounding problem. Physica D: Nonlinear Phenomena  42(1) (1990) 335-346  37. Guadarrama, S., Riano, L., Golland, D., Gouhring, D., Jia, Y., Klein, D., Abbeel, P., Darrell, T.: Grounding spatial relations for human-robot interaction. In: IROS. (2013)   Learning Visual Question Answering by Bootstrapping Hard Attention38. Kong, C., Lin, D., Bansal, M., Urtasun, R., Fidler, S.: What are you talking about? text-to-image coreference. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (2014)  39. Karpathy, A., Fei-Fei, L.: Deep visual-semantic alignments for generating image In: Proceedings of the IEEE Conference on Computer Vision and  descriptions. Pattern Recognition (CVPR). (2015)  40. Rohrbach, A., Rohrbach, M., Hu, R., Darrell, T., Schiele, B.: Grounding of textual phrases in images by reconstruction. In: European Conference on Computer Vision, Springer (2016) 817-834  41. Malinowski, M., Rohrbach, M., Fritz, M.: Ask your neurons: A neural-based ap- proach to answering questions about images. In: Proceedings of the IEEE Inter- national Conference on Computer Vision (ICCV). (2015) 1-9  42. Xu, K., Ba, J., Kiros, R., Courville, A., Salakhutdinov, R., Zemel, R., Bengio, Y.: Show, attend and tell: Neural image caption generation with visual attention. Proceedings of the International Conference on Machine Learning (ICML) (2015) 43. Xiong, C., Merity, S., Socher, R.: Dynamic memory networks for visual and textual  question answering. arXiv preprint arXiv:1603.01417 (2016)  44. De Vries, H., Strub, F., Mary, J., Larochelle, H., Pietquin, O., Courville, A.C.: Modulating early visual processing by language. In: Advances in Neural Informa- tion Processing Systems. (2017) 6597-6607  45. Zhu, Y., Groth, O., Bernstein, M., Fei-Fei, L.: Visual7W: Grounded Question Answering in Images. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (2016)  46. Chen, K., Wang, J., Chen, L.C., Gao, H., Xu, W., Nevatia, R.: Abc-cnn: An attention based convolutional neural network for visual question answering. arXiv:1511.05960 (2015)  47. Shih, K.J., Singh, S., Hoiem, D.: Where to look: Focus regions for visual ques- tion answering. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (2016)  48. Gulcehre, C., Denil, M., Malinowski, M., Razavi, A., Pascanu, R., Hermann, K.M., Battaglia, P., Bapst, V., Raposo, D., Santoro, A., et al.: Hyperbolic attention networks. arXiv preprint arXiv:1805.09786 (2018)  49. Hudson, D.A., Manning, C.D.: Compositional attention networks for machine  reasoning. arXiv preprint arXiv:1803.03067 (2018)  50. Mascharka, D., Tran, P., Soklaski, R., Majumdar, A.: Transparency by design: Closing the gap between performance and interpretability in visual reasoning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (2018) 4942-4950  51. Kim, Y., Denton, C., Hoang, L., Rush, A.M.: Structured attention networks. arXiv  preprint arXiv:1702.00887 (2017)  52. Hu, R., Andreas, J., Darrell, T., Saenko, K.: Explainable Neural Computation via Stack Neural Module Networks. In: Proceedings of the European Conference on Computer Vision (ECCV). (2018)  53. Mokarian, A., Malinowski, M., Fritz, M.: Mean box pooling: A rich image repre- sentation and output embedding for the visual madlibs task. In: Proceedings of the British Machine Vision Conference (BMVC). (2016)  54. Tommasi, T., Mallya, A., Plummer, B., Lazebnik, S., Berg, A.C., Berg, T.L.: Solv- In: Proceedings of the British Machine  ing visual madlibs with multiple cues. Vision Conference (BMVC). (2016)  55. Desta, M.T., Chen, L., Kornuta, T.: Object-based reasoning in vqa. arXiv preprint  arXiv:1801.09718 (2018)   18  M. Malinowski, C. Doersch, A. Santoro and P. Battaglia  56. Singh, S., Gupta, A., Efros, A.A.: Unsupervised discovery of mid-level discrimi- native patches. In: Proceedings of the European Conference on Computer Vision (ECCV). Springer (2012) 73-86  57. Doersch, C., Gupta, A., Efros, A.A.: Mid-level visual element discovery as dis- criminative mode seeking. In: Advances in Neural Information Processing Systems (NIPS). (2013) 494-502  58. Juneja, M., Vedaldi, A., Jawahar, C., Zisserman, A.: Blocks that shout: Distinctive parts for scene classification. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE (2013) 923-930  59. Doersch, C., Singh, S., Gupta, A., Sivic, J., Efros, A.: What makes Paris look like  Paris? SIGGRAPH (2012)  60. Jaderberg, M., Simonyan, K., Zisserman, A., et al.: Spatial transformer networks. In: Advances in Neural Information Processing Systems (NIPS). (2015) 2017-2025 61. Mallya, A., Lazebnik, S.: Packnet: Adding multiple tasks to a single network by iterative pruning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE (2018)  62. Krizhevsky, A., Sutskever, I., Hinton, G.E.:  Imagenet classification with deep In: Advances in Neural Information Processing  convolutional neural networks. Systems (NIPS). (2012)  63. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.  arXiv:1512.03385 (2015)  64. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Computation  (1997)  (2014)  65. Kingma, D., Ba, J.: Adam: A method for stochastic optimization. arXiv:1412.6980  66. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv:1409.1556 (2014)  67. Io\ufb00e, S., Szegedy, C.: Batch normalization: Accelerating deep network training by  reducing internal covariate shift. arXiv preprint arXiv:1502.03167 (2015)"}