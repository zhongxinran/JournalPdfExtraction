{"1": "1. Hosni, A., Rhemann, C., Bleyer, M., Rother, C., Gelautz, M.: Fast cost-volume filtering for visual correspondence and beyond. IEEE Transactions on Pattern Analysis and Machine Intelligence 35(2) (2013) 504-511 2. Okutomi, M., Kanade, T.: A multiple-baseline stereo.  IEEE Transactions on  pattern analysis and machine intelligence 15(4) (1993) 353-363   14  P. H. Seo, J. Lee, D. Jung, B. Han and M. Cho  Fig. 6: Some failure cases of the proposed model with the a\ufb03ne transformation. Each row shows an example of PF-PASCAL. Each example contains 1) source image, 2) source image masked by attention distribution, 3) target image and 4) target image transformed by the predicted a\ufb03ne parameters. Even though the model attends to the matching objects, the model fails to find the correct correspondences due to multiple objects of the same class causing ambiguity or hard examples that are di\ufb03cult to visually percept.  the attentive model with the proposed kernels achieves the state-of-the-art per- formances with large margins over previous methods on the PF-WILLOW and PF-PASCAL benchmarks.  Acknowledgement  This research was supported by Next-Generation Information Computing De- velopment Program (NRF-2017M3C4A7069369) and Basic Science Research Program (NRF-2017R1E1A1A01077999) through the National Research Foun- dation of Korea (NRF) funded by the Ministry of Science, ICT, and Institute for Information & communications Technology Promotion (IITP) funded by the Korea government (MIST) (No. 2017-0-01778, Develoment of Explainable Human-level Deep Machine Learning Inference Framework).  References  1. Hosni, A., Rhemann, C., Bleyer, M., Rother, C., Gelautz, M.: Fast cost-volume filtering for visual correspondence and beyond. IEEE Transactions on Pattern Analysis and Machine Intelligence 35(2) (2013) 504-511 2. Okutomi, M., Kanade, T.: A multiple-baseline stereo.  IEEE Transactions on  pattern analysis and machine intelligence 15(4) (1993) 353-363   Attentive Semantic Alignment with O\ufb00set-Aware Correlation Kernels3. Dosovitskiy, A., Fischer, P., Ilg, E., Hausser, P., Hazirbas, C., Golkov, V., van der Smagt, P., Cremers, D., Brox, T.: Flownet: Learning optical \ufb02ow with convolutional networks. In: ICCV. (2015)  4. Weinzaepfel, P., Revaud, J., Harchaoui, Z., Schmid, C.: Deep\ufb02ow: Large displace-  ment optical \ufb02ow with deep matching. In: ICCV. (2013)  5. Revaud, J., Weinzaepfel, P., Harchaoui, Z., Schmid, C.: Deepmatching: Hierarchical International Journal of Computer Vision 120(3)  deformable dense matching. (2016) 300-323  6. Lowe, D.G.: Distinctive image features from scale-invariant keypoints. International  journal of computer vision 60(2) (2004) 91-110  7. Liu, C., Yuen, J., Torralba, A.: Sift \ufb02ow: Dense correspondence across scenes and its applications. In: Dense Image Correspondences for Computer Vision. Springer (2016) 15-49  8. Dalal, N., Triggs, B.: Histograms of oriented gradients for human detection. In:  CVPR. (2005)  9. Ham, B., Cho, M., Schmid, C., Ponce, J.: Proposal \ufb02ow. In: CVPR. (2016)  10. Taniai, T., Sinha, S.N., Sato, Y.: Joint recovery of dense correspondence and  cosegmentation in two images. In: CVPR. (2016)  11. Kim, J., Liu, C., Sha, F., Grauman, K.: Deformable spatial pyramid matching for  fast dense correspondences. In: CVPR. (2013)  12. Choy, C.B., Gwak, J., Savarese, S., Chandraker, M.: Universal correspondence network. In: Advances in Neural Information Processing Systems. (2016) 2414-2422 13. Rocco, I., Arandjelovic, R., Sivic, J.: Convolutional neural network architecture for  geometric matching. In: CVPR. (2017)  14. Han, K., Rezende, R.S., Ham, B., Wong, K.Y.K., Cho, M., Schmid, C., Ponce, J.:  Scnet: Learning semantic correspondence. In: ICCV. (2017)  15. Ufer, N., Ommer, B.: Deep semantic feature matching. In: CVPR. (2017) 16. Kim, S., Min, D., Lin, S., Sohn, K.: Dctm: Discrete-continuous transformation  matching for semantic \ufb02ow. In: ICCV. (2017)  17. Kim, S., Min, D., Ham, B., Jeon, S., Lin, S., Sohn, K.: Fcss: Fully convolutional  self-similarity for dense semantic correspondence. In: CVPR. (2017)  18. Novotny, D., Larlus, D., Vedaldi, A.: Anchornet: A weakly supervised network to  learn geometry-sensitive features for semantic matching. In: CVPR. (2017)  19. Zagoruyko, S., Komodakis, N.: Learning to compare image patches via convolutional  20. Zbontar, J., LeCun, Y.: Computing the stereo matching cost with a convolutional  neural networks. In: CVPR. (2015)  neural network. In: CVPR. (2015)  21. Han, X., Leung, T., Jia, Y., Sukthankar, R., Berg, A.C.: Matchnet: Unifying feature  and metric learning for patch-based matching. In: CVPR. (2015)  22. Long, J.L., Zhang, N., Darrell, T.: Do convnets learn correspondence? In: NIPS.  (2014)  23. Zhou, T., Krahenbuhl, P., Aubry, M., Huang, Q., Efros, A.A.: Learning dense  correspondence via 3d-guided cycle consistency. In: CVPR. (2016)  24. Kanazawa, A., Jacobs, D.W., Chandraker, M.: Warpnet: Weakly supervised match-  ing for single-view reconstruction. In: CVPR. (2016)  25. Yang, H., Lin, W.Y., Lu, J.: Daisy filter \ufb02ow: A generalized discrete approach to  dense correspondences. In: CVPR. (2014)  26. Hur, J., Lim, H., Park, C., Chul Ahn, S.: Generalized deformable spatial pyramid:  Geometry-preserving dense correspondence estimation. In: CVPR. (2015)  27. Bristow, H., Valmadre, J., Lucey, S.: Dense semantic correspondence where every  pixel is a classifier. In: ICCV. (2015)   16  P. H. Seo, J. Lee, D. Jung, B. Han and M. Cho  28. Berg, A.C., Berg, T.L., Malik, J.: Shape matching and object recognition using  low distortion correspondences. In: CVPR. (2005)  29. Yang, F., Li, X., Cheng, H., Li, J., Chen, L.: Object-aware dense semantic corre-  30. Cho, M., Lee, J., Lee, K.M.: Reweighted random walks for graph matching. In:  31. Duchenne, O., Joulin, A., Ponce, J.: A graph-matching kernel for object categoriza-  spondence. In: CVPR. (2017)  ECCV. (2010)  tion. In: ICCV. (2011)  32. Cho, M., Alahari, K., Ponce, J.: Learning graphs to match. In: ICCV. (2013) 33. Zbontar, J., LeCun, Y.: Stereo matching by training a convolutional neural network to compare image patches. Journal of Machine Learning Research 17(1-32) (2016) 2  34. Luo, W., Schwing, A.G., Urtasun, R.: E\ufb03cient deep learning for stereo matching. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2016) 5695-5703  35. Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., Bengio, Y.: Show, attend and tell: Neural image caption generation with visual attention. In: ICML. (2015)  36. Mun, J., Cho, M., Han, B.: Text-guided attention model for image captioning. In:  AAAI. (2017)  37. Xu, H., Saenko, K.: Ask, attend and answer: Exploring question-guided spatial  attention for visual question answering. In: ECCV. (2016)  38. Yang, Z., He, X., Gao, J., Deng, L., Smola, A.: Stacked attention networks for  image question answering. In: CVPR. (2016)  39. Seo, P.H., Lin, Z., Cohen, S., Shen, X., Han, B.: Progressive attention networks for  visual attribute prediction. arXiv preprint arXiv:1606.02393 (2016)  40. Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly learning  to align and translate. In: ICLR. (2015)  41. Luong, T., Pham, H., Manning, C.D.: E\ufb00ective approaches to attention-based  neural machine translation. In: EMNLP. (2015)  42. Noh, H., Araujo, A., Sim, J., Weyand, T., Han, B.: Large-scale image retrieval with  attentive deep local features. In: ICCV. (2017)  43. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. In: ICLR. (2015)  44. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale  hierarchical image database. In: CVPR. (2009)  45. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint  arXiv:1412.6980 (2014)  46. Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A.: The PAS- CAL Visual Object Classes Challenge 2011 (VOC2011) Results. http://www.pascal- network.org/challenges/VOC/voc2011/workshop/index.html  47. Yang, Y., Ramanan, D.: Articulated human detection with \ufb02exible mixtures of parts. IEEE transactions on pattern analysis and machine intelligence 35(12) (2013) 2878-2890  48. Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J.: Netvlad: Cnn architec-  ture for weakly supervised place recognition. In: CVPR. (2016)"}