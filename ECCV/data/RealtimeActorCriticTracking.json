{"1": "In this work, we propose a novel tracking algorithm with real-time performance based on the \u00e2\u0080\u0098Actor-Critic\u00e2\u0080\u0099 framework. This framework consists of two major components: \u00e2\u0080\u0098Actor\u00e2\u0080\u0099 and \u00e2\u0080\u0098Critic\u00e2\u0080\u0099. The \u00e2\u0080\u0098Actor\u00e2\u0080\u0099 model aims to infer the optimal choice in a continuous action space, which directly makes the tracker move the bounding box to the object location in the current frame. For of\u00ef\u00ac\u0082ine training,the\u00e2\u0080\u0098Critic\u00e2\u0080\u0099modelisintroducedtoforma\u00e2\u0080\u0098Actor-Critic\u00e2\u0080\u0099frameworkwith reinforcement learning and outputs a Q-value to guide the learning process of both \u00e2\u0080\u0098Actor\u00e2\u0080\u0099 and \u00e2\u0080\u0098Critic\u00e2\u0080\u0099 deep networks. Then, we modify the original deep deterministic policy gradient algorithm to effectively train our \u00e2\u0080\u0098Actor-Critic\u00e2\u0080\u0099 model for the tracking task. For online tracking, the \u00e2\u0080\u0098Actor\u00e2\u0080\u0099 model provides a dynamic search strategy to locate the tracked object ef\u00ef\u00ac\u0081ciently and the \u00e2\u0080\u0098Critic\u00e2\u0080\u0099 model acts as a veri\u00ef\u00ac\u0081cation module to make our tracker more robust. To the best of our knowledge, this work is the \u00ef\u00ac\u0081rst attempt to exploit the continuous action and \u00e2\u0080\u0098Actor-Critic\u00e2\u0080\u0099 framework for visual tracking. Extensive experimental results on popular benchmarks demonstrate that the proposed tracker performs favorably against many state-of-the-art methods, with real-time performance."}