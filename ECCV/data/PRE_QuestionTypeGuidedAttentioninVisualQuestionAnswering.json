{"1": "1. Agrawal, A., Batra, D., Parikh, D.: Analyzing the behavior of visual question answering  models. EMNLP (2016)  2. Agrawal, A., Batra, D., Parikh, D., Kembhavi, A.: Don\u2019t just assume; look and answer: Over-  coming priors for visual question answering. CVPR 2018  3. Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang, L.: Bottom-up and top-down attention for image captioning and VQA, http://arxiv.org/abs/1707.07998 4. Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D.: VQA: Visual Question Answering. In: International Conference on Computer Vision (ICCV) (2015) 5. Charikar, M., Chen, K., Farach-Colton, M.: Finding frequent items in data streams. In Pro-  ceedings of ICALP (2002)  6. Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao, T., Xu, B., Zhang, C., Zhang, Z.: Mxnet: A \ufb02exible and efficient machine learning library for heterogeneous distributed systems. Neural Information Processing Systems, Workshop on Machine Learning Systems 2015 (2015)  7. Donahue,  J.,  Jia, Y., Vinyals, O., Hoffman,  T.: Decaf: A deep convolutional activation feature for generic visual http://arxiv.org/abs/1310.1531  J., Zhang, N., Tzeng, E., Darrell, recognition,  8. Fukui, A., Park, D.H., Yang, D., Rohrbach, A., Darrell, T., Rohrbach, M.: Multimodal com- pact bilinear pooling for visual question answering and visual grounding. EMNLP (2016) 9. Gao, Y., Beijbom, O., Zhang, N., Darrell, T.: Compact bilinear pooling. Computer Vision  and Pattern Recognition (CVPR) (2016)  10. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., Parikh, D.: Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering. In: Conference on Computer Vision and Pattern Recognition (CVPR) (2017)  11. Gurari, D., Li, Q., Stangl, A.J., Guo, A., Lin, C., Grauman, K., Luo,  J., Bigham, J.P.: Vizwiz grand challenge: Answering visual questions from blind people, https://arxiv.org/abs/1802.08218  12. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 13. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation 9(8), 1735-  1780 (1997)  14. Johnson, J., Hariharan, B., van der Maaten, L., Fei-Fei, L., Zitnick, C.L., Girshick, R.B.: CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning, http://arxiv.org/abs/1612.06890  15. Ka\ufb02e, K., Kanan, C.: An analysis of visual question answering algorithms. In: ICCV (2017) 16. Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalantidis, Y., Li, L., Shamma, D.A., Bernstein, M.S., Li, F.: Visual genome: Connecting language and vision using crowdsourced dense image annotations, https://arxiv.org/abs/1602.07332  17. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Pereira, F., Burges, C.J.C., Bottou, L., Weinberger, K.Q. (eds.) Ad- vances in Neural Information Processing Systems 25, pp. 1097-1105. Curran Associates, Inc. (2012)  18. Lin, T., Maire, M., Belongie, S.J., Bourdev, L.D., Girshick, R.B., Hays, J., Perona, P., Ra- manan, D., Doll\u00b4ar, P., Zitnick, C.L.: Microsoft COCO: common objects in context. In ECCV (2014)  19. Lu, J., Yang, J., Batra, D., Parikh, D.: Hierarchical question-image co-attention for visual  question answering. In NIPS (2016)   Question Type Guided Attention in Visual Question AnsweringReferences  1. Agrawal, A., Batra, D., Parikh, D.: Analyzing the behavior of visual question answering  models. EMNLP (2016)  2. Agrawal, A., Batra, D., Parikh, D., Kembhavi, A.: Don\u2019t just assume; look and answer: Over-  coming priors for visual question answering. CVPR 2018  3. Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang, L.: Bottom-up and top-down attention for image captioning and VQA, http://arxiv.org/abs/1707.07998 4. Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D.: VQA: Visual Question Answering. In: International Conference on Computer Vision (ICCV) (2015) 5. Charikar, M., Chen, K., Farach-Colton, M.: Finding frequent items in data streams. In Pro-  ceedings of ICALP (2002)  6. Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao, T., Xu, B., Zhang, C., Zhang, Z.: Mxnet: A \ufb02exible and efficient machine learning library for heterogeneous distributed systems. Neural Information Processing Systems, Workshop on Machine Learning Systems 2015 (2015)  7. Donahue,  J.,  Jia, Y., Vinyals, O., Hoffman,  T.: Decaf: A deep convolutional activation feature for generic visual http://arxiv.org/abs/1310.1531  J., Zhang, N., Tzeng, E., Darrell, recognition,  8. Fukui, A., Park, D.H., Yang, D., Rohrbach, A., Darrell, T., Rohrbach, M.: Multimodal com- pact bilinear pooling for visual question answering and visual grounding. EMNLP (2016) 9. Gao, Y., Beijbom, O., Zhang, N., Darrell, T.: Compact bilinear pooling. Computer Vision  and Pattern Recognition (CVPR) (2016)  10. Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., Parikh, D.: Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering. In: Conference on Computer Vision and Pattern Recognition (CVPR) (2017)  11. Gurari, D., Li, Q., Stangl, A.J., Guo, A., Lin, C., Grauman, K., Luo,  J., Bigham, J.P.: Vizwiz grand challenge: Answering visual questions from blind people, https://arxiv.org/abs/1802.08218  12. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 13. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation 9(8), 1735-  1780 (1997)  14. Johnson, J., Hariharan, B., van der Maaten, L., Fei-Fei, L., Zitnick, C.L., Girshick, R.B.: CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning, http://arxiv.org/abs/1612.06890  15. Ka\ufb02e, K., Kanan, C.: An analysis of visual question answering algorithms. In: ICCV (2017) 16. Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalantidis, Y., Li, L., Shamma, D.A., Bernstein, M.S., Li, F.: Visual genome: Connecting language and vision using crowdsourced dense image annotations, https://arxiv.org/abs/1602.07332  17. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Pereira, F., Burges, C.J.C., Bottou, L., Weinberger, K.Q. (eds.) Ad- vances in Neural Information Processing Systems 25, pp. 1097-1105. Curran Associates, Inc. (2012)  18. Lin, T., Maire, M., Belongie, S.J., Bourdev, L.D., Girshick, R.B., Hays, J., Perona, P., Ra- manan, D., Doll\u00b4ar, P., Zitnick, C.L.: Microsoft COCO: common objects in context. In ECCV (2014)  19. Lu, J., Yang, J., Batra, D., Parikh, D.: Hierarchical question-image co-attention for visual  question answering. In NIPS (2016)   16  Y. Shi and T. Furlanello and S. Zha and A. Anandkumar  20. Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J.: Distributed representations of words and phrases and their compositionality. Advances in neural information processing systems pp. 3111-3119  21. Noh, H., Han, B.: Training recurrent answering units with joint loss minimization for VQA,  https://arxiv.org/abs/1606.03647  22. Ren, S., He, K., Girshick, R.B., Sun, J.: Faster R-CNN: towards real-time object detection  with region proposal networks, http://arxiv.org/abs/1506.01497  23. Simon, M., Gao, Y., Darrell, T., Denzler, J., Rodner, E.: Generalized orderless pooling per- forms implicit salient matching. In: International Conference on Computer Vision (ICCV) (2017)  24. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recog-  nition, http://arxiv.org/abs/1409.1556  25. Strub, F., de Vries, H., Mary, J., Piot, B., Courville, A.C., Pietquin, O.: End-to-end optimiza- tion of goal-driven and visually grounded dialogue systems. In: International Joint Confer- ence on Artificial Intelligence (IJCAI) (2017)  26. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural net- works. In: Proceedings of the 27th International Conference on Neural Information Pro- cessing Systems. pp. 3104-3112. NIPS\u201914, MIT Press, Cambridge, MA, USA (2014), http://dl.acm.org/citation.cfm?id=2969033.2969173  27. Teney, D., Anderson, P., He, X., van den Hengel, A.: Tips and tricks for visual question  answering: Learnings from the 2017 challenge, http://arxiv.org/abs/1708.02711  28. Wang, Z., Liu, X., Chen, L., Wang, L., Qiao, Y., Xie, X., Fowlkes, C.: Structured triplet learning with pos-tag guided attention for visual question answering. IEEE Winter Conf. on Applications of Computer Vision (2018)  29. Wu, Y., Schuster, M., Chen, Z., Le, Q.V., Norouzi, M., Macherey, W., Krikun, M., Cao, Y., Gao, Q., Macherey, K., Klingner, J., Shah, A., Johnson, M., Liu, X., \u0141ukasz Kaiser, Gouws, S., Kato, Y., Kudo, T., Kazawa, H., Stevens, K., Kurian, G., Patil, N., Wang, W., Young, C., Smith, J., Riesa, J., Rudnick, A., Vinyals, O., Corrado, G., Hughes, M., Dean, J.: Google\u2019s neural machine translation system: Bridging the gap between human and machine translation http://arxiv.org/abs/1609.08144  30. Xu, H., Saenko, K.: Ask, attend and answer: Exploring question-guided spatial attention for  visual question answering. European Conference on Computer Vision (2016)  31. Xu, K., Ba, J., Kiros, R., Courville, A., Salakhutdinov, R., Zemel, R., Bengio, Y.: Show, attend and tell: Neural image caption generation with visual attention. International Confer- ence on Machine Learning (2015)  32. Yang, Z., He, X., Gao, J., Deng, L., Smola, A.: Stacked attention networks for image question  answering, https://arxiv.org/abs/1511.02274  33. Zhang, P.: Towards Interpretable Vision Systems. Ph.D. thesis, Virginia Polytechnic Institute  and State University (2017)  34. Zhang, P., Goyal, Y., Summers-Stay, D., Batra, D., Parikh, D.: Yin and Yang: Balancing and answering binary visual questions. In: Conference on Computer Vision and Pattern Recog- nition (CVPR) (2016)"}