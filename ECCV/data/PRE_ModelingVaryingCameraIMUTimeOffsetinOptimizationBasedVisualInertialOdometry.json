{"1": "1. Baker, S., Matthews, I.: Lucas-Kanade 20 years on: A unifying framework. Inter-  national Journal of Computer Vision 56(3), 221-255 (2004)  2. Berthold K. P. Horn: Closed-form solution of absolute orientation using unit  quaternions. Optical Society of America 4 (1987)  3. Dai, Y., Li, H., Kneip, L.: Rolling shutter camera relative pose: Generalized epipo- lar geometry. In: Proc. of the IEEE Intl. Conf. on Comput. Vis. and Pattern Recognition (2016)  4. Dong-Si, T., Mourikis, A.I.: Estimator initialization in vision-aided inertial naviga- tion with unknown camera-imu calibration. In: Proc. of the IEEE/RSJ Intl. Conf. on Intell. Robots and Syst. (2012)  5. Forster, C., Carlone, L., Dellaert, F., Scaramuzza, D.: IMU preintegration on manifold for e\ufb03cient visual-inertial maximum-a-posteriori estimation. In: Proc. of Robot.: Sci. and Syst. (2015)  6. Furgale, P., Rehder, J., Siegwart, R.: Unified temporal and spatial calibration for multi-sensor systems. In: Proc. of the IEEE/RSJ Intl. Conf. on Intell. Robots and Syst. (2013)  7. Gao, X.S., Hou, X.R., Tang, J., Cheng, H.F.: Complete solution classification for the perspective-three-point problem. IEEE Transactions on Pattern Analysis and Machine Intelligence (2003)  8. Geiger, A., Lenz, P., Urtasun, R.: Are we ready for autonomous driving? the kitti vision benchmark suite. In: Conference on Computer Vision and Pattern Recogni- tion (CVPR) (2012)  9. Google: ARCore: https://developers.google.com/ar/  10. Guo, C., Kottas, D., DuToit, R., Ahmed, A., Li, R., Roumeliotis, S.: E\ufb03cient visual-inertial navigation using a rolling-shutter camera with inaccurate times- tamps. In: Proceedings of Robotics: Science and Systems (2014)  11. Hesch, J.A., Kottas, D.G., Bowman, S.L., Roumeliotis, S.I.: Consistency analysis and improvement of vision-aided inertial navigation. IEEE Trans. Robot. 30(1), 158-176 (Feb 2014)  12. Jacovitti, G., Scarano, G.: Discrete time techniques for time delay estimation. IEEE  Transactions on Signal Processing 41 (1993)  13. Jung, S.H., Taylor, C.J.: Camera trajectory estimation using inertial sensor mea- surements and structure from motion results. In: Proc. of the IEEE Intl. Conf. on Comput. Vis. and Pattern Recognition (2001)  14. Kelly, J., Sukhatme, G.: A general framework for temporal calibration of multiple proprioceptive and exteroceptive sensors. In: Proc. of the Intl. Sym. on Exp. Robot. (2010)  15. Klein G., Murray D.: Parallel tracking and mapping on a camera phone. In: Proc. Sixth IEEE and ACM International Symposium on Mixed and Augmented Reality (2009)  16. Knuth, D.: The Art of Computer Programming, vol. 1-3. Addison-Wesley Longman  Publishing Co., Inc., Boston, MA, USA (1998)  17. Leutenegger, S., Furgale, P., Rabaud, V., Chli, M., Konolige, K., Siegwart, R.: Keyframe-based visual-inertial SLAM using nonlinear optimization. In: Proc. of Robot.: Sci. and Syst. (2013)  18. Li, M., Mourikis, A.I.: 3D motion estimation and online temporal calibration for camera- IMU systems. In: Proc. of the IEEE Intl. Conf. on Robot. and Autom. (2013)   Modeling Varying Camera-IMU Time O\ufb00set in Optimization-Based VIOReferences  1. Baker, S., Matthews, I.: Lucas-Kanade 20 years on: A unifying framework. Inter-  national Journal of Computer Vision 56(3), 221-255 (2004)  2. Berthold K. P. Horn: Closed-form solution of absolute orientation using unit  quaternions. Optical Society of America 4 (1987)  3. Dai, Y., Li, H., Kneip, L.: Rolling shutter camera relative pose: Generalized epipo- lar geometry. In: Proc. of the IEEE Intl. Conf. on Comput. Vis. and Pattern Recognition (2016)  4. Dong-Si, T., Mourikis, A.I.: Estimator initialization in vision-aided inertial naviga- tion with unknown camera-imu calibration. In: Proc. of the IEEE/RSJ Intl. Conf. on Intell. Robots and Syst. (2012)  5. Forster, C., Carlone, L., Dellaert, F., Scaramuzza, D.: IMU preintegration on manifold for e\ufb03cient visual-inertial maximum-a-posteriori estimation. In: Proc. of Robot.: Sci. and Syst. (2015)  6. Furgale, P., Rehder, J., Siegwart, R.: Unified temporal and spatial calibration for multi-sensor systems. In: Proc. of the IEEE/RSJ Intl. Conf. on Intell. Robots and Syst. (2013)  7. Gao, X.S., Hou, X.R., Tang, J., Cheng, H.F.: Complete solution classification for the perspective-three-point problem. IEEE Transactions on Pattern Analysis and Machine Intelligence (2003)  8. Geiger, A., Lenz, P., Urtasun, R.: Are we ready for autonomous driving? the kitti vision benchmark suite. In: Conference on Computer Vision and Pattern Recogni- tion (CVPR) (2012)  9. Google: ARCore: https://developers.google.com/ar/  10. Guo, C., Kottas, D., DuToit, R., Ahmed, A., Li, R., Roumeliotis, S.: E\ufb03cient visual-inertial navigation using a rolling-shutter camera with inaccurate times- tamps. In: Proceedings of Robotics: Science and Systems (2014)  11. Hesch, J.A., Kottas, D.G., Bowman, S.L., Roumeliotis, S.I.: Consistency analysis and improvement of vision-aided inertial navigation. IEEE Trans. Robot. 30(1), 158-176 (Feb 2014)  12. Jacovitti, G., Scarano, G.: Discrete time techniques for time delay estimation. IEEE  Transactions on Signal Processing 41 (1993)  13. Jung, S.H., Taylor, C.J.: Camera trajectory estimation using inertial sensor mea- surements and structure from motion results. In: Proc. of the IEEE Intl. Conf. on Comput. Vis. and Pattern Recognition (2001)  14. Kelly, J., Sukhatme, G.: A general framework for temporal calibration of multiple proprioceptive and exteroceptive sensors. In: Proc. of the Intl. Sym. on Exp. Robot. (2010)  15. Klein G., Murray D.: Parallel tracking and mapping on a camera phone. In: Proc. Sixth IEEE and ACM International Symposium on Mixed and Augmented Reality (2009)  16. Knuth, D.: The Art of Computer Programming, vol. 1-3. Addison-Wesley Longman  Publishing Co., Inc., Boston, MA, USA (1998)  17. Leutenegger, S., Furgale, P., Rabaud, V., Chli, M., Konolige, K., Siegwart, R.: Keyframe-based visual-inertial SLAM using nonlinear optimization. In: Proc. of Robot.: Sci. and Syst. (2013)  18. Li, M., Mourikis, A.I.: 3D motion estimation and online temporal calibration for camera- IMU systems. In: Proc. of the IEEE Intl. Conf. on Robot. and Autom. (2013)   16  Ling et al.  19. Li, M., Mourikis, A.I.: High-precision, consistent EKF-based visual-inertial odom-  etry. Intl. J. Robot. Research 32(6), 690-711 (May 2013)  20. Li, M., Mourikis, A.I.: Real-time motion tracking on a cellphone using inertial sensing and a rolling shutter camera. In: Proc. of the IEEE Intl. Conf. on Robot. and Autom. (2013)  21. Li, M., Mourikis, A.I.: Online temporal calibration for camera-imu systems: Theory  and algorithms. Intl. J. Robot. Research 33 (2014)  22. Li, M., Mourikis, A.I.: Vision-aided Inertial Navigation with Rolling-Shutter Cam-  eras. Intl. J. Robot. Research 33 (2014)  23. Ling, Y., Kuse, M., Shen, S.: Edge alignment-based visual-inertial fusion for track-  ing of aggressive motions. Autonomous Robots (2017)  24. Ling, Y., Shen, S.: Dense visual-inertial odometry for tracking of aggressive mo-  tions. In: Proc. of the IEEE Intl. Conf. on Robot. and Bio. (2015)  25. Ling, Y., Shen, S.: Aggressive quadrotor \ufb02ight using dense visual-inertial fusion.  In: Proc. of the IEEE Intl. Conf. on Robot. and Autom. (2016)  26. Lynen, S., Achtelik, M., Weiss, S., Chli, M., Siegwart, R.: A robust and mod- ular multi-sensor fusion approach applied to MAV navigation. In: Proc. of the IEEE/RSJ Intl. Conf. on Intell. Robots and Syst. (2013)  27. Mourikis, A.I., Roumeliotis, S.I.: A Multi-State Constraint Kalman Filter for Vision-aided Inertial Navigation. In: Proc. of the IEEE Intl. Conf. on Robot. and Autom. (2007)  28. Mur-Artal, R., D.Tards, J.: Visual-inertial monocular slam with map reuse. IEEE  Robotics and Automation Letters 2 (2017)  29. Mur-Artal, R., Montiel, J.M.M., Tard\u00b4os, J.D.: ORB-SLAM: a versatile and accu- rate monocular SLAM system. IEEE Transactions on Robotics 31(5), 1147-1163 (2015). https://doi.org/10.1109/TRO.2015.2463671  30. Qin, T., Li, P., Shen, S.: VINS-Mono: A robust and versatile monocular visual-  inertial state estimator. arXiv preprint arXiv:1708.03852 (2017)  31. Qin, T., Shen, S.: Robust initialization of monocular visual-inertial estimation on aerial robots. In: Proc. of the IEEE/RSJ Intl. Conf. on Intell. Robots and Syst. (2017)  32. Shen, S., Michael, N., Kumar, V.: Tightly-coupled monocular visual-inertial fusion for autonomous \ufb02ight of rotorcraft MAVs. In: Proc. of the IEEE Intl. Conf. on Robot. and Autom. Seattle, WA (May 2015)  33. Shen, S., Mulgaonkar, Y., Michael, N., Kumar, V.: Vision-based state estimation for autonomous rotorcraft MAVs in complex environments. In: Proc. of the IEEE Intl. Conf. on Robot. and Autom. (2013)  34. Shi, J., Tomasi, C.: Good features to track. In: Proc. of IEEE Conf. on Computer  Vision and Pattern Recognition (1994)  35. S.I. Roumeliotis, A.E. Johnson, J.F. Montgomery: Augmenting inertial navigation with image-based motion estimation. In: Proc. of the IEEE Intl. Conf. on Robot. and Autom. (2002)  36. Steven, L., Alonso, P.P., Gabe, S.: Spline fusion: A continuous-time representation for visual-inertial fusion with application to rolling shutter cameras. In: British Machine Vision Conference (2013)  37. Wang, J., Olson, E.: AprilTag 2: E\ufb03cient and robust fiducial detection. In: Proc.  of the IEEE/RSJ Intl. Conf. on Intell. Robots and Syst. (2016)  38. Weiss, S., Achtelik, M.W., Lynen, S., Chi, M., Siegwart, R.: Real-time onboard visual-inertial state estimation and self-calibration of mavs in unknown environ- ments. In: Proc. of the IEEE Intl. Conf. on Robot. and Autom. (2012)   Modeling Varying Camera-IMU Time O\ufb00set in Optimization-Based VIO39. Yang, Z., Shen, S.: Monocular visual-inertial fusion with online initialization and camera-IMU calibration. In: Proc. of the IEEE/RSJ Intl. Conf. on Intell. Robots and Syst. (2015)  40. Yang, Z., Shen, S.: Tightly-coupled visual-inertial sensor fusion based on IMU pre- integration. Tech. rep., Hong Kong University of Science and Technology (2016), URL: http://www.ece.ust.hk/ eeshaojie/vins2016zhenfei.pdf"}