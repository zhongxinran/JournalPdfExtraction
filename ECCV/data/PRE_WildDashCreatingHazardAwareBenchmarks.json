{"1": "1. Torralba, A., Efros, A.: Unbiased look at dataset bias. In: CVPR. (2011) 1521-1528 2. Brostow, G.J., Shotton, J., Fauqueur, J., Cipolla, R.: Segmentation and recognition  using structure from motion point clouds. In: ECCV (1). (2008) 44-57  3. Franke, U., Gehrig, S., Rabe, C.: Daimler B\u00a8oblingen, 6D-Vision. http://www.  6d-vision.com Accessed: 2016-11-15.  4. Scharw\u00a8achter, T., Enzweiler, M., Roth, S., Franke, U.: Stixmantics: A medium-  level model for real-time semantic scene understanding. In: ECCV. (2014)  5. Cordts, M., Omran, M., Ramos, S., Scharw\u00a8achter, T., Enzweiler, M., Benenson, R., Franke, U., Roth, S., Schiele, B.: The cityscapes dataset. In: CVPR Workshop on The Future of Datasets in Vision. (2015)  6. Tung, F., Chen, J., Meng, L., Little, J.J.: The raincouver scene parsing benchmark for self-driving in adverse weather and at night. IEEE Robotics and Automation Letters 2(4) (2017) 2188-2193  7. Mighty AI:  Mighty AI semantic-segmentation-data Accessed: 2018-03-07.  Sample Data.  https://info.mty.ai/  8. Mapillary Research: Mapillary Vistas Dataset. https://www.mapillary.com/  9. University of California, Berkeley, U.: Berkeley deep drive. http://data-bdd.  dataset/vistas Accessed: 2018-02-16.  berkeley.edu/ Accessed: 2018-03-07.  10. Geiger, A., Lenz, P., Urtasun, R.: Are we ready for autonomous driving? the KITTI  vision benchmark suite. In: CVPR. (2012)  11. Geiger, A., Lenz, P., Stiller, C., Urtasun, R.: The KITTI Vision Benchmark Suite. http://www.cvlibs.net/datasets/kitti/eval_semantics.php Accessed: 2018-02-16.  12. Gaidon, A., Wang, Q., Cabon, Y., Vig, E.: Virtual worlds as proxy for multi-object  tracking analysis. In: CVPR. (2016)  13. Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A.: The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes. In: CVPR. (2016)  14. Hernandez-Juarez, D., Schneider, L., Espinosa, A., Vazquez, D., Lopez, A.M., Franke, U., Pollefeys, M., Moure, J.C.: Slanted stixels: Representing San Fran- cisco steepest streets. In: BMVC. (2017)  15. Richter, S.R., Hayder, Z., Koltun, V.: Playing for benchmarks. In: ICCV. (2017) 16. Zendel, O., Murschitz, M., Humenberger, M., Herzner, W.: CV-HAZOP: Introdu-  cing test data validation for computer vision. In: ICCV. (2015)  17. Transportation Research Board of the National Academy of Sciences: The 2nd Strategic Highway Research Program Naturalistic Driving Study Dataset. Avail- able from the SHRP 2 NDS InSight Data Dissemination web site (2013)  18. Zendel, O., Honauer, K., Murschitz, M., Humenberger, M., Dominguez, G.F.: Ana- lyzing computer vision data - the good, the bad and the ugly. In: CVPR. (2017) 6670-6680  19. Everingham, M., Eslami, S.M.A., Van Gool, L., Williams, C.K.I., Winn, J., Zisser- man, A.: The pascal visual object classes challenge: A retrospective. International Journal of Computer Vision 111(1) (Jan 2015) 98-136  20. Yu, F., Koltun, V., Funkhouser, T.: Dilated residual networks. In: CVPR. (2017)   WildDash - Creating Hazard-Aware BenchmarksReferences  1. Torralba, A., Efros, A.: Unbiased look at dataset bias. In: CVPR. (2011) 1521-1528 2. Brostow, G.J., Shotton, J., Fauqueur, J., Cipolla, R.: Segmentation and recognition  using structure from motion point clouds. In: ECCV (1). (2008) 44-57  3. Franke, U., Gehrig, S., Rabe, C.: Daimler B\u00a8oblingen, 6D-Vision. http://www.  6d-vision.com Accessed: 2016-11-15.  4. Scharw\u00a8achter, T., Enzweiler, M., Roth, S., Franke, U.: Stixmantics: A medium-  level model for real-time semantic scene understanding. In: ECCV. (2014)  5. Cordts, M., Omran, M., Ramos, S., Scharw\u00a8achter, T., Enzweiler, M., Benenson, R., Franke, U., Roth, S., Schiele, B.: The cityscapes dataset. In: CVPR Workshop on The Future of Datasets in Vision. (2015)  6. Tung, F., Chen, J., Meng, L., Little, J.J.: The raincouver scene parsing benchmark for self-driving in adverse weather and at night. IEEE Robotics and Automation Letters 2(4) (2017) 2188-2193  7. Mighty AI:  Mighty AI semantic-segmentation-data Accessed: 2018-03-07.  Sample Data.  https://info.mty.ai/  8. Mapillary Research: Mapillary Vistas Dataset. https://www.mapillary.com/  9. University of California, Berkeley, U.: Berkeley deep drive. http://data-bdd.  dataset/vistas Accessed: 2018-02-16.  berkeley.edu/ Accessed: 2018-03-07.  10. Geiger, A., Lenz, P., Urtasun, R.: Are we ready for autonomous driving? the KITTI  vision benchmark suite. In: CVPR. (2012)  11. Geiger, A., Lenz, P., Stiller, C., Urtasun, R.: The KITTI Vision Benchmark Suite. http://www.cvlibs.net/datasets/kitti/eval_semantics.php Accessed: 2018-02-16.  12. Gaidon, A., Wang, Q., Cabon, Y., Vig, E.: Virtual worlds as proxy for multi-object  tracking analysis. In: CVPR. (2016)  13. Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A.: The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes. In: CVPR. (2016)  14. Hernandez-Juarez, D., Schneider, L., Espinosa, A., Vazquez, D., Lopez, A.M., Franke, U., Pollefeys, M., Moure, J.C.: Slanted stixels: Representing San Fran- cisco steepest streets. In: BMVC. (2017)  15. Richter, S.R., Hayder, Z., Koltun, V.: Playing for benchmarks. In: ICCV. (2017) 16. Zendel, O., Murschitz, M., Humenberger, M., Herzner, W.: CV-HAZOP: Introdu-  cing test data validation for computer vision. In: ICCV. (2015)  17. Transportation Research Board of the National Academy of Sciences: The 2nd Strategic Highway Research Program Naturalistic Driving Study Dataset. Avail- able from the SHRP 2 NDS InSight Data Dissemination web site (2013)  18. Zendel, O., Honauer, K., Murschitz, M., Humenberger, M., Dominguez, G.F.: Ana- lyzing computer vision data - the good, the bad and the ugly. In: CVPR. (2017) 6670-6680  19. Everingham, M., Eslami, S.M.A., Van Gool, L., Williams, C.K.I., Winn, J., Zisser- man, A.: The pascal visual object classes challenge: A retrospective. International Journal of Computer Vision 111(1) (Jan 2015) 98-136  20. Yu, F., Koltun, V., Funkhouser, T.: Dilated residual networks. In: CVPR. (2017)"}