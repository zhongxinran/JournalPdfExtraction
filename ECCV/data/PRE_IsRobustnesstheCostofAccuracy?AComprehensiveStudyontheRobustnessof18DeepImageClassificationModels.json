{"1": "1. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep con- volutional neural networks. In: Advances in neural information processing systems (NIPS). (2012) 1097-1105  2. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M.S., Berg, A.C., Li, F.: Imagenet large scale visual recognition challenge. International Journal of Computer Vision 115(3) (2015) 211-252  3. Goodfellow, I., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial ex- amples. In: International Conference on Learning Representations (ICLR). (2015) 4. Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D.: Fooling vision and language models despite localization and attention mechanism. Proceedings of the Thirtieth IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2018)  5. Chen, H., Zhang, H., Chen, P.Y., Yi, J., Hsieh, C.J.: Attacking visual language grounding with adversarial examples: A case study on neural image captioning. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Volume 1. (2018) 2587-2597  6. Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V.: Universal adversarial pertur-  bations against semantic image segmentation. stat 1050 (2017) 19  7. Cheng, M., Yi, J., Zhang, H., Chen, P.Y., Hsieh, C.J.: Seq2sick: Evaluating the ro- bustness of sequence-to-sequence models with adversarial examples. arXiv preprint arXiv:1803.01128 (2018)  8. Carlini, N., Wagner, D.: Audio adversarial examples: Targeted attacks on speech-  to-text. Deep Learning and Security Workshop (2018)  9. Sun, M., Tang, F., Yi, J., Wang, F., Zhou, J.:  Identify susceptible locations in medical records via adversarial attacks on deep predictive models. In: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). (2018) 793-801  10. Xiao, C., Li, B., yan Zhu, J., He, W., Liu, M., Song, D.: Generating adversarial examples with adversarial networks. In: Proceedings of the Twenty-Seventh Inter- national Joint Conference on Artificial Intelligence, IJCAI-18, International Joint Conferences on Artificial Intelligence Organization (7 2018) 3905-3911  11. Xiao, C., Zhu, J.Y., Li, B., He, W., Liu, M., Song, D.: Spatially transformed adversarial examples. In: International Conference on Learning Representations (ICLR). (2018)  12. Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Kohno, T., Song, D.: Robust physical-world attacks on deep learning visual classification. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2018) 1625-1634  13. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R.: Intriguing properties of neural networks. In: International Conference on Learning Representations (ICLR). (2014)  14. Hein, M., Andriushchenko, M.: Formal guarantees on the robustness of a classifier against adversarial manipulation. In: Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems (NIPS). (2017) 2263-2273  15. Weng, T.W., Zhang, H., Chen, P.Y., Yi, J., Su, D., Gao, Y., Hsieh, C.J., Daniel, L.: Evaluating the robustness of neural networks: An extreme value theory approach. In: International Conference on Learning Representations (ICLR). (2018)   Is Robustness the Cost of Accuracy?References  1. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep con- volutional neural networks. In: Advances in neural information processing systems (NIPS). (2012) 1097-1105  2. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M.S., Berg, A.C., Li, F.: Imagenet large scale visual recognition challenge. International Journal of Computer Vision 115(3) (2015) 211-252  3. Goodfellow, I., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial ex- amples. In: International Conference on Learning Representations (ICLR). (2015) 4. Xu, X., Chen, X., Liu, C., Rohrbach, A., Darell, T., Song, D.: Fooling vision and language models despite localization and attention mechanism. Proceedings of the Thirtieth IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2018)  5. Chen, H., Zhang, H., Chen, P.Y., Yi, J., Hsieh, C.J.: Attacking visual language grounding with adversarial examples: A case study on neural image captioning. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Volume 1. (2018) 2587-2597  6. Metzen, J.H., Kumar, M.C., Brox, T., Fischer, V.: Universal adversarial pertur-  bations against semantic image segmentation. stat 1050 (2017) 19  7. Cheng, M., Yi, J., Zhang, H., Chen, P.Y., Hsieh, C.J.: Seq2sick: Evaluating the ro- bustness of sequence-to-sequence models with adversarial examples. arXiv preprint arXiv:1803.01128 (2018)  8. Carlini, N., Wagner, D.: Audio adversarial examples: Targeted attacks on speech-  to-text. Deep Learning and Security Workshop (2018)  9. Sun, M., Tang, F., Yi, J., Wang, F., Zhou, J.:  Identify susceptible locations in medical records via adversarial attacks on deep predictive models. In: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). (2018) 793-801  10. Xiao, C., Li, B., yan Zhu, J., He, W., Liu, M., Song, D.: Generating adversarial examples with adversarial networks. In: Proceedings of the Twenty-Seventh Inter- national Joint Conference on Artificial Intelligence, IJCAI-18, International Joint Conferences on Artificial Intelligence Organization (7 2018) 3905-3911  11. Xiao, C., Zhu, J.Y., Li, B., He, W., Liu, M., Song, D.: Spatially transformed adversarial examples. In: International Conference on Learning Representations (ICLR). (2018)  12. Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Kohno, T., Song, D.: Robust physical-world attacks on deep learning visual classification. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2018) 1625-1634  13. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R.: Intriguing properties of neural networks. In: International Conference on Learning Representations (ICLR). (2014)  14. Hein, M., Andriushchenko, M.: Formal guarantees on the robustness of a classifier against adversarial manipulation. In: Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems (NIPS). (2017) 2263-2273  15. Weng, T.W., Zhang, H., Chen, P.Y., Yi, J., Su, D., Gao, Y., Hsieh, C.J., Daniel, L.: Evaluating the robustness of neural networks: An extreme value theory approach. In: International Conference on Learning Representations (ICLR). (2018)   16  D. Su, H. Zhang, H. Chen, J. Yi, P-Y. Chen and Y. Gao  16. Weng, T.W., Zhang, H., Chen, H., Song, Z., Hsieh, C.J., Boning, D., Dhillon, I.S., Daniel, L.: Towards fast computation of certified robustness for relu networks. Proceedings of the 35th International Conference on Machine Learning (ICML) (2018)  17. Stock, P., Cisse, M.:  Convnets and imagenet beyond accuracy: Explana- tions, bias detection, adversarial examples and model criticism. arXiv preprint arXiv:1711.11443 (2017)  18. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale im- age recognition. In: International Conference on Learning Representations (ICLR). (2015)  19. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.E., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston, MA, USA, June 7-12, 2015. (2015) 1-9  20. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016. (2016) 770-778  21. Huang, G., Liu, Z., van der Maaten, L., Weinberger, K.Q.: Densely connected con- volutional networks. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (2017)  22. Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., An- dreetto, M., Adam, H.: Mobilenets: E\ufb03cient convolutional neural networks for mobile vision applications. CoRR abs/1704.04861 (2017)  23. Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V.: Learning transferable architectures for scalable image recognition. In: 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (2018)  24. Lin, M., Chen, Q., Yan, S.: Network in network. In: International Conference on  Learning Representations, ICLR (ICLR). (2014)  25. Io\ufb00e, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing internal covariate shift. In: Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015. (2015) 448-456  26. Szegedy, C., Vanhoucke, V., Io\ufb00e, S., Shlens, J., Wojna, Z.: Rethinking the in- ception architecture for computer vision. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016. (2016) 2818-2826  27. Szegedy, C., Io\ufb00e, S., Vanhoucke, V., Alemi, A.A.: Inception-v4, inception-resnet and the impact of residual connections on learning. In: Proceedings of the Thirty- First AAAI Conference on Artificial Intelligence, February 4-9, 2017, San Francisco, California, USA. (2017) 4278-4284  28. Zoph, B., Le, Q.V.: Neural architecture search with reinforcement learning. In:  International Conference on Learning Representations (ICLR). (2017)  29. Wu,  N.,  Sivakumar,  Tensor\ufb02ow-Slim Image https://github.com/tensor\ufb02ow/models/tree/master/research/slim (2017)  S.,  Guadarrama, Classification Model  S., Library.  Andersen,  D.: Github  30. He, K., Zhang, X., Ren, S., Sun, J.: Identity mappings in deep residual networks. In: European Conference on Computer Vision (ECCV), Springer (2016) 630-645 31. Liu, Y., Chen, X., Liu, C., Song, D.: Delving into transferable adversarial examples and black-box attacks. In: International Conference on Learning Representations (ICLR). (2017)   Is Robustness the Cost of Accuracy?32. Papernot, N., McDaniel, P., Goodfellow, I.: Transferability in machine learning: from phenomena to black-box attacks using adversarial samples. arXiv preprint arXiv:1605.07277 (2016)  33. Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J.: Zoo: Zeroth order optimiza- tion based black-box attacks to deep neural networks without training substitute models. In: Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, ACM (2017) 15-26  34. Tu, C., Ting, P., Chen, P., Liu, S., Zhang, H., Yi, J., Hsieh, C., Cheng, S.: Auto- zoom: Autoencoder-based zeroth order optimization method for attacking black- box neural networks. CoRR abs/1805.11770 (2018)  35. Cheng, M., Le, T., Chen, P.Y., Yi, J., Zhang, H., Hsieh, C.J.: Query-e\ufb03cient arXiv preprint  hard-label black-box attack: An optimization-based approach. arXiv:1807.04457 (2018)  36. Tu, C.C., Ting, P., Chen, P.Y., Liu, S., Zhang, H., Yi, J., Hsieh, C.J., Cheng, S.M.: Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks. arXiv preprint arXiv:1805.11770 (2018)  37. Kurakin, A., Goodfellow, I.J., Bengio, S.: Adversarial machine learning at scale.  In: International Conference on Learning Representations (ICLR). (2017)  38. Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., Usunier, N.: Parseval networks: In: International Conference on  Improving robustness to adversarial examples. Machine Learning (ICML). (2017) 854-863  39. Carlini, N., Wagner, D.A.: Towards evaluating the robustness of neural networks. In: 2017 IEEE Symposium on Security and Privacy (Oakland) 2017, San Jose, CA, USA, May 22-26, 2017. (2017) 39-57  40. Carlini, N., Wagner, D.: Adversarial examples are not easily detected: Bypassing ten detection methods. In: Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. AISec \u201917, New York, NY, USA, ACM (2017) 3-14 41. Chen, P.Y., Sharma, Y., Zhang, H., Yi, J., Hsieh, C.J.: Ead: Elastic-net attacks  to deep neural networks via adversarial examples. AAAI (2018)  42. Sharma, Y., Chen, P.Y.: Attacking the Madry defense model with L1-based ad-  versarial examples. arXiv preprint arXiv:1710.10733 (2017)  43. Lu, P.H., Chen, P.Y., Chen, K.C., Yu, C.M.: On the limitation of magnet defense  against L1-based adversarial examples. IEEE/IFIP DSN Workshop (2018)  44. Lu, P.H., Chen, P.Y., Yu, C.M.: On the limitation of local intrinsic dimensionality for characterizing the subspaces of adversarial examples. ICLR Workshop (2018) 45. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database. In: Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, IEEE (2009) 248-255  46. Krizhevsky, A.: Learning multiple layers of features from tiny images. (2009) 47. Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C.: Man vs. computer: Benchmark- ing machine learning algorithms for tra\ufb03c sign recognition. Neural Networks 32 (2012) 323-332  48. Moosavi-Dezfooli, S., Fawzi, A., Frossard, P.: Deepfool: A simple and accurate In: 2016 IEEE Conference on Computer method to fool deep neural networks. Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016. (2016) 2574-2582  49. Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A.: Towards deep learning models resistant to adversarial attacks. In: International Conference on Learning Representations (ICLR). (2018)  50. Athalye, A., Engstrom, L., Ilyas, A., Kwok, K.: Synthesizing robust adversarial examples. 35th International Conference on Machine Learning (ICML) (2018)   18  D. Su, H. Zhang, H. Chen, J. Yi, P-Y. Chen and Y. Gao  51. Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., Yuille, A.: Adversarial examples for semantic segmentation and object detection. In: International Conference on Computer Vision (ICCV), IEEE (2017)"}