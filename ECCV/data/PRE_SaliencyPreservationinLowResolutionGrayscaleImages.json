{"1": "1. McMains, S.A., Kastner, S.: Visual Attention. In Binder, M.D., Hirokawa, N., Windhorst, U., eds.: Encyclopedia of Neuroscience. Springer Berlin Heidelberg (2009) 4296-4302 2. Morawetz, L., Spaethe, J.: Visual attention in a complex search task differs between honey- bees and bumblebees. The Journal of Experimental Biology 215(Pt 14) (July 2012) 2515- 2523  3. Avargus-Weber, A., Dyer, A.G., Ferrah, N., Giurfa, M.: The forest or the trees: preference for global over local image processing is reversed by prior experience in honeybees. Proceedings of the Royal Society B: Biological Sciences 282(1799) (January 2015)  4. Morawetz, L., Svoboda, A., Spaethe, J., Dyer, A.G.: Blue colour preference in honeybees distracts visual attention for learning closed shapes. Journal of Comparative Physiology. A, Neuroethology, Sensory, Neural, and Behavioral Physiology 199(10) (October 2013) 817- 827  5. Hou, W., Gao, X., Tao, D., Li, X.: Visual saliency detection using information divergence.  Pattern Recognition 46(10) (October 2013) 2658-2669  6. Kmmerer, M., Wallis, T.S.A., Bethge, M.: DeepGaze II: Reading fixations from deep features  trained on object recognition. arXiv:1610.01563 [cs, q-bio, stat] (October 2016)  7. Huang, X., Shen, C., Boix, X., Zhao, Q.: SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks. In: 2015 IEEE International Conference on Computer Vision (ICCV). (December 2015) 262-270  8. Kruthiventi, S.S.S., Ayush, K., Babu, R.V.: DeepFix: A Fully Convolutional Neural Net- work for Predicting Human Eye Fixations. IEEE Transactions on Image Processing 26(9) (September 2017) 4446-4456  9. Cornia, M., Baraldi, L., Serra, G., Cucchiara, R.: Predicting Human Eye Fixations via an  LSTM-based Saliency Attentive Model. arXiv:1611.09571 [cs] (November 2016)  10. Rajankar, O.S., D.Kolekar, U.: International Journal of Image, Graphics and Signal Process- ing(IJIGSP). International Journal of Image, Graphics and Signal Processing(IJIGSP) 7(8) 58  11. Wang, W., Shen, J.: Deep Visual Attention Prediction. arXiv:1705.02544 [cs] (May 2017) 12. Vo, A.V., Truong-Hong, L., Laefer, D.F., Tiede, D., dOleire Oltmanns, S., Baraldi, A., Shi- moni, M., Moser, G., Tuia, D.: Processing of Extremely High Resolution LiDAR and RGB Data. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 9(12) (December 2016) 5560-5575  13. Lamb, T.D.: Evolution of Phototransduction, Vertebrate Photoreceptors and Retina. In Kolb, H., Fernandez, E., Nelson, R., eds.: Webvision: The Organization of the Retina and Visual System. University of Utah Health Sciences Center, Salt Lake City (UT) (1995)  14. Judd, T., Durand, F., Torralba, A.: Fixations on low-resolution images. Journal of Vision  11(4) (April 2011) 1-20  15. Shen, C., Huang, X., Zhao, Q.: Learning of Proto-object Representations via Fixations on  Low Resolution. ArXiv e-prints 1412 (December 2014) arXiv:1412.7242  16. Ho-Phuoc, T., Guyader, N., Landragin, F., Gurin-Dugu, A.: When viewing natural scenes, do abnormal colors impact on spatial or temporal parameters of eye movements? Journal of Vision 12(2) (February 2012) 4-4  17. Hamel, S., Guyader, N., Pellerin, D., Houzet, D.: Contribution of Color Information in Visual Saliency Model for Videos. In: Image and Signal Processing. Lecture Notes in Computer Science, Springer, Cham (June 2014) 213-221  18. Hamel, S., Guyader, N., Pellerin, D., Houzet, D.: Contribution of color in saliency model for  videos. Signal, Image and Video Processing 10(3) (March 2016) 423-429   Saliency Preservation in Low-Resolution Grayscale ImagesReferences  1. McMains, S.A., Kastner, S.: Visual Attention. In Binder, M.D., Hirokawa, N., Windhorst, U., eds.: Encyclopedia of Neuroscience. Springer Berlin Heidelberg (2009) 4296-4302 2. Morawetz, L., Spaethe, J.: Visual attention in a complex search task differs between honey- bees and bumblebees. The Journal of Experimental Biology 215(Pt 14) (July 2012) 2515- 2523  3. Avargus-Weber, A., Dyer, A.G., Ferrah, N., Giurfa, M.: The forest or the trees: preference for global over local image processing is reversed by prior experience in honeybees. Proceedings of the Royal Society B: Biological Sciences 282(1799) (January 2015)  4. Morawetz, L., Svoboda, A., Spaethe, J., Dyer, A.G.: Blue colour preference in honeybees distracts visual attention for learning closed shapes. Journal of Comparative Physiology. A, Neuroethology, Sensory, Neural, and Behavioral Physiology 199(10) (October 2013) 817- 827  5. Hou, W., Gao, X., Tao, D., Li, X.: Visual saliency detection using information divergence.  Pattern Recognition 46(10) (October 2013) 2658-2669  6. Kmmerer, M., Wallis, T.S.A., Bethge, M.: DeepGaze II: Reading fixations from deep features  trained on object recognition. arXiv:1610.01563 [cs, q-bio, stat] (October 2016)  7. Huang, X., Shen, C., Boix, X., Zhao, Q.: SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks. In: 2015 IEEE International Conference on Computer Vision (ICCV). (December 2015) 262-270  8. Kruthiventi, S.S.S., Ayush, K., Babu, R.V.: DeepFix: A Fully Convolutional Neural Net- work for Predicting Human Eye Fixations. IEEE Transactions on Image Processing 26(9) (September 2017) 4446-4456  9. Cornia, M., Baraldi, L., Serra, G., Cucchiara, R.: Predicting Human Eye Fixations via an  LSTM-based Saliency Attentive Model. arXiv:1611.09571 [cs] (November 2016)  10. Rajankar, O.S., D.Kolekar, U.: International Journal of Image, Graphics and Signal Process- ing(IJIGSP). International Journal of Image, Graphics and Signal Processing(IJIGSP) 7(8) 58  11. Wang, W., Shen, J.: Deep Visual Attention Prediction. arXiv:1705.02544 [cs] (May 2017) 12. Vo, A.V., Truong-Hong, L., Laefer, D.F., Tiede, D., dOleire Oltmanns, S., Baraldi, A., Shi- moni, M., Moser, G., Tuia, D.: Processing of Extremely High Resolution LiDAR and RGB Data. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 9(12) (December 2016) 5560-5575  13. Lamb, T.D.: Evolution of Phototransduction, Vertebrate Photoreceptors and Retina. In Kolb, H., Fernandez, E., Nelson, R., eds.: Webvision: The Organization of the Retina and Visual System. University of Utah Health Sciences Center, Salt Lake City (UT) (1995)  14. Judd, T., Durand, F., Torralba, A.: Fixations on low-resolution images. Journal of Vision  11(4) (April 2011) 1-20  15. Shen, C., Huang, X., Zhao, Q.: Learning of Proto-object Representations via Fixations on  Low Resolution. ArXiv e-prints 1412 (December 2014) arXiv:1412.7242  16. Ho-Phuoc, T., Guyader, N., Landragin, F., Gurin-Dugu, A.: When viewing natural scenes, do abnormal colors impact on spatial or temporal parameters of eye movements? Journal of Vision 12(2) (February 2012) 4-4  17. Hamel, S., Guyader, N., Pellerin, D., Houzet, D.: Contribution of Color Information in Visual Saliency Model for Videos. In: Image and Signal Processing. Lecture Notes in Computer Science, Springer, Cham (June 2014) 213-221  18. Hamel, S., Guyader, N., Pellerin, D., Houzet, D.: Contribution of color in saliency model for  videos. Signal, Image and Video Processing 10(3) (March 2016) 423-429   16  Yohanandan et al.  19. Hamel, S., Houzet, D., Pellerin, D., Guyader, N.: Does color in\ufb02uence eye movements while  exploring videos? Journal of Eye Movement Research 8(1) (April 2015)  20. Frey, H.P., Honey, C., Knig, P.: What\u2019s color got to do with it? The in\ufb02uence of color on  visual attention in different categories. Journal of Vision 8(14) (October 2008) 6-6  21. Baddeley, R.J., Tatler, B.W.: High frequency edges (but not contrast) predict where we fixate: A Bayesian system identification analysis. Vision Research 46(18) (September 2006) 2824-2833  22. Dorr, M., Vig, E., Barth, E.: Colour Saliency on Video. In: Bio-Inspired Models of Network, Information, and Computing Systems. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, Springer, Berlin, Heidelberg (De- cember 2010) 601-606  23. Xu, Y., Xiao, T., Zhang, J., Yang, K., Zhang, Z.: Scale-Invariant Convolutional Neural Net-  works. arXiv:1411.6369 [cs] (November 2014)  24. Advani, S., Sustersic, J., Irick, K., Narayanan, V.: A multi-resolution saliency framework to drive foveation. In: 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. (May 2013) 2596-2600  25. Lindeberg, T., Florack, L.: Foveal scale-space and the linear increase of receptive field size  as a function of eccentricity. (1994)  26. Koenderink, J.J., Doorn, A.J.v.: Visual detection of spatial contrast; In\ufb02uence of location in the visual field, target extent and illuminance level. Biological Cybernetics 30(3) (September 1978) 157-167  27. Romeny, B.M.H.: Front-End Vision and Multi-Scale Image Analysis: Multi-scale Computer Vision Theory and Applications, written in Mathematica. Springer Science & Business Me- dia (October 2008)  28. Treisman, A.M., Gelade, G.: A feature-integration theory of attention. 12(1) 97-136 29. Humphrey, G.K., Goodale, M.A., Jakobson, L.S., Servos, P.: The role of surface information in object recognition: studies of a visual form agnosic and normal subjects. 23(12) 1457- 1481  30. Gegenfurtner, K.R., Rieger, J.: Sensory and cognitive contributions of color to the recogni-  tion of natural scenes. 10(13) 805-808  31. Lennie, P.: Color vision: Putting it together. 10(16) R589-R591 32. Yang, Y., Song, M., Bu, J., Chen, C., Jin, C.: Color to Gray: Attention Preservation. In: 2010 Fourth Pacific-Rim Symposium on Image and Video Technology. (November 2010) 337-342  33. Pope, B., Druyan, A., Soter, S., deGrasse Tyson, N., Hanich, L., Holtzman, S.: Cosmos: A  Spacetime Odyssey (episode 2: some of the things that molecules do) (2014)  34. Nilsson, D.E.: The evolution of eyes and visually guided behaviour. Philosophical Trans- actions of the Royal Society of London B: Biological Sciences 364(1531) (October 2009) 2833-2847  35. Potter, M.C., Wyble, B., Hagmann, C.E., McCourt, E.S.: Detecting meaning in RSVP at 13 ms per picture. Attention, Perception, & Psychophysics 76(2) (February 2014) 270-279 36. Stojcev, M., Radtke, N., D\u2019Amaro, D., Dyer, A.G., Neumeyer, C.: General principles in motion vision: color blindness of object motion depends on pattern velocity in honeybee and goldfish. Visual Neuroscience 28(4) (July 2011) 361-370  37. Wandell, B.A.: Foundations of Vision. Sinauer Associates (January 1995) 38. Veale, R., Hafed, Z.M., Yoshida, M.: How is visual salience computed in the brain? Insights from behaviour, neurobiology and modelling. Philosophical Transactions of the Royal Soci- ety B: Biological Sciences 372(1714) (February 2017)  39. Okawa, H., Sampath, A.P.: Optimization of single-photon response transmission at the rod-  to-rod bipolar synapse. Physiology (Bethesda, Md.) 22 (August 2007) 279-286   Saliency Preservation in Low-Resolution Grayscale Images40. White, B.J., Kan, J.Y., Levy, R., Itti, L., Munoz, D.P.: Superior colliculus encodes visual saliency before the primary visual cortex. Proceedings of the National Academy of Sciences 114(35) (August 2017) 9451-9456  41. Krauzlis, R.J., Lovejoy, L.P., Znon, A.: Superior Colliculus and Visual Spatial Attention.  Annual Review of Neuroscience 36(1) (2013) 165-182  42. Poynton, C.A.: Rehabilitation of gamma. International Society for Optics and Photonics  3299 (July 1998) 232-250  43. Poynton, C., Funt, B.: Perceptual uniformity in digital image representation and display.  Color Research & Application 39(1) (February 2014) 6-15  44. Torralba, A.: How many pixels make an image? Visual Neuroscience 26(1) (February 2009)  123-131  45. Wooding, D.S.: Fixation Maps: Quantifying Eye-movement Traces. Proceedings of the 2002  Symposium on Eye Tracking Research & Applications (2002) 31-36  46. Tavakoli, H.R., Ahmed, F., Borji, A., Laaksonen, J.: Saliency Revisited: Analysis of Mouse  Movements versus Fixations. arXiv:1705.10546 [cs] (May 2017)  47. Borji, A., Itti, L.: CAT2000: A Large Scale Fixation Dataset for Boosting Saliency Research.  arXiv:1505.03581 [cs] (May 2015)  48. Bylinskii, Z., Judd, T., Oliva, A., Torralba, A., Durand, F.: What do different evaluation  metrics tell us about saliency models? arXiv:1604.03605 [cs] (April 2016)  49. Peters, R.J., Iyer, A., Itti, L., Koch, C.: Components of bottom-up gaze allocation in natural  images. Vision Research 45(18) (August 2005) 2397-2416  50. Liang, J., Zhang, Y.: Top down saliency detection via Kullback-Leibler divergence for ob- ject recognition. In: 2015 International Symposium on Bioelectronics and Bioinformatics (ISBB). (October 2015) 200-203  51. Judd, T., Ehinger, K., Durand, F., Torralba, A.: Learning to predict where humans look. In: 2009 IEEE 12th International Conference on Computer Vision. (September 2009) 2106- 2113  52. Borji, A., Tavakoli, H.R., Sihite, D.N., Itti, L.: Analysis of Scores, Datasets, and Models in Visual Saliency Prediction. In: 2013 IEEE International Conference on Computer Vision. (December 2013) 921-928  53. Le Meur, O., Le Callet, P., Barba, D.: Predicting visual fixations on video based on low-level  visual features. Vision Research 47(19) (September 2007) 2483-2498  54. Koch, C., Ullman, S.: Shifts in selective visual attention: towards the underlying neural  circuitry. Human Neurobiology 4(4) (1985) 219-227  55. Engelke, U., Liu, H., Wang, J., Le Callet, P., Heynderickx, I., Zepernick, H.J., Maeder, A.: A Comparative Study of Fixation Density Maps. IEEE Transactions on Image Processing 22(3) (March 2013) pp.1121-1133  56. Wang, W., Shen, J., Shao, L.: Video salient object detection via fully convolutional networks.  27(1) 38-49  57. Tatler, B.W.: The central fixation bias in scene viewing: selecting an optimal viewing position  independently of motor biases and image feature distributions. 7(14) 4.1-17  58. Judd, T., Durand, F., Torralba, A.: A benchmark of computational models of saliency to  predict human fixations"}