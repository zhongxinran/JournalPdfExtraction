{"1": "1. Athalye, A., Carlini, N., Wagner, D.: Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples. In: Proceedings of the 35th International Conference on Machine Learning (2018)  2. Brendel, W., Rauber, J., Bethge, M.: Decision-based adversarial attacks: Reliable attacks against black-box machine learning models. In: International Conference on Learning Representations (2018)  3. Carlini, N., Wagner, D.: Towards evaluating the robustness of neural networks. In:  IEEE Symposium on Security and Privacy, 2017 (2017)  4. Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J.: Zoo: Zeroth order optimiza- tion based black-box attacks to deep neural networks without training substitute models. In: 11th ACM Workshop on Artificial Intelligence and Security (2017) 5. Clarifai | image & video recognition API. https://clarifai.com, accessed: 2017-  08-22  6. Dang, H., Yue, H., Chang, E.C.: Evading classifiers by morphing in the dark. In:  24th ACM Conference on Computer and Communications Security (2017) 7. Goodfellow, I., Bengio, Y., Courville, A.: Deep learning. MIT Press (2016) 8. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial  examples. In: International Conference on Learning Representations (2015)  9. Vision API - image content analysis | Google cloud platform. https://cloud.  google.com/vision/, accessed: 2017-08-22  10. Gu, S., Rigazio, L.: Towards deep neural network architectures robust to adversarial  examples. arXiv preprint arXiv:1412.5068 (2014)  11. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016)  12. Hildebrand, F.B.: Advanced calculus for applications, vol. 63. Prentice-Hall Engle-  wood Cli\ufb00s, NJ (1962)  13. Ilyas, A., Engstrom, L., Athalye, A., Lin, J.: Black-box adversarial attacks with limited queries and information. In: Proceedings of the 35th International Confer- ence on Machine Learning (2018)  14. Kennedy, J.: Particle swarm optimization. In: Encyclopedia of machine learning,  15. Krizhevsky, A., Hinton, G.: Learning multiple layers of features from tiny images  pp. 760-766. Springer (2011)  (2009)  16. Kurakin, A., Goodfellow, I., Bengio, S.: Adversarial examples in the physical world.  arXiv preprint arXiv:1607.02533 (2016)  17. LeCun, Y., Cortes, C.: The MNIST database of handwritten digits (1998) 18. Liu, A.: Clarifai featured hack: Block unwanted nudity in blog comments with  disqus. https://goo.gl/TCCVrR (2016), accessed: 2017-08-22  19. Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P.: Universal adversarial perturbations. In: IEEE Conference on Computer Vision and Pattern Recognition (2016)  20. Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P.: Deepfool: a simple and accurate method to fool deep neural networks. In: IEEE Conference on Computer Vision and Pattern Recognition (2016)  21. M\u0105dry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A.: Towards deep learning models resistant to adversarial attacks. In: International Conference on Learning Representations (2018)   Practical Black-box Attacks on DNNs using E\ufb03cient QueryingReferences  1. Athalye, A., Carlini, N., Wagner, D.: Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples. In: Proceedings of the 35th International Conference on Machine Learning (2018)  2. Brendel, W., Rauber, J., Bethge, M.: Decision-based adversarial attacks: Reliable attacks against black-box machine learning models. In: International Conference on Learning Representations (2018)  3. Carlini, N., Wagner, D.: Towards evaluating the robustness of neural networks. In:  IEEE Symposium on Security and Privacy, 2017 (2017)  4. Chen, P.Y., Zhang, H., Sharma, Y., Yi, J., Hsieh, C.J.: Zoo: Zeroth order optimiza- tion based black-box attacks to deep neural networks without training substitute models. In: 11th ACM Workshop on Artificial Intelligence and Security (2017) 5. Clarifai | image & video recognition API. https://clarifai.com, accessed: 2017-  08-22  6. Dang, H., Yue, H., Chang, E.C.: Evading classifiers by morphing in the dark. In:  24th ACM Conference on Computer and Communications Security (2017) 7. Goodfellow, I., Bengio, Y., Courville, A.: Deep learning. MIT Press (2016) 8. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial  examples. In: International Conference on Learning Representations (2015)  9. Vision API - image content analysis | Google cloud platform. https://cloud.  google.com/vision/, accessed: 2017-08-22  10. Gu, S., Rigazio, L.: Towards deep neural network architectures robust to adversarial  examples. arXiv preprint arXiv:1412.5068 (2014)  11. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016)  12. Hildebrand, F.B.: Advanced calculus for applications, vol. 63. Prentice-Hall Engle-  wood Cli\ufb00s, NJ (1962)  13. Ilyas, A., Engstrom, L., Athalye, A., Lin, J.: Black-box adversarial attacks with limited queries and information. In: Proceedings of the 35th International Confer- ence on Machine Learning (2018)  14. Kennedy, J.: Particle swarm optimization. In: Encyclopedia of machine learning,  15. Krizhevsky, A., Hinton, G.: Learning multiple layers of features from tiny images  pp. 760-766. Springer (2011)  (2009)  16. Kurakin, A., Goodfellow, I., Bengio, S.: Adversarial examples in the physical world.  arXiv preprint arXiv:1607.02533 (2016)  17. LeCun, Y., Cortes, C.: The MNIST database of handwritten digits (1998) 18. Liu, A.: Clarifai featured hack: Block unwanted nudity in blog comments with  disqus. https://goo.gl/TCCVrR (2016), accessed: 2017-08-22  19. Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P.: Universal adversarial perturbations. In: IEEE Conference on Computer Vision and Pattern Recognition (2016)  20. Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P.: Deepfool: a simple and accurate method to fool deep neural networks. In: IEEE Conference on Computer Vision and Pattern Recognition (2016)  21. M\u0105dry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A.: Towards deep learning models resistant to adversarial attacks. In: International Conference on Learning Representations (2018)   16  A.N. Bhagoji, W. He, B. Li and D. Song  22. Narodytska, N., Kasiviswanathan, S.P.: Simple black-box adversarial perturbations  for deep networks. arXiv preprint arXiv:1612.06299 (2016)  23. Nelson, B., Rubinstein, B.I., Huang, L., Joseph, A.D., Lee, S.J., Rao, S., Tygar, J.: Query strategies for evading convex-inducing classifiers. The Journal of Machine Learning Research 13(1), 1293-1332 (2012)  24. Papernot, N., McDaniel, P., Goodfellow, I.: Transferability in machine learning: from phenomena to black-box attacks using adversarial samples. arXiv preprint arXiv:1605.07277 (2016)  25. Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Berkay Celik, Z., Swami, A.: Practical black-box attacks against deep learning systems using adversarial exam- ples. In: ACM Asia Conference on Computer and Communications Security (2017) 26. Salimans, T., Ho, J., Chen, X., Sutskever, I.: Evolution strategies as a scalable alternative to reinforcement learning. arXiv preprint arXiv:1703.03864 (2017) 27. Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K.: Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. In: ACM Conference on Computer and Communications Security (2016)  28. Shlens, J.: A tutorial on principal  component analysis. arXiv preprint  arXiv:1404.1100 (2014)  29. Spall, J.C.: Multivariate stochastic approximation using a simultaneous pertur- bation gradient approximation. IEEE transactions on automatic control 37(3), 332-341 (1992)  30. Spall, J.C.: Introduction to stochastic search and optimization: estimation, simu-  lation, and control, vol. 65. John Wiley & Sons (2005)  31. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R.: Intriguing properties of neural networks. In: International Conference on Learning Representations (2014)  32. Tram\u00e8r, F., Kurakin, A., Papernot, N., Boneh, D., McDaniel, P.: Ensemble ad- versarial training: Attacks and defenses. In: International Conference on Learning Representations (2018)  33. Watson  visual  recognition.  https://www.ibm.com/watson/services/  visual-recognition/, accessed: 2017-10-27  34. Wright, S.J., Nocedal, J.: Numerical optimization. Springer Science 35(67-68), 7  (1999)  35. Xu, W., Qi, Y., Evans, D.: Automatically evading classifiers. In: Proceedings of  the 2016 Network and Distributed Systems Symposium (2016)  36. Zagoruyko, S., Komodakis, N.: Wide  residual networks. arXiv preprint  arXiv:1605.07146 (2016)"}