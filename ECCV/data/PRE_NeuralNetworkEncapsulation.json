{"1": "1. LeCun, Y., Bottou, L., Bengio, Y., Ha\ufb00ner, P.: Gradient-based learning applied to document recognition. In: Proceedings of the IEEE. Volume 86. (1998) 2278-2324 Imagenet classification with deep  2. Krizhevsky, A., Sutskever, I., Hinton, G.E.:  convolutional neural networks. In: NIPS. (2012) 1106-1114  3. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. In: ICLR. (2015)  4. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: CVPR. (2015) 5. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.  In: CVPR. (2016)  6. Li, H., Liu, Y., Ouyang, W., Wang, X.: Zoom out-and-in network with map atten- tion decision for region proposal and object detection. In: International Journal of Computer Vision (IJCV). (2018)  7. Li, H., Liu, Y., Zhang, X., An, Z., Wang, J., Chen, Y., Tong, J.: Do we really need more training data for object localization. In: IEEE International Conference on Image Processing. (2017)  8. Chi, Z., Li, H., Huchuan, Yang, M.H.: Dual deep network for visual tracking. IEEE  Trans. on Image Processing (2017)  9. Hui, J.: Understanding Matrix capsules with EM Routing.  https://jhui.  github.io/2017/11/14/Matrix-Capsules-with-EM-routing-Capsule-Network (2017) Accessed: 2018-03-10.  10. Sabour, S., Frosst, N., Hinton, G.: Dynamic routing between capsules. In: NIPS.  11. Hinton, G.E., Sabour, S., Frosst, N.: Matrix capsules with EM routing. In: ICLR.  (2017)  (2018)  12. Io\ufb00e, S., Szegedy, C.: Batch normalization: Accelerating deep network training by  reducing internal covariate shift. In: ICML. (2015)  13. Nair, V., Hinton, G.E.: Rectified linear units improve restricted boltzmann ma-  14. Arjovsky, M., Chintala, S., Bottou, L.: Wasserstein GAN.  arXiv preprint:  chines. In: ICML. (2010) 807-814  1701.07875 (2017)  15. Genevay, A., Peyr, G., Cuturi, M.: Learning generative models with sinkhorn  divergences. arXiv preprint: 1706.00292 (2017)  16. Cuturi, M.: Sinkhorn distances: Lightspeed computation of optimal transport.  NIPS (2013)  17. Sinkhorn, R.: A relationship between arbitrary positive matrices and doubly  stochastic matrices. Ann. Math. Statist. (2) (06) 876-879  18. Gretton, A., Borgwardt, K., Rasch, M.J., Scholkopf, B., Smola, A.J.: A kernel  method for the two-sample problem. NIPS (2007)  19. Salimans, T., Zhang, H., Radford, A., Metaxas, D.: Improving GANs using optimal transport. In: International Conference on Learning Representations. (2018) 20. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: ICLR.  (2015)  21. Wang, D., Liu, Q.: An optimization view on dynamic routing between capsules.  In: Submit to ICLR workshop. (2018)  22. Li, M.J., Ng, M.K., ming Cheung, Y., Huang, J.Z.: Agglomerative fuzzy k-means clustering algorithm with selection of number of clusters. IEEE Transactions on Knowledge and Data Engineering 20 (2008) 1519-1534   Neural Network EncapsulationReferences  1. LeCun, Y., Bottou, L., Bengio, Y., Ha\ufb00ner, P.: Gradient-based learning applied to document recognition. In: Proceedings of the IEEE. Volume 86. (1998) 2278-2324 Imagenet classification with deep  2. Krizhevsky, A., Sutskever, I., Hinton, G.E.:  convolutional neural networks. In: NIPS. (2012) 1106-1114  3. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. In: ICLR. (2015)  4. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: CVPR. (2015) 5. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.  In: CVPR. (2016)  6. Li, H., Liu, Y., Ouyang, W., Wang, X.: Zoom out-and-in network with map atten- tion decision for region proposal and object detection. In: International Journal of Computer Vision (IJCV). (2018)  7. Li, H., Liu, Y., Zhang, X., An, Z., Wang, J., Chen, Y., Tong, J.: Do we really need more training data for object localization. In: IEEE International Conference on Image Processing. (2017)  8. Chi, Z., Li, H., Huchuan, Yang, M.H.: Dual deep network for visual tracking. IEEE  Trans. on Image Processing (2017)  9. Hui, J.: Understanding Matrix capsules with EM Routing.  https://jhui.  github.io/2017/11/14/Matrix-Capsules-with-EM-routing-Capsule-Network (2017) Accessed: 2018-03-10.  10. Sabour, S., Frosst, N., Hinton, G.: Dynamic routing between capsules. In: NIPS.  11. Hinton, G.E., Sabour, S., Frosst, N.: Matrix capsules with EM routing. In: ICLR.  (2017)  (2018)  12. Io\ufb00e, S., Szegedy, C.: Batch normalization: Accelerating deep network training by  reducing internal covariate shift. In: ICML. (2015)  13. Nair, V., Hinton, G.E.: Rectified linear units improve restricted boltzmann ma-  14. Arjovsky, M., Chintala, S., Bottou, L.: Wasserstein GAN.  arXiv preprint:  chines. In: ICML. (2010) 807-814  1701.07875 (2017)  15. Genevay, A., Peyr, G., Cuturi, M.: Learning generative models with sinkhorn  divergences. arXiv preprint: 1706.00292 (2017)  16. Cuturi, M.: Sinkhorn distances: Lightspeed computation of optimal transport.  NIPS (2013)  17. Sinkhorn, R.: A relationship between arbitrary positive matrices and doubly  stochastic matrices. Ann. Math. Statist. (2) (06) 876-879  18. Gretton, A., Borgwardt, K., Rasch, M.J., Scholkopf, B., Smola, A.J.: A kernel  method for the two-sample problem. NIPS (2007)  19. Salimans, T., Zhang, H., Radford, A., Metaxas, D.: Improving GANs using optimal transport. In: International Conference on Learning Representations. (2018) 20. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: ICLR.  (2015)  21. Wang, D., Liu, Q.: An optimization view on dynamic routing between capsules.  In: Submit to ICLR workshop. (2018)  22. Li, M.J., Ng, M.K., ming Cheung, Y., Huang, J.Z.: Agglomerative fuzzy k-means clustering algorithm with selection of number of clusters. IEEE Transactions on Knowledge and Data Engineering 20 (2008) 1519-1534   16  H. Li et al.  23. Shahroudnejad, A., Mohammadi, A., Plataniotis, K.N.: Improved explainability of capsule networks: Relevance path by agreement. In: arXiv preprint:1802.10204. (2018)  24. Bahadori, M.T.: Spectral capsule networks. In: ICLR workshop. (2018) 25. Mnih, V., Heess, N., Graves, A., Kavukcuoglu, K.: Recurrent models of visual  attention. In: NIPS. (2014)  26. Stollenga, M.F., Masci, J., Gomez, F., Schmidhuber, J.: Deep networks with inter- nal selective attention through feedback connections. In: NIPS. (2014) 3545-3553 27. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I.: Attention is all you need. arXiv preprint: 1706.03762 (2017) 28. Krizhevsky, A., Hinton, G.: Learning multiple layers of features from tiny images.  In: Technical Report. (2009)  29. Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y.: Reading digits in natural images with unsupervised feature learning. In: NIPS workshop. (2011) 30. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115(3) (2015) 211-252  31. Zagoruyko, S., Komodakis, N.: Wide residual networks. In: BMVC. (2016) 32. Mishkin, D., Matas, J.: All you need is a good init. arXiv preprint:1511.06422  (2015)  33. Snoek, J., Rippel, O., Swersky, K., Kiros, R., Satish, N., Sundaram, N., Patwary, M., Prabhat, M., Adams, R.: Scalable bayesian optimization using deep neural networks. In: ICML. (2015)  34. Clevert, D.A., Unterthiner, T., Hochreiter, S.: Fast and accurate deep network  learning by exponential linear units. arXiv preprint: 1511.07289 (2015)  35. Chang, J.R., Chen, Y.S.: Batch-normalized maxout network in network. In: arXiv  preprint:1511.02583. (2015)  36. Liang, M., Hu, X.: Recurrent convolutional neural network for object recognition. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (June 2015)  37. Agostinelli, F., Ho\ufb00man, M., Sadowski, P., Baldi, P.: Learning activation functions  to improve deep neural networks. In: ICLR workshop. (2015)  38. Lee, C.Y., Xie, S., Gallagher, P., Zhang, Z., Tu, Z.: Deeply-supervised nets. arXiv  39. Lin, M., Chen, Q., Yan, S.: Network in network. In: ICLR. (2014) 40. Goodfellow, I.J., Warde-farley, D., Mirza, M., Courville, A., Bengio, Y.: Maxout  preprint: 1409.5185 (2014)  networks. In: ICML. (2013)"}