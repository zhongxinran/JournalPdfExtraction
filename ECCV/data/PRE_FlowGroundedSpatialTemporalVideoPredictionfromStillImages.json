{"1": "1. Ekman, M., Kok, P., de Lange, F.P.: Time-compressed preplay of anticipated  events in human primary visual cortex. Nature Communications 8 (2017)  2. Mathieu, M., Couprie, C., LeCun, Y.: Deep multi-scale video prediction beyond  mean square error. In: ICLR. (2016)  3. Xingjian, S., Chen, Z., Wang, H., Yeung, D.Y., Wong, W.K., Woo, W.C.: Convo- lutional lstm network: A machine learning approach for precipitation nowcasting. In: NIPS. (2015)  4. Villegas, R., Yang, J., Hong, S., Lin, X., Lee, H.: Decomposing motion and content  for natural video sequence prediction. In: ICLR. (2017)  5. Denton, E., Birodkar, V.: Unsupervised learning of disentangled representations  from video. In: NIPS. (2017)  6. Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M.: Learning spatiotem-  poral features with 3d convolutional networks. In: ICCV. (2015)  7. Walker, J., Doersch, C., Gupta, A., Hebert, M.: An uncertain future: Forecasting  from static images using variational autoencoders. In: ECCV. (2016)  8. Xue, T., Wu, J., Bouman, K., Freeman, B.: Visual dynamics: Probabilistic future  frame synthesis via cross convolutional networks. In: NIPS. (2016)  9. Yuen, J., Torralba, A.: A data-driven approach for event prediction. In: ECCV.  (2010)  191-202  10. Lan, T., Chen, T.C., Savarese, S.: A hierarchical representation for future action  prediction. In: ECCV. (2014)  11. Hoai, M., De la Torre, F.: Max-margin early event detectors. IJCV 107(2) (2014)  12. Kitani, K.M., Ziebart, B.D., Bagnell, J.A., Hebert, M.: Activity forecasting. In:  13. Vondrick, C., Pirsiavash, H., Torralba, A.: Anticipating visual representations from  ECCV. (2012) 201-214  unlabeled video. In: CVPR. (2016)  image. In: ICCV. (2015)  14. Walker, J., Gupta, A., Hebert, M.: Dense optical \ufb02ow prediction from a static  15. Srivastava, N., Mansimov, E., Salakhudinov, R.: Unsupervised learning of video  representations using lstms. In: ICML. (2015)  16. Oh, J., Guo, X., Lee, H., Lewis, R.L., Singh, S.: Action-conditional video prediction  using deep networks in atari games. In: NIPS. (2015)  17. Babaeizadeh, M., Finn, C., Erhan, D., Campbell, R.H., Levine, S.: Stochastic  variational video prediction. In: ICLR. (2018)  18. Finn, C., Levine, S.: Deep visual foresight for planning robot motion. In: ICRA.  19. Vondrick, C., Pirsiavash, H., Torralba, A.: Generating videos with scene dynamics.  (2017)  In: NIPS. (2016)  20. Liang, X., Lee, L., Dai, W., Xing, E.P.: Dual motion gan for future-\ufb02ow embedded  video prediction. In: ICCV. (2017)  21. Tulyakov, S., Liu, M.Y., Yang, X., Kautz, J.: Mocogan: Decomposing motion and  content for video generation. arXiv preprint arXiv:1707.04993 (2017)  22. Finn, C., Goodfellow, I., Levine, S.: Unsupervised learning for physical interaction  through video prediction. In: NIPS. (2016)  23. Vondrick, C., Torralba, A.: Generating the future with adversarial transformers.  In: CVPR. (2017)   Flow-Grounded Spatial-Temporal Video Prediction from Still ImagesReferences  1. Ekman, M., Kok, P., de Lange, F.P.: Time-compressed preplay of anticipated  events in human primary visual cortex. Nature Communications 8 (2017)  2. Mathieu, M., Couprie, C., LeCun, Y.: Deep multi-scale video prediction beyond  mean square error. In: ICLR. (2016)  3. Xingjian, S., Chen, Z., Wang, H., Yeung, D.Y., Wong, W.K., Woo, W.C.: Convo- lutional lstm network: A machine learning approach for precipitation nowcasting. In: NIPS. (2015)  4. Villegas, R., Yang, J., Hong, S., Lin, X., Lee, H.: Decomposing motion and content  for natural video sequence prediction. In: ICLR. (2017)  5. Denton, E., Birodkar, V.: Unsupervised learning of disentangled representations  from video. In: NIPS. (2017)  6. Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M.: Learning spatiotem-  poral features with 3d convolutional networks. In: ICCV. (2015)  7. Walker, J., Doersch, C., Gupta, A., Hebert, M.: An uncertain future: Forecasting  from static images using variational autoencoders. In: ECCV. (2016)  8. Xue, T., Wu, J., Bouman, K., Freeman, B.: Visual dynamics: Probabilistic future  frame synthesis via cross convolutional networks. In: NIPS. (2016)  9. Yuen, J., Torralba, A.: A data-driven approach for event prediction. In: ECCV.  (2010)  191-202  10. Lan, T., Chen, T.C., Savarese, S.: A hierarchical representation for future action  prediction. In: ECCV. (2014)  11. Hoai, M., De la Torre, F.: Max-margin early event detectors. IJCV 107(2) (2014)  12. Kitani, K.M., Ziebart, B.D., Bagnell, J.A., Hebert, M.: Activity forecasting. In:  13. Vondrick, C., Pirsiavash, H., Torralba, A.: Anticipating visual representations from  ECCV. (2012) 201-214  unlabeled video. In: CVPR. (2016)  image. In: ICCV. (2015)  14. Walker, J., Gupta, A., Hebert, M.: Dense optical \ufb02ow prediction from a static  15. Srivastava, N., Mansimov, E., Salakhudinov, R.: Unsupervised learning of video  representations using lstms. In: ICML. (2015)  16. Oh, J., Guo, X., Lee, H., Lewis, R.L., Singh, S.: Action-conditional video prediction  using deep networks in atari games. In: NIPS. (2015)  17. Babaeizadeh, M., Finn, C., Erhan, D., Campbell, R.H., Levine, S.: Stochastic  variational video prediction. In: ICLR. (2018)  18. Finn, C., Levine, S.: Deep visual foresight for planning robot motion. In: ICRA.  19. Vondrick, C., Pirsiavash, H., Torralba, A.: Generating videos with scene dynamics.  (2017)  In: NIPS. (2016)  20. Liang, X., Lee, L., Dai, W., Xing, E.P.: Dual motion gan for future-\ufb02ow embedded  video prediction. In: ICCV. (2017)  21. Tulyakov, S., Liu, M.Y., Yang, X., Kautz, J.: Mocogan: Decomposing motion and  content for video generation. arXiv preprint arXiv:1707.04993 (2017)  22. Finn, C., Goodfellow, I., Levine, S.: Unsupervised learning for physical interaction  through video prediction. In: NIPS. (2016)  23. Vondrick, C., Torralba, A.: Generating the future with adversarial transformers.  In: CVPR. (2017)   16  Y. Li, C. Fang, J. Yang, Z. Wang, X. Lu, M.-H. Yang  24. Chao, Y.W., Yang, J., Price, B., Cohen, S., Deng, J.: Forecasting human dynamics  from static images. In: CVPR. (2017)  25. Villegas, R., Yang, J., Zou, Y., Sohn, S., Lin, X., Lee, H.: Learning to generate  long-term future via hierarchical prediction. In: ICML. (2017) 26. Doretto, G., Chiuso, A., Wu, Y.N., Soatto, S.: Dynamic textures.  IJCV 51(2)  (2003) 91-109  27. Yuan, L., Wen, F., Liu, C., Shum, H.Y.: Synthesizing dynamic texture with closed-  loop linear dynamic system. In: ECCV. (2004)  28. Xie, J., Zhu, S.C., Wu, Y.N.: Synthesizing dynamic patterns by spatial-temporal  generative convnet. In: CVPR. (2017)  29. Kingma, D.P., Welling, M.: Auto-encoding variational bayes. In: ICLR. (2014) 30. Sohn, K., Lee, H., Yan, X.: Learning structured output representation using deep  conditional generative models. In: NIPS. (2015)  31. Reed, S.E., Zhang, Y., Zhang, Y., Lee, H.: Deep visual analogy-making. In: NIPS.  (2015)  ance \ufb02ow. In: ECCV. (2016)  voxel \ufb02ow. In: ICCV. (2017)  32. Zhou, T., Tulsiani, S., Sun, W., Malik, J., Efros, A.A.: View synthesis by appear-  33. Liu, Z., Yeh, R., Tang, X., Liu, Y., Agarwala, A.: Video frame synthesis using deep  34. Park, E., Yang, J., Yumer, E., Ceylan, D., Berg, A.C.: Transformation-grounded  image generation network for novel 3d view synthesis. In: CVPR. (2017)  35. Chopra, S., Hadsell, R., LeCun, Y.: Learning a similarity metric discriminatively,  with application to face verification. In: CVPR. (2005)  36. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer  37. Dosovitskiy, A., Brox, T.: Generating images with perceptual similarity metrics  and super-resolution. In: ECCV. (2016)  based on deep networks. In: NIPS. (2016)  38. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. In: ICLR. (2015)  39. Maaten, L.v.d., Hinton, G.: Visualizing data using t-sne. JMLR 9(Nov) (2008)  2579-2605  40. Wu, Z., Song, S., Khosla, A., Yu, F., Zhang, L., Tang, X., Xiao, J.: 3d shapenets:  A deep representation for volumetric shapes. In: CVPR. (2015)  41. Ranjan, A., Black, M.J.: Optical \ufb02ow estimation using a spatial pyramid network.  42. Schuldt, C., Laptev, I., Caputo, B.: Recognizing human actions: a local svm ap-  In: CVPR. (2017)  proach. In: ICPR. (2004)  43. Gao, R., Xiong, B., Grauman, K.: Im2\ufb02ow: Motion hallucination from static images  for action recognition. arXiv preprint arXiv:1712.04109 (2017)  44. Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O.: The unreasonable  e\ufb00ectiveness of deep networks as a perceptual metric. In: CVPR. (2018)  45. Krizhevsky, A., Sutskever, I., Hinton, G.E.:  Imagenet classification with deep  convolutional neural networks. In: NIPS. (2012)  46. Tsai, Y.H., Shen, X., Lin, Z., Sunkavalli, K., Yang, M.H.: Sky is not the limit: semantic-aware sky replacement. ACM Transactions on Graphics 35(4) (2016) 149-159"}