{"1": "1. HaCohen, Y., Shechtman, E., Goldman, D.B., Lischinski, D.: Non-rigid dense correspondence with applications for image enhancement. ACM transactions on graphics (TOG) 30(4) (2011) 70  2. Liu, C., Yuen, J., Torralba, A.: Sift \ufb02ow: Dense correspondence across scenes and  its applications. IEEE Trans. PAMI 33(5) (2011) 815-830  3. Kim, J., Liu, C., Sha, F., Grauman, K.: Deformable spatial pyramid matching for  fast dense correspondences. In: CVPR (2013)  4. Yang, H., Lin, W.Y., Lu, J.: Daisy filter \ufb02ow: A generalized discrete approach to  dense correspondences. In: CVPR (2014)  5. Zhou, T., Lee, Y.J., Yu, S.X., Efros, A.A.: Flowweb: Joint image set alignment by  weaving consistent, pixel-wise correspondences. In: CVPR (2015)  6. Scharstein, D., Szeliski, R.: A taxonomy and evaluation of dense two-frame stereo  correspondence algorithms. IJCV 47(1) (2002) 7-42  7. Butler, D., Wul\ufb00, J., Stanley, G., Black, M.: A naturalistic open source movie for  optical \ufb02ow evaluation. In: ECCV (2012)  8. Kim, S., Min, D., Ham, B., Jeon, S., Lin, S., Sohn, K.: Fcss: Fully convolutional  self-similarity for dense semantic correspondence. In: CVPR (2017)  9. Choy, C.B., Gwak, J., Savarese, S., Chandraker, M.: Universal correspondence  network. In: NIPS (2016)  10. Kim, S., Min, D., Lin, S., Sohn, K.: Dctm: Discrete-continuous transformation  matching for semantic \ufb02ow. In: ICCV (2017)  11. DeTone, D., Malisiewicz, T., Rabinovich, A.: Deep image homography estimation.  arXiv preprint arXiv:1606.03798 (2016)  12. Rocco, I., Arandjelovi\u00b4c, R., Sivic, J.: Convolutional neural network architecture  for geometric matching. In: CVPR (2017)  13. Jaderberg, M., Simonyan, K., Zisserman, A., Kavukcuoglu, K.: Spatial transformer  14. Lin, C.H., Lucey, S.: Inverse compositional spatial transformer networks. In: CVPR  networks. In: NIPS (2015)  (2017)  15. Schneider, N., Piewak, F., Stiller, C., Franke, U.: Regnet: Multimodal sensor reg-  istration using deep neural networks. In: IV. (2017)  16. Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y.: Deformable convo-  lutional networks. In: ICCV (2017)  17. Hur, J., Lim, H., Park, C., Ahn, S.C.: Generalized deformable spatial pyramid:  Geometry-preserving dense correspondence estimation. In: CVPR (2015)  18. Tola, E., Lepetit, V., Fua, P.: Daisy: An e\ufb03cient dense descriptor applied to wide-  baseline stereo. IEEE Trans. PAMI 32(5) (2010) 815-830  19. Taniai, T., Sinha, S.N., Sato, Y.: Joint recovery of dense correspondence and  cosegmentation in two images. In: CVPR (2016)  20. Ham, B., Cho, M., Schmid, C., Ponce, J.: Proposal \ufb02ow: Semantic correspondences  from object proposals. IEEE Trans. PAMI (2017)  21. Li, F.F., Fergus, R., Perona, P.: One-shot learning of object categories.  IEEE  22. Yang, F., Li, X., Cheng, H., Li, J., Chen, L.: Object-aware dense semantic corre-  23. Bristow, H., Valmadre, J., Lucey, S.: Dense semantic correspondence where every  Trans. PAMI 28(4) (2006) 594-611  spondence. In: CVPR (2017)  pixel is a classifier. In: ICCV (2015)   PARN: Pyramidal A\ufb03ne Regression NetworksReferences  1. HaCohen, Y., Shechtman, E., Goldman, D.B., Lischinski, D.: Non-rigid dense correspondence with applications for image enhancement. ACM transactions on graphics (TOG) 30(4) (2011) 70  2. Liu, C., Yuen, J., Torralba, A.: Sift \ufb02ow: Dense correspondence across scenes and  its applications. IEEE Trans. PAMI 33(5) (2011) 815-830  3. Kim, J., Liu, C., Sha, F., Grauman, K.: Deformable spatial pyramid matching for  fast dense correspondences. In: CVPR (2013)  4. Yang, H., Lin, W.Y., Lu, J.: Daisy filter \ufb02ow: A generalized discrete approach to  dense correspondences. In: CVPR (2014)  5. Zhou, T., Lee, Y.J., Yu, S.X., Efros, A.A.: Flowweb: Joint image set alignment by  weaving consistent, pixel-wise correspondences. In: CVPR (2015)  6. Scharstein, D., Szeliski, R.: A taxonomy and evaluation of dense two-frame stereo  correspondence algorithms. IJCV 47(1) (2002) 7-42  7. Butler, D., Wul\ufb00, J., Stanley, G., Black, M.: A naturalistic open source movie for  optical \ufb02ow evaluation. In: ECCV (2012)  8. Kim, S., Min, D., Ham, B., Jeon, S., Lin, S., Sohn, K.: Fcss: Fully convolutional  self-similarity for dense semantic correspondence. In: CVPR (2017)  9. Choy, C.B., Gwak, J., Savarese, S., Chandraker, M.: Universal correspondence  network. In: NIPS (2016)  10. Kim, S., Min, D., Lin, S., Sohn, K.: Dctm: Discrete-continuous transformation  matching for semantic \ufb02ow. In: ICCV (2017)  11. DeTone, D., Malisiewicz, T., Rabinovich, A.: Deep image homography estimation.  arXiv preprint arXiv:1606.03798 (2016)  12. Rocco, I., Arandjelovi\u00b4c, R., Sivic, J.: Convolutional neural network architecture  for geometric matching. In: CVPR (2017)  13. Jaderberg, M., Simonyan, K., Zisserman, A., Kavukcuoglu, K.: Spatial transformer  14. Lin, C.H., Lucey, S.: Inverse compositional spatial transformer networks. In: CVPR  networks. In: NIPS (2015)  (2017)  15. Schneider, N., Piewak, F., Stiller, C., Franke, U.: Regnet: Multimodal sensor reg-  istration using deep neural networks. In: IV. (2017)  16. Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y.: Deformable convo-  lutional networks. In: ICCV (2017)  17. Hur, J., Lim, H., Park, C., Ahn, S.C.: Generalized deformable spatial pyramid:  Geometry-preserving dense correspondence estimation. In: CVPR (2015)  18. Tola, E., Lepetit, V., Fua, P.: Daisy: An e\ufb03cient dense descriptor applied to wide-  baseline stereo. IEEE Trans. PAMI 32(5) (2010) 815-830  19. Taniai, T., Sinha, S.N., Sato, Y.: Joint recovery of dense correspondence and  cosegmentation in two images. In: CVPR (2016)  20. Ham, B., Cho, M., Schmid, C., Ponce, J.: Proposal \ufb02ow: Semantic correspondences  from object proposals. IEEE Trans. PAMI (2017)  21. Li, F.F., Fergus, R., Perona, P.: One-shot learning of object categories.  IEEE  22. Yang, F., Li, X., Cheng, H., Li, J., Chen, L.: Object-aware dense semantic corre-  23. Bristow, H., Valmadre, J., Lucey, S.: Dense semantic correspondence where every  Trans. PAMI 28(4) (2006) 594-611  spondence. In: CVPR (2017)  pixel is a classifier. In: ICCV (2015)   16  S.Jeon, S.Kim, D.Min, K.Sohn  24. Lowe, D.: Distinctive image features from scale-invariant keypoints. IJCV 60(2)  (2004) 91-110  25. Zhou, T., Krahenbuhl, P., Aubry, M., Huang, Q., Efros, A.A.: Learning dense  correspondence via 3d-guided cycle consistency. In: CVPR (2016)  26. Online.: http://www.shapenet.org/. 27. Novotny, D., Larlus, D., Vedaldi, A.: Anchornet: A weakly supervised network to  learn geometry-sensitive features for semantic matching. In: CVPR (2017)  28. Hassner, T., Mayzels, V., Zelnik-Manor, L.: On sifts and their scales. In: CVPR  (2012)  (2014)  29. Qiu, W., Wang, X., Bai, X., Yuille, A., Tu, Z.: Scale-space sift \ufb02ow. In: WACV  30. Ham, B., Cho, M., Schmid, C., Ponce, J.: Proposal \ufb02ow. In: CVPR (2016) 31. Han, K., Rezende, R.S., Ham, B., Wong, K.Y.K., Cho, M., Schmid, C., Ponce, J.:  Scnet: Learning semantic correspondence. In: ICCV (2017)  32. Li, Y., Min, D., Brown, M.S., Do, M.N., Lu, J.: Spm-bp: Sped-up patchmatch  belief propagation for continuous mrfs. In: ICCV (2015)  33. Hosni, A., Rhemann, C., Bleyer, M., Rother, C., Gelautz, M.: Fast cost-volume filtering for visual correspondence and beyond. IEEE Trans. PAMI 35(2) (2013) 34. Lu, J., Yang, H., Min, D., Do, M.N.: Patchmatch filter: E\ufb03cient edge-aware filter- ing meets randomized search for fast correspondence field estimation. In: CVPR (2013)  35. Revaud, J., Weinzaepfel, P., Harchaoui, Z., Schmid, C.: Deepmatcing: Hierarchical  deformable dense matching. IJCV (2015)  36. Ranjan, A., Black, M.J.: Optical \ufb02ow estimation using a spatial pyramid network.  37. Krizhevsky, A., Sutskever, I., Hinton, G.E.:  Imagenet classification with deep  convolutional neural networks. In: NIPS (2012)  38. He, K., Zhang, X., Ren, S., J., S.: Deep residual learning for image recognition.  In: CVPR (2017)  In: CVPR (2016)  39. Butler, D., Wul\ufb00, J., Stanley, G., Black, M.: A naturalistic open source movie for  optical \ufb02ow evaluation. In: ECCV (2012)  40. Fischler, M.A., Bolles, R.C.: Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Commu- nications of the ACM 24(6) (1981) 381-395  41. Godard, C., Mac Aodha, O., Brostow, G.J.: Unsupervised monocular depth esti-  mation with left-right consistency. In: CVPR (2017)  42. Fischer, P., Dosovitskiy, A., Ilg, E., H\u00a8ausser, P., Haz\u0131rba\u00b8s, C., Golkov, V., Van der Smagt, P., Cremers, D., Brox, T.: Flownet: Learning optical \ufb02ow with convolutional networks. In: ICCV (2015)  43. Noh, H., Hong, S., Han, B.: Learning deconvolution network for semantic segmen-  tation. In: ICCV (2015)  44. Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisseman, A.: The  pascal visual object classes (voc) challenge. IJCV 88(2) (2010) 303-338  45. Chen, X., Mottaghi, R., Liu, X., Fidler, S., Urtasum, R., Yuille, A.: Detect what you can: Detecting and representing objects using holistic models and body parts. In: CVPR (2014)  46. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. In: ICLR (2015)  47. Torr, P.H., Zisserman, A.: Mlesac: A new robust estimator with application to estimating image geometry. Computer Vision and Image Understanding 78(1) (2000) 138-156"}