{"1": "iv:1701.07875 (2017)  tion. In: ICLR (2015)  1. Arjovsky, M., Chintala, S., Bottou, L.: Wasserstein gan. arXiv preprint arX-  2. Ba, J., Mnih, V., Kavukcuoglu, K.: Multiple object recongnition with visual atten-  3. Cao, Y., Long, M., Wang, J., Yang, Q., Philip, S.Y.: Deep visual-semantic hashing  for cross-modal retrieval. In: KDD. pp. 1445-1454 (2016)  4. Cao, Y., Long, M., Wang, J., Zhu, H.: Correlation autoencoder hashing for super-  vised cross-modal search. In: ICMR. pp. 197-204 (2016)  5. Chatfield, K., Simonyan, K., Vedaldi, A., Zisserman, A.: Return of the devil in the  details: Delving deep into convolutional nets. Computer Science (2014)  6. Chua, T.S., Tang, J., Hong, R., Li, H., Luo, Z., Zheng, Y.: Nus-wide: a real-world web image database from national university of singapore. In: ICIVR. p. 48 (2009) 7. Courbariaux, M., Bengio, Y.: Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1. CoRR abs/1602.02830 (2016) 8. Ding, G., Guo, Y., Zhou, J.: Collective matrix factorization hashing for multimodal  data. In: CVPR. pp. 2075-2082 (2014)  9. Escalante, H.J., Hernndez, C.A., Gonzalez, J.A., Lpez-Lpez, A., Montes, M., Morales, E.F., Sucar, L.E., Villaseor, L., Grubinger, M.: The segmented and an- notated iapr tc-12 benchmark. CVIU 114(4), 419-428 (2010)  10. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In: NIPS. pp. 2672-2680 (2014)  11. He, R., Zheng, W.S., Hu, B.G.: Maximum correntropy criterion for robust face  recognition. TPAMI 33(8), 1561-1576 (2011)  12. Hotelling, H.: Relations Between Two Sets of Variates. Springer New York (1992) 13. Huiskes, M.J., Lew, M.S.: The mir \ufb02ickr retrieval evaluation. In: ICMIR. pp. 39-43  (2008)  14. Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadar- rama, S., Darrell, T.: Ca\ufb00e: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.5093 (2014)  15. Jiang, Q.Y., Li, W.: Deep cross-modal hashing. In: CVPR (2016) 16. Lai, H., Pan, Y., Liu, Y., Yan, S.: Simultaneous feature learning and hash coding  with deep neural networks. In: CVPR. pp. 3270-3278 (2015)  17. Lai, H., Yan, P., Shu, X., Wei, Y., Yan, S.: Instance-aware hashing for multi-label  image retrieval. TIP 25(6), 2469-2479 (2016)  18. Li, C., Deng, C., Li, N., Liu, W., Gao, X., Tao, D.: Self-supervised adversarial hashing networks for cross-modal retrieval. In: CVPR. pp. 4242-4251 (2018) 19. Lin, Z., Ding, G., Hu, M., Wang, J.: Semantics-preserving hashing for cross-view  retrieval. In: CVPR. pp. 3864-3872 (2015)  20. Liu, W., Kumar, S., Kumar, S., Chang, S.F.: Discrete graph hashing. In: NIPS.  pp. 3419-3427 (2014)  21. Masci, J., Bronstein, M.M., Bronstein, A.M., Schmidhuber, J.: Multimodal  similarity-preserving hashing. TPAMI 36(4), 824-830 (2014)  22. Mathieu, M.F., Zhao, J.J., Zhao, J., Ramesh, A., Sprechmann, P., LeCun, Y.: Disentangling factors of variation in deep representation using adversarial training. In: NIPS. pp. 5040-5048 (2016)  23. Mirza, M., Osindero, S.: Conditional generative adversarial nets. arXiv preprint  arXiv:1411.1784 (2014)   Attention-aware deep adversarial hashingReferences  iv:1701.07875 (2017)  tion. In: ICLR (2015)  1. Arjovsky, M., Chintala, S., Bottou, L.: Wasserstein gan. arXiv preprint arX-  2. Ba, J., Mnih, V., Kavukcuoglu, K.: Multiple object recongnition with visual atten-  3. Cao, Y., Long, M., Wang, J., Yang, Q., Philip, S.Y.: Deep visual-semantic hashing  for cross-modal retrieval. In: KDD. pp. 1445-1454 (2016)  4. Cao, Y., Long, M., Wang, J., Zhu, H.: Correlation autoencoder hashing for super-  vised cross-modal search. In: ICMR. pp. 197-204 (2016)  5. Chatfield, K., Simonyan, K., Vedaldi, A., Zisserman, A.: Return of the devil in the  details: Delving deep into convolutional nets. Computer Science (2014)  6. Chua, T.S., Tang, J., Hong, R., Li, H., Luo, Z., Zheng, Y.: Nus-wide: a real-world web image database from national university of singapore. In: ICIVR. p. 48 (2009) 7. Courbariaux, M., Bengio, Y.: Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1. CoRR abs/1602.02830 (2016) 8. Ding, G., Guo, Y., Zhou, J.: Collective matrix factorization hashing for multimodal  data. In: CVPR. pp. 2075-2082 (2014)  9. Escalante, H.J., Hernndez, C.A., Gonzalez, J.A., Lpez-Lpez, A., Montes, M., Morales, E.F., Sucar, L.E., Villaseor, L., Grubinger, M.: The segmented and an- notated iapr tc-12 benchmark. CVIU 114(4), 419-428 (2010)  10. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In: NIPS. pp. 2672-2680 (2014)  11. He, R., Zheng, W.S., Hu, B.G.: Maximum correntropy criterion for robust face  recognition. TPAMI 33(8), 1561-1576 (2011)  12. Hotelling, H.: Relations Between Two Sets of Variates. Springer New York (1992) 13. Huiskes, M.J., Lew, M.S.: The mir \ufb02ickr retrieval evaluation. In: ICMIR. pp. 39-43  (2008)  14. Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadar- rama, S., Darrell, T.: Ca\ufb00e: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.5093 (2014)  15. Jiang, Q.Y., Li, W.: Deep cross-modal hashing. In: CVPR (2016) 16. Lai, H., Pan, Y., Liu, Y., Yan, S.: Simultaneous feature learning and hash coding  with deep neural networks. In: CVPR. pp. 3270-3278 (2015)  17. Lai, H., Yan, P., Shu, X., Wei, Y., Yan, S.: Instance-aware hashing for multi-label  image retrieval. TIP 25(6), 2469-2479 (2016)  18. Li, C., Deng, C., Li, N., Liu, W., Gao, X., Tao, D.: Self-supervised adversarial hashing networks for cross-modal retrieval. In: CVPR. pp. 4242-4251 (2018) 19. Lin, Z., Ding, G., Hu, M., Wang, J.: Semantics-preserving hashing for cross-view  retrieval. In: CVPR. pp. 3864-3872 (2015)  20. Liu, W., Kumar, S., Kumar, S., Chang, S.F.: Discrete graph hashing. In: NIPS.  pp. 3419-3427 (2014)  21. Masci, J., Bronstein, M.M., Bronstein, A.M., Schmidhuber, J.: Multimodal  similarity-preserving hashing. TPAMI 36(4), 824-830 (2014)  22. Mathieu, M.F., Zhao, J.J., Zhao, J., Ramesh, A., Sprechmann, P., LeCun, Y.: Disentangling factors of variation in deep representation using adversarial training. In: NIPS. pp. 5040-5048 (2016)  23. Mirza, M., Osindero, S.: Conditional generative adversarial nets. arXiv preprint  arXiv:1411.1784 (2014)   16  Zhang et al.  24. Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 (2015)  25. Sharma, S., Kiros, R., Salakhutdinov, R.: Action recognition using visual attention.  arXiv preprint arXiv:1511.04119 (2015)  26. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale  image recognition. arXiv preprint arXiv:1409.1556 (2014)  27. Sun, L., Ji, S., Ye, J.: A least squares formulation for canonical correlation analysis.  In: ICML. pp. 1024-1031 (2008)  28. Wang, B., Yang, Y., Xu, X., Hanjalic, A., Shen, H.T.: Adversarial cross-modal  retrieval. In: ACMMM. pp. 154-162 (2017)  29. Wang, D., Cui, P., Ou, M., Zhu, W.: Learning compact hash codes for multimodal  representations using orthogonal deep structure. TMM 17(9), 1404-1416 (2015)  30. Wang, D., Gao, X., Wang, X., He, L.: Semantic topic multimodal hashing for  cross-media retrieval. In: ICAI. pp. 3890-3896 (2015)  31. Wang, J., Zhang, T., Sebe, N., Shen, H.T., et al.: A survey on learning to hash.  TPAMI (2017)  32. Wang, J., Yu, L., Zhang, W., Gong, Y., Xu, Y., Wang, B., Zhang, P., Zhang, D.: Irgan: A minimax game for unifying generative and discriminative information retrieval models. arXiv preprint arXiv:1705.10513 (2017)  33. Wang, K., Yin, Q., Wang, W., Wu, S., Wang, L.: A comprehensive survey on  cross-modal retrieval. arXiv preprint arXiv:1607.06215 (2016)  34. Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., Bengio, Y.: Show, attend and tell: Neural image caption generation with visual attention. In: ICML. pp. 2048-2057 (2015)  35. Xu, X., Shen, F., Yang, Y., Shen, H.T., Li, X.: Learning discriminative binary  codes for large-scale cross-modal retrieval. TIP 26(5), 2494-2507 (2017)  36. Yang, E., Deng, C., Liu, W., Liu, X., Tao, D., Gao, X.: Pairwise relationship guided  deep hashing for cross-modal retrieval. In: AAAI. pp. 1618-1625 (2017)  37. Yang, E., Deng, C., Liu, W., Liu, X., Tao, D., Gao, X.: Pairwise relationship guided  deep hashing for cross-modal retrieval. AAAI (2017)  38. Yang, Z., He, X., Gao, J., Deng, L., Smola, A.: Stacked attention networks for  image question answering. In: CVPR. pp. 21-29 (2016)  39. Yu, Z., Wu, F., Yang, Y., Tian, Q., Luo, J., Zhuang, Y.: Discriminative coupled dictionary hashing for fast cross-media retrieval. In: SIGIR. pp. 395-404 (2014) 40. Zhang, D., Li, W.J.: Large-scale supervised multimodal hashing with semantic  correlation maximization. In: AAAI. vol. 1, p. 7 (2014)  41. Zhen, Y., Yeung, D.Y.: Co-regularized hashing for multimodal data. In: NIPS. pp.  1376-1384 (2012)  42. Zhu, J.Y., Park, T., Isola, P., Efros, A.A.: Unpaired image-to-image translation us- ing cycle-consistent adversarial networks. arXiv preprint arXiv:1703.10593 (2017)"}