{"On the Complexity of Best-Arm Identification in Multi-Armed Bandit Models": {"volumn": 17, "url": "http://jmlr.org/papers/v17/kaufman16a.html", "header": "On the Complexity of Best-Arm Identification in Multi-Armed Bandit Models", "author": "Emilie Kaufmann, Olivier Capp\u00c3\u00a9, Aur\u00c3\u00a9lien Garivier", "time": "17(1):1\u221242, 2016.", "abstract": "The stochastic multi-armed bandit model is a simple abstraction that has proven useful in many different contexts in statistics and machine learning. Whereas the achievable limit in terms of regret minimization is now well known, our aim is to contribute to a better understanding of the performance in terms of identifying the $m$ best arms. We introduce generic notions of complexity for the two dominant frameworks considered in the literature: fixed-budget and fixed-confidence settings. In the fixed-confidence setting, we provide the first known distribution-dependent lower bound on the complexity that involves information-theoretic quantities and holds when $m\\geq 1$ under general assumptions. In the specific case of two armed- bandits, we derive refined lower bounds in both the fixed- confidence and fixed-budget settings, along with matching algorithms for Gaussian and Bernoulli bandit models. These results show in particular that the complexity of the fixed- budget setting may be smaller than the complexity of the fixed- confidence setting, contradicting the familiar behavior observed when testing fully specified alternatives. In addition, we also provide improved sequential stopping rules that have guaranteed error probabilities and shorter average running times. The proofs rely on two technical results that are of independent interest : a deviation lemma for self-normalized sums (Lemma 7) and a novel change of measure inequality for bandit models (Lemma 1).", "pdf_url": "http://jmlr.org/papers/volume17/kaufman16a/kaufman16a.pdf", "keywords": ["multi-armed bandit", "best-arm identification", "pure exploration", "information theoretic divergences", "sequential testing"], "reference": "S. Agrawal and N. Goyal. Further optimal regret bounds for Thompson Sampling.  In  Conference on Artificial Intelligence and Statistics (AISTATS), 2013.  J-Y. Audibert, S. Bubeck, and R. Munos. Best arm identification in multi-armed bandits.  In Conference on Learning Theory (COLT), 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine Learning, 47(2):235-256, 2002.  Robert Bechhofer, Jack Kiefer, and Milton Sobel. Sequential identification and ranking  procedures. The university of Chicago Press, 1968.  S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in finitely armed and continuous  armed bandits. Theoretical Computer Science, 412:1832-1852, 2011.  S. Bubeck, V. Perchet, and P. Rigollet. Bounded regret in stochastic multi-armed bandits.  In Conference On Learning Theory (COLT), 2013a.  S. Bubeck, T. Wang, and N. Viswanathan. Multiple identifications in multi-armed bandits.  In International Conference on Machine Learning (ICML), 2013b.  A.N Burnetas and M. Katehakis. Optimal adaptive policies for sequential allocation prob-  lems. Advances in Applied Mathematics, 17(2):122-142, 1996.  O. Capp\u00b4e, A. Garivier, O-A. Maillard, R. Munos, and G. Stoltz. Kullback-Leibler upper confidence bounds for optimal sequential allocation. Annals of Statistics, 41(3):1516- 1541, 2013.  T. Cover and J. Thomas. Elements of information theory (2nd Edition). Wiley, 2006.  E. Even-Dar, S. Mannor, and Y. Mansour. Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. Journal of Machine Learning Research, 7:1079-1105, 2006.  V. Gabillon, M. Ghavamzadeh, and A. Lazaric. Best arm identification: a unified approach In Advances in Neural Information Processing  to fixed budget and fixed confidence. Systems (NIPS), 2012.  V. Heidrich-Meisner and C. Igel. Hoe\ufb00ding and Bernstein races for selecting policies in evo- lutionary direct policy search. In International Conference on Machine Learning (ICML), 2009.  41   Complexity of Best-Arm Identification in Multi-Armed Bandits  thus  max  (cid:16)  (cid:17) pt(\u03bd), pt(\u03bd[a,b])  (cid:18)  (cid:18)  exp  exp  1 4  1 4  (cid:20) 2\u03c32t H\u22062 a (cid:19)  \u2212  4t \u02dcH  \u2212  \u2265  =  4\u22062 a 2\u03c32 +  with \u02dcH =  (cid:21)(cid:19)  4\u22062 2\u03c32t b H \u2212\u22062 2\u03c32 b HH \u2212 H + H \u2212 .  References  S. Agrawal and N. Goyal. Further optimal regret bounds for Thompson Sampling.  In  Conference on Artificial Intelligence and Statistics (AISTATS), 2013.  J-Y. Audibert, S. Bubeck, and R. Munos. Best arm identification in multi-armed bandits.  In Conference on Learning Theory (COLT), 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine Learning, 47(2):235-256, 2002.  Robert Bechhofer, Jack Kiefer, and Milton Sobel. Sequential identification and ranking  procedures. The university of Chicago Press, 1968.  S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in finitely armed and continuous  armed bandits. Theoretical Computer Science, 412:1832-1852, 2011.  S. Bubeck, V. Perchet, and P. Rigollet. Bounded regret in stochastic multi-armed bandits.  In Conference On Learning Theory (COLT), 2013a.  S. Bubeck, T. Wang, and N. Viswanathan. Multiple identifications in multi-armed bandits.  In International Conference on Machine Learning (ICML), 2013b.  A.N Burnetas and M. Katehakis. Optimal adaptive policies for sequential allocation prob-  lems. Advances in Applied Mathematics, 17(2):122-142, 1996.  O. Capp\u00b4e, A. Garivier, O-A. Maillard, R. Munos, and G. Stoltz. Kullback-Leibler upper confidence bounds for optimal sequential allocation. Annals of Statistics, 41(3):1516- 1541, 2013.  T. Cover and J. Thomas. Elements of information theory (2nd Edition). Wiley, 2006.  E. Even-Dar, S. Mannor, and Y. Mansour. Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. Journal of Machine Learning Research, 7:1079-1105, 2006.  V. Gabillon, M. Ghavamzadeh, and A. Lazaric. Best arm identification: a unified approach In Advances in Neural Information Processing  to fixed budget and fixed confidence. Systems (NIPS), 2012.  V. Heidrich-Meisner and C. Igel. Hoe\ufb00ding and Bernstein races for selecting policies in evo- lutionary direct policy search. In International Conference on Machine Learning (ICML), 2009. Kaufmann, Capp\u00b4e and Garivier  J. Honda and A. Takemura. An asymptotically optimal policy for finite support models in  the multiarmed bandit problem. Machine Learning, 85(3):361-391, 2011.  K. Jamieson, M. Malloy, R. Nowak, and S. Bubeck. lil\u2019UCB: an optimal exploration algo-  rithm for multi-armed bandits. In Conference on Learning Theory (COLT), 2014.  C. Jennison, I.M. Johnstone, and B.W. Turnbull. Asymptotically optimal procedures for sequential adaptive selection of the best of several normal means. Statistical Decision Theory and Related Topics III, 2:55-86, 1982.  S. Kalyanakrishnan, A. Tewari, P. Auer, and P. Stone. PAC subset selection in stochastic multi-armed bandits. In International Conference on Machine Learning (ICML), 2012.  Z. Karnin, T. Koren, and O. Somekh. Almost optimal exploration in multi-armed bandits.  In International Conference on Machine Learning (ICML), 2013.  E. Kaufmann and S. Kalyanakrishnan. Information complexity in bandit subset selection.  In Conference On Learning Theory (COLT), 2013.  E. Kaufmann, A. Garivier, and O. Capp\u00b4e. On Bayesian upper-confidence bounds for bandit problems. In Conference on Artificial Intelligence and Statistics (AISTATS), 2012a.  E. Kaufmann, N. Korda, and R. Munos. Thompson Sampling : an asymptotically optimal  finite-time analysis. In Algorithmic Learning Theory (ALT), 2012b.  T.L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6(1):4-22, 1985.  S. Mannor and J. Tsitsiklis. The sample complexity of exploration in the multi-armed  bandit problem. Journal of Machine Learning Research, pages 623-648, 2004.  O. Maron and A. Moore. The Racing algorithm: Model selection for lazy learners. Artificial  Intelligence Review, 11(1-5):113-131, 1997.  E. Paulson. A sequential procedure for selecting the population with the largest mean from  k normal populations. Annals of Mathematical Statistics, 35:174-180, 1964.  H. Robbins. Some aspects of the sequential design of experiments. Bulletin of the American  Mathematical Society, 58(5):527-535, 1952.  H. Robbins. Statistical methods related to the law of the iterated logarithm. Annals of  Mathematical Statistics, 41(5):1397-1409, 1970.  D. Siegmund. Sequential analysis. Springer-Verlag, 1985.  W.R. Thompson. On the likelihood that one unknown probability exceeds another in view  of the evidence of two samples. Biometrika, 25:285-294, 1933.  A. Wald. Sequential tests of statistical hypotheses. Annals of Mathematical Statistics, 16(2):  117-186, 1945. "}, "Consistent Algorithms for Clustering Time Series": {"volumn": 17, "url": "http://jmlr.org/papers/v17/khaleghi16a.html", "header": "Consistent Algorithms for Clustering Time Series", "author": "Azadeh Khaleghi, Daniil Ryabko, J\u00c3\u00a9r\u00c3\u00a9mie Mary, Philippe Preux", "time": "17(3):1\u221232, 2016.", "abstract": "The problem of clustering is considered for the case where every point is a time series. The time series are either given in one batch (offline setting), or they are allowed to grow with time and new time series can be added along the way (online setting). We propose a natural notion of consistency for this problem, and show that there are simple, computationally efficient algorithms that are asymptotically consistent under extremely weak assumptions on the distributions that generate the data. The notion of consistency is as follows. A clustering algorithm is called consistent if it places two time series into the same cluster if and only if the distribution that generates them is the same. In the considered framework the time series are allowed to be highly dependent, and the dependence can have arbitrary form. If the number of clusters is known, the only assumption we make is that the (marginal) distribution of each time series is stationary ergodic. No parametric, memory or mixing assumptions are made. When the number of clusters is unknown, stronger assumptions are provably necessary, but it is still possible to devise nonparametric algorithms that are consistent under very general conditions. The theoretical findings of this work are illustrated with experiments on both synthetic and real data.", "pdf_url": "http://jmlr.org/papers/volume17/khaleghi16a/khaleghi16a.pdf", "keywords": [""], "reference": "F.R. Bach and M.I. Jordan. Learning graphical models for stationary time series. IEEE  Transactions on Signal Processing, 52(8):2189 - 2199, Aug. 2004.  M.F. Balcan, A. Blum, and S. Vempala. A discriminative framework for clustering via similarity functions. In Proceedings of the 40th Annual ACM Symposium on Theory of Computing, pages 671-680, 2008.  C. Biernacki, G. Celeux, and G. Govaert. Assessing a mixture model for clustering with the integrated completed likelihood. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 22(7):719-725, 2000.  P. Billingsley. Statistical methods in Markov chains. The Annals of Mathematical Statistics,  32(1):12-40, 1961.  Springer, 1996.  P. Billingsley. Convergence of Probability Measures. John Wiley & Sons, 1999.  D. Bosq. Nonparametric Statistics for Stochastic Processes. Estimation and Prediction.  R.C. Bradley. Basic properties of strong mixing conditions: A survey and some open  questions. Probability Surveys, 2:107-144, 2005.  29   Consistent Algorithms for Clustering Time Series  exploit is that it can be estimated consistently. In principle, one can use other distances with this property, in order to obtain consistent clustering algorithms. While there are not many known distances that can be consistently estimated for arbitrary stationary ergodic distributions, there is at least one, namely the telescope distance recently introduced by Ryabko and Mary (2013). Moreover, the definition of consistency proposed does not entail the need to use a distance between time-series distributions. As an alternative, the use of compression-based methods can be considered. Such methods have been used to solve various statistical problems concerning stationary ergodic time series (Ryabko and Astola, 2006; Ryabko, 2010a). Compression-based methods have also been used for clustering time- series data before, albeit without consistency analysis, by Cilibrasi and Vitanyi (2005). Combining our consistency framework with these compression-based methods is another promising direction for further research.  Acknowledgments  This paper is an extended version of two conference papers: (Ryabko, 2010b) and (Khaleghi et al., 2012). Most of the work by Azadeh Khaleghi has been done during her PhD at INRIA Lille - Nord Europe. This work is supported by the French Ministry of Higher Education and Research, by FP7/2007-2013 under grant agreements 270327 (CompLACS), by the Nord-Pas-de-Calais Regional Council and FEDER, and by the European Research Coun- cil (SMAC-ERC-280032). J\u00b4er\u00b4emie Mary and Philippe Preux acknowledge the support of INRIA. J\u00b4er\u00b4emie Mary further acknowledges INRIA for the support through partial second- ments.  References  F.R. Bach and M.I. Jordan. Learning graphical models for stationary time series. IEEE  Transactions on Signal Processing, 52(8):2189 - 2199, Aug. 2004.  M.F. Balcan, A. Blum, and S. Vempala. A discriminative framework for clustering via similarity functions. In Proceedings of the 40th Annual ACM Symposium on Theory of Computing, pages 671-680, 2008.  C. Biernacki, G. Celeux, and G. Govaert. Assessing a mixture model for clustering with the integrated completed likelihood. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 22(7):719-725, 2000.  P. Billingsley. Statistical methods in Markov chains. The Annals of Mathematical Statistics,  32(1):12-40, 1961.  Springer, 1996.  P. Billingsley. Convergence of Probability Measures. John Wiley & Sons, 1999.  D. Bosq. Nonparametric Statistics for Stochastic Processes. Estimation and Prediction.  R.C. Bradley. Basic properties of strong mixing conditions: A survey and some open  questions. Probability Surveys, 2:107-144, 2005. Khaleghi, Ryabko, Mary and Preux  E. Carlstein and S. Lele. Nonparametric change-point estimation for data from an ergodic  sequence. Theory of Probability & its Applications, 38(4):726-733, 1994.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  R. Cilibrasi and P.M.B. Vitanyi. Clustering by compression. IEEE Transactions on Infor-  mation Theory, 51:1523-1545, 2005.  P. Doukhan. Mixing. Springer, 1994.  P. Doukhan, G. Lang, D. Surgailis, and G. Teyssi`ere. Dependence in Probability and Statis-  tics. Springer, 2010.  R. Gray. Probability, Random Processes, and Ergodic Properties. Springer Verlag, 1988.  R. Grossi and J.S. Vitter. Compressed su\ufb03x arrays and su\ufb03x trees with applications to text indexing and string matching. SIAM Journal on Computing, 35(2):378-407, 2005.  M. Gutman. Asymptotically optimal classification for multiple tests with empirically ob-  served statistics. IEEE Transactions on Information Theory, 35(2):402-408, 1989.  T. Jebara, Y. Song, and K. Thadani. Spectral clustering and embedding with hidden  Markov models. Machine Learning: ECML 2007, pages 164-175, 2007.  I. Katsavounidis, C.-C. Jay Kuo, and Zhen Zhang. A new initialisation technique for  generalised Lloyd iteration. IEEE Signal Processing Letters, 1:144-146, 1994.  A. Khaleghi and D. Ryabko. Locating changes in highly-dependent data with unknown number of change points. In Neural Information Processing Systems (NIPS), Lake Tahoe, Nevada, United States, 2012.  A. Khaleghi, D. Ryabko, J. Mary, and P. Preux. Online clustering of processes. In Interna- tional Conference on Artificial Intelligence and Statistics (AI&STATS), JMLR W&CP 22, pages 601-609, 2012.  A. Khaleghi and D. Ryabko. Asymptotically consistent estimation of the number of change points in highly dependent time series. In the Proceedings of the 29th International Conference on Machine Learning (ICML), JMLR W&CP, pages 539-547, Beijing, China, 2014.  J. Kleinberg. An impossibility theorem for clustering. In Neural Information Processing  Systems (NIPS), pages 446-453, Montreal, Canada, 2002.  I. Kontoyiannis and Y.M. Suhov. Prefixes and the entropy rate for long-range sources. In  IEEE International Symposium on Information Theory, pages 194-194, 1994.  M. Kumar, N.R. Patel, and J. Woo. Clustering seasonality patterns in the presence of errors. In Proceedings of the 8th International Conference on Knowledge Discovery and Data Mining (ACM SIGKDD), pages 557-563. ACM, 2002. Consistent Algorithms for Clustering Time Series  E. Lehmann. Testing Statistical Hypotheses, 2nd edition. Wiley, New York, 1986.  L. Li and B.A. Prakash. Time series clustering: Complex is simpler! In the Proceedings of the 28th International Conference on Machine Learning (ICML), pages 185-192, 2011.  M. Mahajan, P. Nimbhorkar, and K. Varadarajan. The planar k-means problem is NP-hard. In the Proceedings of the 3rd International Workshop on Algorithms and Computation (WALCOM), pages 274-285, Berlin, Heidelberg, 2009.  G. Morvai and B. Weiss. On classifying processes. Bernoulli, 11(3):523-532, 2005.  MOCAP. CMU graphics lab motion capture database. Available at http://mocap.cs.  G. Morvai and B. Weiss. A note on prediction for discrete time series. Kybernetika, 48(4):  D.S. Ornstein and B. Weiss. How sampling reveals a process. Annals of Probability, 18(3):  E. Rio. Th\u00b4eorie asymptotique des processus al\u00b4eatoires faiblement d\u00b4ependants, volume 31.  cmu.edu/.  809-823, 2012.  905-930, 1990.  Springer, 1999.  B. Ryabko. Prediction of random sequences and universal coding. Problems of Information  Transmission, 24:87-96, 1988.  Methodology, 3:375-397, 2006.  B. Ryabko and J. Astola. Universal codes as a basis for time series testing. Statistical  B. Ryabko. Applications of universal source coding to statistical analysis of time series. Selected Topics in Information and Coding Theory, World Scientific Publishing, pages 289-338, 2010a.  D. Ryabko. Clustering processes. In the Proceedings of the 27th International Conference  on Machine Learning (ICML), pages 919-926, Haifa, Israel, 2010b.  D. Ryabko. Discrimination between B-processes is impossible. Journal of Theoretical Prob-  ability, 23(2):565-575, 2010c.  D. Ryabko. Testing composite hypotheses about discrete ergodic processes. Test, 21(2):  D. Ryabko. Uniform hypothesis testing for finite-valued stationary processes. Statistics, 48  317-329, 2012.  (1):121-128, 2014.  D. Ryabko and B. Ryabko. Nonparametric statistical inference for ergodic processes. IEEE  Transactions on Information Theory, 56(3):1430-1435, 2010.  D. Ryabko and J. Mary. A binary-classification-based metric between time-series distri- butions and its use in statistical and learning problems. Journal of Machine Learning Research, 14:2837-2856, 2013. Khaleghi, Ryabko, Mary and Preux  P. Shields. The Ergodic Theory of Discrete Sample Paths. AMS Bookstore, 1996.  P. Smyth. Clustering sequences with hidden Markov models. In Advances in Neural Infor-  mation Processing Systems, pages 648-654. MIT Press, 1997.  M. Tschannen and H. Bolcskei. Nonparametric nearest neighbor random process clustering. In Proceedings of the 2015 IEEE International Symposium on Information Theory, pages 1207-1211, Hong Kong, 2015. IEEE.  E. Ukkonen. On-line construction of su\ufb03x trees. Algorithmica, 14(3):249-260, 1995.  S. Zhong and J. Ghosh. A unified framework for model-based clustering. Journal of Machine  Learning Research, 4:1001-1037, 2003. "}, "Random Rotation Ensembles": {"volumn": 17, "url": "http://jmlr.org/papers/v17/blaser16a.html", "header": "Random Rotation Ensembles", "author": "Rico Blaser, Piotr Fryzlewicz", "time": "17(4):1\u221226, 2016.", "abstract": "In machine learning, ensemble methods combine the predictions of multiple base learners to construct more accurate aggregate predictions. Established supervised learning algorithms inject randomness into the construction of the individual base learners in an effort to promote diversity within the resulting ensembles. An undesirable side effect of this approach is that it generally also reduces the accuracy of the base learners. In this paper, we introduce a method that is simple to implement yet general and effective in improving ensemble diversity with only modest impact on the accuracy of the individual base learners. By randomly rotating the feature space prior to inducing the base learners, we achieve favorable aggregate predictions on standard data sets compared to state of the art ensemble methods, most notably for tree-based ensembles, which are particularly sensitive to rotation.", "pdf_url": "http://jmlr.org/papers/volume17/blaser16a/blaser16a.pdf", "keywords": [""], "reference": "Dean Abbott. Why ensembles win data mining competitions. In Predictive Analytics Centre  of Excellence Tech Talks, University of California, San Diego, 2012.  Theodore W. Anderson, Ingram Olkin, and Les G. Underhill. Generation of random or- thogonal matrices. SIAM Journal on Scientific and Statistical Computing, 8:625-629, 1987.  Kevin Bache and Moshe Lichman. UCI machine learning repository. University of California, Irvine, School of Information and Computer Science, 2013. URL http: //archive.ics.uci.edu/ml.  Leo Breiman. Bagging predictors. Machine Learning, 24:123-140, 1996.  Leo Breiman. Random forests - random features. Technical report, University of California  at Berkeley, Berkeley, California, 1999.  Leo Breiman. Randomizing outputs to increase prediction accuracy. Machine Learning, 40:  229-242, 2000.  Leo Breiman. Random forests. Machine Learning, 45:5-32, 2001.  Rich Caruana and Alexandru Niculescu-Mizil. An empirical comparison of supervised learn- ing algorithms. In Proceedings of the 23rd International Conference on Machine Learning, pages 161-168, 2006.  Adele Cutler and Guohua Zhao. PERT-perfect random tree ensembles. Computing Science  and Statistics, 33:490-497, 2001.  Koen W. De Bock and Dirk Van den Poel. An empirical evaluation of rotation-based ensemble classifiers for customer churn prediction. Expert Systems with Applications, 38: 12293-12301, 2011.  Persi Diaconis and Mehrdad Shahshahani. The subgroup algorithm for generating uniform random variables. Probability in the Engineering and Informational Sciences, 1:15-32, 1987.  Haytham Elghazel, Alex Aussem, and Florence Perraud. Trading-o\ufb00 diversity and accuracy for optimal ensemble tree selection in random forests. In Ensembles in Machine Learn- ing Applications, Studies in Computational Intelligence, pages 169-179. Springer Berlin Heidelberg, 2011.  Wei Fan, Joe McCloskey, and Philip S. Yu. A general framework for accurate and fast re- gression by data summarization in random decision trees. In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201906, pages 136-146, New York, NY, USA, 2006. ACM.  Khaled Fawagreh, Mohamed Medhat Gaber, and Eyad Elyan. Random forests: from early developments to recent advancements. Systems Science & Control Engineering, 2(1): 602-609, September 2014.  24   Blaser and Fryzlewicz  References  Dean Abbott. Why ensembles win data mining competitions. In Predictive Analytics Centre  of Excellence Tech Talks, University of California, San Diego, 2012.  Theodore W. Anderson, Ingram Olkin, and Les G. Underhill. Generation of random or- thogonal matrices. SIAM Journal on Scientific and Statistical Computing, 8:625-629, 1987.  Kevin Bache and Moshe Lichman. UCI machine learning repository. University of California, Irvine, School of Information and Computer Science, 2013. URL http: //archive.ics.uci.edu/ml.  Leo Breiman. Bagging predictors. Machine Learning, 24:123-140, 1996.  Leo Breiman. Random forests - random features. Technical report, University of California  at Berkeley, Berkeley, California, 1999.  Leo Breiman. Randomizing outputs to increase prediction accuracy. Machine Learning, 40:  229-242, 2000.  Leo Breiman. Random forests. Machine Learning, 45:5-32, 2001.  Rich Caruana and Alexandru Niculescu-Mizil. An empirical comparison of supervised learn- ing algorithms. In Proceedings of the 23rd International Conference on Machine Learning, pages 161-168, 2006.  Adele Cutler and Guohua Zhao. PERT-perfect random tree ensembles. Computing Science  and Statistics, 33:490-497, 2001.  Koen W. De Bock and Dirk Van den Poel. An empirical evaluation of rotation-based ensemble classifiers for customer churn prediction. Expert Systems with Applications, 38: 12293-12301, 2011.  Persi Diaconis and Mehrdad Shahshahani. The subgroup algorithm for generating uniform random variables. Probability in the Engineering and Informational Sciences, 1:15-32, 1987.  Haytham Elghazel, Alex Aussem, and Florence Perraud. Trading-o\ufb00 diversity and accuracy for optimal ensemble tree selection in random forests. In Ensembles in Machine Learn- ing Applications, Studies in Computational Intelligence, pages 169-179. Springer Berlin Heidelberg, 2011.  Wei Fan, Joe McCloskey, and Philip S. Yu. A general framework for accurate and fast re- gression by data summarization in random decision trees. In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201906, pages 136-146, New York, NY, USA, 2006. ACM.  Khaled Fawagreh, Mohamed Medhat Gaber, and Eyad Elyan. Random forests: from early developments to recent advancements. Systems Science & Control Engineering, 2(1): 602-609, September 2014. Random Rotation Ensembles  Yoav Freund and Robert Schapire. Experiments with a new boosting algorithm. In Pro- ceedings of the Thirteenth International Conference on Machine Learning, pages 148-156, Bari, Italy, 1996. Morgan Kaufmann Publishers Inc.  Mark Galassi. GNU scientific library reference manual - third edition. Network Theory  Ltd., January 2009.  Nicols Garca-Pedrajas, Csar Garca-Osorio, and Colin Fyfe. Nonlinear boosting projections  for ensemble construction. Journal of Machine Learning Research, 8:1-33, 2007.  Pierre Geurts, Damien Ernst, and Louis Wehenkel. Extremely randomized trees. Machine  Learning, 63:3-42, 2006.  Gal Guennebaud, Benot Jacob, et al. Eigen: linear algebra template library. 2010. URL  http://eigen.tuxfamily.org.  Trevor Hastie, Robert Tibshirani, and Jerome H. Friedman. The elements of statistical  learning: data mining, inference, and prediction. Springer, New York, 2009.  Tin K. Ho. Random decision forests. In Proceedings of the Third International Conference  on Document Analysis and Recognition, volume 1, pages 278-282, 1995.  Tin K. Ho. The random subspace method for constructing decision forests. IEEE Trans-  actions on Pattern Analysis and Machine Intelligence, 20:832-844, 1998.  Alston S. Householder. Unitary triangularization of a nonsymmetric matrix. Journal of the  ACM, 5:339-342, 1958.  Andrew Kerr, Dan Campbell, and Mark Richards. QR decomposition on GPUs. In Pro- ceedings of 2nd Workshop on General Purpose Processing on Graphics Processing Units, GPGPU-2, pages 71-78, New York, NY, USA, 2009. ACM.  Donald E. Knuth. Art of computer programming, volume 2: seminumerical algorithms.  Addison-Wesley Professional, Reading, Mass, 3 edition edition, November 1997.  Max Kuhn and Kjell Johnson. Applied predictive modeling. Springer, New York, 2013  edition edition, September 2013. ISBN 9781461468486.  Ludmila I. Kuncheva and Juan J. Rodriguez. An experimental study on rotation forest In Proceedings of the 7th International Conference on Multiple Classifier  ensembles. Systems, MCS\u201907, pages 459-468, Berlin, Heidelberg, 2007. Springer-Verlag.  Dan Ledermann and Carol Alexander. ROM simulation with random rotation matrices. SSRN Scholarly Paper ID 1805662, Social Science Research Network, Rochester, NY, 2011.  Andy Liaw and Matthew Wiener. Classification and regression by randomforest. R News,  2(3):18-22, 2002. URL http://CRAN.R-project.org/doc/Rnews/. Blaser and Fryzlewicz  Fei Tony Liu, Kai Ming Ting, and Wei Fan. Maximizing tree diversity by building complete- random decision trees. In Proceedings of the 9th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining, PAKDD\u201905, pages 605-610, Berlin, Heidelberg, 2005. Springer-Verlag.  Makoto Matsumoto and Takuji Nishimura. Mersenne twister: A 623-dimensionally equidis- tributed uniform pseudo-random number generator. ACM Transactions on Modeling and Computer Simulation, 8:3-30, 1998.  Bjoern H. Menze, B. Michael Kelm, Daniel N. Splittho\ufb00, Ullrich Koethe, and Fred A. In Proceedings of the European Conference Hamprecht. On oblique random forests. on Machine Learning and Knowledge Discovery in Databases - Volume Part II, ECML PKDD\u201911, pages 453-469, Berlin, Heidelberg, 2011. Springer-Verlag.  Francesco Mezzadri. How to generate random matrices from the classical compact groups. Notices of the AMS, 54:592-604, 2007. NOTICES of the AMS, Vol. 54 (2007), 592-604.  Greg Ridgeway. gbm: generalized boosted regression models, 2013. URL http://CRAN.  R-project.org/package=gbm. R package version 2.1.  Juan J. Rodriguez, Ludmila I. Kuncheva, and Carlos J. Alonso. Rotation forest: A new classifier ensemble method. IEEE Transactions on Pattern Analysis and Machine Intel- ligence, 28:1619-1630, 2006.  Lior Rokach. Ensemble-based classifiers. Artificial Intelligence Review, 33:1-39, 2010.  Jaak Simm and Ildefons Magrans de Abril. Extratrees: extratrees method, 2013. URL  http://CRAN.R-project.org/package=extraTrees. R package version 0.4-5. "}, "Should We Really Use Post-Hoc Tests Based on Mean-Ranks?": {"volumn": 17, "url": "http://jmlr.org/papers/v17/benavoli16a.html", "header": "Should We Really Use Post-Hoc Tests Based on Mean-Ranks?", "author": "Alessio Benavoli, Giorgio Corani, Francesca Mangili", "time": "17(5):1\u221210, 2016.", "abstract": "The statistical comparison of multiple algorithms over multiple data sets is fundamental in machine learning. This is typically carried out by the Friedman test. When the Friedman test rejects the null hypothesis, multiple comparisons are carried out to establish which are the significant differences among algorithms. The multiple comparisons are usually performed using the mean-ranks test. The aim of this technical note is to discuss the inconsistencies of the mean-ranks post-hoc test with the goal of discouraging its use in machine learning as well as in medicine, psychology, etc.. We show that the outcome of the mean-ranks test depends on the pool of algorithms originally included in the experiment. In other words, the outcome of the comparison between algorithms $A$ and $B$ depends also on the performance of the other algorithms included in the original experiment. This can lead to paradoxical situations. For instance the difference between $A$ and $B$ could be declared significant if the pool comprises algorithms $C,D,E$ and not significant if the pool comprises algorithms $F,G,H$. To overcome these issues, we suggest instead to perform the multiple comparison using a test whose outcome only depends on the two algorithms being compared, such as the sign-test or the Wilcoxon signed-rank test.", "pdf_url": "http://jmlr.org/papers/volume17/benavoli16a/benavoli16a.pdf", "keywords": [""], "reference": "A. Benavoli, F. Mangili, G. Corani, M. Za\ufb00alon, and F. Ruggeri. A Bayesian Wilcoxon signed-rank test based on the Dirichlet process. In Proceedings of the 30th International Conference on Machine Learning (ICML 2014), pages 1-9, 2014.  A. Benavoli, F. Mangili, F. Ruggeri, and M. Za\ufb00alon.  Imprecise Dirichlet Process with application to the hypothesis test on the probability that X \u2264 Y. Journal of Statistical Theory and Practice, February 2014. doi: 10.1080/15598608.2014.985997. Accepted for publication.  G. Corani and A. Benavoli. A Bayesian approach for comparing cross-validated algorithms  on multiple data sets. Machine Learning, 2015. Accepted for publication.  Janez Dem\u02c7sar. Statistical comparisons of classifiers over multiple data sets. Journal of  Machine Learning Research, 7:1-30, 2006.  8   Benavoli, Corani, and Mangili  and thus it is generally recommended (Dem\u02c7sar, 2006). Compared to the sign test, the Wilcoxon signed-rank test makes the additional assumption of a symmetric distribution of the di\ufb00erences between the two algorithms being compared. The decision between sign test and signed-rank test thus depends on whether the symmetry assumption is tenable on to the analyzed data.  Regardless the adopted test, the multiple comparisons should be performed adjusting the significance level to control the family-wise Type-I error. This can be done using the correction for multiple comparison discussed by Dem\u02c7sar (2006); Garcia and Herrera (2008). If we adopt the Wilcoxon signed-rank test in Example 3 for comparing C2, C4, we obtain the p-value 0.0002, independently from the performance of the other algorithms. Thus, for any pool of algorithms C2, C4, Cx, Cy, we always report the same decision: C2, C4 are significantly di\ufb00erent because the p-value is less than the Bonferroni corrected significance level \u03b1/m(m \u2212 1) (in the case m = 4, \u03b1/m(m \u2212 1) = 0.0042).  The MATLAB scripts of the above examples can be downloaded from ipg.idsia.ch/ software/meanRanks/matlab.zip  6. Software  7. Conclusions  The mean-ranks post-hoc test is widely used test for multiple pairwise comparison. We discuss a number of drawbacks of this test, which we recommend to avoid. We instead recommend to adopt the sign-test or the Wilcoxon signed-rank, whose decision does not depend on the pool of classifiers included in the original experiment.  We moreover bring to the attention of the reader the Bayesian counterparts of these tests, which overcome the many drawbacks (Kruschke, 2010, Chap.11) of null-hypothesis significance testing.  References  A. Benavoli, F. Mangili, G. Corani, M. Za\ufb00alon, and F. Ruggeri. A Bayesian Wilcoxon signed-rank test based on the Dirichlet process. In Proceedings of the 30th International Conference on Machine Learning (ICML 2014), pages 1-9, 2014.  A. Benavoli, F. Mangili, F. Ruggeri, and M. Za\ufb00alon.  Imprecise Dirichlet Process with application to the hypothesis test on the probability that X \u2264 Y. Journal of Statistical Theory and Practice, February 2014. doi: 10.1080/15598608.2014.985997. Accepted for publication.  G. Corani and A. Benavoli. A Bayesian approach for comparing cross-validated algorithms  on multiple data sets. Machine Learning, 2015. Accepted for publication.  Janez Dem\u02c7sar. Statistical comparisons of classifiers over multiple data sets. Journal of  Machine Learning Research, 7:1-30, 2006. Should We Use the Post-Hoc Tests Based on Mean-Ranks?  Janez Dem\u02c7sar. On the appropriateness of statistical tests in machine learning. In Workshop  on Evaluation Methods for Machine Learning in conjunction with ICML, 2008.  Michael A. Fligner. A note on two-sided distribution-free treatment versus control multiple comparisons. Journal of the American Statistical Association, 79(385):pp. 208-211, 1984.  K Ruben Gabriel. Simultaneous test procedures-some theory of multiple comparisons. The  Annals of Mathematical Statistics, pages 224-250, 1969.  Salvador Garcia and Francisco Herrera. An extension on\u201d Statistical Comparisons of Classi- fiers over Multiple Data Sets\u201d for all pairwise comparisons. Journal of Machine Learning Research, 9(12), 2008.  Jean Dickinson Gibbons and Subhabrata Chakraborti. Nonparametric Statistical Inference.  Springer, 2011.  Steven N Goodman. Toward evidence-based medical statistics: The p-value fallacy. Annals  of Internal Medicine, 130(12):995-1004, 1999.  Myles Hollander, Douglas A Wolfe, and Eric Chicken. Nonparametric Statistical Methods,  volume 751. John Wiley & Sons, 2013.  John K Kruschke. Bayesian data analysis. Wiley Interdisciplinary Reviews: Cognitive  Science, 1(5):658-676, 2010.  Paul H Kvam and Brani Vidakovic. Nonparametric Statistics With Applications to Science  and Engineering, volume 653. John Wiley & Sons, 2007.  B. J. McDonald and Jr Thompson, W. A. Rank sum multiple comparisons in one- and  two-way classifications. Biometrika, 54(3/4):pp. 487-497, 1967.  Rupert G Miller. Simultaneous Statistical Inference. Springer, 1966.  P. Nemenyi. Distribution-free multiple comparisons. Ph.D. thesis, Princeton University,  1963.  Press, 2003.  David J Sheskin. Handbook of Parametric and Nonparametric Statistical Procedures. CRC  Ian H Witten and Eibe Frank. Data Mining: Practical machine learning tools and tech-  niques. Morgan Kaufmann, 2005. Benavoli, Corani, and Mangili  Table of Accuracies Used in Example 3  Dataset  C1  C2  C3  C4  C5  C6  C7  anneal audiology wisconsin-breast-cancer cmc contact-lenses credit german-credit pima-diabetes ecoli eucalyptus glass grub-damage haberman hayes-roth cleeland-14 hungarian-14 hepatitis hypothyroid ionosphere iris kr-s-kp labor lier-disorders lymphography monks1 monks3 monks mushroom nursery optdigits page-blocks pasture-production pendigits postoperatie primary-tumor segment solar-\ufb02are-C solar-\ufb02are-m solar-\ufb02are-X sonar soybean spambase spect-reordered splice squash-stored squash-unstored tae credit owel waveform white-clover wine yeast zoo  98.44 78.32 93.7 50.71 81.67 86.38 72.4 73.7 81.52 64.28 71.58 38.79 72.87 60 78.82 78.64 79.46 99.28 91.17 93.33 99.44 85 56.25 78.33 98.74 98.92 64.72 100 97.05 78.97 96.62 75 89.05 70 40.11 94.24 88.86 90.1 97.84 74.48 92.39 92.81 78.29 94.36 70 76.67 47 84.93 76.67 74.38 56.9 88.79 57.01 92.18  98 73.42 96.71 52.81 68.33 84.64 76.6 74.09 80.04 63.2 74.26 36.88 71.53 56.88 81.47 84.39 85.13 99.18 90.88 92 92.46 88 56.25 85 100 97.84 64.57 99.96 94.28 96.17 96.84 85.83 97.61 67.78 48.08 96.36 88.24 87.02 97.53 79.83 94.58 92.31 82.07 96.18 58 69 44.38 83.91 84.65 84.52 79.29 98.33 57.48 100  98 71.66 96.99 51.39 71.67 86.67 76.6 75.01 81.83 58.71 73.83 43.92 72.52 60 81.8 84.39 83.79 98.54 90.88 92.67 91.24 84.67 56.25 85.71 85.44 96.75 63.73 99.95 92.71 96.9 96.95 80.83 97.82 67.78 47.49 94.5 88.54 87.92 97.84 81.26 93.4 93.37 80.93 96.21 60 70.67 47 85.07 77.78 84.92 68.57 98.33 56.74 95.09  96.43 71.23 97.14 51.05 71.67 86.23 76 74.36 82.12 51.1 70.63 47.79 72.52 60 83.44 84.74 82.5 98.3 89.17 92.67 87.89 83 56.25 84.38 74.64 96.39 62.24 95.83 90.32 92.3 93.51 80.83 87.78 66.67 46.89 91.3 86.08 87 93.17 80.29 92.08 89.85 79.03 95.36 61.67 61.67 47 84.2 60.3 79.86 66.9 98.89 56.8 93.18  98.55 78.32 93.7 50.78 81.67 86.52 72.4 73.56 81.52 64.01 71.1 39.42 72.87 60 78.48 78.64 79.46 99.28 91.74 93.33 99.37 85 56.25 79 98.74 98.92 64.72 100 97.08 81.01 96.66 75 89.87 70 40.11 94.03 88.86 90.1 97.84 74.45 92.98 93.22 78.29 94.2 70 76.67 47 84.93 76.87 74.9 56.9 89.35 57.01 92.18  98.33 77.41 97.28 50.98 65 87.25 75.3 74.75 80.63 59.52 75.69 40.13 73.52 60 82.78 84.38 82.5 98.62 89.17 92 91.21 81.33 56.25 86.33 82.21 96.39 64.9 99.84 91.61 94.2 94.15 81.67 94.81 66.67 49.55 94.29 87.92 86.99 94.41 80.79 93.55 90.63 83.15 95.89 63.67 68.67 47 85.22 77.88 83.62 64.76 98.33 57.48 96.18  99 73.89 95.57 48.67 78.33 85.07 73 72.67 78.84 59.4 73.33 42.63 72.16 59.38 81.81 81.97 81.25 98.97 91.75 93.33 98.87 84.67 56.25 79.62 98.56 97.84 70.72 100 98.09 91.8 96.97 75.83 95.67 60 38.31 96.06 86.05 85.46 95.99 78.36 92.68 93.65 80.56 89.37 57.67 77.33 45.67 83.33 84.95 79.68 70 97.22 56.26 95.09  Table 2: Accuracy of classifiers on di\ufb00erent data sets. "}, "Minimax Rates in Permutation Estimation for Feature Matching": {"volumn": 17, "url": "http://jmlr.org/papers/v17/collier16a.html", "header": "Minimax Rates in Permutation Estimation for Feature Matching", "author": "Olivier Collier, Arnak S. Dalalyan", "time": "17(6):1\u221231, 2016.", "abstract": "The problem of matching two sets of features appears in various tasks of computer vision and can be often formalized as a problem of permutation estimation. We address this problem from a statistical point of view and provide a theoretical analysis of the accuracy of several natural estimators. To this end, the minimax rate of separation is investigated and its expression is obtained as a function of the sample size, noise level and dimension of the features. We consider the cases of homoscedastic and heteroscedastic noise and establish, in each case, tight upper bounds on the separation distance of several estimators. These upper bounds are shown to be unimprovable both in the homoscedastic and heteroscedastic settings. Interestingly, these bounds demonstrate that a phase transition occurs when the dimension $d$ of the features is of the order of the logarithm of the number of features $n$. For $d=O(\\log n)$, the rate is dimension free and equals $\\sigma (\\log n)^{1/2}$, where $\\sigma$ is the noise level. In contrast, when $d$ is larger than $c\\log n$ for some constant $c>0$, the minimax rate increases with $d$ and is of the order of $\\sigma(d\\log n)^{1/4}$. We also discuss the computational aspects of the estimators and provide empirical evidence of their consistency on synthetic data. Finally, we show that our results extend to more general matching criteria.", "pdf_url": "http://jmlr.org/papers/volume17/collier16a/collier16a.pdf", "keywords": ["permutation estimation", "minimax rate of separation", "feature matching"], "reference": "1960.  R. R. Bahadur. On the asymptotic e\ufb03ciency of tests and estimates. Sankhy\u00afa, 22:229-252,  Herbert Bay, Andreas Ess, Tinne Tuytelaars, and Luc Van Gool. Speeded-up robust features  (surf). Comput. Vis. Image Underst., 110(3):346-359, jun 2008.  Eric Budish, Yeon-Koo Che, Fuhito Kojima, and Paul Milgrom. Designing random allocation mechanisms: Theory and applications. American Economic Review, 103(2):585-623, 2013.  Olivier Collier. Minimax hypothesis testing for curve registration. Electron. J. Stat., 6:  1129-1154, 2012.  Olivier Collier and Arnak S. Dalalyan. Permutation estimation and minimax rates of iden- tifiability. Journal of Machine Learning Research, W & CP 31 (AI-STATS 2013):10-19, 2013.  Olivier Collier and Arnak S. Dalalyan. Curve registration by nonparametric goodness-of-fit  testing. J. Statist. Plann. Inference, 162:20-42, July 2015.  Richard Hartley and Andrew Zisserman. Multiple view geometry in computer vision. Cam-  bridge University Press, Cambridge, second edition, 2003.  Yu. I. Ingster and I. A. Suslina. Nonparametric goodness-of-fit testing under Gaussian mod-  els, volume 169 of Lecture Notes in Statistics. Springer-Verlag, New York, 2003.  Tony Jebara. Images as bags of pixels. In ICCV, pages 265-272. IEEE Computer Society,  2003.  A. P. Korostelev and V. G. Spokoiny. Exact asymptotics of minimax Bahadur risk in  Lipschitz regression. Statistics, 28(1):13-24, 1996.  Alexander Korostelev. A minimaxity criterion in nonparametric regression based on large-  deviations probabilities. Ann. Statist., 24(3):1075-1083, 1996.  H. W. Kuhn. The Hungarian method for the assignment problem. Naval Res. Logist. Quart.,  2:83-97, 1955.  B. Laurent and P. Massart. Adaptive estimation of a quadratic functional by model selection.  Ann. Statist., 28(5):1302-1338, 2000.  David G. Lowe. Distinctive image features from scale-invariant keypoints. International  Journal of Computer Vision, 60(2):91-110, 2004.  David W. Pentico. Assignment problems: A golden anniversary survey. European Journal  of Operational Research, 176(2):774-793, 2007.  H. Edwin Romeijn and Dolores Romero Morales. A class of greedy algorithms for the generalized assignment problem. Discrete Applied Mathematics, 103(1-3):209-235, 2000.  30   Collier and Dalalyan  References  1960.  R. R. Bahadur. On the asymptotic e\ufb03ciency of tests and estimates. Sankhy\u00afa, 22:229-252,  Herbert Bay, Andreas Ess, Tinne Tuytelaars, and Luc Van Gool. Speeded-up robust features  (surf). Comput. Vis. Image Underst., 110(3):346-359, jun 2008.  Eric Budish, Yeon-Koo Che, Fuhito Kojima, and Paul Milgrom. Designing random allocation mechanisms: Theory and applications. American Economic Review, 103(2):585-623, 2013.  Olivier Collier. Minimax hypothesis testing for curve registration. Electron. J. Stat., 6:  1129-1154, 2012.  Olivier Collier and Arnak S. Dalalyan. Permutation estimation and minimax rates of iden- tifiability. Journal of Machine Learning Research, W & CP 31 (AI-STATS 2013):10-19, 2013.  Olivier Collier and Arnak S. Dalalyan. Curve registration by nonparametric goodness-of-fit  testing. J. Statist. Plann. Inference, 162:20-42, July 2015.  Richard Hartley and Andrew Zisserman. Multiple view geometry in computer vision. Cam-  bridge University Press, Cambridge, second edition, 2003.  Yu. I. Ingster and I. A. Suslina. Nonparametric goodness-of-fit testing under Gaussian mod-  els, volume 169 of Lecture Notes in Statistics. Springer-Verlag, New York, 2003.  Tony Jebara. Images as bags of pixels. In ICCV, pages 265-272. IEEE Computer Society,  2003.  A. P. Korostelev and V. G. Spokoiny. Exact asymptotics of minimax Bahadur risk in  Lipschitz regression. Statistics, 28(1):13-24, 1996.  Alexander Korostelev. A minimaxity criterion in nonparametric regression based on large-  deviations probabilities. Ann. Statist., 24(3):1075-1083, 1996.  H. W. Kuhn. The Hungarian method for the assignment problem. Naval Res. Logist. Quart.,  2:83-97, 1955.  B. Laurent and P. Massart. Adaptive estimation of a quadratic functional by model selection.  Ann. Statist., 28(5):1302-1338, 2000.  David G. Lowe. Distinctive image features from scale-invariant keypoints. International  Journal of Computer Vision, 60(2):91-110, 2004.  David W. Pentico. Assignment problems: A golden anniversary survey. European Journal  of Operational Research, 176(2):774-793, 2007.  H. Edwin Romeijn and Dolores Romero Morales. A class of greedy algorithms for the generalized assignment problem. Discrete Applied Mathematics, 103(1-3):209-235, 2000. Minimax Permutation Estimation  V.G. Spokoiny. Adaptive hypothesis testing using wavelets. The Annals of Statistics, 24(6):  2477-2498, 1996.  Jos F. Sturm. Using SeDuMi 1.02, a MATLAB toolbox for optimization over symmetric  cones. Optim. Methods Softw., 11/12(1-4):625-653, 1999.  Richard Szeliski. Computer Vision: Algorithms and Applications. Springer-Verlag New  York, Inc., New York, NY, USA, 1st edition, 2010.  Alexandre B. Tsybakov. Introduction to nonparametric estimation. Springer Series in Statis-  tics. Springer, New York, 2009. "}, "Consistency and Fluctuations For Stochastic Gradient Langevin Dynamics": {"volumn": 17, "url": "http://jmlr.org/papers/v17/teh16a.html", "header": "Consistency and Fluctuations For Stochastic Gradient Langevin Dynamics", "author": "Yee Whye Teh, Alexandre H. Thiery, Sebastian J. Vollmer", "time": "17(7):1\u221233, 2016.", "abstract": "Applying standard Markov chain Monte Carlo (MCMC) algorithms to large data sets is computationally expensive. Both the calculation of the acceptance probability and the creation of informed proposals usually require an iteration through the whole data set. The recently proposed stochastic gradient Lange", "pdf_url": "http://jmlr.org/papers/volume17/teh16a/teh16a.pdf", "keywords": ["Markov chain Monte Carlo", "Langevin dynamics", "big data"], "reference": "A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J. Smola. Scalable inference in latent variable models. In Proceedings of the ACM international conference on Web search and data mining, pages 123-132. ACM, 2012.  S. Ahn, A. Korattikara, and M. Welling. Bayesian posterior sampling via stochastic gradient Fisher scoring. In Proceedings of the International Conference on Machine Learning, 2012.  S. Ahn, B. Shahbaba, and M. Welling. Distributed stochastic gradient MCMC. In Proceed-  ings of the International Conference on Machine Learning, 2014.  Shun-ichi Amari and Hiroshi Nagaoka. Methods of information geometry, volume 191.  American Mathematical Society, 2007.  R\u00b4emi Bardenet, Arnaud Doucet, and Chris C. Holmes. Towards scaling up MCMC: an adaptive subsampling approach. Proceedings of the International Conference on Machine Learning (ICML), 2014.  A. Beskos, G. O. Roberts, A. M. Stuart, and J. Voss. MCMC methods for di\ufb00usion bridges.  Stochastics and Dynamics, 8(03):319-350, 2008.  Patrick Billingsley. Probability and Measure. Wiley-Interscience, 3 edition, 1995.  L. Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings  of COMPSTAT\u20192010, pages 177-186. Springer, 2010.  Tianqi Chen, Emily B Fox, and Carlos Guestrin. Stochastic gradient hamiltonian monte  carlo. arXiv preprint arXiv:1402.4102, 2014.  S.L. Cotter, G.O. Roberts, A.M. Stuart, and D. White. MCMC methods for functions: modifying old algorithms to make them faster. Statistical Science, 28(3):424-446, 2013.  S. Duane, A. D. Kennedy, B. J. Pendleton, and D. Roweth. Hybrid Monte Carlo. Physics  letters B, 195(2):216-222, 1987.  Stewart N. Ethier and Thomas G. Kurtz. Markov processes. Wiley Series in Probability and Mathematical Statistics: Probability and Mathematical Statistics. John Wiley & Sons Inc., New York, 1986. Characterization and convergence.  30   Teh, Thi\u00b4ery and Vollmer  To prove Equation (46) it su\ufb03ces to use the assumption that (cid:80) m] < \u221e and then follow the same approach used to establish that the quantity (44) is finite. Lemma 6 shows that to prove Equation (47) it su\ufb03ces to verify that  m/[\u03b4m\u21262  m\u22650 \u03c92  (cid:104) (cid:88)  E  m\u22650  (cid:12)\u2206(\u03c9m/\u03b4m)(cid:12) (cid:12)  (cid:12) V p(\u03b8m)/\u2126m  (cid:105)  < \u221e.  This directly follows from the assumption that (cid:80) that supm\u22650 E[V p(\u03b8m)] is finite.  (cid:12)\u2206(\u03c9m/\u03b4m)(cid:12) (cid:12)  m\u22650  (cid:12)/\u2126m < \u221e and the fact  References  A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J. Smola. Scalable inference in latent variable models. In Proceedings of the ACM international conference on Web search and data mining, pages 123-132. ACM, 2012.  S. Ahn, A. Korattikara, and M. Welling. Bayesian posterior sampling via stochastic gradient Fisher scoring. In Proceedings of the International Conference on Machine Learning, 2012.  S. Ahn, B. Shahbaba, and M. Welling. Distributed stochastic gradient MCMC. In Proceed-  ings of the International Conference on Machine Learning, 2014.  Shun-ichi Amari and Hiroshi Nagaoka. Methods of information geometry, volume 191.  American Mathematical Society, 2007.  R\u00b4emi Bardenet, Arnaud Doucet, and Chris C. Holmes. Towards scaling up MCMC: an adaptive subsampling approach. Proceedings of the International Conference on Machine Learning (ICML), 2014.  A. Beskos, G. O. Roberts, A. M. Stuart, and J. Voss. MCMC methods for di\ufb00usion bridges.  Stochastics and Dynamics, 8(03):319-350, 2008.  Patrick Billingsley. Probability and Measure. Wiley-Interscience, 3 edition, 1995.  L. Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings  of COMPSTAT\u20192010, pages 177-186. Springer, 2010.  Tianqi Chen, Emily B Fox, and Carlos Guestrin. Stochastic gradient hamiltonian monte  carlo. arXiv preprint arXiv:1402.4102, 2014.  S.L. Cotter, G.O. Roberts, A.M. Stuart, and D. White. MCMC methods for functions: modifying old algorithms to make them faster. Statistical Science, 28(3):424-446, 2013.  S. Duane, A. D. Kennedy, B. J. Pendleton, and D. Roweth. Hybrid Monte Carlo. Physics  letters B, 195(2):216-222, 1987.  Stewart N. Ethier and Thomas G. Kurtz. Markov processes. Wiley Series in Probability and Mathematical Statistics: Probability and Mathematical Statistics. John Wiley & Sons Inc., New York, 1986. Characterization and convergence. Consistency and Fluctuations for Stochastic Gradient Langevin Dynamics  M. Girolami and B. Calderhead. Riemann manifold Langevin and Hamiltonian Monte Carlo methods. Journal of the Royal Statistical Society. Series B. Statistical Methodology, 73 (2):123-214, 2011. With discussion and a reply by the authors.  J Gonzalez. Emerging systems for large-scale machine learning. ICML Tutorial, 2014.  M. Hairer, A. M. Stuart, and S. J. Vollmer. Spectral gaps for a metropolis-hastings algorithm  in infinite dimensions. The Annals of Applied Probability, (to appear), 2014.  Peter Hall and Christopher C Heyde. Martingale limit theory and its application. Academic  press New York, 1980.  data. ICML Tutorial, 2014.  Z. Harchaoui and M. Jaggi. Frank-Wolfe and greedy optimization for learning with big  G. Hinton, L. Deng, D. Yu, G. Dahl, A. Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, P. Nguyen, and T. N. Sainath. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. Signal Processing Magazine, IEEE, 29(6):82-97, 2012.  J. N. Hirschhorn and M. J. Daly. Genome-wide association studies for common diseases  and complex traits. Nature Reviews Genetics, 6(2):95-108, 2005.  M. D Ho\ufb00man, D. M. Blei, and F. R. Bach. Online learning for latent dirichlet allocation.  In NIPS, volume 2, page 5, 2010.  M. D. Ho\ufb00man, D. M. Blei, C. Wang, and J. Paisley. Stochastic variational inference.  Journal of Machine Learning Research, 14(1):1303-1347, 2013.  S. F. Jarner and G. O. Roberts. Convergence of heavy-tailed monte carlo markov chain  algorithms. Scandinavian Journal of Statistics, 34(4):781-815, 2007.  K. Kamatani. Rate optimality of random walk metropolis algorithm in high-dimension with  heavy-tailed target distribution. arXiv preprint arXiv:1406.5392, 2014.  A. Korattikara, Y. Chen, and M. Welling. Austerity in MCMC land: Cutting the Metropolis-Hastings budget. In Proceedings of the International Conference on Machine Learning, 2014.  A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolu-  tional neural networks. In NIPS, volume 1, page 4, 2012.  D. Lamberton and G. Pages. Recursive computation of the invariant distribution of a  di\ufb00usion. Bernoulli, 8(3):367-405, 2002.  D. Lamberton and G. Pages. Recursive computation of the invariant distribution of a di\ufb00usion: the case of a weakly mean reverting drift. Stochastics and Dynamics, 3(04): 435-451, 2003.  V. Lemaire. An adaptive scheme for the approximation of dissipative systems. Stochastic  Processes and their Applications, 117(10):1491-1518, 2007. Teh, Thi\u00b4ery and Vollmer  S. Livingstone and M. Girolami. Information-geometric markov chain monte carlo methods  using di\ufb00usions. arXiv preprint arXiv:1403.7957, 2014.  G. Maruyama. Continuous markov processes and stochastic equations. Rendiconti del  Circolo Matematico di Palermo, 4(1):48-90, 1955.  J. C. Mattingly, A. M. Stuart, and D. J. Higham. Ergodicity for sdes and approxima- tions: locally lipschitz vector fields and degenerate noise. Stochastic processes and their applications, 101(2):185-232, 2002.  J. C. Mattingly, N. S. Pillai, and A. M. Stuart. Di\ufb00usion limits of the random walk metropo- lis algorithm in high dimensions. The Annals of Applied Probability, 22(3):881-930, 2012.  M. I. McCarthy, G. R. Abecasis, L. R. Cardon, D. B. Goldstein, J. Little, J. P.A. Ioannidis, and J. N. Hirschhorn. Genome-wide association studies for complex traits: consensus, uncertainty and challenges. Nature Reviews Genetics, 9(5):356-369, 2008.  S. Minsker, S. Srivastava, L. Lin, and D. B. Dunson. Robust and scalable bayes via a  median of subset posterior measures. arXiv preprint arXiv:1403.2660, 2014.  R. M. Neal. MCMC using hamiltonian dynamics. Handbook of Markov Chain Monte Carlo:  Methods and Applications, page 113, 2010.  W. Neiswanger, C. Wang, and E. Xing. Asymptotically exact, embarrassingly parallel  mcmc. arXiv preprint arXiv:1311.4780, 2013.  G. Pages and F. Panloup. Ergodic approximation of the distribution of a stationary di\ufb00u-  sion: rate of convergence. The Annals of Probability, 22(3):1059-1100, 2012.  F. Panloup. Recursive computation of the invariant measure of a stochastic di\ufb00erential equation driven by a l\u00b4evy process. The Annals of Applied Probability, 18(2):379-426, 2008.  S. Patterson and Y. W. Teh. Stochastic gradient Riemannian Langevin dynamics on the  probability simplex. In Advances in Neural Information Processing Systems, 2013a.  S. Patterson and Y. W. Teh. Stochastic Gradient Riemannian Langevin dynamics on the probability simplex. In Advances in Neural Information Processing Systems, 2013b.  N. S. Pillai, A. M. Stuart, and A. H. Thi\u00b4ery. Optimal scaling and di\ufb00usion limits for the Langevin algorithm in high dimensions. The Annals of Applied Probability, 22(6): 2320-2356, 2012.  H. Robbins and S. Monro. A stochastic approximation method. The Annals of Mathematical  Statistics, pages 400-407, 1951a.  H. Robbins and S. Monro. A Stochastic Approximation Method. The Annals of Mathe-  maitcal Statistics, 22:400-407, 1951b. ISSN 0003-4851.  G. O. Roberts and J. S. Rosenthal. Optimal Scaling of Discrete Approximations to Langevin  Di\ufb00usions. J. R. Stat. Soc. Ser. B Stat. Methodol., 60(1):255-268, 1998. Consistency and Fluctuations for Stochastic Gradient Langevin Dynamics  G. O. Roberts and O. Stramer. Langevin di\ufb00usions and Metropolis-Hastings algorithms.  Methodology and computing in applied probability, 4(4):337-357, 2002.  G. O. Roberts and R. L. Tweedie. Exponential convergence of langevin distributions and  their discrete approximations. Bernoulli, pages 341-363, 1996.  Walter Rudin. Real and complex analysis (3rd). New York: McGraw-Hill Inc, 1986.  A. Koratticara S. Ahn and M. Welling. Bayesian posterior sampling via stochastic gradient  fisher scoring. In ICML, 2012.  13(7):1649-1681, 2001.  M.-A. Sato. Online model selection based on the variational bayes. Neural Computation,  Albert N Shiryaev. Probability. Graduate Texts in Mathematics, 1996.  Nathan Srebro and Ambuj Tewari. Stochastic optimization for machine learning. ICML  Tutorial, 2010.  O. Stramer and R.L. Tweedie. Langevin-type models I: Di\ufb00usions with given stationary dis- tributions and their discretizations*. Methodology and Computing in Applied Probability, 1(3):283-306, 1999a.  O. Stramer and R.L. Tweedie. Langevin-type models II: Self-targeting candidates for MCMC algorithms. Methodology and Computing in Applied Probability, 1(3):307-328, 1999b.  S. Thrun. Toward robotic cars. Communications of the ACM, 53(4):99-106, 2010.  W. Y.S. Wang, B. J. Barratt, D. G. Clayton, and J. A. Todd. Genome-wide association studies: theoretical and practical concerns. Nature Reviews Genetics, 6(2):109-118, 2005.  M. Welling and Y. W. Teh. Bayesian learning via Stochastic Gradient Langevin Dynamics. In Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages 681-688, 2011. "}, "Knowledge Matters: Importance of Prior Information for Optimization": {"volumn": 17, "url": "http://jmlr.org/papers/v17/gulchere16a.html", "header": "Knowledge Matters: Importance of Prior Information for Optimization", "author": "\u00c3\u0087a\u00c4\u009flar G\u00c3\u00bcl\u00c3\u00a7ehre, Yoshua Bengio", "time": "17(8):1\u221232, 2016.", "abstract": "We explored the effect of introducing prior knowledge into the intermediate level of deep supervised neural networks on two tasks. On a task we designed, all black-box state-of-the-art machine learning algorithms which we tested, failed to generalize well. We motivate our work from the hypothesis that, there is a training barrier involved in the nature of such tasks, and that humans learn useful intermediate concepts from other individuals by using a form of supervision or guidance using a curriculum. Our results provide a positive evidence in favor of this hypothesis. In our experiments, we trained a two- tiered MLP architecture on a dataset for which each input image contains three sprites, and the binary target class is $1$ if all of three shapes belong to the same category and otherwise the class is $0$. In terms of generalization, black-box machine learning algorithms could not perform better than chance on this task. Standard deep supervised neural networks also failed to generalize. However, using a particular structure and guiding the learner by providing intermediate targets in the form of intermediate concepts (the presence of each object) allowed us to solve the task efficiently. We obtained much better than chance, but imperfect results by exploring different architectures and optimization variants. This observation might be an indication of optimization difficulty when the neural network trained without hints on this task. We hypothesize that the learning difficulty is due to the  composition  of two highly non-linear tasks. Our findings are also consistent with the hypotheses on cultural learning inspired by the observations of training of neural networks sometimes getting stuck, even though good solutions exist, both in terms of training and generalization error.", "pdf_url": "http://jmlr.org/papers/volume17/gulchere16a/gulchere16a.pdf", "keywords": ["learning", "training with hints"], "reference": "Journal of Machine Learning Research, -1.  Andrew G Barto and Sridhar Mahadevan. Recent advances in hierarchical reinforcement learn-  ing. Discrete Event Dynamic Systems, 13(4):341-379, 2003.  Asa Ben-Hur and Jason Weston. A user\u2019s guide to support vector machines. Methods in  Molecular Biology, 609:223-239, 2010.  Yoshua Bengio. Learning deep architectures for AI. Foundations and Trends in Machine  Learning, 2(1):1-127, 2009. Also published as a book. Now Publishers, 2009.  Yoshua Bengio. Evolving culture vs local minima. In Growing Adaptive Machines: Integrating Development and Learning in Artificial Neural Networks, number also as ArXiv 1203.2990v1, pages T. Kowaliw, N. Bredeche & R. Doursat, eds. Springer-Verlag, March 2013a. URL http://arxiv.org/abs/1203.2990.  Yoshua Bengio. Practical recommendations for gradient-based training of deep architectures. In K.-R. M\u00a8uller, G. Montavon, and G. B. Orr, editors, Neural Networks: Tricks of the Trade. Springer, 2013b.  Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. Greedy layer-wise training of deep networks. In Bernhard Sch\u00a8olkopf, John Platt, and Thomas Ho\ufb00man, editors, Ad- vances in Neural Information Processing Systems 19 (NIPS\u201906), pages 153-160. MIT Press, 2007.  Yoshua Bengio, Jerome Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In L\u00b4eon Bottou and Michael Littman, editors, Proceedings of the Twenty-sixth International Conference on Machine Learning (ICML\u201909). ACM, 2009.  Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspectives. Technical Report arXiv:1206.5538, U. Montreal, 2012. URL http:// arxiv.org/abs/1206.5538.  Yoshua Bengio, Aaron Courville, and Pascal Vincent. Unsupervised feature learning and deep learning: A review and new perspectives. IEEE Trans. Pattern Analysis and Machine Intel- ligence (PAMI), 2013.  James Bergstra, Olivier Breuleux, Fr\u00b4ed\u00b4eric Bastien, Pascal Lamblin, Razvan Pascanu, Guil- laume Desjardins, Joseph Turian, David Warde-Farley, and Yoshua Bengio. Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference (SciPy), 2010.  L\u00b4eon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of  COMPSTAT\u20192010, pages 177-186. Springer, 2010.  29   Knowledge Matters: Importance of Prior Information for Optimization  In this experiment we have used 400 hidden units for the first layer DAE and 100 hidden units for the second layer DAE. The other hyperparameters for DAE and supervised finetuning are the same as with the CAE+DAE MLP Supervised Finetuning experiment.  References  Journal of Machine Learning Research, -1.  Andrew G Barto and Sridhar Mahadevan. Recent advances in hierarchical reinforcement learn-  ing. Discrete Event Dynamic Systems, 13(4):341-379, 2003.  Asa Ben-Hur and Jason Weston. A user\u2019s guide to support vector machines. Methods in  Molecular Biology, 609:223-239, 2010.  Yoshua Bengio. Learning deep architectures for AI. Foundations and Trends in Machine  Learning, 2(1):1-127, 2009. Also published as a book. Now Publishers, 2009.  Yoshua Bengio. Evolving culture vs local minima. In Growing Adaptive Machines: Integrating Development and Learning in Artificial Neural Networks, number also as ArXiv 1203.2990v1, pages T. Kowaliw, N. Bredeche & R. Doursat, eds. Springer-Verlag, March 2013a. URL http://arxiv.org/abs/1203.2990.  Yoshua Bengio. Practical recommendations for gradient-based training of deep architectures. In K.-R. M\u00a8uller, G. Montavon, and G. B. Orr, editors, Neural Networks: Tricks of the Trade. Springer, 2013b.  Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. Greedy layer-wise training of deep networks. In Bernhard Sch\u00a8olkopf, John Platt, and Thomas Ho\ufb00man, editors, Ad- vances in Neural Information Processing Systems 19 (NIPS\u201906), pages 153-160. MIT Press, 2007.  Yoshua Bengio, Jerome Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In L\u00b4eon Bottou and Michael Littman, editors, Proceedings of the Twenty-sixth International Conference on Machine Learning (ICML\u201909). ACM, 2009.  Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspectives. Technical Report arXiv:1206.5538, U. Montreal, 2012. URL http:// arxiv.org/abs/1206.5538.  Yoshua Bengio, Aaron Courville, and Pascal Vincent. Unsupervised feature learning and deep learning: A review and new perspectives. IEEE Trans. Pattern Analysis and Machine Intel- ligence (PAMI), 2013.  James Bergstra, Olivier Breuleux, Fr\u00b4ed\u00b4eric Bastien, Pascal Lamblin, Razvan Pascanu, Guil- laume Desjardins, Joseph Turian, David Warde-Farley, and Yoshua Bengio. Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference (SciPy), 2010.  L\u00b4eon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of  COMPSTAT\u20192010, pages 177-186. Springer, 2010. C\u00b8 a\u02d8glar G\u00a8ulc\u00b8ehre and Yoshua Bengio  Leo Breiman. Random forests. Machine Learning, 45(1):5-32, 2001.  Leo Breiman, Jerome Friedman, Charles J. Stone, and Richard A. Olshen. Classification and  regression trees. Belmont, Calif.: Wadsworth, 1984.  Anna Choromanska, Mikael Hena\ufb00, Michael Mathieu, G\u00b4erard Ben Arous, and Yann LeCun. The loss surface of multilayer networks. AISTATS 2015, Proceedings of the Eighteenth In- ternational Conference on Artificial Intelligence and Statistics, pages 192-204, 2015.  Dan C. Ciresan, Ueli Meier, Luca M. Gambardella, and J\u00a8urgen Schmidhuber. Deep big simple  neural nets for handwritten digit recognition. Neural Computation, 22:1-14, 2010.  Yann Dauphin and Yoshua Bengio. Big neural networks waste capacity. Technical Report  arXiv:1301.3583, Universite de Montreal, 2013.  Yann Dauphin, Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Surya Ganguli, and Yoshua Bengio. Identifying and attacking the saddle point problem in high-dimensional non-convex optimization. In NIPS\u20192014, 2014.  Richard Dawkins. The Selfish Gene. Oxford University Press, 1976.  John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning  and stochastic optimization. Journal of Machine Learning Research, 2011.  Dumitru Erhan, Yoshua Bengio, Aaron Courville, Pierre-Antoine Manzagol, Pascal Vincent, and Samy Bengio. Why does unsupervised pre-training help deep learning? In Journal of Machine Learning Research JML (-1), pages 625-660.  Alexandre Gramfort Vincent Michel Bertrand Thirion Olivier Grisel Mathieu Blondel et al Fabian Pedregosa, Gal Varoquaux. Scikit-learn: Machine learning in python. The Journal of Machine Learning Research, 12:2825-2830, 2011.  Franois Fleuret, Ting Li, Charles Dubout, Emma K. Wampler, Steven Yantis, and Donald Geman. Comparing machines and humans on a visual categorization test. Proceedings of the National Academy of Sciences, 108(43):17621-17625, 2011.  Xavier Glorot and Yoshua Bengio. Understanding the di\ufb03culty of training deep feedforward neural networks. In JMLR W&CP: Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2010), volume 9, pages 249-256, May 2010.  Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep sparse rectifier neural networks. In JMLR W&CP: Proceedings of the Fourteenth International Conference on Artificial Intelli- gence and Statistics (AISTATS 2011), April 2011.  Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron Courville, and Yoshua Bengio.  Maxout networks. In ICML\u20192013, 2013.  Caglar Gulcehre, Kyunghyun Cho, Razvan Pascanu, and Yoshua Bengio. Learned-norm pooling  for deep neural networks. arXiv preprint arXiv:1311.1780, 2013. Knowledge Matters: Importance of Prior Information for Optimization  Joseph Henrich and Richard McElreath. The evolution of cultural evolution. Evolutionary  Anthropology: Issues, News, and Reviews, 12(3):123-135, 2003.  Geo\ufb00rey E. Hinton, Simon Osindero, and Yee Whye Teh. A fast learning algorithm for deep  belief nets. Neural Computation, 18:1527-1554, 2006.  Geo\ufb00rey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi- nov. Improving neural networks by preventing co-adaptation of feature detectors. Technical report, arXiv:1207.0580, 2012.  Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin. A practical guide to support vector  classification, 2003.  Kevin Jarrett, Koray Kavukcuoglu, Marc\u2019Aurelio Ranzato, and Yann LeCun. What is the best multi-stage architecture for object recognition? In Proc. International Conference on Computer Vision (ICCV\u201909), pages 2146-2153. IEEE, 2009.  Faisal Khan, Xiaojin Zhu, and Bilge Mutlu. How do humans teach: On curriculum learning and teaching dimension. In Advances in Neural Information Processing Systems 24 (NIPS\u201911), pages 1449-1457, 2011.  Alex Krizhevsky, Ilya Sutskever, and Geo\ufb00rey Hinton.  ImageNet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems 25 (NIPS\u20192012). 2012.  Kai A. Krueger and Peter Dayan. Flexible shaping: how learning in small steps helps. Cognition,  110:380-394, 2009.  Gautam Kunapuli, Kristin P. Bennett, Richard Maclin, and Jude W. Shavlik. The adviceptron: Giving advice to the perceptron. Proceedings of the Conference on Artificial Neural Networks In Engineering (ANNIE 2010), 2010.  Hugo Larochelle, Yoshua Bengio, Jerome Louradour, and Pascal Lamblin. Exploring strategies for training deep neural networks. Journal of Machine Learning Research, 10:1-40, 2009.  Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Ha\ufb00ner. Gradient-based learning  applied to document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.  Tom M. Mitchell. The Need for Biases in Learning Generalizations. Department of Computer  Science, Laboratory for Computer Science Research, Rutgers Univ., 1980.  Tom M. Mitchell and Sebastian B. Thrun. Explanation-based neural network learning for robot  control. Advances in Neural information processing systems, pages 287-287, 1993.  Richard Montague. Universal grammar. Theoria, 36(3):373-398, 1970.  Vinod Nair and Geo\ufb00rey E Hinton. Rectified linear units improve restricted boltzmann ma- chines. In Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 807-814, 2010.  Joseph O\u2019Sullivan. Integrating initialization bias and search bias in neural network learning,  1996. C\u00b8 a\u02d8glar G\u00a8ulc\u00b8ehre and Yoshua Bengio  Gail B. Peterson. A day of great illumination: B. F. Skinner\u2019s discovery of shaping. Journal of  the Experimental Analysis of Behavior, 82(3):317-328, 2004.  Salah Rifai, Pascal Vincent, Xavier Muller, Xavier Glorot, and Yoshua Bengio. Contractive auto-encoders: Explicit invariance during feature extraction. In Proceedings of theTwenty- eight International Conference on Machine Learning (ICML\u201911), June 2011.  Salah Rifai, Yoshua Bengio, Yann Dauphin, and Pascal Vincent. A generative process for sam- pling contractive auto-encoders. In Proceedings of the Twenty-nine International Conference on Machine Learning (ICML\u201912). ACM, 2012. URL http://icml.cc/discuss/2012/590. html.  Ruslan Salakhutdinov and Geo\ufb00rey E Hinton. Deep boltzmann machines. Conference on Artificial Intelligence and Statistics, pages 448-455, 2009.  In International  Burrhus F. Skinner. Reinforcement today. American Psychologist, 13:94-99, 1958.  Ray J. Solomono\ufb00. A system for incremental learning based on algorithmic probability. In Proceedings of the Sixth Israeli Conference on Artificial Intelligence, Computer Vision and Pattern Recognition, pages 515-527. Citeseer, 1989.  Tijmen Tieleman and Geo\ufb00rey Hinton. Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning, 4, 2012.  Geo\ufb00rey G. Towell and Jude W. Shavlik. Knowledge-based artificial neural networks. Artificial  intelligence, 70(1):119-165, 1994.  Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre-Antoine Manzagol. Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. In Journal of Machine Learning Research JML (-1), pages 3371- 3408.  Luis Von Ahn, Manuel Blum, Nicholas J Hopper, and John Langford. Captcha: Using hard In Advances in CryptologyEUROCRYPT 2003, pages 294-311.  ai problems for security. Springer, 2003.  Jason Weston, Fr\u00b4ed\u00b4eric Ratle, and Ronan Collobert. Deep learning via semi-supervised em- bedding. In William W. Cohen, Andrew McCallum, and Sam T. Roweis, editors, Pro- ceedings of the Twenty-fifth International Conference on Machine Learning (ICML\u201908), doi: pages 1168-1175, New York, NY, USA, 2008. ACM. 10.1145/1390156.1390303.  ISBN 978-1-60558-205-4.  Matthew D Zeiler.  Adadelta: An adaptive learning rate method.  arXiv preprint  arXiv:1212.5701, 2012. "}, "Herded Gibbs Sampling": {"volumn": 17, "url": "http://jmlr.org/papers/v17/chen16a.html", "header": "Herded Gibbs Sampling", "author": "Yutian Chen, Luke Bornn, Nando de Freitas, Mareija Eskelin, Jing Fang, Max Welling", "time": "17(10):1\u221229, 2016.", "abstract": "The Gibbs sampler is one of the most popular algorithms for inference in statistical models. In this paper, we introduce a herding variant of this algorithm, called herded Gibbs, that is entirely deterministic. We prove that herded Gibbs has an $O(1/T)$ convergence rate for models with independent variables and for fully connected probabilistic graphical models. Herded Gibbs is shown to outperform Gibbs in the tasks of image denoising with MRFs and named entity recognition with CRFs. However, the convergence for herded Gibbs for sparsely connected probabilistic graphical models is still an open problem.", "pdf_url": "http://jmlr.org/papers/volume17/chen16a/chen16a.pdf", "keywords": ["Gibbs sampling", "herding", "deterministic sampling"], "reference": "Fiction, 2013.  Pulp Fiction - Wikipedia, the free encyclopedia. http://en.wikipedia.org/wiki/Pulp_  D. H. Ackley, G. Hinton, and T. Sejnowski. A learning algorithm for Boltzmann machines.  Cognitive Science, 9:147-169, 1985.  C. Andrieu, N. de Freitas, A. Doucet, and M. I. Jordan. An introduction to MCMC for  machine learning. Machine Learning, 50(1):5-43, 2003.  F. Bach, S. Lacoste-Julien, and G. Obozinski. On the equivalence between herding and conditional gradient algorithms. In International Conference on Machine Learning, 2012.  L. Bornn, P. E. Jacob, P. Del Moral, and A. Doucet. An adaptive interacting wang-landau algorithm for automatic density exploration. Journal of Computational and Graphical Statistics, 22(3):749-773, 2013.  P. Br\u00b4emaud. Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues, vol-  ume 31. Springer, 1999.  27   Herded Gibbs Sampling  B.5 Proof of Corollary 4  Proof Since \u03c4 \u2217(T ) is a monotonically increasing function of T , for any T \u2265 T \u2217 + \u03c4 \u2217(T \u2217), we can find a number t so that  T = t + \u03c4 \u2217(t), t \u2265 T \u2217.  Partition the sample sequence S0,T = {X(kN ) : 0 \u2264 k < T } into two parts: the burn-in period S0,\u03c4 \u2217(t) and the stable period S\u03c4 \u2217(t),T . The discrepancy in the burn-in period is bounded by 1 and according to Theorem 3, the discrepancy in the stable period is bounded by  Hence, the discrepancy of the whole set S0,T is bounded by  dv( \u02dcP (St,T ) \u2212 \u03c0) \u2264  \u03bb t  .  dv( \u02dcP (S0,T ) \u2212 \u03c0) = dv (cid:18) \u03c4 \u2217(t) T  \u2264 dv  (cid:18) \u03c4 \u2217(t) T  \u02dcP (S0,\u03c4 \u2217(t)) + (cid:19)  t T  \u02dcP (S\u03c4 \u2217(t),T ) \u2212 \u03c0  (cid:19)  (cid:19)  ( \u02dcP (S0,\u03c4 \u2217(t)) \u2212 \u03c0  + dv  ( \u02dcP (S\u03c4 \u2217(t),T ) \u2212 \u03c0  (cid:18) t T  dv( \u02dcP (S0,\u03c4 \u2217(t)) \u2212 \u03c0) +  dv( \u02dcP (S\u03c4 \u2217(t),T ) \u2212 \u03c0)  \u2264  \u2264  \u03c4 \u2217(t) T \u03c4 \u2217(t) T  t T \u03c4 \u2217(T ) + \u03bb T  .  \u00b7 1 +  t T  \u03bb t  \u2264  (52)  References  Fiction, 2013.  Pulp Fiction - Wikipedia, the free encyclopedia. http://en.wikipedia.org/wiki/Pulp_  D. H. Ackley, G. Hinton, and T. Sejnowski. A learning algorithm for Boltzmann machines.  Cognitive Science, 9:147-169, 1985.  C. Andrieu, N. de Freitas, A. Doucet, and M. I. Jordan. An introduction to MCMC for  machine learning. Machine Learning, 50(1):5-43, 2003.  F. Bach, S. Lacoste-Julien, and G. Obozinski. On the equivalence between herding and conditional gradient algorithms. In International Conference on Machine Learning, 2012.  L. Bornn, P. E. Jacob, P. Del Moral, and A. Doucet. An adaptive interacting wang-landau algorithm for automatic density exploration. Journal of Computational and Graphical Statistics, 22(3):749-773, 2013.  P. Br\u00b4emaud. Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues, vol-  ume 31. Springer, 1999. Chen et al.  P. Carbonetto, J. Kisynski, N. de Freitas, and D. Poole. Nonparametric Bayesian logic. In  Uncertainty in Artificial Intelligence, pages 85-93, 2005.  S. Chen, J. Dick, and A. B. Owen. Consistency of Markov chain quasi-Monte Carlo on continuous state spaces. The Annals of Statistics, 39(2):673-701, 04 2011. doi: 10.1214/ 10-AOS831. URL http://dx.doi.org/10.1214/10-AOS831.  S. Chen, M. Matsumoto, T. Nishimura, and A. Owen. New inputs and methods for Markov chain quasi-Monte Carlo. In L. Plaskota and H. Wozniakowski, editors, Monte Carlo and Quasi-Monte Carlo Methods 2010, volume 23 of Springer Proceedings in Mathematics & Statistics, pages 313-327. Springer Berlin Heidelberg, 2012. URL http://dx.doi.org/ 10.1007/978-3-642-27440-4_15.  Y. Chen, M. Welling, and A.J. Smola. Supersamples from kernel-herding. In Uncertainty  in Artificial Intelligence, pages 109-116, 2010.  A. Doucet, N. de Freitas, and N. Gordon. Sequential Monte Carlo Methods in Practice.  Statistics for Engineering and Information Science. Springer, 2001.  A. Gelfand, Y. Chen, L. van der Maaten, and M. Welling. On herding and the perceptron cycling theorem. In Advances in Neural Information Processing Systems, pages 694-702, 2010.  N. D. Goodman, V. K. Mansinghka, D. M. Roy, K. Bonawitz, and J. B. Tenenbaum. Church:  a language for generative models. Uncertainty in Artificial Intelligence, 2008.  G. E. Hinton and R. R. Salakhutdinov. Reducing the dimensionality of data with neural  networks. Science, 313(5786):504-507, 2006.  A. E. Holroyd and J. Propp. Rotor walks and Markov chains. Algorithmic Probability and  Combinatorics, 520:105-126, 2010.  F. Huszar and D. Duvenaud. Optimally-weighted herding is Bayesian quadrature. In Pro- ceedings of the Twenty-Eighth Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-12), pages 377-386, Corvallis, Oregon, 2012. AUAI Press.  T. Grenager J. R. Finkel and C. Manning. Incorporating non-local information into infor- mation extraction systems by Gibbs sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL \u201905, pages 363-370, Stroudsburg, PA, USA, 2005. Association for Computational Linguistics. doi: 10.3115/1219840.1219885. URL http://dx.doi.org/10.3115/1219840.1219885.  J. S. Liu. Monte Carlo Strategies in Scientific Computing. Springer, 2001.  D. J. Lunn, A. Thomas, N. Best, and D. Spiegelhalter. WinBUGS a Bayesian modelling framework: Concepts, structure, and extensibility. Statistics and Computing, 10(4):325- 337, 2000.  B. Milch and S. Russell. General-purpose MCMC inference over relational structures. In  Uncertainty in Artificial Intelligence, pages 349-358, 2006. Herded Gibbs Sampling  K. P. Murphy. Machine Learning: a Probabilistic Perspective. MIT Press, 2012.  I. Murray and L. T. Elliott. Driving Markov chain Monte Carlo with a dependent random  stream. arXiv preprint arXiv:1204.3187, 2012.  I. Porteous, D. Newman, A. Ihler, A. Asuncion, P. Smyth, and M. Welling. Fast collapsed Gibbs sampling for latent Dirichlet allocation. In ACM SIGKDD International Confer- ence on Knowledge Discovery and Data Mining, pages 569-577, 2008.  C. P. Robert and G. Casella. Monte Carlo Statistical Methods. Springer, 2nd edition, 2004.  M. Welling. Herding dynamical weights to learn. In International Conference on Machine  Learning, pages 1121-1128, 2009a.  M. Welling. Herding dynamic weights for partially observed random field models.  In  Uncertainty in Artificial Intelligence, pages 599-606, 2009b.  H. Weyl. \u00a8Uber die gleichverteilung von zahlen mod. eins. Mathematische Annalen, 77: 313-352, 1916. ISSN 0025-5831. doi: 10.1007/BF01475864. URL http://dx.doi.org/ 10.1007/BF01475864. "}, "Complexity of Representation and Inference in Compositional Models with Part Sharing": {"volumn": 17, "url": "http://jmlr.org/papers/v17/yuille16a.html", "header": "Complexity of Representation and Inference in Compositional Models with Part Sharing", "author": "Alan Yuille, Roozbeh Mottaghi", "time": "17(11):1\u221228, 2016.", "abstract": "This paper performs a complexity analysis of a class of serial and parallel compositional models of multiple objects and shows that they enable efficient representation and rapid inference. Compositional models are generative and represent objects in a hierarchically distributed manner in terms of parts and subparts, which are constructed recursively by part-subpart compositions. Parts are represented more coarsely at higher level of the hierarchy, so that the upper levels give coarse summary descriptions (e.g., there is a horse in the image) while the lower levels represents the details (e.g., the positions of the legs of the horse). This hierarchically distributed representation obeys the  executive summary  principle, meaning that a high level executive only requires a coarse summary description and can, if necessary, get more details by consulting lower level executives. The parts and subparts are organized in terms of hierarchical dictionaries which enables  part sharing  between different objects allowing efficient representation of many objects. The first main contribution of this paper is to show that compositional models can be mapped onto a parallel visual architecture similar to that used by bio- inspired visual models such as deep convolutional networks but more explicit in terms of representation, hence enabling part detection as well as object detection, and suitable for complexity analysis. Inference algorithms can be run on this architecture to exploit the gains caused by part sharing and executive summary. Effectively, this compositional architecture enables us to perform exact inference simultaneously over a large class of generative models of objects. The second contribution is an analysis of the complexity of compositional models in terms of computation time (for serial computers) and numbers of nodes (e.g., \"neurons\") for parallel computers. In particular, we compute the complexity gains by part sharing and executive summary and their dependence on how the dictionary scales with the level of the hierarchy. We explore three regimes of scaling behavior where the dictionary size (i) increases exponentially with the level of the hierarchy, (ii) is determined by an unsupervised compositional learning algorithm applied to real data, (iii) decreases exponentially with scale. This analysis shows that in some regimes the use of shared parts enables algorithms which can perform inference in time linear in the number of levels for an exponential number of objects. In other regimes part sharing has little advantage for serial computers but can enable linear processing on parallel computers.", "pdf_url": "http://jmlr.org/papers/volume17/yuille16a/yuille16a.pdf", "keywords": ["compositional models", "object detection", "hierarchical architectures", "part shar ing"], "reference": "N. J. Adams and C. K. I. Williams. Dynamic trees for image modelling. Image and Vision  Computing, 20(10):865-877, 2003.  I. Biederman. Recognition-by-components: A theory of human image understanding. Psy-  chological Review, 94(2):115-147, 1987.  G. Blanchard and D. Geman. Hierarchical testing designs for pattern recognition. Annals  of Statistics, 35:11551202, 2005.  26  00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91rf(r)123456789100.50.60.70.80.91LevelrTrue Positive Rate Yuille and Mottaghi  part. Using the 2-out-of-3 rule, we obtain the update rule:  \u03c1h+1 = f (\u03c1h), with f (\u03c1) = \u03c13 + 3\u03c12(1 \u2212 \u03c1).  (18)  We can analyze the robustness of the rule by studying the behavior of the iterative map \u03c1t+1 = f (\u03c1t). It can be calculated that there are fixed points at \u03c1 = 0, 0.5, 1. Observe that f (\u03c1) > \u03c1 for 0.5 < \u03c1 < 1 and f (\u03c1) < \u03c1 for 0 < \u03c1 < 0.5, see Figure (13). Hence if the initial value of \u03c1 < 0.5 (i.e. the detectors at the leaf nodes miss the object more than half the time) then the iterative map converges to zero and we cannot detect the object. Conversely, if \u03c1 > 0.5 (the initial detectors miss parts less than half the time) then the iterative map converges to 1 and we always detect the object if there are a su\ufb03cient number of levels.  Figure 13: Left Panel: we plot f (\u03c1) as a function of \u03c1, showing fixed points at \u03c1 = 0, 0.5, 1, and that f (\u03c1) > \u03c1 for 0.5 < \u03c1 < 1, but f (\u03c1) < \u03c1 for 0 < \u03c1 < 0.5. Right Panel: we show the true positive rate (the detection rate) as a function of the number of levels and in terms of the \u03c1 parameter.  We performed simulations to verify this result and to estimate how many levels are needed to obtain almost perfect detection as a function of \u03c1. These are shown in Fig- ure (13)(right panel). Observe that if \u03c1 > 0.6 then only a small number of levels are needed to get almost perfect performance.  References  N. J. Adams and C. K. I. Williams. Dynamic trees for image modelling. Image and Vision  Computing, 20(10):865-877, 2003.  I. Biederman. Recognition-by-components: A theory of human image understanding. Psy-  chological Review, 94(2):115-147, 1987.  G. Blanchard and D. Geman. Hierarchical testing designs for pattern recognition. Annals  of Statistics, 35:11551202, 2005.00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91rf(r)123456789100.50.60.70.80.91LevelrTrue Positive Rate Compositional Models with Part Sharing  E. Borenstein and S. Ullman. Class-specific, top-down segmentation. In European Confer-  ence on Computer Vision (ECCV), 2002.  M. Chavira, A. Darwiche, and M. Jaeger. Compiling relational bayesian networks for exact  inference. In International Journal of Approximate Reasoning, pages 49-56, 2004.  J. J. DiCarlo, D. Zoccolan, and N. C. Rust. How does the brain solve visual object recog-  nition? Neuron, 73(3):415-434, 2012.  K. Fukushima. Neocognitron - a hierarchical neural network capable of visual-pattern  recognition. Neural Networks, 1(2):119-130, 1988.  S. Geman, D. F. Potter, and Z. Chi. Composition systems. Quarterly of Applied Mathe-  matics, 60(4):707-736, 2002.  News, January 23, 2000.  S.W. Hawking. I think the next century will be the century of complexity. San Jose Mercury  G. E. Hinton, S. Osindero, and Y. Teh. A fast learning algorithm for deep belief nets.  Neural Computation, 18:1527-54, 2006.  D. Kersten. Predictability and redundancy of natural images. JOSA A, 4(12):2395-2400,  1987.  I. Kokkinos and A. Yuille. Inference and learning with hierarchical shape models. Interna-  tional Journal of Computer Vision (IJCV), 93(2):201-225, 2011.  S. M. Konishi, A. Yuille, J. Coughlan, and S. C. Zhu. Statistical edge detection: Learning and evaluating edge cues. IEEE Transactions on Pattern Analysis and Machine Intelli- gence (TPAMI), 25:57-74, 2003.  A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolu- tional neural networks. In Advances in Neural Information Processing Systems (NIPS), 2012.  Y. LeCun and Y. Bengio. Convolutional networks for images, speech, and time-series. In M. A. Arbib, editor, The Handbook of Brain Theory and Neural Networks. MIT Press, 1995.  P. Lennie. Single units and visual cortical organization. Perception, 27:889-935, 1998.  J. Mao, J. Zhu, and A. Yuille. An active patch model for real world texture and appearance  classification. In European Conference on Computer Vision (ECCV), 2014.  G. Papandreou, L.-C. Chen, and A. Yuille. Modeling image patches with a generic dictionary In IEEE Conference on Computer Vision and Pattern Recognition  of mini-epitomes. (CVPR), 2014.  H. Poon and P. Domingos. Sum-product networks: A new deep architecture. In Uncertainty  in Artificial Intelligence (UAI), 2010. Yuille and Mottaghi  M. Riesenhuber and T. Poggio. Hierarchical models of object recognition in cortex. Nature  Neuroscience, 2:1019-1025, 1999.  T. Serre, L. Wolf, S. Bileschi, M. Riesenhuber, and T. Poggio. Robust object recogni- tion with cortex-like mechanisms. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 29:411-426, 2007.  S. Thorpe, D. Fize, and C. Marlot. Speed of processing in the human visual system. Nature,  381(6582):520-522, 1996.  J. K. Tsotsos. A Computational Perspective on Visual Attention. The MIT Press, 1st  edition, 2011. ISBN 0262015412, 9780262015417.  L. G. Valiant. Circuits of the Mind. Oxford University Press, 2000.  A. Yuille. Towards a theory of compositional learning and encoding of objects. In ICCV Workshop on Information Theory in Computer Vision and Pattern Recognition, 2011.  A. L. Yuille, J.M. Coughlan, Y.N. Wu, and S.C. Zhu. Order parameters for minimax entropy distributions: When does high level knowledge help? International Journal of Computer Vision, 41(1/2):9-33, 2001.  M. D. Zeiler, D. Krishnan, G. W. Taylor, and R. Fergus. Deconvolutional networks. In  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010.  L. Zhu, C. Lin, H. Huang, Y. Chen, and A. Yuille. Unsupervised structure learning: Hi- erarchical recursive composition, suspicious coincidence and competitive exclusion. In European Conference on Computer Vision (ECCV), 2008.  L. Zhu, Y. Chen, A. Torralba, W. Freeman, and A. Yuille. Part and appearance sharing: Re- cursive compositional models for multi-view multi-object detection. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010. "}, "Noisy Sparse Subspace Clustering": {"volumn": 17, "url": "http://jmlr.org/papers/v17/13-354.html", "header": "Noisy Sparse Subspace Clustering", "author": "Yu-Xiang Wang, Huan Xu", "time": "17(12):1\u221241, 2016.", "abstract": "This paper considers the problem of subspace clustering under noise. Specifically, we study the behavior of Sparse Subspace Clustering (SSC) when either adversarial or random noise is added to the unlabeled input data points, which are assumed to be in a union of low-dimensional subspaces. We show that a modified version of SSC is  provably effective  in correctly identifying the underlying subspaces, even with noisy data. This extends theoretical guarantee of this algorithm to more practical settings and provides justification to the success of SSC in a class of real applications.", "pdf_url": "http://jmlr.org/papers/volume17/13-354/13-354.pdf", "keywords": ["Subspace clustering", "robustness", "stability", "compressive sensing", "sparse"], "reference": "31:1-58, 1997.  Keith Ball. An elementary introduction to modern convex geometry. Flavors of geometry,  Ronen Basri and David W Jacobs. Lambertian re\ufb02ectance and linear subspaces. Pattern  Analysis and Machine Intelligence, IEEE Transactions on, 25(2):218-233, 2003.  A. Ben-Tal and A. Nemirovski. Robust convex optimization. Mathematics of Operations  Research, 23(4):769-805, 1998.  D. Bertsimas and M. Sim. The price of robustness. Operations research, 52(1):35-53, 2004.  Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends R(cid:13) in Machine Learning, 3(1):1-122, 2011.  Paul S Bradley and Olvi L Mangasarian. k-plane clustering. Journal of Global Optimization,  16(1):23-32, 2000.  Ren\u00b4e Brandenberg, Abhi Dattasharma, Peter Gritzmann, and David Larman.  Isoradial  bodies. Discrete & Computational Geometry, 32(4):447-457, 2004.  Emmanuel J Cand`es. The restricted isometry property and its implications for compressed  sensing. Comptes Rendus Mathematique, 346(9):589-592, 2008.  Guangliang Chen and Gilad Lerman. Spectral curvature clustering (scc).  International  Journal of Computer Vision, 81(3):317-330, 2009.  38   Wang and Xu  Algorithm 1 Matrix-LASSO-SSC  Input: Data points as columns in X \u2208 Rn\u00d7N , tradeo\ufb00 parameter \u03bb, numerical parame- ters \u00b50 and \u03c1. Initialize C = 0, J = 0, \u039b = 0, k = 0. while not converged do  1. Update J by  2. Update C by  3. Update \u039b by  J = (\u03bbX T X + \u00b5kI)\u22121(\u03bbX T X + \u00b5kC \u2212 \u039b).  (cid:48)  C  = SoftThresh 1 \u00b5k  (J + \u039b/\u00b5k) ,  (cid:48)  (cid:48)  C = C  \u2212 diag(C  ).  \u039b = \u039b + \u00b5k(J \u2212 C)  4. Update parameter \u00b5k+1 = \u03c1\u00b5k. 5.  Iterate k = k + 1;  end while Output: A\ufb03nity matrix W = |C| + |C|T  References  31:1-58, 1997.  Keith Ball. An elementary introduction to modern convex geometry. Flavors of geometry,  Ronen Basri and David W Jacobs. Lambertian re\ufb02ectance and linear subspaces. Pattern  Analysis and Machine Intelligence, IEEE Transactions on, 25(2):218-233, 2003.  A. Ben-Tal and A. Nemirovski. Robust convex optimization. Mathematics of Operations  Research, 23(4):769-805, 1998.  D. Bertsimas and M. Sim. The price of robustness. Operations research, 52(1):35-53, 2004.  Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends R(cid:13) in Machine Learning, 3(1):1-122, 2011.  Paul S Bradley and Olvi L Mangasarian. k-plane clustering. Journal of Global Optimization,  16(1):23-32, 2000.  Ren\u00b4e Brandenberg, Abhi Dattasharma, Peter Gritzmann, and David Larman.  Isoradial  bodies. Discrete & Computational Geometry, 32(4):447-457, 2004.  Emmanuel J Cand`es. The restricted isometry property and its implications for compressed  sensing. Comptes Rendus Mathematique, 346(9):589-592, 2008.  Guangliang Chen and Gilad Lerman. Spectral curvature clustering (scc).  International  Journal of Computer Vision, 81(3):317-330, 2009. Noisy Sparse Subspace Clustering  Yudong Chen, Ali Jalali, Sujay Sanghavi, and Huan Xu. Clustering partially observed graphs via convex optimization. The Journal of Machine Learning Research, 15(1):2213- 2238, 2014.  Joao Paulo Costeira and Takeo Kanade. A multi-body factorization method for motion analysis. In International Conference on Computer Vision (ICCV-95), pages 1071-1076. IEEE, 1995.  Jo\u02dcao Paulo Costeira and Takeo Kanade. A multibody factorization method for indepen- dently moving objects. International Journal of Computer Vision, 29(3):159-179, 1998.  Sanjoy Dasgupta and Anupam Gupta. An elementary proof of a theorem of johnson and  lindenstrauss. Random structures and algorithms, 22(1):60-65, 2003.  David L Donoho. De-noising by soft-thresholding. Information Theory, IEEE Transactions  on, 41(3):613-627, 1995.  David L Donoho, Michael Elad, and Vladimir N Temlyakov. Stable recovery of sparse overcomplete representations in the presence of noise. Information Theory, IEEE Trans- actions on, 52(1):6-18, 2006.  Eva L Dyer, Aswin C Sankaranarayanan, and Richard G Baraniuk. Greedy feature selection for subspace clustering. The Journal of Machine Learning Research, 14(1):2487-2517, 2013.  Ehsan Elhamifar and Ren\u00b4e Vidal. Sparse subspace clustering. In Computer Vision and  Pattern Recognition (CVPR-09), pages 2790-2797. IEEE, 2009.  Ehsan Elhamifar and Ren\u00b4e Vidal. Clustering disjoint subspaces via sparse representation. In Acoustics Speech and Signal Processing (ICASSP-10), pages 1926-1929. IEEE, 2010.  Ehsan Elhamifar and Rene Vidal. Sparse subspace clustering: Algorithm, theory, and applications. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(11): 2765-2781, 2013.  Brian Eriksson, Laura Balzano, and Robert Nowak. High-rank matrix completion.  In International Conference on Artificial Intelligence and Statistics (AISTATS-12), pages 373-381, 2012.  Trevor Hastie and Patrice Y Simard. Metrics and models for handwritten character recog-  nition. Statistical Science, pages 54-65, 1998.  Reinhard Heckel and Helmut B\u00a8olcskei. Noisy subspace clustering via thresholding.  In Information Theory Proceedings (ISIT), 2013 IEEE International Symposium on, pages 1382-1386. IEEE, 2013.  Kenichi Kanatani. Motion segmentation by subspace separation and model selection. In In- ternational Conference on Computer Vision (ICCV-01), volume 2, pages 586-591. IEEE, 2001. Wang and Xu  Fabien Lauer and Christoph Schnorr. Spectral clustering of linear subspaces for motion segmentation. In International Conference on Computer Vision (ICCV-09), pages 678- 685. IEEE, 2009.  Kuang-Chih Lee, Je\ufb00rey Ho, and David J Kriegman. Acquiring linear subspaces for face recognition under variable lighting. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 27(5):684-698, 2005.  G. Liu, Z. Lin, S. Yan, J. Sun, Y. Yu, and Y. Ma. Robust recovery of subspace struc- tures by low-rank representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(1):171-184, 2013.  Guangcan Liu, Zhouchen Lin, and Yong Yu. Robust subspace segmentation by low-rank representation. In International Conference on Machine Learning (ICML-10), pages 663- 670, 2010.  Guangcan Liu, Huan Xu, and Shuicheng Yan. Exact subspace segmentation and outlier de- tection by low-rank representation. In International Conference on Artificial Intelligence and Statistics (AISTATS-12), pages 703-711, 2012.  Behrooz Nasihatkon and Richard Hartley. Graph connectivity in sparse subspace clustering. In Computer Vision and Pattern Recognition (CVPR-11), pages 2137-2144. IEEE, 2011.  Andrew Y Ng, Michael I Jordan, Yair Weiss, et al. On spectral clustering: Analysis and an algorithm. Advances in Neural Information Processing Systems (NIPS-02), 2:849-856, 2002.  Shankar R Rao, Roberto Tron, Ren\u00b4e Vidal, and Yi Ma. Motion segmentation via robust subspace separation in the presence of outlying, incomplete, or corrupted trajectories. In Computer Vision and Pattern Recognition (CVPR-08), pages 1-8. IEEE, 2008.  Mahdi Soltanolkotabi, Emmanuel J Candes, et al. A geometric analysis of subspace clus-  tering with outliers. The Annals of Statistics, 40(4):2195-2238, 2012.  Mahdi Soltanolkotabi, Ehsan Elhamifar, Emmanuel J Candes, et al. Robust subspace  clustering. The Annals of Statistics, 42(2):669-699, 2014.  Jos F Sturm. Using sedumi 1.02, a matlab toolbox for optimization over symmetric cones.  Optimization methods and software, 11(1-4):625-653, 1999.  Ryan J Tibshirani et al. The lasso problem and uniqueness. Electronic Journal of Statistics,  7:1456-1490, 2013.  Kim-Chuan Toh, Michael J Todd, and Reha H T\u00a8ut\u00a8unc\u00a8u. Sdpt3a matlab software package for semidefinite programming, version 1.3. Optimization methods and software, 11(1-4): 545-581, 1999.  Roberto Tron and Ren\u00b4e Vidal. A benchmark for the comparison of 3-d motion segmentation algorithms. In Computer Vision and Pattern Recognition (CVPR-07), pages 1-8. IEEE, 2007. Noisy Sparse Subspace Clustering  P Tseng. Nearest q-\ufb02at to m points. Journal of Optimization Theory and Applications, 105  Ren\u00b4e Vidal. A tutorial on subspace clustering. IEEE Signal Processing Magazine, 28(2):  (1):249-252, 2000.  52-68, 2010.  Ren\u00b4e Vidal, Stefano Soatto, Yi Ma, and Shankar Sastry. An algebraic geometric approach to the identification of a class of linear hybrid systems. In Decision and Control, 2003. Proceedings. 42nd IEEE Conference on, volume 1, pages 167-172. IEEE, 2003.  Rene Vidal, Yi Ma, and Shankar Sastry. Generalized principal component analysis (GPCA). Pattern Analysis and Machine Intelligence, IEEE Transactions on, 27(12):1945-1959, 2005.  Yu-Xiang Wang and Huan Xu. Noisy sparse subspace clustering. In International Confer-  ence on Machine Learning (ICML-13), pages 89-97, 2013.  Yu-Xiang Wang, Huan Xu, and Chenlei Leng. Provable subspace clustering: When LRR In Advances in Neural Information Processing Systems (NIPS-13), pages  meets SSC. 64-72, 2013.  Yu-Xiang Wang, Choon Meng Lee, Loong-Fah Cheong, and Kim-Chuan Toh. Practical matrix completion and corruption recovery using proximal alternating robust subspace minimization. International Journal of Computer Vision, 111(3):315-344, 2015.  Jingyu Yan and Marc Pollefeys. A general framework for motion segmentation: Indepen- dent, articulated, rigid, non-rigid, degenerate and non-degenerate. In Computer Vision- ECCV 2006, pages 94-106. Springer, 2006.  A. Zhang, N. Fawaz, S. Ioannidis, and A. Montanari. Guess who rated this movie: Identi-  fying users through subspace clustering. arXiv preprint arXiv:1208.1544, 2012.  Shaohua Kevin Zhou, Gaurav Aggarwal, Rama Chellappa, and David W Jacobs. Appear- ance characterization of linear lambertian objects, generalized photometric stereo, and illumination-invariant face recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 29(2):230-245, 2007. "}, "Learning the Variance of the Reward-To-Go": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-335.html", "header": "Learning the Variance of the Reward-To-Go", "author": "Aviv Tamar, Dotan Di Castro, Shie Mannor", "time": "17(13):1\u221236, 2016.", "abstract": "In Markov decision processes (MDPs), the variance of the reward- to-go is a natural measure of uncertainty about the long term performance of a policy, and is important in domains such as finance, resource allocation, and process control. Currently however, there is no tractable procedure for calculating it in large scale MDPs. This is in contrast to the case of the expected reward-to-go, also known as the value function, for which effective simulation-based algorithms are known, and have been used successfully in various domains. In this paper we extend temporal difference (TD) learning algorithms to estimating the variance of the reward-to- go for a fixed policy. We propose variants of both TD(0) and LSTD($\\lambda$) with linear function approximation, prove their convergence, and demonstrate their utility in an option pricing problem. Our results show a dramatic improvement in terms of sample efficiency over standard Monte-Carlo methods, which are currently the state-of-the-art.", "pdf_url": "http://jmlr.org/papers/volume17/14-335/14-335.pdf", "keywords": ["simulation", "temporal di\ufb00erences"], "reference": "D. P. Bertsekas. Temporal di\ufb00erence methods for general projected equations. IEEE Trans-  actions on Automatic Control, 56(9):2128-2139, 2011.  D. P. Bertsekas. Dynamic Programming and Optimal Control, Vol II. Athena Scientific,  fourth edition, 2012.  D. P. Bertsekas and J. N. Tsitsiklis. Neuro-Dynamic Programming. Athena Scientific, 1996.  V. S. Borkar. Stochastic Approximation: A Dynamical Systems Viewpoint. Cambridge  University Press, 2008.  ing, 49(2):233-246, 2002.  J. A. Boyan. Technical update: least-squares temporal di\ufb00erence learning. Machine Learn-  J. C. Cox, S. A. Ross, and M. Rubinstein. Option pricing: A simplified approach. Journal  of Financial Economics, 7(3):229-263, 1979.  D. Du\ufb03e. Dynamic Asset Pricing Theory. Princeton University Press, 2010.  Y. Engel, S. Mannor, and R. Meir. Reinforcement learning with Gaussian processes. In  International Conference on Machine Learning, 2005.  J. A. Filar, L. C. M. Kallenberg, and H. M. Lee. Variance-penalized Markov decision  processes. Mathematics of Operations Research, 14(1):pp. 147-161, 1989.  34   Tamar, Di Castro, and Mannor  C.3.5 Proof of (37):  We now return to (38), where, using (39), (40), and (41) we have  (cid:107)\u03a0+  q T +w \u2212 \u03a0+ qN  T + N w(cid:107)q \u2264 \u03b71(N ) + \u03b72(N )(cid:107)w(cid:107)q + \u03b73(N ) + \u03b74(N ) + \u03b75(N )(cid:107)w(cid:107)q.  The uniform convergence of empirical distributions (Van der Vaart, 2000, Theorem 19.1) guarantees that PN and \u03b60;N uniformly converge to P and \u03b60 w.p. 1, respectively, and therefore qN \u2192 q and \u02c6w\u2217 J w.p. 1. Therefore, for every (cid:15), \u02dc(cid:15) > 0, w.p. 1 there is some N ((cid:15), \u02dc(cid:15)) such that for N > N ((cid:15), \u02dc(cid:15)) we have \u03b71(N )+\u03b73(N )+\u03b74(N ) \u2264 (cid:15), and \u03b72(N )+\u03b75(N ) \u2264 \u02dc(cid:15), therefore Eq. (37) holds.  J \u2192 w\u2217  Using Lemma 18 and Eq. (37) we have that for N > N ((cid:15), \u02dc(cid:15))  (cid:107)w+  M ;N \u2212 w+  M (cid:107)q \u2264  (cid:15) + \u02dc(cid:15)(cid:107)w+ 1 \u2212 \u03b3  M (cid:107)q  .  (42)  C.4 Convergence in k and N  Finally, using (42) and (36) we have that for any \u00af(cid:15) > 0, w.p. 1 there is a N (\u00af(cid:15)) such that for any N > N (\u00af(cid:15)) there is a k(N, \u00af(cid:15)), such that for all k > k(N, \u00af(cid:15))  (cid:107)wk;N \u2212 w+  M (cid:107) \u2264 \u00af(cid:15).  References  D. P. Bertsekas. Temporal di\ufb00erence methods for general projected equations. IEEE Trans-  actions on Automatic Control, 56(9):2128-2139, 2011.  D. P. Bertsekas. Dynamic Programming and Optimal Control, Vol II. Athena Scientific,  fourth edition, 2012.  D. P. Bertsekas and J. N. Tsitsiklis. Neuro-Dynamic Programming. Athena Scientific, 1996.  V. S. Borkar. Stochastic Approximation: A Dynamical Systems Viewpoint. Cambridge  University Press, 2008.  ing, 49(2):233-246, 2002.  J. A. Boyan. Technical update: least-squares temporal di\ufb00erence learning. Machine Learn-  J. C. Cox, S. A. Ross, and M. Rubinstein. Option pricing: A simplified approach. Journal  of Financial Economics, 7(3):229-263, 1979.  D. Du\ufb03e. Dynamic Asset Pricing Theory. Princeton University Press, 2010.  Y. Engel, S. Mannor, and R. Meir. Reinforcement learning with Gaussian processes. In  International Conference on Machine Learning, 2005.  J. A. Filar, L. C. M. Kallenberg, and H. M. Lee. Variance-penalized Markov decision  processes. Mathematics of Operations Research, 14(1):pp. 147-161, 1989. Learning the Variance of the Reward-To-Go  J. A. Filar, D. Krass, and K. W. Ross. Percentile performance criteria for limiting average Markov decision processes. IEEE Transaction on Automatic Control, 40(1):2-10, 1995.  P. Geibel and F. Wysotzki. Risk-sensitive reinforcement learning applied to control under  constraints. Journal of Artificial Intelligence Research, 24(1):81-108, 2005.  G. Grimmett and D. Stirzaker. Probability and Random Processes. Oxford university press,  2001.  edition, 2012.  J. B. Hiriart-Urruty and C. Lemar\u00b4echal. Convex Analysis and Minimization Algorithms I:  Fundamentals. Springer science & business media, 2013.  R. A. Horn and C. R. Johnson. Matrix Analysis. Cambridge University Press, second  J. C. Hull. Options, Futures, and Other Derivatives (6th edition). Prentice Hall, 2006.  H. K. Khalil and J. W. Grizzle. Nonlinear Systems. Prentice hall New Jersey, 1996.  V. Konda. Actor-Critic Algorithms. PhD thesis, Department of Computer Science and  Electrical Engineering, MIT, Cambridge, MA, 2002.  V. R. Konda and John N Tsitsiklis. On actor-critic algorithms. SIAM Journal on Control  and Optimization, 42(4):1143-1166, 2003.  M. G. Lagoudakis and R. Parr. Least-squares policy iteration. Journal of Machine Learning  Research, 4:1107-1149, 2003.  A. Lazaric, M. Ghavamzadeh, and R. Munos. Finite-sample analysis of LSTD. In Interna-  tional Conference on Machine Learning, 2010.  Y. Li, C. Szepesvari, and D. Schuurmans. Learning exercise policies for American options. In International Conference on Artificial Intelligence and Statistics, JMLR: W&CP, vol- ume 5, pages 352-359, 2009.  F. A. Longsta\ufb00 and E. S. Schwartz. Valuing American options by simulation: a simple  least-squares approach. Review of Financial Studies, 14(1):113-147, 2001.  S. Mannor and J. N. Tsitsiklis. Algorithmic aspects of mean-variance optimization in Markov decision processes. European Journal of Operational Research, 231(3):645 - 653, 2013. ISSN 0377-2217.  O. Mihatsch and R. Neuneier. Risk-sensitive reinforcement learning. Machine Learning, 49  (2):267-290, 2002.  J. Moody and M. Sa\ufb00ell. Learning to trade via direct reinforcement. IEEE Transactions  on Neural Networks, 12(4):875-889, 2001.  T. Morimura, M. Sugiyama, H. Kashima, H. Hachiya, and T. Tanaka. Parametric return density estimation for reinforcement learning. In Conference on Uncertainty in Artificial Intelligence, 2010. Tamar, Di Castro, and Mannor  W. B. Powell. Approximate Dynamic Programming. John Wiley and Sons, 2011.  L. A. Prashanth and M. Ghavamzadeh. Actor-critic algorithms for risk-sensitive MDPs. In  Advances in Neural Information Processing Systems, 2013.  M. L. Puterman. Markov Decision Processes: Discrete Stochastic Dynamic Programming.  John Wiley & Sons, Inc., 1994.  A. Ruszczy\u00b4nski. Risk-averse dynamic programming for Markov decision processes. Mathe-  matical Programming, 125(2):235-261, 2010.  M. Sato, H. Kimura, and S. Kobayashi. TD algorithm for the variance of return and mean-variance reinforcement learning. Transactions of the Japanese Society for Artificial Intelligence, 16:353-362, 2001.  W. F. Sharpe. Mutual fund performance. The Journal of Business, 39(1):119-138, 1966.  S. M. Shortreed, E. Laber, D. J. Lizotte, T. S. Stroup, J. Pineau, and S. A. Murphy. In- forming sequential clinical decision-making through reinforcement learning: an empirical study. Machine learning, 84(1):109-136, 2011.  M. J. Sobel. The variance of discounted Markov decision processes. Journal of Applied  Probability, pages 794-802, 1982.  R. S. Sutton. Learning to predict by the methods of temporal di\ufb00erences. Machine Learning,  3(1):9-44, 1988.  R. S. Sutton and A. G. Barto. Reinforcement Learning. MIT Press, 1998.  A. Tamar and S. Mannor. Variance adjusted actor critic algorithms.  arXiv preprint  arXiv:1310.3697, http://arxiv.org/abs/1310.3697, 2013.  A. Tamar, D. Di Castro, and S. Mannor. Policy gradients with variance related risk criteria.  In International Conference on Machine Learning, 2012.  A. Tamar, D. Di Castro, and S. Mannor. Temporal di\ufb00erence methods for the variance of  the reward to go. In International Conference on Machine Learning, 2013.  A. Tamar, S. Mannor, and H. Xu. Scaling up robust MDPs using function approximation.  In International Conference on Machine Learning, 2014.  G. Tesauro. Temporal di\ufb00erence learning and TD-gammon. Communications of the ACM,  38(3):58-68, 1995.  J. N. Tsitsiklis and B. Van Roy. Regression methods for pricing complex American-style  options. IEEE Transactions on Neural Networks, 12(4):694-703, 2001.  A. W. Van der Vaart. Asymptotic Statistics, volume 3. Cambridge university press, 2000.  N. D. Yen. Lipschitz continuity of solutions of variational inequalities with a parametric polyhedral constraint. Mathematics of Operations Research, 20(3):pp. 695-708, 1995. "}, "Convex Calibration Dimension for Multiclass Loss Matrices": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-316.html", "header": "Convex Calibration Dimension for Multiclass Loss Matrices", "author": "Harish G. Ramaswamy, Shivani Agarwal", "time": "17(14):1\u221245, 2016.", "abstract": "We study consistency properties of surrogate loss functions for general multiclass learning problems, defined by a general multiclass loss matrix. We extend the notion of classification calibration, which has been studied for binary and multiclass 0-1 classification problems (and for certain other specific learning problems), to the general multiclass setting, and derive necessary and sufficient conditions for a surrogate loss to be calibrated with respect to a loss matrix in this setting. We then introduce the notion of convex calibration dimension of a multiclass loss matrix, which measures the smallest \"size\" of a prediction space in which it is possible to design a convex surrogate that is calibrated with respect to the loss matrix. We derive both upper and lower bounds on this quantity, and use these results to analyze various loss matrices. In particular, we apply our framework to study various subset ranking losses, and use the convex calibration dimension as a tool to show both the existence and non-existence of various types of convex calibrated surrogates for these losses. Our results strengthen recent results of Duchi et al. (2010) and Calauz\u00c3\u0083\u00c2\u00a8nes et al. (2012) on the non-existence of certain types of convex calibrated surrogates in subset ranking. We anticipate the convex calibration dimension may prove to be a useful tool in the study and design of surrogate losses for general multiclass learning problems.", "pdf_url": "http://jmlr.org/papers/volume17/14-316/14-316.pdf", "keywords": ["surrogates", "calibrated surrogates", "classification calibration", "subset ranking."], "reference": "Shivani Agarwal. Surrogate regret bounds for bipartite ranking via strongly proper losses.  Journal of Machine Learning Research, 15:1653-1674, 2014.  Peter L. Bartlett, Michael Jordan, and Jon McAuli\ufb00e. Convexity, classification and risk  bounds. Journal of the American Statistical Association, 101(473):138-156, 2006.  Dimitri Bertsekas, Angelia Nedic, and Asuman Ozdaglar. Convex Analysis and Optimiza-  tion. Athena Scientific, 2003.  David Bu\ufb00oni, Cl\u00b4ement Calauz`enes, Patrick Gallinari, and Nicolas Usunier. Learning scor- ing functions with order-preserving losses and standardized supervision. In International Conference on Machine Learning, 2011.  Cl\u00b4ement Calauz`enes, Nicolas Usunier, and Patrick Gallinari. On the (non-)existence of convex, calibrated surrogate losses for ranking. In Neural Information Processing Systems, 2012.  St\u00b4ephan Cl\u00b4emen\u00b8con and Nicolas Vayatis. Ranking the best instances. Journal of Machine  Learning Research, 8:2671-2699, 2007.  St\u00b4ephan Cl\u00b4emen\u00b8con, G\u00b4abor Lugosi, and Nicolas Vayatis. Ranking and empirical minimiza-  tion of U-statistics. Annals of Statistics, 36:844-874, 2008.  David Cossock and Tong Zhang. Statistical analysis of Bayes optimal subset ranking. IEEE  Transactions on Information Theory, 54(11):5140-5154, 2008.  Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-  based vector machines. Journal of Machine Learning Research, 2:265-292, 2001.  John Duchi, Lester Mackey, and Michael Jordan. On the consistency of ranking algorithms.  In International Conference on Machine Learning, 2010.  Jean Gallier. Notes on convex sets, polytopes, polyhedra, combinatorial topology, Voronoi diagrams and Delaunay triangulations. Technical report, Department of Computer and Information Science, University of Pennsylvania, 2009.  Wei Gao and Zhi-Hua Zhou. On the consistency of multi-label learning. In Conference on  Learning Theory, 2011.  Kalervo J\u00a8arvelin and Jaana Kek\u00a8al\u00a8ainen. Ir evaluation methods for retrieving highly relevant documents. In International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000.  Wenxin Jiang. Process consistency for AdaBoost. Annals of Statistics, 32(1):13-29, 2004.  Wojciech Kotlowski, Krzysztof Dembczynski, and Eyke Huellermeier. Bipartite ranking through minimization of univariate loss. In International Conference on Machine Learn- ing, 2011.  43   Convex Calibration Dimension for Multiclass Loss Matrices  References  Shivani Agarwal. Surrogate regret bounds for bipartite ranking via strongly proper losses.  Journal of Machine Learning Research, 15:1653-1674, 2014.  Peter L. Bartlett, Michael Jordan, and Jon McAuli\ufb00e. Convexity, classification and risk  bounds. Journal of the American Statistical Association, 101(473):138-156, 2006.  Dimitri Bertsekas, Angelia Nedic, and Asuman Ozdaglar. Convex Analysis and Optimiza-  tion. Athena Scientific, 2003.  David Bu\ufb00oni, Cl\u00b4ement Calauz`enes, Patrick Gallinari, and Nicolas Usunier. Learning scor- ing functions with order-preserving losses and standardized supervision. In International Conference on Machine Learning, 2011.  Cl\u00b4ement Calauz`enes, Nicolas Usunier, and Patrick Gallinari. On the (non-)existence of convex, calibrated surrogate losses for ranking. In Neural Information Processing Systems, 2012.  St\u00b4ephan Cl\u00b4emen\u00b8con and Nicolas Vayatis. Ranking the best instances. Journal of Machine  Learning Research, 8:2671-2699, 2007.  St\u00b4ephan Cl\u00b4emen\u00b8con, G\u00b4abor Lugosi, and Nicolas Vayatis. Ranking and empirical minimiza-  tion of U-statistics. Annals of Statistics, 36:844-874, 2008.  David Cossock and Tong Zhang. Statistical analysis of Bayes optimal subset ranking. IEEE  Transactions on Information Theory, 54(11):5140-5154, 2008.  Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-  based vector machines. Journal of Machine Learning Research, 2:265-292, 2001.  John Duchi, Lester Mackey, and Michael Jordan. On the consistency of ranking algorithms.  In International Conference on Machine Learning, 2010.  Jean Gallier. Notes on convex sets, polytopes, polyhedra, combinatorial topology, Voronoi diagrams and Delaunay triangulations. Technical report, Department of Computer and Information Science, University of Pennsylvania, 2009.  Wei Gao and Zhi-Hua Zhou. On the consistency of multi-label learning. In Conference on  Learning Theory, 2011.  Kalervo J\u00a8arvelin and Jaana Kek\u00a8al\u00a8ainen. Ir evaluation methods for retrieving highly relevant documents. In International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000.  Wenxin Jiang. Process consistency for AdaBoost. Annals of Statistics, 32(1):13-29, 2004.  Wojciech Kotlowski, Krzysztof Dembczynski, and Eyke Huellermeier. Bipartite ranking through minimization of univariate loss. In International Conference on Machine Learn- ing, 2011. Ramaswamy and Agarwal  Nicolas Lambert and Yoav Shoham. Eliciting truthful answers to multiple-choice questions.  In ACM Conference on Electronic Commerce, 2009.  Yoonkyung Lee, Yi Lin, and Grace Wahba. Multicategory support vector machines: The- ory and application to the classification of microarray data. Journal of the American Statistical Association, 99(465):67-81, 2004.  G\u00b4abor Lugosi and Nicolas Vayatis. On the Bayes-risk consistency of regularized boosting  methods. Annals of Statistics, 32(1):30-55, 2004.  Deirdre O\u2019Brien, Maya Gupta, and Robert Gray. Cost-sensitive multi-class classification from probability estimates. In International Conference on Machine Learning, 2008.  Bernardo \u00b4A. Pires, Csaba Szepesvari, and Mohammad Ghavamzadeh. Cost-sensitive multi- class classification risk bounds. In International Conference on Machine Learning, 2013.  Harish G. Ramaswamy and Shivani Agarwal. Classification calibration dimension for general  multiclass losses. In Neural Information Processing Systems, 2012.  Harish G. Ramaswamy, Shivani Agarwal, and Ambuj Tewari. Convex calibrated surro- In Neural  gates for low-rank loss matrices with applications to subset ranking losses. Information Processing Systems, 2013.  Harish G. Ramaswamy, Ambuj Tewari, and Shivani Agarwal. Consistent algorithms for  multiclass classification with a reject option. arXiv:1505.04137, 2015.  Pradeep Ravikumar, Ambuj Tewari, and Eunho Yang. On NDCG consistency of listwise ranking methods. In International Conference on Artificial Intelligence and Statistics, 2011.  Mark D. Reid and Robert C. Williamson. Composite binary losses. Journal of Machine  Learning Research, 11:2387-2422, 2010.  Clayton Scott. Calibrated asymmetric surrogate losses. Electronic Journal of Statistics, 6:  958-992, 2012.  Ingo Steinwart. Consistency of support vector machines and other regularized kernel clas-  sifiers. IEEE Transactions on Information Theory, 51(1):128-142, 2005.  Ingo Steinwart. How to compare di\ufb00erent loss functions and their risks. Constructive  Approximation, 26:225-287, 2007.  Ambuj Tewari and Peter L. Bartlett. On the consistency of multiclass classification methods.  Journal of Machine Learning Research, 8:1007-1025, 2007.  Elodie Vernet, Robert C. Williamson, and Mark D. Reid. Composite multiclass losses. In  Neural Information Processing Systems, 2011.  Jason Weston and Chris Watkins. Support vector machines for multi-class pattern recog-  nition. In 7th European Symposium On Artificial Neural Networks, 1999. Convex Calibration Dimension for Multiclass Loss Matrices  Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, and Hang Li. Listwise approach to learning to rank: Theory and algorithm. In International Conference on Machine Learn- ing, 2008.  Ming Yuan and Marten Wegkamp. Classification methods with reject option based on convex risk minimization. Journal of Machine Learning Research, 11:111-130, 2010.  Tong Zhang. Statistical behavior and consistency of classification methods based on convex  risk minimization. Annals of Statistics, 32(1):56-134, 2004a.  Tong Zhang. Statistical analysis of some multi-category large margin classification methods.  Journal of Machine Learning Research, 5:1225-1251, 2004b. "}, "A Consistent Information Criterion for Support Vector Machines in Diverging Model Spaces": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-231.html", "header": "A Consistent Information Criterion for Support Vector Machines in Diverging Model Spaces", "author": "Xiang Zhang, Yichao Wu, Lan Wang, Runze Li", "time": "17(16):1\u221226, 2016.", "abstract": "Information criteria have been popularly used in model selection and proved to possess nice theoretical properties. For classification, Claeskens et al. (2880) proposed support vector machine information criterion for feature selection and provided encouraging numerical evidence. Yet no theoretical justification was given there. This work aims to fill the gap and to provide some theoretical justifications for support vector machine information criterion in both fixed and diverging model spaces. We first derive a uniform convergence rate for the support vector machine solution and then show that a modification of the support vector machine information criterion achieves model selection consistency even when the number of features diverges at an exponential rate of the sample size. This consistency result can be further applied to selecting the optimal tuning parameter for various penalized support vector machine methods. Finite-sample performance of the proposed information criterion is investigated using Monte Carlo studies and one real-world gene selection problem.", "pdf_url": "http://jmlr.org/papers/volume17/14-231/14-231.pdf", "keywords": ["Bayesian Information Criterion", "Diverging Model Spaces", "Feature Selection", "Support Vector Machines"], "reference": "Hirotugu Akaike. Information theory and an extension of the maximum likelihood principle. In Second international symposium on information theory, pages 267-281. Akademinai Kiado, 1973.  23   A Consistent Information Criterion for Support Vector Machines in Diverging Model Spaces  as n \u2192 \u221e. Similar to the proof of Lemma 2, under condition (A6) and (A8), it can be shown  1/n  (1\u2212YiXT  i, \u02dcS (cid:98)\u03b2 \u02dcS)+ \u22121/n  (1\u2212YiXT i, \u02dcS  \u03b2\u2217 \u02dcS  )+ \u2264 1/nC| \u02dcS| log(p)\u03bbmax(H(\u03b2\u2217 \u02dcS  )) \u2192 0 (18)  n (cid:88)  i=1  n (cid:88)  i=1  as n \u2192 \u221e. Notice that  n (cid:88)  {1/n  inf S\u2208\u2126\u2212 (cid:110)  \u22651/n  i=1 nE[(1 \u2212 YiXT i, \u02dcS  inf S\u2208\u2126\u2212  (1 \u2212 YiXT i, \u02dcS  \u00af\u03b2 \u02dcS)+ \u2212 1/n  (1 \u2212 YiXT i, \u02dcS  \u03b2\u2217 \u02dcS  )+}  n (cid:88)  i=1  \u00af\u03b2 \u02dcS)+ \u2212 (1 \u2212 YiXT i, \u02dcS  \u03b2\u2217 \u02dcS  )+]  n (cid:88)  i=1  n (cid:88)  i=1  (1 \u2212 YiXT i, \u02dcS  \u00af\u03b2 \u02dcS)+ \u2212  (1 \u2212 YiXT i, \u02dcS  \u03b2\u2217 \u02dcS  )+ \u2212 nE[(1 \u2212 YiXT i, \u02dcS  \u00af\u03b2 \u02dcS)+ \u2212 (1 \u2212 YiXT i, \u02dcS  \u03b2\u2217 \u02dcS  )+]|}  (cid:111) .  \u2212 sup S\u2208\u2126\u2212  {|  n (cid:88)  i=1  {|  sup S\u2208\u2126\u2212  n (cid:88)  i=1  n (cid:88)  i=1  Similar to the proof of Lemma 2, it can be shown  (1 \u2212 YiXT i, \u02dcS  \u00af\u03b2 \u02dcS)+ \u2212  (1 \u2212 YiXT i, \u02dcS  \u03b2\u2217 \u02dcS  )+ \u2212 nE[(1 \u2212 YiXT i, \u02dcS  \u00af\u03b2 \u02dcS)+ \u2212 (1 \u2212 YiXT i, \u02dcS  \u03b2\u2217 \u02dcS  )+]|}  =Op(|  YiXT i, \u02dcS  (\u00af\u03b2 \u02dcS \u2212 \u03b2\u2217 \u02dcS  )1(1 \u2212 YiXT  i,S\u03b2\u2217 \u02dcS  \u2265 0)|) = Op(  n| \u02dcS| log(p)).  (cid:113)  By Taylor expansion of hinge loss function, we have  E[(1 \u2212 YiXT i, \u02dcS  \u00af\u03b2 \u02dcS)+ \u2212 (1 \u2212 YiXT i, \u02dcS  \u03b2\u2217 \u02dcS  )+] \u2265 0.5\u03bbmin(H(\u02dc\u03b2  \u2217 \u02dcS))\u22062 > 0,  where \u02dc\u03b2  \u2217 \u02dcS lies in the set defined in condition (A7). By (16)-(20), we have  inf S\u2208\u2126\u2212  {1/n  n (cid:88)  i=1  n (cid:88)  i=1  (1 \u2212 YiXT  i,S (cid:98)\u03b2S)+ \u2212 1/n  (1 \u2212 YiXT  i, \u02dcS (cid:98)\u03b2 \u02dcS)+} \u2265 0.5\u03bbmin(H(\u03b2\u2217 \u02dcS  ))\u22062 > 0  (19)  (20)  for su\ufb03cient large n, which completes the proof.  Theorem 5 Under conditions (A1)-(A8) and \u03bbn = 1/n, we have  Pr( \u02c6S = S\u2217) \u2192 1.  as n, p \u2192 \u221e, where (cid:98)S = arg minS:|S|\u2264Mn SVMICH (S). Proof. The proof can be easily checked by combing the results from Lemma 3 and Lemma 4 and thus is omitted here.  References  Hirotugu Akaike. Information theory and an extension of the maximum likelihood principle. In Second international symposium on information theory, pages 267-281. Akademinai Kiado, 1973. Xiang Zhang, Yichao Wu, Lan Wang and Runze Li  Natalia Becker, Grischa Toedt, Peter Lichter, and Axel Benner. Elastic scad as a novel penalization method for svm classification tasks in high-dimensional data. BMC bioin- formatics, 12(1):138, 2011.  Paul S Bradley and Olvi L Mangasarian. Feature selection via concave minimization and  support vector machines. In ICML, volume 98, pages 82-90, 1998.  Peter Lukas B\u00a8uhlmann, Sara A van de Geer, and Sara Van de Geer. Statistics for high-  dimensional data. Springer, 2011.  Tony Cai and Weidong Liu. A direct estimation approach to sparse linear discriminant  analysis. Journal of the American Statistical Association, 106(496), 2011.  Jiahua Chen and Zehua Chen. Extended bayesian information criteria for model selection  with large model spaces. Biometrika, 95(3):759-771, 2008.  Gerda Claeskens, Christophe Croux, and Johan Van Kerckhoven. An information criterion for variable selection in support vector machines. The Journal of Machine Learning Research, 9:541-558, 2008.  Jianqing Fan and Yingying Fan. High dimensional classification using features annealed  independence rules. Annals of statistics, 36(6):2605, 2008.  Jianqing Fan and Runze Li. Variable selection via nonconcave penalized likelihood and its oracle properties. Journal of the American Statistical Association, 96(456):1348-1360, 2001.  Jianqing Fan and Jinchi Lv. Non-concave penalized likelihood with np-dimensionality. IEEE  Transactions on Information Theory, 57:5467-5484, 2011.  Jianqing Fan and Heng Peng. On non-concave penalized likelihood with diverging number  of parameters. The Annals of Statistics, 32:928-961, 2004.  Yingying Fan and Cheng Yong Tang. Tuning parameter selection in high dimensional pe- nalized likelihood. Journal of the Royal Statistical Society: Series B (Statistical Method- ology), 75(3):531-552, 2013.  Isabelle Guyon and Andr\u00b4e Elissee\ufb00. An introduction to variable and feature selection. The  Journal of Machine Learning Research, 3:1157-1182, 2003.  Isabelle Guyon, Jason Weston, Stephen Barnhill, and Vladimir Vapnik. Gene selection for cancer classification using support vector machines. Machine learning, 46(1-3):389-422, 2002.  Trevor. Hastie, Robert. Tibshirani, and J Jerome H Friedman. The elements of statistical  learning, volume 1. Springer New York, 2001.  Trevor Hastie, Saharon Rosset, Robert Tibshirani, and Ji Zhu. The entire regularization path for the support vector machine. In Journal of Machine Learning Research, pages 1391-1415, 2004. A Consistent Information Criterion for Support Vector Machines in Diverging Model Spaces  Shuichi Kawano. Selection of tuning parameters in bridge regression models via bayesian  information criterion. Statistical Papers, pages 1-17, 2012.  Ja-Yong Koo, Yoonkyung Lee, Yuwon Kim, and Changyi Park. A bahadur representation of the linear support vector machine. The Journal of Machine Learning Research, 9: 1343-1368, 2008.  Eun Ryung Lee, Hohsuk Noh, and Byeong U Park. Model selection via bayesian information criterion for quantile regression models. Journal of the American Statistical Association, 109(505):216-229, 2014.  Rahul Mazumder, Jerome H Friedman, and Trevor Hastie. Sparsenet: Coordinate descent with nonconvex penalties. Journal of the American Statistical Association, 106(495), 2011.  Gideon Schwarz. Estimating the dimension of a model. The annals of statistics, 6(2):  Jun Shao. An asymptotic theory for linear model selection. Statistica Sinica, 7(2):221-242,  461-464, 1978.  1997.  Peide Shi and Chih-Ling Tsai. Regression model selectiona residual likelihood approach. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 64(2):237- 252, 2002.  Sara van de Geer. Empirical processes in m-estimation. cambridge series in statistical and  probabilistic mathematics, 2000.  Aad W Van Der Vaart and Jon A Wellner. Weak Convergence. Springer, 1996.  Grace Wahba et al. Support vector machines, reproducing kernel hilbert spaces and the randomized gacv. Advances in Kernel Methods-Support Vector Learning, 6:69-87, 1999.  Hansheng Wang, Runze Li, and Chih-Ling Tsai. Tuning parameter selectors for the  smoothly clipped absolute deviation method. Biometrika, 94(3):553-568, 2007.  Hansheng Wang, Bo Li, and Chenlei Leng. Shrinkage tuning parameter selection with a diverging number of parameters. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 71(3):671-683, 2009.  Lan Wang, Yichao Wu, and Runze Li. Quantile regression for analyzing heterogeneity in ultra-high dimension. Journal of the American Statistical Association, 107(497):214-222, 2012.  Li Wang, Ji Zhu, and Hui Zou. The doubly regularized support vector machine. Statistica  Sinica, 16(2):589, 2006.  17:1368-1385, 2011.  Marten Wegkamp and Ming Yuan. Support vector machines with a reject option. Bernoulli, Xiang Zhang, Yichao Wu, Lan Wang and Runze Li  Jason Weston, Sayan Mukherjee, Olivier Chapelle, Massimiliano Pontil, Tomaso Poggio, and Vladimir Vapnik. Feature selection for svms. In NIPS, volume 12, pages 668-674, 2000.  Ming Yuan. High dimensional inverse covariance matrix estimation via linear programming.  The Journal of Machine Learning Research, 99:2261-2286, 2010.  Cun-Hui Zhang. Nearly unbiased variable selection under minimax concave penalty. The  Annals of Statistics, 38(2):894-942, 2010.  Cun-Hui Zhang and Jian Huang. The sparsity and bias of the lasso selection in high-  dimensional linear regression. The Annals of Statistics, 36(4):1567-1594, 2008.  Hao Helen Zhang, Jeongyoun Ahn, Xiaodong Lin, and Cheolwoo Park. Gene selection using support vector machines with non-convex penalty. Bioinformatics, 22(1):88-95, 2006.  Xiang Zhang, Yichao Wu, Lan Wang, and Runze Li. Variable selection for support vector machines in moderately high dimensions. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 2014.  Ji Zhu, Saharon Rosset, Trevor Hastie, and Rob Tibshirani. 1-norm support vector ma-  chines. Advances in neural information processing systems, 16(1):49-56, 2004.  Hui Zou and Runze Li. One-step sparse estimates in nonconcave penalized likelihood models.  Annals of statistics, 36(4):1509, 2008.  Hui Zou and Ming Yuan. The fo-norm support vector machine. Statistica Sinica, 18:  379-398, 2008. "}, "Extremal Mechanisms for Local Differential Privacy": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-135.html", "header": "Extremal Mechanisms for Local Differential Privacy", "author": "Peter Kairouz, Sewoong Oh, Pramod Viswanath", "time": "17(17):1\u221251, 2016.", "abstract": "Local differential privacy has recently surfaced as a strong measure of privacy in contexts where personal information remains private even from data analysts. Working in a setting where both the data providers and data analysts want to maximize the utility of statistical analyses performed on the released data, we study the fundamental trade-off between local differential privacy and utility. This trade-off is formulated as a constrained optimization problem: maximize utility subject to local differential privacy constraints. We introduce a combinatorial family of extremal privatization mechanisms, which we call staircase mechanisms, and show that it contains the optimal privatization mechanisms for a broad class of information theoretic utilities such as mutual information and $f$-divergences. We further prove that for any utility function and any privacy level, solving the privacy-utility maximization problem is equivalent to solving a finite-dimensional linear program, the outcome of which is the optimal staircase mechanism. However, solving this linear program can be computationally expensive since it has a number of variables that is exponential in the size of the alphabet the data lives in. To account for this, we show that two simple privatization mechanisms, the binary and randomized response mechanisms, are universally optimal in the low and high privacy regimes, and well approximate the intermediate regime.", "pdf_url": "http://jmlr.org/papers/volume17/15-135/15-135.pdf", "keywords": ["information theoretic utilities", "f -divergences", "mutual information", "statistical inference", "hy pothesis testing", "estimation"], "reference": "A. Acquisti. Privacy in electronic commerce and the economics of immediate gratification. In Proceedings of the 5th ACM conference on Electronic commerce, pages 21-29. ACM, 2004.  A. Acquisti and J. Grossklags. What can behavioral economics teach us about privacy.  Digital Privacy, page 329, 2007.  R. F. Barber and J. C. Duchi. Privacy and statistical risk: Formalisms and minimax bounds.  arXiv preprint arXiv:1412.4451, 2014.  A. Beimel, K. Nissim, and E. Omri. Distributed private data analysis: Simultaneously solv- ing how and what. In Advances in Cryptology-CRYPTO 2008, pages 451-468. Springer, 2008.  D. Blackwell. Equivalent comparisons of experiments. The Annals of Mathematical Statis-  tics, 24(2):265-272, 1953.  49   Extremal Mechanisms for Local Differential Privacy  Hence, the randomized response mechanism achieves the upper bound (75). This proves the optimality of the randomized response for all \u03b5 \u2265 \u03b5\u2217.  10. Proof of Proposition 17 Let U (Q) be a utility mechanism of the form U (Q) = (cid:80) Y \u00b5(Qy), where \u00b5 is a sublinear function. Consider a stochastic mapping W of dimensions (cid:96) \u00d7 m and let QW be the stochastic mapping obtained by first applying Q to X \u2208 X to obtain Y \u2208 Y and then applying W to Y to obtain Z \u2208 Z.  U (QW ) =  \u00b5 ((QW )z)  (cid:32)  (cid:88)  (cid:88)  \u00b5  QyWy,z  (cid:33)  Y  Wy,z\u00b5 (Qy)  (cid:88)  Z  Z (cid:88)  Y,Z (cid:88)  =  \u2264  =  \u00b5(Qy)  Y = U (Q) ,  where the inequality follows from sublinearity and the second to last equality follows from the row stochastic property of W . Therefore, U (Q) obeys the data processing inequality.  (80)  This research is supported in part by NSF CISE award CCF-1422278, NSF SaTC award CNS-1527754, NSF CMMI award MES-1450848 and NSF ENG award ECCS-1232257.  Acknowledgments  References  A. Acquisti. Privacy in electronic commerce and the economics of immediate gratification. In Proceedings of the 5th ACM conference on Electronic commerce, pages 21-29. ACM, 2004.  A. Acquisti and J. Grossklags. What can behavioral economics teach us about privacy.  Digital Privacy, page 329, 2007.  R. F. Barber and J. C. Duchi. Privacy and statistical risk: Formalisms and minimax bounds.  arXiv preprint arXiv:1412.4451, 2014.  A. Beimel, K. Nissim, and E. Omri. Distributed private data analysis: Simultaneously solv- ing how and what. In Advances in Cryptology-CRYPTO 2008, pages 451-468. Springer, 2008.  D. Blackwell. Equivalent comparisons of experiments. The Annals of Mathematical Statis-  tics, 24(2):265-272, 1953. Kairouz, Oh and Viswanath  J. Blocki, A. Blum, A. Datta, and O. She\ufb00et. The Johnson-Lindenstrauss transform itself In Foundations of Computer Science, 2012 IEEE 53rd  preserves di\ufb00erential privacy. Annual Symposium on, pages 410-419. IEEE, 2012.  K. Chatzikokolakis, T. Chothia, and A. Guha. Statistical measurement of information leakage. In Tools and Algorithms for the Construction and Analysis of Systems, pages 390-404. Springer, 2010.  K. Chaudhuri and D. Hsu. Convergence rates for di\ufb00erentially private statistical estimation.  arXiv preprint arXiv:1206.6395, 2012.  K. Chaudhuri and C. Monteleoni. Privacy-preserving logistic regression. In NIPS, volume 8,  pages 289-296, 2008.  K. Chaudhuri, A. D. Sarwate, and K. Sinha. Near-optimal di\ufb00erentially private principal  components. In NIPS, pages 998-1006, 2012.  T. M. Cover and J. A. Thomas. Elements of information theory. John Wiley & Sons, 2012.  A. De. Lower bounds in di\ufb00erential privacy. In Theory of Cryptography, pages 321-338.  Springer, 2012.  J. C Duchi, M. I. Jordan, and M. J. Wainwright. Local privacy and statistical minimax In Foundations of Computer Science, 2013 IEEE 54th Annual Symposium on,  rates. pages 429-438. IEEE, 2013.  C. Dwork. Di\ufb00erential privacy.  In Automata, languages and programming, pages 1-12.  Springer, 2006.  C. Dwork and J. Lei. Di\ufb00erential privacy and robust statistics. In Proceedings of the 41st  annual ACM symposium on Theory of computing, pages 371-380. ACM, 2009.  C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data, ourselves: Privacy via distributed noise generation. In Advances in Cryptology-EUROCRYPT 2006, pages 486-503. Springer, 2006a.  C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private  data analysis. In Theory of Cryptography, pages 265-284. Springer, 2006b.  Q. Geng and P. Viswanath. The optimal mechanism in di\ufb00erential privacy. arXiv preprint  arXiv:1212.1186, 2012.  Q. Geng and P. Viswanath. The optimal mechanism in ((cid:15),\u03b4)-di\ufb00erential privacy. arXiv  preprint arXiv:1305.1330, 2013a.  Q. Geng and P. Viswanath. The optimal mechanism in di\ufb00erential privacy: Multidimen-  sional setting. arXiv preprint arXiv:1312.0655, 2013b.  A. Ghosh, T. Roughgarden, and M. Sundararajan. Universally utility-maximizing privacy  mechanisms. SIAM Journal on Computing, 41(6):1673-1693, 2012. Extremal Mechanisms for Local Differential Privacy  M. Hardt and A. Roth. Beating randomized response on incoherent matrices. In Proceedings  of the 44th symposium on Theory of Computing, pages 1255-1268. ACM, 2012.  M. Hardt and G. N. Rothblum. A multiplicative weights mechanism for privacy-preserving data analysis. In Foundations of Computer Science, 2010 51st Annual IEEE Symposium on, pages 61-70. IEEE, 2010.  M. Hardt and K. Talwar. On the geometry of di\ufb00erential privacy. In Proceedings of the  42nd ACM symposium on Theory of computing, pages 705-714. ACM, 2010.  M. Hardt, K. Ligett, and F. McSherry. A simple and practical algorithm for di\ufb00erentially  private data release. In NIPS, pages 2348-2356, 2012.  P. Kairouz, S. Oh, and P. Viswanath. The composition theorem for di\ufb00erential privacy.  arXiv preprint arXiv:1311.0776, 2013.  P. Kairouz, S. Oh, and P. Viswanath. Extremal mechanisms for local di\ufb00erential privacy.  arXiv preprint arXiv:1407.1338, 2014a.  P. Kairouz, S. Oh, and P. Viswanath. Di\ufb00erentially private multi-party computation: Op- timality of non-interactive randomized response. arXiv preprint arXiv:1407.1546, 2014b.  M. Kapralov and K. Talwar. On di\ufb00erentially private low rank approximation. In SODA,  volume 5, page 1. SIAM, 2013.  J. Lei. Di\ufb00erentially private m-estimators. In NIPS, pages 361-369, 2011.  F. McSherry and K. Talwar. Mechanism design via di\ufb00erential privacy. In Foundations of Computer Science, 2007. 48th Annual IEEE Symposium on, pages 94-103. IEEE, 2007.  L. Sankar, S. R. Rajagopalan, and H. V. Poor. Utility-privacy tradeo\ufb00s in databases: An information-theoretic approach. Information Forensics and Security, IEEE Transactions on, 8(6):838-852, 2013.  A. D. Sarwate and L. Sankar. A rate-disortion perspective on local di\ufb00erential privacy. In Communication, Control, and Computing (Allerton), 2014 52nd Annual Allerton Con- ference on, pages 903-908. IEEE, 2014.  A. B. Tsybakov and V. Zaiats.  Introduction to nonparametric estimation, volume 11.  Springer, 2009.  W. Wang, L. Ying, and J. Zhang. On the relation between identifiability, di\ufb00erential privacy  and mutual-information privacy. arXiv preprint arXiv:1402.3757, 2014a.  Y. Wang, Z. Huang, S. Mitra, and G.E. Dullerud. Entropy-minimizing mechanism for In Decision and Control di\ufb00erential privacy of discrete-time linear feedback systems. (CDC), 2014 IEEE 53rd Annual Conference on, pages 2130-2135, Dec 2014b. doi: 10. 1109/CDC.2014.7039713.  S. L. Warner. Randomized response: A survey technique for eliminating evasive answer  bias. Journal of the American Statistical Association, 60(309):63-69, 1965. "}, "Loss Minimization and Parameter Estimation with Heavy Tails": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-273.html", "header": "Loss Minimization and Parameter Estimation with Heavy Tails", "author": "Daniel Hsu, Sivan Sabato", "time": "17(18):1\u221240, 2016.", "abstract": "This work studies applications and generalizations of a simple estimation technique that provides exponential concentration under heavy-tailed distributions, assuming only bounded low- order moments. We show that the technique can be used for approximate minimization of smooth and strongly convex losses, and specifically for least squares linear regression. For instance, our $d$-dimensional estimator requires just $\\tilde{O}(d\\log(1/\\delta))$ random samples to obtain a constant factor approximation to the optimal least squares loss with probability $1-\\delta$, without requiring the covariates or noise to be bounded or subgaussian. We provide further applications to sparse linear regression and low-rank covariance matrix estimation with similar allowances on the noise and covariate distributions. The core technique is a generalization of the median-of-means estimator to arbitrary metric spaces.", "pdf_url": "http://jmlr.org/papers/volume17/14-273/14-273.pdf", "keywords": ["Heavy-tailed distributions", "unbounded losses", "linear regression", "least squares"], "reference": "Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the  frequency moments. Journal of Computer and System Sciences, 58:137-147, 1999.  Jean-Yves Audibert and Olivier Catoni. Robust linear least squares regression. Ann. Stat.,  39(5):2766-2794, 2011.  Alexandre Belloni and Victor Chernozhukov.  l1-penalized quantile regression in high-  dimensional sparse models. The Annals of Statistics, 39(1):82-130, 2011.  Peter J Bickel, Yaacov Ritov, and Alexandre B Tsybakov. Simultaneous analysis of lasso  and dantzig selector. The Annals of Statistics, 37(4):1705-1732, 2009.  Leo Breiman. Bagging predictors. Machine learning, 24(2):123-140, 1996.  C. Brownlees, E. Joly, and G. Lugosi. Empirical risk minimization for heavy-tailed losses.  ArXiv e-prints, June 2014.  S. Bubeck, N. Cesa-Bianchi, and G. Lugosi. Bandits with heavy tail. IEEE Transactions  on Information Theory, 59:7711-7717, 2013.  Olivier Catoni. Challenging the empirical mean and empirical variance: a deviation study.  Ann. Inst. H. Poincar Probab. Statist., 48(4):1148-1185, 2012.  A Chatterjee and SN Lahiri. Rates of convergence of the adaptive lasso estimators to the oracle distribution and higher order refinements by the bootstrap. The Annals of Statistics, 41(3):1232-1259, 2013.  Samprit Chatterjee and Ali S Hadi.  In\ufb02uential observations, high leverage points, and  outliers in linear regression. Statistical Science, 1(3):379-393, 1986.  Bradley Efron. Bootstrap methods: another look at the jackknife. The annals of Statistics,  pages 1-26, 1979.  Jianqing Fan, Yingying Fan, and Emre Barut. Adaptive robust variable selection. arXiv  preprint arXiv:1205.4795, 2012.  38   Hsu and Sabato  Therefore (cid:107)\u03b4[s](cid:107)2 \u2264 3\u03bb  s  \u221a \u03b32 . Now,  (cid:107)\u03b4(cid:107)2 = (cid:107)\u03b4[s]C (cid:107)2 + (cid:107)\u03b4[s](cid:107)2 \u2264  (cid:107)\u03b4[s]C (cid:107)1(cid:107)\u03b4[s]C (cid:107)\u221e + (cid:107)\u03b4[s](cid:107)2.  (cid:113)  From \u03b4 \u2208 Es we get (cid:107)\u03b4[s]C (cid:107)1 \u2264 3(cid:107)\u03b4[s](cid:107)1. In addition, since \u03b4[s] spans the largest coor- dinates of \u03b4 in absolute value, (cid:107)\u03b4[s]C (cid:107)\u221e \u2264 (cid:107)\u03b4[s](cid:107)1/s. Combining these with the inequality above we get  (cid:107)\u03b4(cid:107)2 \u2264 3(cid:107)\u03b4[s](cid:107)1/  s + (cid:107)\u03b4[s](cid:107)2 \u2264 4(cid:107)\u03b4[s](cid:107)2 \u2264  \u221a  \u221a  s  .  12\u03bb \u03b32  References  Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the  frequency moments. Journal of Computer and System Sciences, 58:137-147, 1999.  Jean-Yves Audibert and Olivier Catoni. Robust linear least squares regression. Ann. Stat.,  39(5):2766-2794, 2011.  Alexandre Belloni and Victor Chernozhukov.  l1-penalized quantile regression in high-  dimensional sparse models. The Annals of Statistics, 39(1):82-130, 2011.  Peter J Bickel, Yaacov Ritov, and Alexandre B Tsybakov. Simultaneous analysis of lasso  and dantzig selector. The Annals of Statistics, 37(4):1705-1732, 2009.  Leo Breiman. Bagging predictors. Machine learning, 24(2):123-140, 1996.  C. Brownlees, E. Joly, and G. Lugosi. Empirical risk minimization for heavy-tailed losses.  ArXiv e-prints, June 2014.  S. Bubeck, N. Cesa-Bianchi, and G. Lugosi. Bandits with heavy tail. IEEE Transactions  on Information Theory, 59:7711-7717, 2013.  Olivier Catoni. Challenging the empirical mean and empirical variance: a deviation study.  Ann. Inst. H. Poincar Probab. Statist., 48(4):1148-1185, 2012.  A Chatterjee and SN Lahiri. Rates of convergence of the adaptive lasso estimators to the oracle distribution and higher order refinements by the bootstrap. The Annals of Statistics, 41(3):1232-1259, 2013.  Samprit Chatterjee and Ali S Hadi.  In\ufb02uential observations, high leverage points, and  outliers in linear regression. Statistical Science, 1(3):379-393, 1986.  Bradley Efron. Bootstrap methods: another look at the jackknife. The annals of Statistics,  pages 1-26, 1979.  Jianqing Fan, Yingying Fan, and Emre Barut. Adaptive robust variable selection. arXiv  preprint arXiv:1205.4795, 2012. Loss minimization and parameter estimation with heavy tails  Daniel Hsu and Sivan Sabato. Approximate loss minimization with heavy tails. CoRR,  abs/1307.1827, 2013. URL http://arxiv.org/abs/1307.1827.  Daniel Hsu and Sivan Sabato. Heavy-tailed regression with a generalized median-of-means.  In Thirty-First International Conference on Machine Learning, 2014.  Daniel Hsu, Sham M. Kakade, and Tong Zhang. Random design analysis of ridge regression.  Foundations of Computational Mathematics, 14(3):569-600, 2014.  P. J. Huber. Robust Statistics. Wiley, 1981.  Anatoli Juditsky and Arkadii S. Nemirovski. Large deviations of vector-valued martingales  in 2-smooth normed spaces. ArXiv e-prints, 0809.0813, 2008.  Matti K\u00a8a\u00a8ari\u00a8ainen. Generalization error bounds using unlabeled data. In Learning Theory,  pages 127-142. Springer, 2005.  V. Koltchinskii, K. Lounici, and A. B. Tsybakov. Nuclear norm penalization and optimal rates for noisy low rank matrix completion. Annals of Statistics, 39(5):2302-2329, 2011.  Casimir Kuratowski. Quelques probl`emes concernant les espaces m\u00b4etriques non-s\u00b4eparables.  Fundamenta Mathematicae, 25(1):534-545, 1935.  O. V. Lepski. Asymptotically minimax adaptive estimation I: Upper bounds. optimally  adaptive estimates. Theory Probab. Appl., 36(4):682-697, 1991.  M. Lerasle and R. I. Oliveira. Robust empirical mean Estimators. ArXiv e-prints, December  2011.  Leonid A. Levin. Notes for miscellaneous lectures. CoRR, abs/cs/0503039, 2005.  Alexander E. Litvak, Alain Pajor, Mark Rudelson, and Nicole Tomczak-Jaegermann. Smallest singular value of random matrices and geometry of random polytopes. Adv. Math., 195(2):491-523, 2005. ISSN 0001-8708. doi: 10.1016/j.aim.2004.08.004. URL http://dx.doi.org/10.1016/j.aim.2004.08.004.  Mehrdad Mahdavi and Rong Jin. Passive learning with target risk. In Twenty-Sixth Con-  ference on Learning Theory, 2013.  S. Mendelson. Learning without Concentration. ArXiv e-prints, January 2014.  Stanislav Minsker. Geometric median and robust estimation in banach spaces. arXiv  preprint arXiv:1308.1334, 2013.  A. S. Nemirovsky and D. B. Yudin. Problem Complexity and Method E\ufb03ciency in Opti-  mization. Wiley-Interscience, 1983.  M. Nussbaum. Minimax risk: Pinsker bound. In S. Kotz, editor, Encyclopedia of Statistical  Sciences, Update Volume 3, pages 451-460. Wiley, New York, 1999.  Roberto Oliveira. Sums of random Hermitian matrices and an inequality by Rudelson.  Electron. Commun. Probab., 15(19):203-212, 2010. Hsu and Sabato  Alexander Rakhlin, Karthik Sridharan, and Alexandre B. Tsybakov. Empirical entropy,  minimax regret and minimax risk. arXiv preprint arXiv:1308.1147, 2013.  O. Shamir. The Sample Complexity of Learning Linear Predictors with the Squared Loss.  ArXiv e-prints, June 2014.  Nathan Srebro, Karthik Sridharan, and Ambuj Tewari. Smoothness, low noise and fast  rates. In Advances in Neural Information Processing Systems 23, 2010.  N. Srivastava and R. Vershynin. Covariance estimation for distributions with 2+(cid:15) moments.  Annals of Probability, 41:3081-3111, 2013.  Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal  Statistical Society. Series B (Methodological), pages 267-288, 1996.  Sara van de Geer and Patric M\u00a8uller. Quasi-likelihood and/or robust estimation in high  dimensions. Statistical Science, 27(4):469-480, 2012.  Hansheng Wang, Guodong Li, and Guohua Jiang. Robust regression shrinkage and consis- tent variable selection through the lad-lasso. Journal of Business & Economic Statistics, 25(3):347-355, 2007.  Lie Wang. L1 penalized lad estimator for high dimensional linear regression. Journal of  Multivariate Analysis, 2013.  J. Wolfowitz. Minimax estimates of the mean of a normal distribution with known variance.  The Annals of Mathematical Statistics, 21:218-230, 1950.  Yichao Wu and Yufeng Liu. Variable selection in quantile regression. Statistica Sinica, 19  (2):801, 2009.  Tong Zhang. Some sharp performance bounds for least squares regression with l1 regular-  ization. The Annals of Statistics, 37(5A):2109-2144, 2009.  Yuchen Zhang, John C Duchi, and Martin J Wainwright. Divide and conquer kernel ridge regression: A distributed algorithm with minimax optimal rates. arXiv preprint arXiv:1305.5029, 2013.  Shuheng Zhou. Restricted eigenvalue conditions on subgaussian random matrices. arXiv  preprint arXiv:0912.4045, 2009.  Hui Zou. The adaptive lasso and its oracle properties. Journal of the American statistical  association, 101(476):1418-1429, 2006.  Hui Zou and Ming Yuan. Composite quantile regression and the oracle model selection  theory. The Annals of Statistics, 36(3):1108-1126, 2008. "}, "Analysis of Classification-based Policy Iteration Algorithms": {"volumn": 17, "url": "http://jmlr.org/papers/v17/10-364.html", "header": "Analysis of Classification-based Policy Iteration Algorithms", "author": "Alessandro Lazaric, Mohammad Ghavamzadeh, R{\\'e}mi Munos", "time": "17(19):1\u221230, 2016.", "abstract": "We introduce a variant of the classification-based approach to policy iteration which uses a cost-sensitive loss function weighting each classification mistake by its actual  regret , that is, the difference between the action- value of the greedy action and of the action chosen by the classifier. For this algorithm, we provide a full finite-sample analysis. Our results state a performance bound in terms of the number of policy improvement steps, the number of rollouts used in each iteration, the capacity of the considered policy space (classifier), and a capacity measure which indicates how well the policy space can approximate policies that are greedy with respect to any of its members. The analysis reveals a tradeoff between the estimation and approximation errors in this classification-based policy iteration setting. Furthermore it confirms the intuition that classification-based policy iteration algorithms could be favorably compared to value-based approaches when the policies can be approximated more easily than their corresponding value functions. We also study the consistency of the algorithm when there exists a sequence of policy spaces with increasing capacity.", "pdf_url": "http://jmlr.org/papers/volume17/10-364/10-364.pdf", "keywords": ["policy iteration", "finite-sample analysis."], "reference": "A. Antos, Cs. Szepesv\u00b4ari, and R. Munos. Learning near-optimal policies with Bellman- residual minimization based fitted policy iteration and a single sample path. Machine Learning Journal, 71:89-129, 2008.  B. \u00b4Avila Pires, M. Ghavamzadeh, and Cs. Szepesv\u00b4ari. Cost-sensitive multiclass classifica- tion risk bounds. In Proceedings of the Thirtieth International Conference on Machine Learning, pages 1391-1399, 2013.  J. Bagnell, S. Kakade, A. Ng, and J. Schneider. Policy search by dynamic programming. In Proceedings of Advances in Neural Information Processing Systems 16. MIT Press, 2003.  S. Ben-David, N. Cesa-Bianchi, D. Haussler, and P. M. Long. Characterizations of learn- -valued functions. Journal of Computer and System Sciences, 0...n }  {  ability for classes of 50:74-86, 1995.  A. Beygelzimer, V. Dani, T. Hayes, J. Langford, and B. Zadrozny. Error limiting reduc- In Proceedings of the Twenty-Second International  tions between classification tasks. Conference on Machine Learning, pages 49-56, 2005.  Alina Beygelzimer, John Langford, and Pradeep Ravikumar. Error-correcting tournaments. In Proceedings of the 20th International Conference on Algorithmic Learning Theory, pages 247-262, 2009.  S. Bradtke and A. Barto. Linear least-squares algorithms for temporal di\ufb00erence learning.  Journal of Machine Learning, 22:33-57, 1996.  27  (cid:54)  Analysis of Classification-based Policy Iteration Algorithms  We now show how the covering number of the space k is related to the VC-dimension of \u03a0. Let \u00af\u03a0 be an (cid:15) -cover of \u03a0 using the empirical distance defined at the 2(1\u2212\u03b3H )Qmax \u00afR\u03c0k ( i=1, then \u00af N ) = R\u03c0k ( xi states ; \u00af\u03c0) k = } \u00b7 \u00b7 { H \u00af k, there exist a \u00afR\u03c0k R\u03c0k k such that H  k. In fact for any  is an (cid:15)-cover of  { \u2208 H  \u00af\u03c0 |  \u00af\u03a0  H  H  \u2208  \u2208  }  1 M N  i,j  (cid:88)  (cid:12) (cid:12)R\u03c0k (\u03c9ij)  \u00afR\u03c0k (\u03c9ij)  (cid:12) (cid:12) =  \u2212  1 M N  N (cid:88)  M (cid:88)  i=1  j=1  (cid:12) (cid:12)R\u03c0k j  (cid:0)xi, \u03c0(xi)(cid:1)  R\u03c0k j  (cid:0)xi, \u00af\u03c0(xi)(cid:1)(cid:12) (cid:12)  \u2212  2(1  \u2264  \u2212  \u03b3H )Qmax  \u03c0(xi)  = \u00af\u03c0(xi)  2(1  } \u2264  \u2212  \u03b3H )Qmax  1 N  N (cid:88)  I  i=1  {  (cid:15) \u03b3H )Qmax  = (cid:15).  2(1  \u2212  We can now relate the covering number of  k to the VC-dimension of \u03a0  F  (cid:16) (cid:15) 8  ,  FN  (cid:17)  k, \u03c9M N 1  (cid:18)  1 \u2264 N  16(1  \u2212  (cid:15) \u03b3H )Qmax  , \u03a0, \u03c9M N 1  (cid:19)  \u2264  S\u03a0(M N )  (cid:18) eM N h  (cid:19)h  ,  \u2264  where S\u03a0(N ) is the growth function of \u03a0 and the last inequality follows from the Sauer\u2019s lemma. The final statement is obtained by inverting the Pollard\u2019s bound.  References  A. Antos, Cs. Szepesv\u00b4ari, and R. Munos. Learning near-optimal policies with Bellman- residual minimization based fitted policy iteration and a single sample path. Machine Learning Journal, 71:89-129, 2008.  B. \u00b4Avila Pires, M. Ghavamzadeh, and Cs. Szepesv\u00b4ari. Cost-sensitive multiclass classifica- tion risk bounds. In Proceedings of the Thirtieth International Conference on Machine Learning, pages 1391-1399, 2013.  J. Bagnell, S. Kakade, A. Ng, and J. Schneider. Policy search by dynamic programming. In Proceedings of Advances in Neural Information Processing Systems 16. MIT Press, 2003.  S. Ben-David, N. Cesa-Bianchi, D. Haussler, and P. M. Long. Characterizations of learn- -valued functions. Journal of Computer and System Sciences, 0...n }  {  ability for classes of 50:74-86, 1995.  A. Beygelzimer, V. Dani, T. Hayes, J. Langford, and B. Zadrozny. Error limiting reduc- In Proceedings of the Twenty-Second International  tions between classification tasks. Conference on Machine Learning, pages 49-56, 2005.  Alina Beygelzimer, John Langford, and Pradeep Ravikumar. Error-correcting tournaments. In Proceedings of the 20th International Conference on Algorithmic Learning Theory, pages 247-262, 2009.  S. Bradtke and A. Barto. Linear least-squares algorithms for temporal di\ufb00erence learning.  Journal of Machine Learning, 22:33-57, 1996.(cid:54)  Lazaric, Ghavamzadeh, and Munos  R. Busa-Fekete and B. K\u00b4egl. Fast boosting using adversarial bandits. In Proceedings of the Twenty-Seventh International Conference on Machine Learning, pages 49-56, 2010.  L. Devroye, L. Gy\u00a8orfi, and G. Lugosi. A Probabilistic Theory of Pattern Recognition.  Springer-Verlag, 1996.  imate policy iteration. Springer, 2008a.  C. Dimitrakakis and M. Lagoudakis. Algorithms and bounds for sampling-based approx- In Recent Advances in Reinforcement Learning (EWRL-2008).  C. Dimitrakakis and M. Lagoudakis. Rollout sampling approximate policy iteration. Ma-  chine Learning Journal, 72(3):157-171, 2008b.  A. M. Farahmand, R. Munos, and Cs. Szepesv\u00b4ari. Error propagation for approximate policy  and value iteration. In Advances in Neural Information Processing Systems, 2010.  A. M. Farahmand, D. Precup, A. Barreto, and M. Ghavamzadeh. CAPI: Generalized classification-based approximate policy iteration. In Proceedings of the Multidisciplinary Conference on Reinforcement Learning and Decision Making, 2013.  A. Fern, S. Yoon, and R. Givan. Approximate policy iteration with a policy language bias.  In Proceedings of Advances in Neural Information Processing Systems 16, 2004.  A. Fern, S. Yoon, and R. Givan. Approximate policy iteration with a policy language bias: Solving relational Markov decision processes. Journal of Artificial Intelligence Research, 25:85-118, 2006.  V. Gabillon, A. Lazaric, and M. Ghavamzadeh.  Rollout allocation strategies for classification-based policy iteration. In ICML Workshop on Reinforcement Learning and Search in Very Large Spaces, 2010.  V. Gabillon, A. Lazaric, M. Ghavamzadeh, and B. Scherrer. Classification-based policy iteration with a critic. In Proceedings of the Twenty-Eighth International Conference on Machine Learning, pages 1049-1056, 2011.  V. Gabillon, M. Ghavamzadeh, and B. Scherrer. Approximate dynamic programming finally performs well in the game of Tetris. In Proceedings of Advances in Neural Information Processing Systems 26, pages 1754-1762, 2013.  M. Ghavamzadeh and A. Lazaric. Conservative and greedy approaches to classification- based policy iteration. In Proceedings of the Twenty-Sixth Conference on Artificial Intel- ligence, pages 914-920, 2012.  L. Gy\u00a8orfi, M. Kohler, A. Krzyzak, and H. Walk. A distribution-free theory of nonparametric  regression. Springer, New York, Berlin, Paris, 2002.  D. Haussler. Sphere packing numbers for subsets of the boolean n-cube with bounded Vapnik-Chervonenkis dimension. Journal of Combinatorial Theory, Series A, 69(2):217- 232, 1995. Analysis of Classification-based Policy Iteration Algorithms  R. Howard. Dynamic Programming and Markov Processes. The MIT Press, Cambridge,  MA, 1960.  S. Kakade. On the Sample Complexity of Reinforcement Learning. PhD thesis, Gatsby  Computational Neuroscience Unit., University College London, 2003.  S. Kakade and J. Langford. Approximately optimal approximate reinforcement learning. In Proceedings of the Nineteenth International Conference on Machine Learning, pages 267-274, 2002.  M. Lagoudakis and R. Parr. Least-squares policy iteration. Journal of Machine Learning  Research, 4:1107-1149, 2003a.  M. Lagoudakis and R. Parr. Reinforcement learning as classification: Leveraging modern classifiers. In Proceedings of the Twentieth International Conference on Machine Learn- ing, pages 424-431, 2003b.  J. Langford and B. Zadrozny. Relating reinforcement learning performance to classification performance. In Proceedings of the Twenty-Second international conference on Machine learning, pages 473-480, 2005.  A. Lazaric, M. Ghavamzadeh, and R. Munos. Analysis of a classification-based policy iteration algorithm. In Proceedings of the Twenty-Seventh International Conference on Machine Learning, pages 607-614, 2010.  A. Lazaric, M. Ghavamzadeh, and R. Munos. Finite-sample analysis of least-squares policy  iteration. Journal of Machine Learning Research, 13:3041-3074, 2012.  L. Li, V. Bulitko, and R. Greiner. Focus of attention in reinforcement learning. Journal of  Universal Computer Science, 13(9):1246-1269, 2007.  A. Lozano and N. Abe. Multi-class cost-sensitive boosting with p-norm loss functions. In Proceeding of the Fourteenth ACM SIGKDD International Conference on Knowledge discovery and data mining, pages 506-514, 2008.  P. Mineiro.  class http://www.machinedlearnings.com/2010/08/error-and-regret-bounds-for-cost.html.  classification  Error  and reduction  regret to  bounds regression,  for  cost-sensitive multi- URL 2010.  R. Munos. Performance bounds in Lp norm for approximate value iteration. SIAM Journal  of Control and Optimization, 2007.  R. Munos and Cs. Szepesv\u00b4ari. Finite time bounds for fitted value iteration. Journal of  Machine Learning Research, 9:815-857, 2008.  D. Pollard. Convergence of Stochastic Processes. Springer-Verlag, 1984.  B. Scherrer, M. Ghavamzadeh, V. Gabillon, and M. Geist. Approximate modified pol- icy iteration. In Proceedings of the Twenty-Ninth International Conference on Machine Learning, pages 1207-1214, 2012. Lazaric, Ghavamzadeh, and Munos  H. Tu and H. Lin. One-sided support vector regression for multiclass cost-sensitive clas- sification. In Proceedings of the Twenty-Seventh International Conference on Machine learning, pages 49-56, 2010.  V. Vapnik. Statistical Learning Theory. John Wiley, 1998.  B. Zadrozny, J. Langford, and N. Abe. Cost-sensitive learning by cost-proportionate ex- ample weighting. In Proceedings of the Third IEEE International Conference on Data Mining, page 435, 2003. "}, "Operator-valued Kernels for Learning from Functional Response Data": {"volumn": 17, "url": "http://jmlr.org/papers/v17/11-315.html", "header": "Operator-valued Kernels for Learning from Functional Response Data", "author": "Hachem Kadri, Emmanuel Duflos, Philippe Preux, St\u00c3\u00a9phane Canu, Alain Rakotomamonjy, Julien Audiffren", "time": "17(20):1\u221254, 2016.", "abstract": "In this paper (This is a combined and expanded version of previous conference papers Kadri et al., 2010, 2011c) we consider the problems of supervised classification and regression in the case where attributes and labels are functions: a data is represented by a set of functions, and the label is also a function. We focus on the use of reproducing kernel Hilbert space theory to learn from such functional data. Basic concepts and properties of kernel-based learning are extended to include the estimation of function-valued functions. In this setting, the representer theorem is restated, a set of rigorously defined infinite-dimensional operator-valued kernels that can be valuably applied when the data are functions is described, and a learning algorithm for nonlinear functional data analysis is introduced. The methodology is illustrated through speech and audio signal processing experiments.", "pdf_url": "http://jmlr.org/papers/volume17/11-315/11-315.pdf", "keywords": ["nonlinear functional data analysis", "operator-valued kernels", "function-valued reproducing kernel Hilbert spaces", "audio signal processing"], "reference": "J. Abernethy, F. Bach, T. Evgeniou, and J. P. Vert. A new approach to collaborative filtering: operator estimation with spectral regularization. Journal of Machine Learning Research, 10:803-826, 2009.  D. Alpay, A. Dijksma, J. Rovnyak, and H. de Snoo. Schur Functions, Operator Colligations, and Reproducing Kernel Pontryagin Spaces, volume 96 of Operator theory: Advances and Applications. Birkh\u00a8auser Verlag, 1997.  M. A. \u00b4Alvarez, L. Rosasco, and N. D. Lawrence. Kernels for vector-valued functions: a  review. Foundation and Trends in Machine Learning, 4(3):195-266, 2012.  R. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks  and unlabeled data. Journal of Machine Learning Research, 6:1817-1853, 2005.  A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Machine  Learning, 73(3):243-272, 2008.  Society, 68:337-404, 1950.  N. Aronszajn. Theory of reproducing kernels. Transactions of the American Mathematical  A. Asif and J. Moura. Block matrices with L-block-banded inverse: inversion algorithms.  IEEE Transactions on Signal Processing, 53(2):630-642, February 2005.  J. Audi\ufb00ren and H. Kadri. Stability of multi-task kernel regression algorithms. In Asian  Conference on Machine Learning (ACML), volume 29, pages 1-16, 2013.  J. Audi\ufb00ren and H. Kadri. Online learning with operator-valued kernels.  In European  symposium on artificial neural networks (ESANN), 2015.  L. Baldassarre, L. Rosasco, A. Barla, and A. Verri. Multi-output learning via spectral  filtering. Machine Learning, 87(3):259-301, 2012.  Jonathan Baxter. A model of inductive bias learning. Journal of Artificial Intelligence  Research, 12:149-198, 2000.  S. Ben-david and R. Schuller-Borbely. A notion of task relatedness yielding provable  multiple-task learning guarantees. Machine Learning, 73:273-287, 2008.  P. Birkholz, B. J. Kr\u00a8oger, and C. Neuschaefer-Rube. Articulatory synthesis and perception of plosive-vowel syllables with virtual consonant targets. In Interspeech, pages 1017-1020. ISCA, 2010.  O. Bousquet and A. Elissee\ufb00. Stability and generalization. Journal of Machine Learning  Research, 2:499-526, 2002.  L. Breiman and J. Friedman. Predicting multivariate responses in multiple linear regression.  Journal of the Royal Statistical Society, Series B, 59:3-54, 1997.  48   Kadri et al.  References  J. Abernethy, F. Bach, T. Evgeniou, and J. P. Vert. A new approach to collaborative filtering: operator estimation with spectral regularization. Journal of Machine Learning Research, 10:803-826, 2009.  D. Alpay, A. Dijksma, J. Rovnyak, and H. de Snoo. Schur Functions, Operator Colligations, and Reproducing Kernel Pontryagin Spaces, volume 96 of Operator theory: Advances and Applications. Birkh\u00a8auser Verlag, 1997.  M. A. \u00b4Alvarez, L. Rosasco, and N. D. Lawrence. Kernels for vector-valued functions: a  review. Foundation and Trends in Machine Learning, 4(3):195-266, 2012.  R. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks  and unlabeled data. Journal of Machine Learning Research, 6:1817-1853, 2005.  A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Machine  Learning, 73(3):243-272, 2008.  Society, 68:337-404, 1950.  N. Aronszajn. Theory of reproducing kernels. Transactions of the American Mathematical  A. Asif and J. Moura. Block matrices with L-block-banded inverse: inversion algorithms.  IEEE Transactions on Signal Processing, 53(2):630-642, February 2005.  J. Audi\ufb00ren and H. Kadri. Stability of multi-task kernel regression algorithms. In Asian  Conference on Machine Learning (ACML), volume 29, pages 1-16, 2013.  J. Audi\ufb00ren and H. Kadri. Online learning with operator-valued kernels.  In European  symposium on artificial neural networks (ESANN), 2015.  L. Baldassarre, L. Rosasco, A. Barla, and A. Verri. Multi-output learning via spectral  filtering. Machine Learning, 87(3):259-301, 2012.  Jonathan Baxter. A model of inductive bias learning. Journal of Artificial Intelligence  Research, 12:149-198, 2000.  S. Ben-david and R. Schuller-Borbely. A notion of task relatedness yielding provable  multiple-task learning guarantees. Machine Learning, 73:273-287, 2008.  P. Birkholz, B. J. Kr\u00a8oger, and C. Neuschaefer-Rube. Articulatory synthesis and perception of plosive-vowel syllables with virtual consonant targets. In Interspeech, pages 1017-1020. ISCA, 2010.  O. Bousquet and A. Elissee\ufb00. Stability and generalization. Journal of Machine Learning  Research, 2:499-526, 2002.  L. Breiman and J. Friedman. Predicting multivariate responses in multiple linear regression.  Journal of the Royal Statistical Society, Series B, 59:3-54, 1997. Operator-valued Kernels for Learning from Functional Response Data  C. Brouard, F. d\u2019Alch\u00b4e-Buc, and M. Szafranski. Semi-supervised penalized output kernel regression for link prediction. In International Conference on Machine Learning (ICML), 2011.  S. Canu, X. Mary, and A. Rakotomamonjy. Functional learning through kernel.  in Ad- vances in Learning Theory: Methods, Models and Applications. NATO Science Series III: Computer and Systems Sciences, 2003.  A. Caponnetto and E. De Vito. Optimal rates for the regularized least-squares algorithm.  Foundations of Computational Mathematics, 7(3):331-368, 2006.  A. Caponnetto, C. A. Micchelli, M. Pontil, and Y. Ying. Universal multi-task kernels.  Journal of Machine Learning Research, 68:1615-1646, 2008.  C. Carmeli, E. De Vito, and A. Toigo. Vector-valued reproducing kernel Hilbert spaces of integrable functions and Mercer theorem. Analysis and Applications, 4:377-408, 2006.  C. Carmeli, E. De Vito, and A. Toigo. Vector-valued reproducing kernel Hilbert spaces and  universality. Analysis and Applications, 8:19-61, 2010.  J. M. Chiou, H. G. M\u00a8uller, and J. L. Wang. Functional response models. Statistica Sinica,  14:675-693, 2004.  J. Dauxois, A. Pousse, and Y. Romain. Asymptotic theory for the principal component analysis of a vector random function: some applications to statistical inference. Journal of Multivariate Analysis, 12:136-154, 1982.  F. Dinuzzo, C. S. Ong, P. Gehler, and G. Pillonetto. Learning output kernels with block coordinate descent. In International Conference on Machine Learning (ICML), 2011.  A. Dufaux, L. Besacier, M. Ansorge, and F. Pellandini. Automatic sound detection and In European Signal Processing Conference (EU-  recognition for noisy environment. SIPCO), pages 1033-1036, 2000.  H. Dym. J Contractive Matrix Functions, Reproducing Kernel Spaces and Interpolation.  American Mathematical Society, 1989.  T. Evgeniou and M. Pontil. Regularized multi-task learning. In International Conference  on Knowledge Discovery and Data Mining (ACM SIGKDD), 2004.  T. Evgeniou, C. A. Micchelli, and M. Pontil. Learning multiple tasks with kernel methods.  Journal of Machine Learning Research, 6:615-637, 2005.  J. Faraway. Regression analysis for a functional response. Technometrics, 39(3):254-261,  1997.  F. Ferraty and P. Vieu. Curves discrimination: a nonparametric functional approach.  Computational Statistics & Data Analysis, 44(1-2):161-173, 2003. Kadri et al.  F. Ferraty and P. Vieu. Nonparametric models for functional data, with applications in regression, time series prediction and curves discrimination. Journal of Nonparametric Statistics, 16:111-125, 2004.  F. Ferraty and P. Vieu. Nonparametric Functional Data Analysis. Springer Verlag, 2006.  T. Hastie and R. Tibshirani. Varying-coe\ufb03cient models. Journal of the Royal Statistical  Society B, 55:757-796, 1993.  T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning. Springer,  2001.  2012.  T. C. Hesterberg, N. H. Choi, L. Meier, and C. Fraley. Least angle and (cid:96)1 penalized  regression: a review. Statistics Surveys, 2:61-93, 2008.  L. Horv\u00b4ath and P. Kokoszka. Inference for Functional Data with Applications. Springer,  D. Istrate, E. Castelli, M. Vacher, L. Besacier, and J. F. Serignat. Information extraction from sound for medical telemonitoring. IEEE Transactions on Information Technology in Biomedicine, 10:264-274, 2006.  G. James. Generalized linear models with functional predictors. Journal of the Royal  Statistical Society Series B, 64(3):411-432, 2002.  T. Jebara. Multi-task feature and kernel selection for SVMs. In International Conference  on Machine Learning (ICML), 2004.  H. Kadri, E. Du\ufb02os, Ph. Preux, S. Canu, and M. Davy. Nonlinear functional regression: a functional RKHS approach. In International Conference on Artificial Intelligence and Statistics (AISTATS), pages 111-125, 2010.  H. Kadri, E. Du\ufb02os, and Ph. Preux. Learning vocal tract variables with multi-task kernels. In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2011a.  H. Kadri, E. Du\ufb02os, Ph. Preux, and S. Canu. Multiple functional regression with both discrete and continuous covariates. In International Workshop on Functional and Oper- atorial Statistics (IWFOS). Springer, 2011b.  H. Kadri, A. Rabaoui, Ph. Preux, E. Du\ufb02os, and A. Rakotomamonjy. Functional regularized least squares classification with operator-valued kernels. In International Conference on Machine Learning (ICML), pages 993-1000, 2011c.  H. Kadri, A. Rakotomamonjy, F. Bach, and Ph. Preux. Multiple operator-valued kernel  learning. In Advances in Neural Information Processing Systems (NIPS), 2012.  H. Kadri, S. Ayache, C. Capponi, S. Ko\u00b8co, F. X. Dup\u00b4e, and E. Morvant. The multi-task learning view of multimodal data. In Asian Conference on Machine Learning (ACML), pages 261-276, 2013a. Operator-valued Kernels for Learning from Functional Response Data  H. Kadri, M. Ghavamzadeh, and Ph. Preux. A generalized kernel approach to structured  output learning. In International Conference on Machine Learning (ICML), 2013b.  K. Kircho\ufb00. Robust Speech Recognition Using Articulatory Information. PhD thesis, Uni-  versity of Bielefeld, 1999.  A. Kurdila and M. Zabarankin. Convex Functional Analysis. Birkhauser Verlag, 2005.  Leonardo Software. http://www.leonardosoft.com.  D. J. Levitin, R. L. Nuzzo, B. W. Vines, and J. O. Ramsay. Introduction to functional data  analysis. Canadian Psychology, 48(3):135-155, 2007.  H. Lian. Nonlinear functional models for functional responses in reproducing kernel Hilbert  spaces. The Canadian Journal of Statistics, 35:597-606, 2007.  N. Lim, Y. Senbabaoglu, G. Michailidis, and F. d\u2019Alch\u00b4e-Buc. OKVAR-Boost: a novel boost- ing algorithm to infer nonlinear dynamics and interactions in gene regulatory networks. Bioinformatics, 29(11):1416-1423, 2013.  N. Lim, F. d\u2019Alch\u00b4e-Buc, C. Auliac, and G. Michailidis. Operator-valued kernel-based vector autoregressive models for network inference. Machine Learning, 99(3):489-513, 2015.  A. Maurer. Bounds for linear multi-task learning. Journal of Machine Learning Research,  7:117-139, 2006.  A. Maurer and M. Pontil. Excess risk bounds for multitask learning with trace norm  regularization. In Conference on Learning Theory (COLT), pages 55-76, 2013.  C. A. Micchelli and M. Pontil. On learning vector-valued functions. Neural Computation,  17:177-204, 2005a.  C. A. Micchelli and M. Pontil. Kernels for multi-task learning. Information Processing Systems (NIPS), pages 921-928, 2005b.  In Advances in Neural  H. Q. Minh and V. Sindhwani. Vector-valued manifold regularization.  In International  Conference on Machine Learning (ICML), 2011.  H. Q. Minh, S. H. Kang, and T. M. Le. Image and video colorization using vector-valued reproducing kernel Hilbert spaces. Journal of Mathematical Imaging and Vision, 37(1): 49-65, 2010.  H. Q. Minh, L. Bazzani, and V. Murino. A unifying framework for vector-valued man- In International Conference on Machine  ifold regularization and multi-view learning. Learning (ICML), 2013.  V. Mitra, Y. Ozbek, H. Nam, X. Zhou, and C. Y. Espy-Wilson. From acoustics to vocal tract time functions. In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 4497-4500, 2009. Kadri et al.  V. Mitra, H. Nam, C. Espy-Wilson, E. Saltzman, and L. Goldstein. Retrieving tract vari- ables from acoustics: a comparison of di\ufb00erent machine learning strategies. IEEE Journal of Selected Topics in Signal Processing, pages 1027-1045, 2010.  K. Muandet, K. Fukumizu, F. Dinuzzo, and B. Sch\u00a8olkopf. Learning from distributions In Advances in Neural Information Processing Sys-  via support measure machines. tems (NIPS), pages 10-18, 2012.  H. G. M\u00a8uller. Functional modeling and classification of longitudinal data. Scandinavian  Journal of Statistics, 32:223-240, 2005.  H. Nam, L. Goldstein, E. Saltzman, and D. Byrd. TADA: an enhanced, portable task dynamics model in MATLAB. Journal of the Acoustical Society of America, 115:2430, 2004.  A. W. Naylor and G. R. Sell. Linear Operator Theory in Engineering and Science. Holt,  Rinehart and Winston, Inc., New York, 1971.  J. Oliva, B. Poczos, and J. Schneider. Distribution to distribution regression. In Interna-  tional Conference on Machine Learning (ICML), 2013.  V. Peltonen, J. Tuomi, A. Klapuri, J. Huopaniemi, and T. Sorsa. Computational audiroty scene recognition. In International Conference on Acoustics, Speech and Signal Process- ing (ICASSP), 2002.  B. Poczos, L. Xiong, D. Sutherland, and J. Schneider. Support distribution machines.  Technical report, Carnegie Mellon University, Pittsburgh, PA, USA, 2012.  B. Poczos, A. Rinaldo, A. Singh, and L. Wasserman. Distribution-free distribution regres- In International Conference on Artificial Intelligence and Statistics (AISTATS),  sion. pages 507-515, 2013.  L. Prchal and P. Sarda. Spline estimator for the functional linear regression with functional  response. Preprint, 2007.  C. Preda. Regression models for functional data by reproducing kernel Hilbert spaces  methods. Journal of Statistical Planning and Inference, 137:829-840, 2007.  A. Rabaoui, M. Davy, S. Rossignol, and N. Ellouze. Using one-class SVMs and wavelets for audio surveillance. IEEE Transactions on Information Forensics and Security, 3(4): 763-775, 2008.  J. O. Ramsay. When the data are functions. Psychometrika, 47:379-396, 1982.  J. O. Ramsay and J. L. Dalzell. Some tools for functional data analysis. Journal of the  Royal Statistical Society, B(53):539-572, 1991.  J. O. Ramsay and B. W. Silverman. Applied Functional Data Analysis. Springer Verlag,  New York, 2002. Operator-valued Kernels for Learning from Functional Response Data  J. O. Ramsay and B. W. Silverman. Functional Data Analysis, 2nd ed. Springer Verlag,  New York, 2005.  Real World Computing Paternship. Cd-sound scene database in real acoustical environ-  ments, 2000. URL http://tosa.mri.co.jp/sounddb/indexe.htm.  M. Reisert and H. Burkhardt. Learning equivariant functions with matrix-valued kernels.  Journal of Machine Learning Research, 8:385-408, 2007.  J. A. Rice. Functional and longitudinal data analysis: perspectives on smoothing. Statistica  Sinica, 14:613-629, 2004.  J. A. Rice and B. W. Silverman. Estimating the mean and covariance structure nonpara- metrically when the data are curves. Journal of the Royal Statistical Society. Series B, 53(1):233-243, 1991.  K. Richmond. Estimating Articulatory Parameters from the Acoustic Speech Signal. PhD  thesis, The Center for Speech Technology Research, Edinburgh University, 2002.  K. Richmond. A multitask learning perspective on acoustic-articulatory inversion. In In-  terspeech. ISCA, 2007.  R. Rifkin and A. Klautau.  In defense of one-vs-all classification. Journal of Machine  Learning Research, 5:101-141, 2004.  R. Rifkin, G. Yeo, and T. Poggio. Regularized least squares classification. Advances in Learning Theory: Methods, Model and Applications NATO Science Series III: Computer and Systems Sciences, 190:131-153, 2003.  F. Rossi and N. Villa. Support vector machine for functional data classification. Neurocom-  puting, 69(7-9):730-742, 2006.  W. Rudin. Functional Analysis. McGraw-Hill Science, 1991.  B. Sch\u00a8olkopf and A. J. Smola. Learning with Kernels: Support Vector Machines, Regular-  ization, Optimization, and Beyond. MIT Press, Cambridge, MA, USA, 2002.  B. Sch\u00a8olkopf, S. Mika, C. J. C. Burges, P. Knirsch, K. R. M\u00a8uller, G. R\u00a8atsch, and A. J. Smola. Input space vs. feature space in kernel-based methods. IEEE Transactions on Neural Networks, 10(5):1000-1017, 1999.  J. Schroeter and M. M. Sondhi. Techniques for estimating vocal-tract shapes from the speech signal. IEEE Transactions on Speech and Audio Processing, 2:133-150, 1994.  L. Schwartz.  Sous-espaces hilbertiens d\u2019espaces vectoriels topologiques et noyaux as-  soci\u00b4es (noyaux reproduisants). Journal d\u2019Analyse Math\u00b4ematique, 13:115-256, 1964.  E. Senkene and A. Tempel\u2019man. Hilbert spaces of operator-valued functions. Lithuanian  Mathematical Journal, 1973. Kadri et al.  J. Shawe-Taylor and N. Cristanini. Kernel Methods for Pattern Analysis. Cambridge Uni-  versity Press, 2004.  Press, 2011.  J. Q. Shi and T. Choi. Gaussian Process Regression Analysis for Functional Data. CRC  T. Simila and J. Tikka. Input selection and shrinkage in multiresponse linear regression.  Computational Statistics and Data Analysis, 52:406-422, 2007.  V. Sindhwani, H. Q. Minh, and A. C. Lozano. Scalable matrix-valued kernel learning for high-dimensional nonlinear multivariate regression and granger causality. In Uncertainty in Artificial Intelligence (UAI), 2013.  A. Smola, A. Gretton, L. Song, and B. Sch\u00a8olkopf. A Hilbert space embedding for distribu-  tions. In Algorithmic Learning Theory (ALT), pages 13-31, 2007.  B. Sriperumbudur, A. Gretton, K. Fukumizu, G. Lanckriet, and B. Sch\u00a8olkopf. Hilbert space embeddings and metrics on probability measures. Journal of Machine Learning Research, 11:1517-1561, 2010.  S. Szedmak, J. Shawe-Taylor, and E. Parado-Hernandez. Learning via linear operators: maximum margin regression; multiclass and multiview learning at one-class complexity. Technical report, PASCAL, Southampton, UK, 2006. URL http://arxiv.org/pdf/ 1106.6251v1.  T. Toda, A. W. Black, and K. Tokuda. Mapping from articulatory movements to vocal tract spectrum with gaussian mixture model for articulatory speech synthesis. In ISCA Speech Synthesis Workshop, 2004.  A. Toutios and K. Margaritis. A support vector approach to the acoustic-to-articulatory  mapping. In Interspeech, pages 3221-3224. ISCA, 2005.  C. Tretter. Spectral theory of block operator matrices and applications. Imperial College  Press, London, 2008.  metrics, 47:349-363, 2005.  Mathematics (SIAM), 1990.  user\u2019s handbook, 1994.  B. A. Turlach, W. N. Venables, and S. J. Wright. Simultaneous variable selection. Techno-  G. Wahba. Spline Models for Observational Data. Society for Industrial and Applied  J. R. Westbury, G. Turner, and J. Dembovski. X-ray microbeam speech production database  F. Yao, H. G. M\u00a8uller, and J. L. Wang. Functional linear regression analysis for longitudinal  data. Annals of Statistics, 33:2873-2903, 2005.  H. Zhang, Y. Xu, and Q. Zhang. Refinement of operator-valued reproducing kernels. Journal  of Machine Learning Research, 13:91-136, 2012.  X. Zhao, J. S. Marron, and M. T. Wells. The functional data analysis view of longitudinal  data. Statistica Sinica, 14:789-808, 2004. "}, "Gradients Weights improve Regression and Classification": {"volumn": 17, "url": "http://jmlr.org/papers/v17/13-351.html", "header": "Gradients Weights improve Regression and Classification", "author": "Samory Kpotufe, Abdeslam Boularias, Thomas Schultz, Kyoungok Kim", "time": "17(22):1\u221234, 2016.", "abstract": "In regression problems over $\\mathbb{R}^d$, the unknown function $f$ often varies more in some coordinates than in others. We show that weighting each coordinate $i$ according to an estimate of the variation of $f$ along coordinate $i$ -- e.g. the $L_1$ norm of the $i$th-directional deriva", "pdf_url": "http://jmlr.org/papers/volume17/13-351/13-351.pdf", "keywords": ["Nonparametric learning", "feature selection", "feature weighting", "nonparametric sparsity", "metric learning."], "reference": "A. Beygelzimer, S. Kakade, and J. Langford. Cover trees for nearest neighbors. ICML, 2006.  Abdeslam Boularias, James Andrew Bagnell, and Anthony Stentz. Efficient Optimization for Au- tonomous Robotic Manipulation of Natural Objects. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, pages 2520-2526, 2014a.  32   S. KPOTUFE, A. BOULARIAS, T. SCHULTZ, K. KIM  KR error KR-\u03c1 error KR-\u03c12 error KR-\u03c13 error KR-\u03c14 error KR time KR-\u03c1 time  KR error KR-\u03c1 error KR-\u03c12 error KR-\u03c13 error KR-\u03c14 error KR time KR-\u03c1 time  Barrett joint 1 0.50 \u00b1 0.02 0.38 \u00b1 0.03 0.30 \u00b1 0.03 0.18 \u00b1 0.02 0.17 \u00b1 0.01 0.39 \u00b1 0.02 0.41 \u00b1 0.03  Barrett joint 5 0.50 \u00b1 0.03 0.35 \u00b1 0.02 0.28 \u00b1 0.03 0.20 \u00b1 0.01 0.20 \u00b1 0.01 0.37 \u00b1 0.01 0.38 \u00b1 0.02  Concrete Strength Wine Quality 0.75 \u00b1 0.03 0.75 \u00b1 0.02 0.72 \u00b1 0.02 0.73 \u00b1 0.03 0.78 \u00b1 0.02 0.19 \u00b1 0.02 0.19 \u00b1 0.02  0.42 \u00b1 0.05 0.37 \u00b1 0.03 0.31 \u00b1 0.02 0.28 \u00b1 0.04 0.37 \u00b1 0.04 0.14 \u00b1 0.02 0.14 \u00b1 0.01  k-NN error k-NN-\u03c1 error k-NN-\u03c12 error k-NN-\u03c13 error k-NN-\u03c14 error k-NN time k-NN-\u03c1 time  k-NN error k-NN-\u03c1 error k-NN-\u03c12 error k-NN-\u03c13 error k-NN-\u03c14 error k-NN time k-NN-\u03c1 time  Barrett joint 1 0.41 \u00b1 0.02 0.29 \u00b1 0.01 0.21 \u00b1 0.02 0.11 \u00b1 0.02 0.15 \u00b1 0.01 0.21 \u00b1 0.04 0.13 \u00b1 0.04  Barrett joint 5 0.40 \u00b1 0.02 0.30 \u00b1 0.02 0.23 \u00b1 0.01 0.19 \u00b1 0.01 0.20 \u00b1 0.01 0.16 \u00b1 0.03 0.16 \u00b1 0.03  Concrete Strength Wine Quality 0.73 \u00b1 0.04 0.72 \u00b1 0.03 0.70 \u00b1 0.01 0.71 \u00b1 0.01 0.78 \u00b1 0.01 0.15 \u00b1 0.01 0.15 \u00b1 0.01  0.40 \u00b1 0.04 0.38 \u00b1 0.03 0.31 \u00b1 0.06 0.26 \u00b1 0.02 0.38 \u00b1 0.05 0.10 \u00b1 0.01 0.11 \u00b1 0.01  SARCOS joint 1 0.16 \u00b1 0.02 0.14 \u00b1 0.02 0.11 \u00b1 0.02 0.18 \u00b1 0.03 0.37 \u00b1 0.02 0.28 \u00b1 0.05 0.32 \u00b1 0.05 Telecom 0.30 \u00b1 0.02 0.23 \u00b1 0.02 0.37 \u00b1 0.08 0.57 \u00b1 0.02 0.54 \u00b1 0.03 0.15\u00b10.01 0.16\u00b10.01  SARCOS joint 1 0.08 \u00b1 0.01 0.07 \u00b1 0.01 0.06 \u00b1 0.01 0.08 \u00b1 0.01 0.37 \u00b1 0.01 0.13 \u00b1 0.01 0.14 \u00b1 0.01 Telecom 0.13 \u00b1 0.02 0.17 \u00b1 0.02 0.34 \u00b1 0.05 0.55 \u00b1 0.03 0.52 \u00b1 0.02 0.16\u00b10.02 0.15\u00b10.01  SARCOS joint 5 0.14 \u00b1 0.02 0.12 \u00b1 0.01 0.12 \u00b1 0.01 0.14 \u00b1 0.02 0.20 \u00b1 0.01 0.23 \u00b1 0.03 0.23 \u00b1 0.02 Ailerons 0.40 \u00b1 0.02 0.39 \u00b1 0.02 0.37 \u00b1 0.02 0.38 \u00b1 0.02 0.41 \u00b1 0.01 0.20\u00b10.01 0.21\u00b10.01  SARCOS joint 5 0.08 \u00b1 0.01 0.07 \u00b1 0.01 0.06 \u00b1 0.01 0.05 \u00b1 0.01 0.16 \u00b1 0.01 0.13 \u00b1 0.01 0.13 \u00b1 0.01 Ailerons 0.37 \u00b1 0.01 0.34 \u00b1 0.01 0.34 \u00b1 0.01 0.36 \u00b1 0.01 0.45 \u00b1 0.01 0.12\u00b10.01 0.11\u00b10.01  Housing 0.37 \u00b1 0.08 0.25 \u00b1 0.06 0.21 \u00b1 0.04 0.25 \u00b1 0.03 0.39 \u00b1 0.08 0.10 \u00b10.01 0.11 \u00b10.01 Parkinson\u2019s 0.38 \u00b1 0.03 0.34 \u00b1 0.03 0.34 \u00b1 0.02 0.31 \u00b1 0.02 0.30 \u00b1 0.01 0.30\u00b10.03 0.30\u00b10.03  Housing 0.28 \u00b1 0.09 0.22 \u00b1 0.06 0.18 \u00b1 0.03 0.23 \u00b1 0.03 0.31 \u00b1 0.07 0.08 \u00b10.01 0.08 \u00b10.01 Parkinson\u2019s 0.22 \u00b1 0.01 0.20 \u00b1 0.01 0.20 \u00b1 0.01 0.22 \u00b1 0.01 0.25 \u00b1 0.01 0.14\u00b10.01 0.15\u00b10.01  Table 6: Normalized mean square prediction errors and average prediction time per point (in mil- liseconds). The top five tables are for KR vs KR-\u03c1, KR-\u03c12,KR-\u03c13 and KR-\u03c14, the bottom five for k-NN vs k-NN-\u03c1, k-NN-\u03c12, k-NN-\u03c13 and k-NN-\u03c14.  References  A. Beygelzimer, S. Kakade, and J. Langford. Cover trees for nearest neighbors. ICML, 2006.  Abdeslam Boularias, James Andrew Bagnell, and Anthony Stentz. Efficient Optimization for Au- tonomous Robotic Manipulation of Natural Objects. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, pages 2520-2526, 2014a. GRADIENTS WEIGHTS  Abdeslam Boularias, James Andrew Bagnell, and Anthony Stentz.  Robot Grasping Data http://www.cs.rutgers.edu/\u02dcab1544/data/AAAI2014Data.tar.bz2.  Set. Carnegie Mellon University, Robotics Department, 2014b.  K. Clarkson. Nearest-neighbor searching and metric space dimensions. Nearest-Neighbor Methods  for Learning and Vision: Theory and Practice, 2005.  Jason V. Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and Inderjit S. Dhillon. Information-theoretic  metric learning. In ICML, pages 209-216, 2007.  L. Devroye, L. Gyorfi, and G. Lugosi. A Probabilistic Theory of Pattern Recognition. Springer,  Rong-En Fan. LIBSVM Data: Classification, Regression, and Multi-label, 2012. URL http:  //www.csie.ntu.edu.tw/\u02dccjlin/libsvmtools/datasets/.  A. Frank and A. Asuncion. UCI machine learning repository. http://archive.ics.uci. edu/ml. University of California, Irvine, School of Information and Computer Sciences, 2012.  Haijie Gu and John Lafferty. Sequential nonparametric regression. arXiv preprint arXiv:1206.6408,  1996.  2012.  L. Gyorfi, M. Kohler, A. Krzyzak, and H. Walk. A Distribution Free Theory of Nonparametric  Regression. Springer, New York, NY, 2002.  W. H\u00a8ardle and T. Gasser. On robust kernel estimation of derivatives of regression functions. Scan-  dinavian journal of statistics, pages 233-240, 1985.  Marc Hoffmann and Oleg Lepski. Random rates in anisotropic regression. Annals of statistics,  pages 325-358, 2002.  Kenji Kira and Larry A. Rendell. A practical approach to feature selection. In Proceedings of the  Ninth International Workshop on Machine Learning, ML92, pages 249-256, 1992.  Igor Kononenko. Estimating attributes: Analysis and extensions of RELIEF. In Proc. European  Conf. on Machine Learning, pages 171-182, 1994.  S. Kpotufe. k-NN Regression Adapts to Local Intrinsic Dimension. NIPS, 2011.  S. Kpotufe and A. Boularias. Gradient weights help nonparametric regressors. NIPS, 2012.  J. Lafferty and L. Wasserman. Rodeo: Sparse nonparametric regression in high dimensions. Arxiv  preprint math/0506342, 2005.  Duy Nguyen-Tuong and Jan Peters. Incremental online sparsification for model learning in real-time  robot control. Neurocomputing, 74(11):1859-1867, 2011.  Duy Nguyen-Tuong, Matthias W. Seeger, and Jan Peters. Model learning with local gaussian pro-  cess regression. Advanced Robotics, 23(15):2015-2034, 2009.  M Nusbaum. Optimal filtration of a function of many variables in white gaussian noise. PROB.  INFO. TRANSMISSION., 19(2):105-111, 1983. S. KPOTUFE, A. BOULARIAS, T. SCHULTZ, K. KIM  Philippe Rigollet and Alexandre Tsybakov. Exponential screening and optimal rates of sparse esti-  mation. The Annals of Statistics, 39(2):731-771, 2011.  Marko Robnik- \u02c7Sikonja and Igor Kononenko. Theoretical and empirical analysis of relieff and rreli-  eff. Machine learning, 53(1-2):23-69, 2003.  L. Rosasco, S. Villa, S. Mosci, M. Santoro, and A. Verri. Nonparametric sparsity and regularization.  http://arxiv.org/abs/1208.2572, 2012.  Shai Shalev-shwartz, Yoram Singer, and Andrew Y. Ng. Online and batch learning of pseudo-  metrics. In ICML, pages 743-750. ACM Press, 2004.  C. J. Stone. Optimal rates of convergence for non-parametric estimators. Ann. Statist., 8:1348-1360,  C. J. Stone. Optimal global rates of convergence for non-parametric estimators. Ann. Statist., 10:  1980.  1340-1353, 1982.  Yijun Sun. Iterative RELIEF for feature weighting: Algorithms, theories, and applications. IEEE  Trans. Pattern Analysis and Machine Intelligence, 29(6):1035-1051, 2007.  Luis Torgo. Regression datasets. http://www.liaad.up.pt/\u02dcltorgo. University of Porto,  Department of Computer Science, 2012.  Shubhendu Trivedi, Jialei Wang, Samory Kpotufe, and Gregory Shakhnarovich. A consistent es- In Proceedings of the Thirtieth Conference on  timator of the expected gradient outerproduct. Uncertainty in Artificial Intelligence, pages 819-828, 2014.  V. Vapnik and A. Chervonenkis. On the uniform convergence of relative frequencies of events to  their expectation. Theory of probability and its applications, 16:264-280, 1971.  Kilian Q. Weinberger and Gerald Tesauro. Metric learning for kernel regression. Journal of Machine  Learning Research - Proceedings Track, 2:612-619, 2007.  Dietrich Wettschereck, David W. Aha, and Takao Mohri. A review and empirical evaluation of feature weighting methods for a class of lazy learning algorithms. Artificial Intelligence Review, 11:273-314, 1997.  Bo Xiao, Xiaokang Yang, Yi Xu, and Hongyuan Zha. Learning distance metric for regression by semidefinite programming with application to human age estimation. In Proceedings of the 17th ACM international conference on Multimedia, pages 451-460, 2009.  Yingbo Zhou, Utkarsh Porwal, Ce Zhang, Hung Q Ngo, Long Nguyen, Christopher R\u00b4e, and Venu Govindaraju. Parallel feature selection inspired by group testing. In Z. Ghahramani, M. Welling, C. Cortes, N.D. Lawrence, and K.Q. Weinberger, editors, Advances in Neural Information Pro- cessing Systems 27, pages 3554-3562. Curran Associates, Inc., 2014. "}, "Learning Using Anti-Training with Sacrificial Data": {"volumn": 17, "url": "http://jmlr.org/papers/v17/13-589.html", "header": "Learning Using Anti-Training with Sacrificial Data", "author": "Michael L. Valenzuela, Jerzy W. Rozenblit", "time": "17(24):1\u221242, 2016.", "abstract": "Traditionally the machine-learning community has viewed the No Free Lunch (NFL) theorems for search and optimization as a limitation. We review, analyze, and unify the NFL theorem with the perspectives of \"blind\" search and meta-learning to arrive at necessary conditions for improving black-box optimization. We survey meta-learning literature to determine when and how meta- learning can benefit machine learning. Then, we generalize meta- learning in the context of the NFL theorems, to arrive at a novel technique called  anti-training with sacrificial data  (ATSD). Our technique applies at the meta level to arrive at domain specific algorithms. We also show how to generate sacrificial data. An extensive case study is presented along with simulated annealing results to demonstrate the efficacy of the ATSD method.", "pdf_url": "http://jmlr.org/papers/volume17/13-589/13-589.pdf", "keywords": ["Machine Learning", "Optimization", "Meta Optimization", "No Free Lunch", "Anti Training", "Sacrificial Data"], "reference": "Sylvain Arlot and Alain Celisse. A survey of cross-validation procedures for model selection. Statistics Surveys, 4:40--79, 2010. doi: 10.1214/09-SS054. URL \\tth \\ttt \\ttt \\ttp ://\\tta \\ttr \\ttx \\tti \\ttv .\\tto \\ttr \\ttg /\\tta \\ttb \\tts / \\ttzero \\ttnine \\ttzero \\ttseven .\\ttfour \\ttseven \\tttwo \\tteight .  36   Valenzuela and Rozenblit  \\bigm|  \\bigm|  \\bigm|   \\bigm|  \\bigm|  \\bigm|   \\^\\scrF  -   \\^\\scrF +  \\bigm|  \\bigm|  \\bigm|  /  ATSD+ML is a technique still in its infancy. Much work remains to be done on accurately estimating how much and what kind of sacrificial data ATSD+ML needs. We only touched on the proper balance between ATSD and ML. In general, a safe value for \\beta  \\bigm|  \\bigm|  in (8) is 0 \\leq  \\beta  < \\bigm| , or when the sums are replaced with averages 0 \\leq  \\beta  < 1. Another future research direction includes studying the implications of the NFL theorems approximately holding, when the equality in (1) is replaced with upper and lower bounds. We conjecture that the benefits from anti-training would diminish as the equality becomes less strict. However, this would need to be investigated more thoroughly. ATSD+ML could be viewed as a form of regularization and studied as such. It might also be able to be applied to model selection rather than algorithm selection. A probabilistic model would be useful in answering these questions.  The basic concept of ATSD---improving performance by training to perform worse on irrelevant data---may have benefits for selecting solutions (not algorithms) to improve predictive accuracy. This baseline ATSD does not follow from the NFL theorems in the same manner. It may still follow from the NFL theorems, but for a different reason. However, baseline ATSD may be justifiable in terms of regularization. If a solution fits random noise in addition to the actual data, then the solution may be unnecessarily complex.  We conducted four experiments showing how ATSD may function in practice. The first experiment produced results showing ATSD improves performance for optimizers. The second experiment confirmed that ATSD should fail when ML fails. The third experiment was inconclusive as the algorithms discovered from ML outperformed the ATSD candidates even at their own meta-objective function; a side effect of the NFL algorithms. The fourth experiment provides supportive, but inconclusive evidence that ATSD benefits classification algorithms. More experiments are left for future work. Such experiments include repeating similar experiments that take significantly less time to complete, using 10-fold cross- validation for machine learning experiments, and comparing direct meta-optimization (as in the first three experiments) to sampling based approached (as in the fourth experiment). Convex optimization is a desirable property needed for more sophisticated machine learning procedures. This is the issue when extending ATSD to work with support- vector machines, support-vector regression, or any other optimization that depends on convex optimization problems. The results from the third experiment motivate a convex meta-optimization framework to ensure algorithms actually optimize their meta-objective function. The issue is that it is possible for the global minimum to occur whenever the sacrificial performance approaches positive infinity; this drives the objective function to negative infinity. This in turn causes the traditional objective function to be largely ignored. The most natural approach would be to apply some convex non-decreasing saturating function (e.g., exp( - x)) to the sacrificial term. The effects of this saturating ATSD on convex optimization techniques should be studied, as well as other techniques to extend ATSD to a convex optimization framework.  References  Sylvain Arlot and Alain Celisse. A survey of cross-validation procedures for model selection. Statistics Surveys, 4:40--79, 2010. doi: 10.1214/09-SS054. URL \\tth \\ttt \\ttt \\ttp ://\\tta \\ttr \\ttx \\tti \\ttv .\\tto \\ttr \\ttg /\\tta \\ttb \\tts / \\ttzero \\ttnine \\ttzero \\ttseven .\\ttfour \\ttseven \\tttwo \\tteight . Learning Using Anti-Training with Sacrificial Data  Peter Auer, Mark Herbster, and Manfred K. Warmuth. Exponentially many local minima  for single neurons, 1995.  Anne Auger and Olivier Teytaud. Continuous lunches are free!  In Proceedings of the 9th annual conference on Genetic and evolutionary computation, GECCO '07, pages 916-- 922, New York, NY, USA, 2007. ACM. ISBN 978-1-59593-697-4. doi: 10.1145/1276958. 1277145. URL \\tth \\ttt \\ttt \\ttp ://\\ttd \\tto \\tti .\\tta \\ttc \\ttm .\\tto \\ttr \\ttg /\\ttone \\ttzero .\\ttone \\ttone \\ttfour \\ttfive /\\ttone \\tttwo \\ttseven \\ttsix \\ttnine \\ttfive \\tteight .\\ttone \\tttwo \\ttseven \\ttseven \\ttone \\ttfour \\ttfive .  Anne Auger and Olivier Teytaud. Continuous lunches are free plus the design of optimal optimization algorithms. Algorithmica, 57:121--146, 2010. ISSN 0178-4617. doi: 10.1007/ s00453-008-9244-5. URL \\tth \\ttt \\ttt \\ttp ://\\ttd \\ttx .\\ttd \\tto \\tti .\\tto \\ttr \\ttg /\\ttone \\ttzero .\\ttone \\ttzero \\ttzero \\ttseven /\\tts \\ttzero \\ttzero \\ttfour \\ttfive \\ttthree -\\ttzero \\ttzero \\tteight -\\ttnine \\tttwo \\ttfour \\ttfour -\\ttfive .  K. Bache and M. Lichman. UCI machine learning repository, 2013. URL \\tth \\ttt \\ttt \\ttp ://\\tta \\ttr \\ttc \\tth \\tti \\ttv \\tte .  \\tti \\ttc \\tts .\\ttu \\ttc \\tti .\\tte \\ttd \\ttu /\\ttm \\ttl .  Mokhtar S. Bazaraa, Hanif D. Sherali, and C. M. Shetty. Nonlinear Programming: Theory  and Algorithms, chapter 4, pages 188--195. Wiley, 3rd edition, 2006.  J. Bergstra and Y. Bengio. Random search for hyper-parameter optimization. The Journal  of Machine Learning Research, 13:281--305, 2012.  W. Bialek, I. Nemenman, and N. Tishby. Predictability, complexity, and learning. Neural  Computation, 13(11):2409--2463, 2001.  Peter J Brockwell and Richard A Davis. Introduction to time series and forecasting. Springer  Verlag, 2002. ISBN: 9780387953519.  D. Corne and J. Knowles. No free lunch and free leftovers theorems for multiobjective optimisation problems. In Evolutionary Multi-Criterion Optimization, pages 66--66. Springer, 2003a. URL \\tth \\ttt \\ttt \\ttp ://\\ttc \\tti \\ttt \\tte \\tts \\tte \\tte \\ttr \\ttx .\\tti \\tts \\ttt .\\ttp \\tts \\ttu .\\tte \\ttd \\ttu /\\ttv \\tti \\tte \\ttw \\ttd \\tto \\ttc /\\tts \\ttu \\ttm \\ttm \\tta \\ttr \\tty ?\\ttd \\tto \\tti =\\ttone \\ttzero .\\ttone . \\ttone .\\ttone \\ttfive .\\ttone \\ttfour \\tteight \\ttzero .  D. Corne and J. Knowles. Some multiobjective optimizers are better than others.  In Proceedings Congress Evolutionary Computation CEC '03, volume 4, pages 2506--2512, 2003b. doi: 10.1109/CEC.2003.1299403.  T.M. Cover and J.A. Thomas. Elements of Information Theory, chapter Kolmogorov Complexity, pages 463--508. John Wiley \\& Sons, Inc., Hoboken, New Jersey, second edition, 2006. ISBN 978-0471241959.  Joseph C. Culberson. On the futility of blind search: An algorithmic view of `no free lunch'. Evolutionary Computation, 6:109--127, June 1998. ISSN 1063-6560. doi: http:// dx.doi.org/10.1162/evco.1998.6.2.109. URL \\tth \\ttt \\ttt \\ttp ://\\ttd \\ttx .\\ttd \\tto \\tti .\\tto \\ttr \\ttg /\\ttone \\ttzero .\\ttone \\ttone \\ttsix \\tttwo /\\tte \\ttv \\ttc \\tto .\\ttone \\ttnine \\ttnine \\tteight . \\ttsix .\\tttwo .\\ttone \\ttzero \\ttnine .  Stefan Droste, Thomas Jansen, and Ingo Wegener. Optimization with randomized search heuristics -- the (a)nfl theorem, realistic scenarios, and difficult functions. Theoreti- cal Computer Science, 287(1):131--144, 2002. URL \\tth \\ttt \\ttt \\ttp ://\\ttc \\tti \\ttt \\tte \\tts \\tte \\tte \\ttr \\ttx .\\tti \\tts \\ttt .\\ttp \\tts \\ttu .\\tte \\ttd \\ttu / \\ttv \\tti \\tte \\ttw \\ttd \\tto \\ttc /\\tts \\ttu \\ttm \\ttm \\tta \\ttr \\tty ?\\ttd \\tto \\tti =\\ttone \\ttzero .\\ttone .\\ttone .\\ttthree \\ttfive .\\ttfive \\tteight \\ttfive \\ttzero . Valenzuela and Rozenblit  N. Gershenfeld. The nature of mathematical modeling, chapter Linear and Nonlinear Time  Series, pages 204--224. Cambridge University Press, 1999.  C. Giraud-Carrier and F. Provost. Toward a justification of meta-learning:  Is the no free lunch theorem a show-stopper? In Proceedings of the ICML-2005 Workshop on Meta-learning, pages 12--19, Bonn, Germany, 2005. URL \\tth \\ttt \\ttt \\ttp ://\\ttd \\ttm \\ttl .\\ttc \\tts .\\ttb \\tty \\ttu .\\tte \\ttd \\ttu /\\~\\ttc \\ttg \\ttc / \\ttp \\ttu \\ttb \\tts /\\ttI \\ttC \\ttM \\ttL \\tttwo \\ttzero \\ttzero \\ttfive \\ttW \\ttS .\\ttp \\ttd \\ttf .  David S. Goodsell and Arthur J. Olson. Automated docking of substrates to proteins by simulated annealing. Proteins: Structure, Function, and Bioinformatics, 8(3):195--202, ISSN 1097-0134. doi: 10.1002/prot.340080302. URL \\tth \\ttt \\ttt \\ttp ://\\ttd \\ttx .\\ttd \\tto \\tti .\\tto \\ttr \\ttg /\\ttone \\ttzero . 1990. \\ttone \\ttzero \\ttzero \\tttwo /\\ttp \\ttr \\tto \\ttt .\\ttthree \\ttfour \\ttzero \\ttzero \\tteight \\ttzero \\ttthree \\ttzero \\tttwo .  Christian Igel and Marc Toussaint. On classes of functions for which no free lunch results hold. Information Processing Letters, 86(6):317--321, June 2003. ISSN 0020-0190. doi: 10.1016/S0020-0190(03)00222-9. URL \\tth \\ttt \\ttt \\ttp ://\\ttd \\ttx .\\ttd \\tto \\tti .\\tto \\ttr \\ttg /\\ttone \\ttzero .\\ttone \\ttzero \\ttone \\ttsix /\\ttS \\ttzero \\ttzero \\tttwo \\ttzero -\\ttzero \\ttone \\ttnine \\ttzero (\\ttzero \\ttthree ) \\ttzero \\ttzero \\tttwo \\tttwo \\tttwo -\\ttnine .  Christian Igel and Marc Toussaint. A no-free-lunch theorem for non-uniform distributions of target functions. Journal of Mathematical Modelling and Algorithms, 3:2004, 2004. URL \\tth \\ttt \\ttt \\ttp ://\\ttc \\tti \\ttt \\tte \\tts \\tte \\tte \\ttr \\ttx .\\tti \\tts \\ttt .\\ttp \\tts \\ttu .\\tte \\ttd \\ttu /\\ttv \\tti \\tte \\ttw \\ttd \\tto \\ttc /\\tts \\ttu \\ttm \\ttm \\tta \\ttr \\tty ?\\ttd \\tto \\tti =\\ttone \\ttzero .\\ttone .\\ttone .\\ttseven \\ttone .\\tteight \\ttfour \\ttfour \\ttsix .  L. Ingber. Simulated annealing: Practice versus theory. Mathematical and Computer Modelling, 18(11):29 -- 57, 1993. ISSN 0895-7177. doi: http://dx.doi.org/10.1016/ 0895-7177(93)90204-C. URL \\tth \\ttt \\ttt \\ttp ://\\ttw \\ttw \\ttw .\\tts \\ttc \\tti \\tte \\ttn \\ttc \\tte \\ttd \\tti \\ttr \\tte \\ttc \\ttt .\\ttc \\tto \\ttm /\\tts \\ttc \\tti \\tte \\ttn \\ttc \\tte /\\tta \\ttr \\ttt \\tti \\ttc \\ttl \\tte /\\ttp \\tti \\tti / \\ttzero \\tteight \\ttnine \\ttfive \\ttseven \\ttone \\ttseven \\ttseven \\ttnine \\ttthree \\ttnine \\ttzero \\tttwo \\ttzero \\ttfour \\ttC .  Lester Ingber. Adaptive simulated annealing (asa): Lessons learned. Control and Cyber-  netics, 25:33--54, 1996.  Malvin H Kalos and Paula A Whitlock. Monte carlo methods, chapter Quasi-Monte Carlo,  pages 101--103. John Wiley \\& Sons, second edition, 2008.  Ron Kohavi. A study of cross-validation and bootstrap for accuracy estimation and model selection. In Proceedings of the 14th international joint conference on Artificial intelligence - Volume 2, IJCAI'95, pages 1137--1143, San Francisco, CA, USA, 1995. Morgan Kaufmann Publishers Inc. ISBN 1-55860-363-8. URL \\tth \\ttt \\ttt \\ttp ://\\ttd \\ttl .\\tta \\ttc \\ttm .\\tto \\ttr \\ttg / \\ttc \\tti \\ttt \\tta \\ttt \\tti \\tto \\ttn .\\ttc \\ttf \\ttm ?\\tti \\ttd =\\ttone \\ttsix \\ttfour \\ttthree \\ttzero \\ttthree \\ttone .\\ttone \\ttsix \\ttfour \\ttthree \\ttzero \\ttfour \\ttseven .  Ron Kohavi. Scaling up the accuracy of naive-bayes classifiers: a decision-tree hybrid. In Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, pages 202--207, Menlo Park, California, 1996. AAAI Press.  Lauwerens Kuipers and Harald Niederreiter. Uniform distribution of sequences, chapter Special Sequences, pages 129--130. Courier Dover Publications, 1st edition, 1974. URL \\tth \\ttt \\ttt \\ttp ://\\ttw \\tte \\ttb .\\ttm \\tta \\ttt \\tth \\tts .\\ttu \\ttn \\tts \\ttw .\\tte \\ttd \\ttu .\\tta \\ttu /\\~\\ttj \\tto \\tts \\tte \\ttf \\ttd \\tti \\ttc \\ttk /\\ttp \\ttr \\tte \\ttp \\ttr \\tti \\ttn \\ttt \\tts /\\ttK \\ttu \\tti \\ttp \\tte \\ttr \\tts \\ttN \\tti \\tte \\ttd \\.\\ttb \\tto \\tto \\ttk .\\ttp \\ttd \\ttf .  E.L. Lehmann. Elements of Large-Sample Theory, chapter 3.4 Comparison of tests: Relative  efficiency, pages 173--187. Springer, 2004. Learning Using Anti-Training with Sacrificial Data  E.L. Lehmann and Joseph P. Romano. Testing statistical hypotheses, chapter 3.1 Stating The Problem, pages 56--59. Springer, Spring Street, New York, NY 10013, USA, 2008.  Ming Li and Paul Vit\\'anyi. An introduction to Kolmogorov complexity and its applications, chapter Algorithmic Complexity, pages 101 -- 107. Springer, Spring Street, New York, NY, 3rd edition, 2008. doi: 10.1007/978-0-387-49820-1.  Sean Luke. Essentials of Metaheuristics. Lulu, second edition, 2013. URL \\tth \\ttt \\ttt \\ttp : //\\ttc \\tts .\\ttg \\ttm \\ttu .\\tte \\ttd \\ttu /\\~\\tts \\tte \\tta \\ttn /\\ttb \\tto \\tto \\ttk /\\ttm \\tte \\ttt \\tta \\tth \\tte \\ttu \\ttr \\tti \\tts \\ttt \\tti \\ttc \\tts /\\ttE \\tts \\tts \\tte \\ttn \\ttt \\tti \\tta \\ttl \\tts .\\ttp \\ttd \\ttf . Available for free at http://cs.gmu.edu/\\sim sean/book/metaheuristics/.  M.D. McKay, R.J. Beckman, and W.J. Conover. Comparison of three methods for selecting values of input variables in the analysis of output from a computer code. Technometrics, 21(2):239--245, 1979.  John R. Rice. The algorithm selection problem. Advances in Computers, 15:65-- 118, 1976. URL \\tth \\ttt \\ttt \\ttp ://\\ttw \\ttw \\ttw .\\ttc \\tts .\\ttp \\ttu \\ttr \\ttd \\ttu \\tte .\\tte \\ttd \\ttu /\\ttr \\tte \\tts \\tte \\tta \\ttr \\ttc \\tth /\\ttt \\tte \\ttc \\tth \\ttn \\tti \\ttc \\tta \\ttl \\.\\ttr \\tte \\ttp \\tto \\ttr \\ttt \\tts /\\ttone \\ttnine \\ttseven \\ttfive /\\ttT \\ttR \\% \\tttwo \\ttzero \\ttseven \\ttfive -\\ttone \\ttfive \\tttwo .\\ttp \\ttd \\ttf .  J. Rissanen. Universal coding, information, prediction, and estimation. Information Theory, IEEE Transactions on, 30(4):629 -- 636, jul 1984. ISSN 0018-9448. doi: 10.1109/TIT. 1984.1056936.  J. Rissanen. Stochastic complexity and modeling. The Annals of Statistics, pages 1080--  1100, 1986.  J. Rissanen. Stochastic complexity. Journal of the Royal Statistical Society. Series B  (Methodological), pages 223--239, 1987.  J. Rissanen. Stochastic complexity and statistical inquiry. World Scientific, Singapore, 1989.  Christian P. Robert, Nicolas Chopin, and Judith Rousseau. Harold jeffreyss theory of probability revisited. Statistical Science, 24(2):141--172, 2009. doi: 10.1214/09-STS284.  C. Schumacher, M.D. Vose, and L.D. Whitley. The no free lunch and problem descrip- In Proceedings of the Genetic and Evolutionary Computation Conference  tion length. (GECCO-2001), pages 565--570, 2001.  Robert H Shumway and David S Stoffer. Time series analysis and its applications: with R  examples. Springer, New York, Dordrecht, Heidelberg, London, 3rd edition, 2011.  Ricardo Vilalta and Youssef Drissi. A perspective view and survey of meta-learning.  Artificial Intelligence Review, 18:77--95, 2002.  Guan Ming Wang, Estela Blaisten-Barojas, A. E. Roitberg, and T. P. Martin. Strontium clusters: Many-body potential, energetics, and structural transitions. The Journal of Chemical Physics, 115(8):3640--3646, 2001. doi: 10.1063/1.1384454. URL \\tth \\ttt \\ttt \\ttp ://\\ttl \\tti \\ttn \\ttk . \\tta \\tti \\ttp .\\tto \\ttr \\ttg /\\ttl \\tti \\ttn \\ttk /?\\ttJ \\ttC \\ttP /\\ttone \\ttone \\ttfive /\\ttthree \\ttsix \\ttfour \\ttzero /\\ttone . Valenzuela and Rozenblit  Darrell Whitley and Jean Watson. Complexity theory and the no free lunch theorem. In Edmund K. Burke and Graham Kendall, editors, Search Methodologies, pages 317-- 339. Springer US, 2005. ISBN 978-0-387-28356-2. doi: 10.1007/0-387-28356-0 11. URL \\tth \\ttt \\ttt \\ttp ://\\ttd \\ttx .\\ttd \\tto \\tti .\\tto \\ttr \\ttg /\\ttone \\ttzero .\\ttone \\ttzero \\ttzero \\ttseven /\\ttzero -\\ttthree \\tteight \\ttseven -\\tttwo \\tteight \\ttthree \\ttfive \\ttsix -\\ttzero \\.\\ttone \\ttone .  Mark Wineberg. Introductory statistics for evolutionary computation. In The Sixth Genetic  and Evolutionary Computation Conference (GECCO 2004), 2004.  David H. Wolpert. The supervised learning no-free-lunch theorems.  In Proceedings 6th Online World Conference on Soft Computing in Industrial Applications, pages 25--42, 2001. URL \\tth \\ttt \\ttt \\ttp ://\\ttc \\tti \\ttt \\tte \\tts \\tte \\tte \\ttr \\ttx .\\tti \\tts \\ttt .\\ttp \\tts \\ttu .\\tte \\ttd \\ttu /\\ttv \\tti \\tte \\ttw \\ttd \\tto \\ttc /\\tts \\ttu \\ttm \\ttm \\tta \\ttr \\tty ?\\ttd \\tto \\tti =\\ttone \\ttzero .\\ttone .\\ttone .\\ttnine \\ttnine .\\ttone \\ttthree \\ttthree .  D.H. Wolpert and W.G. Macready. No free lunch theorems for optimization.  Transactions on Evolutionary Computation, 1(1):67 --82, apr 1997. doi: 10.1109/4235.585893.  IEEE ISSN 1089-778X.  D.H. Wolpert and W.G. Macready. Coevolutionary free lunches. IEEE Transactions on ISSN 1089-778X. doi: 10.1109/  Evolutionary Computation, 9(6):721--735, dec. 2005. TEVC.2005.856205.  Xiaoguang Zhang, Li Yu, Yuan Zheng, Yu Shen, Guangtao Zhou, Lin Chen, Lixia Xi, Tiecheng Yuan, Jianzhong Zhang, and Bojun Yang. Two-stage adaptive pmd com- pensation in a 10 gbit/s optical communication system using particle swarm optimiza- tion algorithm. Optics Communications, 231(1--6):233 -- 242, 2004. ISSN 0030-4018. doi: 10.1016/j.optcom.2003.12.045. URL \\tth \\ttt \\ttt \\ttp ://\\ttw \\ttw \\ttw .\\tts \\ttc \\tti \\tte \\ttn \\ttc \\tte \\ttd \\tti \\ttr \\tte \\ttc \\ttt .\\ttc \\tto \\ttm /\\tts \\ttc \\tti \\tte \\ttn \\ttc \\tte / \\tta \\ttr \\ttt \\tti \\ttc \\ttl \\tte /\\ttp \\tti \\tti /\\ttS \\ttzero \\ttzero \\ttthree \\ttzero \\ttfour \\ttzero \\ttone \\tteight \\ttzero \\ttthree \\ttzero \\tttwo \\ttthree \\tteight \\ttfive \\ttX . Learning Using Anti-Training with Sacrificial Data  Appendix A. Proof of the two-valued nature of \\^P+(f ) in practice The estimate of P+(f ) is denoted \\^P+(f ). We argue that \\^P+(f ) is practically going to \\bigm|  \\bigm|  \\^\\scrF +(f ) \\bigm|  \\bigm|  \\bigm| . This is demonstrated by showing that when be a two-valued function: 0 and 1/ \\bigm|  independently sampling from \\scrF +, the probability that any two functions are identical is exceedingly small in practice. If one stops to ponder for a moment about similar problems, one realizes this problem reduces to the well known birthday problem in probability theory. The birthday problem asks ``what is the probability that out of n people (samples), some pair of them will have the same birthday (function).\"\" The answer is 100\\% if the number of people exceed the number of days in a year, but otherwise it is:  When replacing days with functions and people with samples this becomes  While (13) is exact, it must be used iteratively to figure out how much larger \\bigm|   \\bigm|  \\bigm|  must be than n to ensure a small probability of failure (that two functions will be identical). We provide an approximate n which limits the probability of failure to \\epsilon . Consider the probability of two samples having different functions,  \\bigm| \\scrF +  (13)  1  -   n!\\bigl( 365 \\bigr)  n 365n .  1  -   \\bigr)  n!\\bigl( | \\scrF +|  n n . \\bigm|  \\bigm|  \\bigm| \\scrF + \\bigm|   \\Biggl(   1  -   \\Biggr)   .  1 \\bigm|  \\bigm| \\scrF +  \\bigm|  \\bigm|   If there are n samples, then there exist n(n  -  1)/2 pairs of samples. Assuming each comparison is independent (this is approximately true if n \\ll  \\bigm|  \\bigm|  \\bigm| ), then the probability that all samples are unique is  \\bigm| \\scrF +  1 \\bigm|  \\bigm| \\scrF + Using the binomial theorem, this expands to  1  -   \\bigm|  \\bigm|   \\Biggl(   \\Biggr) n(n - 1)/2  1  -   \\biggl(  n2 - n 2 1  \\biggr)  1 \\bigm|  \\bigm| \\scrF +  \\bigm|  \\bigm|   +  \\biggl(  n2 - n 2 2  \\biggr)  1 \\bigm|  \\bigm| \\scrF +  \\bigm|  \\bigm|  \\bigm|  \\bigm|  We will bound the lth term of (14) using the well known inequality \\bigl( n l  2  -   \\biggl(  n2 - n 2 3  \\biggr)  1 \\bigm|  \\bigm| \\scrF +  3 + \\bigm|  \\bigm|   \\biggl(  n2 - n 2 4  \\biggr)  1 \\bigm|  \\bigm| \\scrF +  4  -  . . . .  (14)  \\bigr)  \\leq  nl  l! to get  \\biggl(  n2 - n 2 l  \\biggr)  1 \\bigm|  \\bigm| \\scrF +  l \\leq  \\bigm|  \\bigm|   \\Bigr) l  \\Bigl(  n2 - n 2 l!\\bigm|  l \\bigm|   \\bigm|  \\bigm| \\scrF + \\Biggr) l  n2  -  n 2\\bigm|  \\bigm| \\scrF +  \\bigm|  l \\bigm|   \\Biggr) l  .  n2  -  n \\bigm|  2 \\bigm|  \\bigm| \\scrF + \\bigm|   \\Biggl(   \\Biggl(   \\leq   = Valenzuela and Rozenblit  Thus, all higher order terms are negligible so long as  n2  -  n \\bigm|  2 \\bigm|  \\bigm| \\scrF + \\bigm|   \\ll  1  The first two terms are kept and set equal to the desired level of probability  1  -   \\geq  1  -  \\epsilon   \\biggl(  n2 - n 2 1 \\biggl(  n2 - n 2 1  \\bigm|  \\bigm|   \\leq  \\epsilon   \\biggr)  1 \\bigm|  \\bigm| \\scrF + \\biggr)  1 \\bigm|  \\bigm|  \\bigm| \\scrF + \\bigm|  n2  -  n 2 \\bigm|  \\bigm|  \\bigm| \\scrF + \\bigm|  n2  -  n \\leq  2 \\bigm|   \\leq  \\epsilon   \\bigm| \\scrF +  \\bigm|  \\bigm|  \\epsilon   \\sqrt{}   8 \\bigm|   \\bigm| \\scrF +  \\bigm|  \\bigm|  \\epsilon  + 1 + 1 2  n \\leq   n \\leq   \\sqrt{}   2 \\bigm|   \\bigm| \\scrF +  \\bigm|  \\bigm|  \\epsilon .  where \\epsilon  is the probability that two functions will be the same. When \\bigm|  than one, then this is well approximated by:  \\bigm| \\scrF +  \\bigm|  \\bigm|  \\cdot  \\epsilon  is much larger  For example, problems as small as those with a 16-bit input and an 8-bit output have \\bigm|  | \\scrF |  \\approx  2.6 \\cdot  10157826. Assuming n = 1012 and \\bigm|  \\bigm|  = 10100 (hundreds of thousands of orders \\bigm| \\scrF + of magnitude smaller), (13) states the probability that any two samples will have the same function is approximately 5.0\\cdot 10 - 77. Thus, in sampling the problem domain to build \\^P+(f ), it is extremely likely that a particular function will be sampled once or not at all. This leads to the two-valued nature of \\^P+(f ) in practice. Equation (16) shows how many samples are permitted while maintaining the two-valued nature with approximately 1  -  \\epsilon  confidence. Continuing the above example, when setting the probability of failure \\epsilon  \\approx  e - 100, we see n may be as large as 2.7 \\cdot  1028.  (15)  (16)  \\blacksquare  "}, "A Unifying Framework in Vector-valued Reproducing Kernel Hilbert Spaces for Manifold Regularization and Co-Regularized Multi-view Learning": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-036.html", "header": "A Unifying Framework in Vector-valued Reproducing Kernel Hilbert Spaces for Manifold Regularization and Co-Regularized Multi-view Learning", "author": "H\u00c3\u00a0 Quang Minh, Loris Bazzani, Vittorio Murino", "time": "17(25):1\u221272, 2016.", "abstract": "This paper presents a general vector-valued reproducing kernel Hilbert spaces (RKHS) framework for the problem of le", "pdf_url": "http://jmlr.org/papers/volume17/14-036/14-036.pdf", "keywords": ["learning", "multi-kernel learning", "manifold regularization", "multi-class classification"], "reference": "F. Bach, G. Lanckriet, and M. Jordan. Multiple kernel learning, conic duality, and the SMO algorithm. In Proceedings of the International Conference on Machine Learning (ICML), 2004.  M. Belkin, P. Niyogi, and V. Sindhwani. Manifold regularization: A geometric framework for learning from labeled and unlabeled examples. Journal of Machine Learning Research, 7:2399-2434, 2006.  U. Brefeld, T. G\u00a8artner, T. Sche\ufb00er, and S. Wrobel. E\ufb03cient co-regularised least squares regression. In Proceedings of the International Conference on Machine Learning(ICML), 2006.  C. Brouard, F. D\u2019Alche-Buc, and M. Szafranski. Semi-supervised penalized output kernel regression for link prediction. In Proceedings of the International Conference on Machine Learning (ICML), 2011.  S. Bucak, R. Jin, and A.K. Jain. Multiple kernel learning for visual object recognition: A review. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(7):1354- 1369, 2014.  A. Caponnetto, M. Pontil, C.Micchelli, and Y. Ying. Universal multi-task kernels. Journal  of Machine Learning Research, 9:1615-1646, 2008.  C. Carmeli, E. De Vito, and A. Toigo. Vector-valued reproducing kernel Hilbert spaces of integrable functions and Mercer theorem. Analysis and Applications, 4:377-408, 2006.  M. Christoudias, R. Urtasun, and T. Darrell. Bayesian localized multiple kernel learning.  Univ. California Berkeley, Berkeley, CA, 2009.  K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based  vector machines. Journal of Machine Learning Research, 2:265-292, 2001.  F. Dinuzzo, C.S. Ong, P. Gehler, and G. Pillonetto. Learning output kernels with block coordinate descent. In Proceedings of the International Conference on Machine Learning (ICML), 2011.  69   Unifying Vector-valued Manifold Regularization and Multi-view Learning  where we have used the identity  1(u+l)m1T  (u+l)mJ (u+l)m  ml  1(u+l)m1T  (u+l)m = ml1(u+l)m1T  (u+l)m.  (229)  A = (B + l\u03b3AI(u+l)m)\u22121YC =  \uf8eb  \uf8ed  I(u+l)m l\u03b3A  \u2212  J (u+l)m ml  1(u+l)m1T l2m\u03b3A(m\u03b3A + 1)  (u+l)m  \uf8f6  \uf8f8 YC.  (230)  Thus in this case we have an analytic expression for the coe\ufb03cient matrix A, as we claimed.  We have thus  References  F. Bach, G. Lanckriet, and M. Jordan. Multiple kernel learning, conic duality, and the SMO algorithm. In Proceedings of the International Conference on Machine Learning (ICML), 2004.  M. Belkin, P. Niyogi, and V. Sindhwani. Manifold regularization: A geometric framework for learning from labeled and unlabeled examples. Journal of Machine Learning Research, 7:2399-2434, 2006.  U. Brefeld, T. G\u00a8artner, T. Sche\ufb00er, and S. Wrobel. E\ufb03cient co-regularised least squares regression. In Proceedings of the International Conference on Machine Learning(ICML), 2006.  C. Brouard, F. D\u2019Alche-Buc, and M. Szafranski. Semi-supervised penalized output kernel regression for link prediction. In Proceedings of the International Conference on Machine Learning (ICML), 2011.  S. Bucak, R. Jin, and A.K. Jain. Multiple kernel learning for visual object recognition: A review. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(7):1354- 1369, 2014.  A. Caponnetto, M. Pontil, C.Micchelli, and Y. Ying. Universal multi-task kernels. Journal  of Machine Learning Research, 9:1615-1646, 2008.  C. Carmeli, E. De Vito, and A. Toigo. Vector-valued reproducing kernel Hilbert spaces of integrable functions and Mercer theorem. Analysis and Applications, 4:377-408, 2006.  M. Christoudias, R. Urtasun, and T. Darrell. Bayesian localized multiple kernel learning.  Univ. California Berkeley, Berkeley, CA, 2009.  K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based  vector machines. Journal of Machine Learning Research, 2:265-292, 2001.  F. Dinuzzo, C.S. Ong, P. Gehler, and G. Pillonetto. Learning output kernels with block coordinate descent. In Proceedings of the International Conference on Machine Learning (ICML), 2011. Minh, Bazzani, and Murino  T. Evgeniou, M. Pontil, and C.A. Micchelli. Learning multiple tasks with kernel methods.  Journal of Machine Learning Research, 6:615-637, 2005.  L. Fei-Fei, R. Fergus, and P. Perona. One-shot learning of object categories. IEEE Trans-  actions on Pattern Analysis and Machine Intelligence, 28(4):594 -611, 2006.  D. Figueira, L. Bazzani, H.Q. Minh, M. Cristani, A. Bernardino, and V. Murino. Semi- supervised multi-feature learning for person re-identification. In Proceedings of the IEEE International Conference on Advanced Video and Signal-based Surveillance (AVSS), 2013.  G.E. Forsythe and G. Golub. On the stationary values of a second-degree polynomial on the unit sphere. Journal of the Society for Industrial & Applied Mathematics, 13(4): 1050-1068, 1965.  W. Gander. Least squares with a quadratic constraint. Numerische Mathematik, 36:291-  307, 1981.  P. Gehler and S. Nowozin. On feature combination for multiclass object classification. In  Proceedings of the International Conference on Computer Vision (ICCV), 2009.  G. Golub and U. von Matt. Quadratically constrained least squares and quadratic problems.  Numerische Mathematik, 59:561-580, 1991.  K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling in deep convolutional networks for visual recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(9):1904-1916, 2015.  S. Hill and A. Doucet. A framework for kernel-based multi-category classification. Journal  of Artificial Intelligence Research, 30(1):525-564, 2007.  H. Kadri, A. Rabaoui, P. Preux, E. Du\ufb02os, and A. Rakotomamonjy. Functional regularized least squares classification with operator-valued kernels. In Proceedings of the Interna- tional Conference on Machine Learning(ICML), 2011.  H. Kadri, S. Ayache, C. Capponi, S. Koo, F.-X. Dup, and E. Morvant. The multi-task learning view of multimodal data. In Proceedings of the Asian Conference on Machine Learning (ACML), 2013.  Y. Lee, Y. Lin, and G. Wahba. Multicategory support vector machines: Theory and appli- cation to the classification of microarray data and satellite radiance data. Journal of the American Statistical Association, 99:67-81, 2004.  Y. Luo, D. Tao, C. Xu, D. Li, and C. Xu. Vector-valued multi-view semi-supervised learning for multi-label image classification. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2013a.  Y. Luo, D. Tao, C. Xu, C. Xu, H. Liu, and Y. Wen. Multiview vector-valued manifold regularization for multilabel image classification. IEEE Transactions on Neural Networks and Learning Systems, 24(5):709-722, 2013b. Unifying Vector-valued Manifold Regularization and Multi-view Learning  C. A. Micchelli and M. Pontil. On learning vector-valued functions. Neural Computation,  17:177-204, 2005.  H. Q. Minh and V. Sindhwani. Vector-valued manifold regularization. In Proceedings of the  International Conference on Machine Learning (ICML), 2011.  H.Q. Minh, L. Bazzani, and V. Murino. A unifying framework for vector-valued manifold regularization and multi-view learning. In Proceedings of the International Conference on Machine Learning (ICML), 2013.  Y. Mroueh, T. Poggio, L. Rosasco, and J.-J. Slotine. Multiclass learning with simplex  coding. In Advances in Neural Information Processing Systems (NIPS), 2012.  M-E. Nilsback and A. Zisserman. A visual vocabulary for \ufb02ower classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2006.  M-E. Nilsback and A. Zisserman. Automated \ufb02ower classification over a large number of classes. In Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP), 2008.  J. Platt. Fast training of support vector machines using sequential minimal optimization. In B. Sch\u00a8olkopf, C. Burges, and A. Smola, editors, Advances in kernel methods, pages 185-208. MIT Press, Cambridge, MA, USA, 1999.  A.S. Razavian, H. Azizpour, J. Sullivan, and S. Carlsson. CNN features o\ufb00-the-shelf: An astounding baseline for recognition. In IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2014.  M. Reisert and H. Burkhardt. Learning equivariant functions with matrix valued kernels.  Journal of Machine Learning Research, 8:385-408, 2007.  G. Ro\ufb00o, M. Cristani, L. Bazzani, H.Q. Minh, and V. Murino. Trusting Skype: Learning the way people chat for fast user recognition and verification. In International Conference on Computer Vision Workshops (ICCVW), 2013.  D. Rosenberg, V. Sindhwani, P. Bartlett, and P. Niyogi. A kernel for semi-supervised learning with multi-view point cloud regularization. IEEE Signal Processing Magazine, 26(5):145-150, 2009.  M. J. Saberian and N. Vasconcelos. Multiclass boosting: Theory and algorithms. In Ad-  vances in Neural Information Processing Systems (NIPS), 2011.  B. Sch\u00a8olkopf and A. Smola. Learning with kernels: Support Vector Machines, Regulariza-  tion, Optimization, and Beyond. The MIT Press, Cambridge, 2002.  J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. Cambridge  University Press, 2004.  regularization. (ICML), 2008.  V. Sindhwani and D. Rosenberg. An RKHS for multi-view learning and manifold co- In Proceedings of the International Conference on Machine Learning Minh, Bazzani, and Murino  V. Sindhwani, H.Q. Minh, and A.C. Lozano. Scalable matrix-valued kernel learning for high-dimensional nonlinear multivariate regression and granger causality. In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2013.  S. Sun. Multi-view Laplacian support vector machines. In Proceedings of the International  Conference on Advanced Data Mining and Applications (ADMA), 2011.  A. Vedaldi, V. Gulshan, M. Varma, and A. Zisserman. Multiple kernels for object detection.  In Proceedings of the International Conference on Computer Vision (ICCV), 2009.  C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. The Caltech-UCSD Birds- 200-2011 dataset. Technical report, California Institute of Technology, 2011. URL http: //www.vision.caltech.edu/visipedia/CUB-200-2011.html.  G. Wahba. Practical approximate solutions to linear operator equations when the data are  noisy. SIAM Journal on Numerical Analysis, 14(4):651-667, 1977.  J. Weston and C. Watkins. Support vector machines for multi-class pattern recognition. In Proceedings of the European Symposium on Artificial Neural Networks (ESANN), 1999.  T.T. Wu and K. Lange. Multicategory vertex discriminant analysis for high-dimensional  data. The Annals of Applied Statistics, 4(4):1698-1721, 2010.  F. Yan, J. Kittler, K. Mikolajczyk, and A. Tahir. Non-sparse multiple kernel Fisher dis-  criminant analysis. Journal of Machine Learning Research, 13:607-642, 2012.  J. Yang, Y. Li, Y. Tian, L. Duan, and W. Gao. Group-sensitive multiple kernel learning for object categorization. In Proceedings of the International Conference on Computer Vision (ICCV), 2009.  M. Zeiler and R. Fergus. Visualizing and understanding convolutional networks. In Pro-  ceedings of the European Conference on Computer Vision (ECCV), 2014.  H. Zhang, Y. Xu, and Q. Zhang. Refinement of operator-valued reproducing kernels. Journal  of Machine Learning Research, 13:91-136, Jan 2012. "}, "Quantifying Uncertainty in Random Forests via Confidence Intervals and Hypothesis Tests": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-168.html", "header": "Quantifying Uncertainty in Random Forests via Confidence Intervals and Hypothesis Tests", "author": "Lucas Mentch, Giles Hooker", "time": "17(26):1\u221241, 2016.", "abstract": "This work develops formal statistical inference procedures for predictions generated by supervised learning ensembles. Ensemble methods based on bootstrapping, such as bagging and random forests, have improved the predictive accuracy of individual trees, but fail to provide a framework in which distributional results can be easily determined. Instead of aggregating full bootstrap samples, we consider predicting by averaging over trees built on subsamples of the training set and demonstrate that the resulting estimator takes the form of a U-statistic. As such, predictions for individual feature vectors are asymptotically normal, allowing for confidence intervals to accompany predictions. In practice, a subset of subsamples is used for computational speed; here our estimators take the form of incomplete U-statistics and equivalent results are derived. We further demonstrate that this setup provides a framework for testing the significance of features. Moreover, the internal estimation method we develop allows us to estimate the variance parameters and perform these inference procedures at no additional computational cost. Simulations and illustrations on a real data set are provided.", "pdf_url": "http://jmlr.org/papers/volume17/14-168/14-168.pdf"}, "Statistical-Computational Tradeoffs in Planted Problems and Submatrix Localization with a Growing Number of Clusters and Submatrices": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-330.html", "header": "Statistical-Computational Tradeoffs in Planted Problems and Submatrix Localization with a Growing Number of Clusters and Submatrices", "author": "Yudong Chen, Jiaming Xu", "time": "17(27):1\u221257, 2016.", "abstract": "", "pdf_url": "http://jmlr.org/papers/volume17/14-330/14-330.pdf"}, "Non-linear Causal Inference using Gaussianity Measures": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-375.html", "header": "Non-linear Causal Inference using Gaussianity Measures", "author": "Daniel Hern{\\'a}ndez-Lobato, Pablo Morales-Mombiela, David Lopez-Paz, Alberto Su{\\'a}rez", "time": "17(28):1\u221239, 2016.", "abstract": "We provide theoretical and empirical evidence for a type of asymmetry between causes and effects that is present when these are related via linear models contaminated with additive non- Gaussian noise. Assuming that the causes and the effects have the same distribution, we show that the distribution of the residuals of a linear fit in the anti-causal direction is closer to a Gaussian than the distribution of the residuals in the causal direction. This Gaussianization effect is characterized by reduction of the magnitude of the high-order cumulants and by an increment of the differential entropy of the residuals. The problem of non-linear causal inference is addressed by performing an embedding in an expanded feature space, in which the relation between causes and effects can be assumed to be linear. The effectiveness of a method to discriminate between causes and effects based on this type of asymmetry is illustrated in a variety of experiments using different measures of Gaussianity. The proposed method is shown to be competitive with state-of-the-art techniques for causal inference.", "pdf_url": "http://jmlr.org/papers/volume17/14-375/14-375.pdf"}, "Consistent Distribution-Free $K$-Sample and Independence Tests for Univariate Random Variables": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-441.html", "header": "Consistent Distribution-Free $K$-Sample and Independence Tests for Univariate Random Variables", "author": "Ruth Heller, Yair Heller, Shachar Kaufman, Barak Brill, Malka Gorfine", "time": "17(29):1\u221254, 2016.", "abstract": "A popular approach for testing if two univariate random variables are statistically independent consists of partitioning the sample space into bins, and evaluating a test statistic on the binned data. The partition size matters, and the optimal partition size is data dependent. While for detecting simple relationships coarse partitions may be best, for detecting complex relationships a great gain in power can be achieved by considering finer partitions. We suggest novel consistent distribution-free tests that are based on summation or maximization aggregation of scores over all partitions of a fixed size. We show that our test statistics based on summation can serve as good estimators of the mutual information. Moreover, we suggest regularized tests that aggregate over all partition sizes, and prove those are consistent too. We provide polynomial-time algorithms, which are critical for computing the suggested test statistics efficiently. We show that the power of the regularized tests is excellent compared to existing tests, and almost as powerful as the tests based on the optimal (yet unknown in practice) partition size, in simulations as well as on a real data example.", "pdf_url": "http://jmlr.org/papers/volume17/14-441/14-441.pdf"}, "A Gibbs Sampler for Learning DAGs": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-486.html", "header": "A Gibbs Sampler for Learning DAGs", "author": "Robert J. B. Goudie, Sach Mukherjee", "time": "17(30):1\u221239, 2016.", "abstract": "We propose a Gibbs sampler for structure learning in directed acyclic graph (DAG) models. The standard Markov chain Monte Carlo algorithms used for learning DAGs are random-walk Metropolis-Hastings samplers. These samplers are guaranteed to converge asymptotically but often mix slowly when exploring the large graph spaces that arise in structure learning. In each step, the sampler we propose draws entire sets of parents for multiple nodes from the appropriate conditional distribution. This provides an efficient way to make large moves in graph space, permitting faster mixing whilst retaining asymptotic guarantees of convergence. The conditional distribution is related to variable selection with candidate parents playing the role of covariates or inputs. We empirically examine the performance of the sampler using several simulated and real data examples. The proposed method gives robust results in diverse settings, outperforming several existing Bayesian and frequentist methods. In addition, our empirical results shed some light on the relative merits of Bayesian and constraint- based methods for structure learning.", "pdf_url": "http://jmlr.org/papers/volume17/14-486/14-486.pdf"}, "Dimension-free Concentration Bounds on Hankel Matrices for Spectral Learning": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-501.html", "header": "Dimension-free Concentration Bounds on Hankel Matrices for Spectral Learning", "author": "Fran\u00c3\u00a7ois Denis, Mattias Gybels, Amaury Habrard", "time": "17(31):1\u221232, 2016.", "abstract": "Learning probabilistic models over strings is an important issue for many applications. Spectral methods propose elegant solutions to the problem of inferring weighted automata from finite samples of variable-length strings drawn from an unknown target distribution $p$. These methods rely on a singular value decomposition of a matrix $\\v{H}_S$, called the empirical Hankel matrix, that records the frequencies of (some of) the observed strings $S$. The accuracy of the learned distribution depends both on the quantity of information embedded in $\\v{H}_S$ and on the distance between $\\v{H}_S$ and its mean $\\v{H}_p$. Existing concentration bounds seem to indicate that the concentration over $\\v{H}_p$ gets looser with its dimensions, suggesting that it might be necessary to bound the dimensions of $\\v{H}_S$ for learning. We prove new  dimension-free  concentration bounds for classical Hankel matrices and several variants, based on prefixes or factors of strings, that are useful for learning. Experiments demonstrate that these bounds are tight and that they significantly improve existing (dimension-dependent) bounds. One consequence of these results is that the spectral learning approach remains consistent even if all the observations are recorded within the empirical matrix.", "pdf_url": "http://jmlr.org/papers/volume17/14-501/14-501.pdf"}, "Distinguishing Cause from Effect Using Observational Data: Methods and Benchmarks": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-518.html", "header": "Distinguishing Cause from Effect Using Observational Data: Methods and Benchmarks", "author": "Joris M. Mooij, Jonas Peters, Dominik Janzing, Jakob Zscheischler, Bernhard Sch\u00c3\u00b6lkopf", "time": "17(32):1\u2212102, 2016.", "abstract": "The discovery of causal relationships from purely observational data is a fundamental problem in science. The most elementary form of such a causal discovery problem is to decide whether $X$ causes $Y$ or, alternatively, $Y$ causes $X$, given joint observations of two variables $X,Y$. An example is to decide whether altitude causes temperature, or vice versa, given only joint measurements of both variables. Even under the simplifying assumptions of no confounding, no feedback loops, and no selection bias, such bivariate causal discovery problems are challenging. Nevertheless, several approaches for addressing those problems have been proposed in recent years. We review two families of such methods: methods based on Additive Noise Models (ANMs) and Information Geometric Causal Inference (IGCI). We present the benchmark  CauseEffectPairs  that consists of data for 100 different cause-effect pairs selected from 37 data sets from various domains (e.g., meteorology, biology, medicine, engineering, economy, etc.) and motivate our decisions regarding the ground truth causal directions of all pairs. We evaluate the performance of several bivariate causal discovery methods on these real-world benchmark data and in addition on artificially simulated data. Our empirical results on real-world data indicate that certain methods are indeed able to distinguish cause from effect using only purely observational data, although more benchmark data would be needed to obtain statistically significant conclusions. One of the best performing methods overall is the method based on Additive Noise Models that has originally been proposed by Hoyer et al. (2009), which obtains an accuracy of 63 $\\pm$ 10 % and an AUC of 0.74 $\\pm$ 0.05 on the real-world benchmark. As the main theoretical contribution of this work we prove the consistency of that method.  [ ][ ]", "pdf_url": "http://jmlr.org/papers/volume17/14-518/14-518.pdf"}, "OLPS: A Toolbox for On-Line Portfolio Selection": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-317.html", "header": "OLPS: A Toolbox for On-Line Portfolio Selection", "author": "Bin Li, Doyen Sahoo, Steven C.H. Hoi", "time": "17(35):1\u22125, 2016.", "abstract": "On-line portfolio selection is a practical financial engineering problem, which aims to sequentially allocate capital among a set of assets in order to maximize long-term return. In recent years, a variety of machine learning algorithms have been proposed to address this challenging problem, but no comprehensive open-source toolbox has been released for various reasons. This article presents the first open-source toolbox for \"On-Line Portfolio Selection\" (OLPS), which implements a collection of classical and state-of-the-art strategies powered by machine learning algorithms. We hope that OLPS can facilitate the development of new learning methods and enable the performance benchmarking and comparisons of different strategies. OLPS is an open-source project released under Apache License (version 2.0), which is available at  github.com/OLPS/OLPS  or  OLPS.stevenhoi.org .", "pdf_url": "http://jmlr.org/papers/volume17/15-317/15-317.pdf"}, "A Bounded p-norm Approximation of Max-Convolution for Sub-Quadratic Bayesian Inference on Additive Factors": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-319.html", "header": "A Bounded p-norm Approximation of Max-Convolution for Sub-Quadratic Bayesian Inference on Additive Factors", "author": "Julianus Pfeuffer, Oliver Serang", "time": "17(36):1\u221239, 2016.", "abstract": "Max-convolution is an important problem closely resembling standard convolution; as such, max-convolution occurs frequently across many fields. Here we extend the method with fastest known worst-case runtime, which can be applied to nonnegative vectors by numerically approximating the Chebyshev norm $\\| \\cdot \\|_\\infty$, and use this approach to derive two numerically stable methods based on the idea of computing $p$-norms via fast convolution: The first method proposed, with runtime in $O( k \\log(k) \\log(\\log(k)) )$ (which is less than $18 k \\log(k)$ for any vectors that can be practically realized), uses the $p$-norm as a direct approximation of the Chebyshev norm. The second approach proposed, with runtime in $O( k \\log(k) )$ (although in practice both perform similarly), uses a novel null space projection method, which extracts information from a sequence of $p$-norms to estimate the maximum value in the vector (this is equivalent to querying a small number of moments from a distribution of bounded support in order to estimate the maximum). The $p$-norm approaches are compared to one another and are shown to compute an approximation of the Viterbi path in a hidden Markov model where the transition matrix is a Toeplitz matrix; the runtime of approximating the Viterbi path is thus reduced from $O( n k^2 )$ steps to $O( n k \\log(k))$ steps in practice, and is demonstrated by inferring the U.S. unemployment rate from the S&P 500 stock index.", "pdf_url": "http://jmlr.org/papers/volume17/15-319/15-319.pdf"}, "Hybrid Orthogonal Projection and Estimation (HOPE): A New Framework to Learn Neural Networks": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-335.html", "header": "Hybrid Orthogonal Projection and Estimation (HOPE): A New Framework to Learn Neural Networks", "author": "Shiliang Zhang, Hui Jiang, Lirong Dai", "time": "17(37):1\u221233, 2016.", "abstract": "In this paper, we propose a novel model for high-dimensional data, called the  Hybrid Orthogonal Projection and Estimation (HOPE)  model, which combines a linear orthogonal projection and a finite mixture model under a unified generative modeling framework. The HOPE", "pdf_url": "http://jmlr.org/papers/volume17/15-335/15-335.pdf"}, "The Optimal Sample Complexity of PAC Learning": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-389.html", "header": "The Optimal Sample Complexity of PAC Learning", "author": "Steve Hanneke", "time": "17(38):1\u221215, 2016.", "abstract": "This work establishes a new upper bound on the number of samples sufficient for PAC learning in the realizable case. The bound matches known lower bounds up to numerical constant factors. This solves a long-standing open problem on the sample complexity of PAC learning. The technique and analysis build on a recent breakthrough by Hans Simon.", "pdf_url": "http://jmlr.org/papers/volume17/15-389/15-389.pdf"}, "End-to-End Training of Deep Visuomotor Policies": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-522.html", "header": "End-to-End Training of Deep Visuomotor Policies", "author": "Sergey Levine, Chelsea Finn, Trevor Darrell, Pieter Abbeel", "time": "17(39):1\u221240, 2016.", "abstract": "Policy search methods can allow robots to learn control policies for a wide range of tasks, but practical applications of policy search often require hand-engineered components for perception, state estimation, and low-level control. In this paper, we aim to answer the following question: does training the perception and control systems jointly end-to-end provide better performance than training each component separately? To this end, we develop a method that can be used to learn policies that map raw image observations directly to torques at the robot's motors. The policies are represented by deep convolutional neural networks (CNNs) with 92,000 parameters, and are trained using a guided policy search method, which transforms policy search into supervised learning, with supervision provided by a simple trajectory-centric reinforcement learning method. We evaluate our method on a range of real-world manipulation tasks that require close coordination between vision and control, such as screwing a cap onto a bottle, and present simulated comparisons to a range of prior policy search methods.", "pdf_url": "http://jmlr.org/papers/volume17/15-522/15-522.pdf"}, "On Quantile Regression in Reproducing Kernel Hilbert Spaces with the Data Sparsity Constraint": {"volumn": 17, "url": "http://jmlr.org/papers/v17/zhang16a.html", "header": "On Quantile Regression in Reproducing Kernel Hilbert Spaces with the Data Sparsity Constraint", "author": "Chong Zhang, Yufeng Liu, Yichao Wu", "time": "17(40):1\u221245, 2016.", "abstract": "For spline regressions, it is well known that the choice of knots is crucial for the performance of the estimator. As a general learning framework covering the smoothing splines, learning in a Reproducing Kernel Hilbert Space (RKHS) has a similar issue. However, the selection of training data points for kernel functions in the RKHS representation has not been carefully studied in the literature. In this paper we study quantile regression as an example of learning in a RKHS. In this case, the regular squared norm penalty does not perform training data selection. We propose a data sparsity constraint that imposes thresholding on the kernel function coefficients to achieve a sparse kernel function representation. We demonstrate that the proposed data sparsity method can have competitive prediction performance for certain situations, and have comparable performance in other cases compared to that of the traditional squared norm penalty. Therefore, the data sparsity method can serve as a competitive alternative to the squared norm penalty method. Some theoretical properties of our proposed method using the data sparsity constraint are obtained. Both simulated and real data sets are used to demonstrate the usefulness of our data sparsity constraint.", "pdf_url": "http://jmlr.org/papers/volume17/zhang16a/zhang16a.pdf"}, "BayesPy: Variational Bayesian Inference in Python": {"volumn": 17, "url": "http://jmlr.org/papers/v17/luttinen16a.html", "header": "BayesPy: Variational Bayesian Inference in Python", "author": "Jaakko Luttinen", "time": "17(41):1\u22126, 2016.", "abstract": "BayesPy is an open-source Python software package for performing variational Bayesian inference. It is based on the variational message passing framework and supports conjugate exponential family models. By removing the tedious task of implementing the variational Bayesian update equations, the user can construct models faster and in a less error-prone way. Simple syntax, flexible model construction and efficient inference make BayesPy suitable for both average and expert Bayesian users. It also supp", "pdf_url": "http://jmlr.org/papers/volume17/luttinen16a/luttinen16a.pdf"}, "On the Estimation of the Gradient Lines of a Density and the Consistency of the Mean-Shift Algorithm": {"volumn": 17, "url": "http://jmlr.org/papers/v17/ariascastro16a.html", "header": "On the Estimation of the Gradient Lines of a Density and the Consistency of the Mean-Shift Algorithm", "author": "Ery Arias-Castro, David Mason, Bruno Pelletier", "time": "17(43):1\u221228, 2016.", "abstract": "We consider the problem of estimating the gradient lines of a density, which can be used to cluster points sampled from that density, for example via the mean-shift algorithm of Fukunaga and Hostetler (1975). We prove general convergence bounds that we then specialize to kernel density estimation.", "pdf_url": "http://jmlr.org/papers/volume17/ariascastro16a/ariascastro16a.pdf"}, "A Unified View on Multi-class Support Vector Classification": {"volumn": 17, "url": "http://jmlr.org/papers/v17/11-229.html", "header": "A Unified View on Multi-class Support Vector Classification", "author": "{\\\"U}r\u00c3\u00bcn Do\\u{g}an, Tobias Glasmachers, Christian Igel", "time": "17(45):1\u221232, 2016.", "abstract": "", "pdf_url": "http://jmlr.org/papers/volume17/11-229/11-229.pdf"}, "Addressing Environment Non-Stationarity by Repeating Q-learning Updates": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-037.html", "header": "Addressing Environment Non-Stationarity by Repeating Q-learning Updates", "author": "Sherief Abdallah, Michael Kaisers", "time": "17(46):1\u221231, 2016.", "abstract": "", "pdf_url": "http://jmlr.org/papers/volume17/14-037/14-037.pdf"}, "Large Scale Online Kernel Learning": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-148.html", "header": "Large Scale Online Kernel Learning", "author": "Jing Lu, Steven C.H. Hoi, Jialei Wang, Peilin Zhao, Zhi-Yong Liu", "time": "17(47):1\u221243, 2016.", "abstract": "In this paper, we present a new framework for large scale online kernel learning, making kernel methods efficient and scalable for large-scale online learning applications. Unlike the regular budget online kernel learning scheme that usually uses some budget maintenance strategies to bound the number of support vectors, our framework explores a completely different approach of kernel functional approximation techniques to make the subsequent online learning task efficient and scalable. Specifically, we present two different online kernel machine learning algorithms: (i) Fourier Online Gradient Descent (FOGD) algorithm that applies the random Fourier features for approximating kernel functions; and (ii) Nystr\u00c3\u0083\u00c2\u00b6m Online Gradient Descent (NOGD) algorithm that applies the Nystr\u00c3\u0083\u00c2\u00b6m method to approximate large kernel matrices. We explore these two approaches to tackle three online learning tasks: binary classification, multi-class classification, and regression. The encouraging results of our experiments on large-scale datasets validate the effectiveness and efficiency of the proposed algorithms, making them potentially more practical than the family of existing budget online kernel learning approaches.", "pdf_url": "http://jmlr.org/papers/volume17/14-148/14-148.pdf"}, "Kernel Mean Shrinkage Estimators": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-195.html", "header": "Kernel Mean Shrinkage Estimators", "author": "Krikamol Mu, et, Bharath Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard Sch\u00c3\u00b6lkopf", "time": "17(48):1\u221241, 2016.", "abstract": "A mean function in a reproducing kernel Hilbert space (RKHS), or a kernel mean, is central to kernel methods in that it is used by many classical algorithms such as kernel principal component analysis, and it also forms the core inference step of modern kernel methods that rely on embedding probability distributions in RKHSs. Given a finite sample, an empirical average has been used commonly as a standard estimator of the true kernel mean. Despite a widespread use of this estimator, we show that it can be improved thanks to the well-known Stein phenomenon. We propose a new family of estimators called kernel mean shrinkage estimators (KMSEs), which benefit from both theoretical justifications and good empirical performance. The results demonstrate that the proposed estimators outperform the standard one, especially in a \"large $d$, small $n$\" paradigm.", "pdf_url": "http://jmlr.org/papers/volume17/14-195/14-195.pdf"}, "SPSD Matrix Approximation vis Column Selection: Theories, Algorithms, and Extensions": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-199.html", "header": "SPSD Matrix Approximation vis Column Selection: Theories, Algorithms, and Extensions", "author": "Shusen Wang, Luo Luo, Zhihua Zhang", "time": "17(49):1\u221249, 2016.", "abstract": "Symmetric positive semidefinite (SPSD) matrix approximation is an important problem with applications in kernel methods. However, existing SPSD matrix approximation methods such as the Nystr\u00c3\u0083\u00c2\u00b6m method only have weak error bounds. In this paper we conduct in-depth studies of an SPSD matrix approximation model and establish strong relative-error bounds. We call it the prototype model for it has more efficient and effective extensions, and some of its extensions have high scalability. Though the prototype model itself is not suitable for large- scale data, it is still useful to study its properties, on which the analysis of its extensions relies. This paper offers novel theoretical analysis, efficient algorithms, and a highly accurate extension. First, we establish a lower error bound for the prototype model and improve the error bound of an existing column selection algorithm to match the lower bound. In this way, we obtain the first optimal column selection algorithm for the prototype model. We also prove that the prototype model is exact under certain conditions. Second, we develop a simple column selection algorithm with a provable error bound. Third, we propose a so-called spectral shifting model to make the approximation more accurate when the eigenvalues of the matrix decay slowly, and the improvement is theoretically quantified. The spectral shifting method can also be applied to improve other SPSD matrix approximation models.", "pdf_url": "http://jmlr.org/papers/volume17/14-199/14-199.pdf"}, "Combinatorial Multi-Armed Bandit and Its Extension to Probabilistically Triggered Arms": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-298.html", "header": "Combinatorial Multi-Armed Bandit and Its Extension to Probabilistically Triggered Arms", "author": "Wei Chen, Yajun Wang, Yang Yuan, Qinshi Wang", "time": "17(50):1\u221233, 2016.", "abstract": "We define a general framework for a large class of combinatorial multi-armed bandit (CMAB) problems, where subsets of base arms with unknown distributions form  super arms . In each round, a super arm is played and the base arms contained in the super arm are played and their outcomes are observed. We further consider the extension in which more base arms could be probabilistically triggered based on the outcomes of already triggered arms. The reward of the super arm depends on the outcomes of all played arms, and it only needs to satisfy two mild assumptions, which allow a large class of nonlinear reward instances. We assume the availability of an offline $(\\alpha,\\beta)$-approximation oracle that takes the means of the outcome distributions of arms and outputs a super arm that with probability $\\beta$ generates an $\\alpha$ fraction of the optimal expected reward. The objective of an online learning algorithm for CMAB is to minimize  $(\\alpha,\\beta)$-approximation regret , which is the difference in total expected reward between the $\\alpha\\beta$ fraction of expected reward when always playing the optimal super arm, and the expected reward of playing super arms according to the algorithm. We provide CUCB algorithm that achieves $O(\\log n)$ distribution-dependent regret, where $n$ is the number of rounds played, and we further provide distribution-independent bounds for a large class of reward functions. Our regret analysis is tight in that it matches the bound of UCB1 algorithm (up to a constant factor) for the classical MAB problem, and it significantly improves the regret bound in an earlier paper on combinatorial bandits with linear rewards. We apply our CMAB framework to two new applications, probabilistic maximum coverage (PMC) for online advertising and social influence maximization for viral marketing, both having nonlinear reward structures. In particular, application to social influence maximization requires our extension on probabilistically triggered arms.", "pdf_url": "http://jmlr.org/papers/volume17/14-298/14-298.pdf"}, "Differentially Private Data Releasing for Smooth Queries": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-388.html", "header": "Differentially Private Data Releasing for Smooth Queries", "author": "Ziteng Wang, Chi Jin, Kai Fan, Jiaqi Zhang, Junliang Huang, Yiqiao Zhong, Liwei Wang", "time": "17(51):1\u221242, 2016.", "abstract": "In the past few years, differential privacy has become a standard concept in the area of privacy. One of the most important problems in this field is to answer queries while preserving differential privacy. In spite of extensive studies, most existing work on differentially private query answering assumes the data are  discrete  (i.e., in $\\{0,1\\}^d$) and focuses on queries induced by \\emph{Boolean} functions. In real applications however,  continuous  data are at least as common as binary data. Thus, in this work we explore a less studied topic, namely, differential privately query answering for continuous data with continuous function. As a first step towards the continuous case, we study a natural class of linear queries on continuous data which we refer to as  smooth  queries. A linear query is said to be $K$-smooth if it is specified by a function defined on $[-1,1]^d$ whose partial derivatives up to order $K$ are all bounded. We develop two $\\epsilon$-differentially private mechanisms which are able to answer  all  smooth queries. The first mechanism outputs a summary of the database and can then give answers to the queries. The second mechanism is an improvement of the first one and it outputs a synthetic database. The two mechanisms both achieve an accuracy of $O (n^{-\\frac{K}{2d+K}}/\\epsilon )$. Here we assume that the dimension $d$ is a constant. It turns out that even in this parameter setting (which is almost trivial in the discrete case), using existing discrete mechanisms to answer the smooth queries is difficult and requires more noise. Our mechanisms are based on $L_{\\infty}$-approximation of (transformed) smooth functions by low-degree even trigonometric polynomials with uniformly bounded coefficients. We also develop practically efficient variants of the mechanisms with promising experimental results.", "pdf_url": "http://jmlr.org/papers/volume17/14-388/14-388.pdf"}, "Iterative Hessian Sketch: Fast and Accurate Solution Approximation for Constrained Least-Squares": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-460.html", "header": "Iterative Hessian Sketch: Fast and Accurate Solution Approximation for Constrained Least-Squares", "author": "Mert Pilanci, Martin J. Wainwright", "time": "17(53):1\u221238, 2016.", "abstract": "We study randomized sketching methods for approximately solving least-squares problem with a general convex constraint. The quality of a least-squares approximation can be assessed in different ways: either in terms of the value of the quadratic objective function (cost approximation), or in terms of some distance measure between the approximate minimizer and the true minimizer (solution approximation). Focusing on the latter criterion, our first main result provides a general lower bound on any randomized method that sketches both the data matrix and vector in a least-squares problem; as a surprising consequence, the most widely used least-squares sketch is sub-optimal for solution approximation. We then present a new method known as the  iterative Hessian sketch , and show that it can be used to obtain approximations to the original least-squares problem using a projection dimension proportional to the statistical complexity of the least-squares minimizer, and a logarithmic number of iterations. We illustrate our general theory with simulations for both unconstrained and constrained versions of least-squares, including $\\ell_1$-regularization and nuclear norm constraints. We also numerically demonstrate the practicality of our approach in a real face expression classification experiment.", "pdf_url": "http://jmlr.org/papers/volume17/14-460/14-460.pdf"}, "Estimating Causal Structure Using Conditional DAG Models": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-479.html", "header": "Estimating Causal Structure Using Conditional DAG Models", "author": "Chris. J. Oates, Jim Q. Smith, Sach Mukherjee", "time": "17(54):1\u221223, 2016.", "abstract": "This paper considers inference of causal structure in a class of graphical models called conditional DAGs. These are directed acyclic graph (DAG) models with two kinds of variables, primary and secondary. The secondary variables are used to aid in the estimation of the structure of causal relationships between the primary variables. We prove that, under certain", "pdf_url": "http://jmlr.org/papers/volume17/14-479/14-479.pdf"}, "Causal Inference through a Witness Protection Program": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-130.html", "header": "Causal Inference through a Witness Protection Program", "author": "Ricardo Silva, Robin Evans", "time": "17(56):1\u221253, 2016.", "abstract": "One of the most fundamental problems in causal inference is the estimation of a causal effect when treatment and outcome are confounded. This is difficult in an observational study, because one has no direct evidence that all confounders have been adjusted for. We introduce a novel approach for estimating causal effects that exploits observational conditional independencies to suggest \u00c3\u00a2\u00c2\u0080\u00c2\u009cweak\u00c3\u00a2\u00c2\u0080\u00c2\u009d paths in an unknown causal graph. The widely used faithfulness condition of Spirtes et al. is relaxed to allow for varying degrees of \u00c3\u00a2\u00c2\u0080\u00c2\u009cpath cancellations\u00c3\u00a2\u00c2\u0080\u00c2\u009d that imply conditional independencies but do not rule out the existence of confounding causal paths. The output is a posterior distribution over bounds on the average causal effect via a linear programming approach and Bayesian inference. We claim this approach should be used in regular practice as a complement to other tools in observational studies.", "pdf_url": "http://jmlr.org/papers/volume17/15-130/15-130.pdf"}, "Structure Discovery in Bayesian Networks by Sampling Partial Orders": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-140.html", "header": "Structure Discovery in Bayesian Networks by Sampling Partial Orders", "author": "Teppo Niinim\\\"{a}ki, Pekka Parviainen, Mikko Koivisto", "time": "17(57):1\u221247, 2016.", "abstract": "We present methods based on Metropolis-coupled Markov chain Monte Carlo (MC3) and annealed importance sampling (AIS) for estimating the posterior distribution of Bayesian networks. The methods draw samples from an appropriate distribution of partial orders on the nodes, continued by sampling directed acyclic graphs (DAGs) conditionally on the sampled partial orders. We show that the computations needed for the sampling algorithms are feasible as long as the encountered partial orders have relatively few down-sets. While the algorithms assume suitable modularity properties of the priors, arbitrary priors can be handled by dividing the importance weight of each sampled DAG by the number of topological sorts it has---we give a practical dynamic programming algorithm to compute these numbers. Our empirical results demonstrate that the presented partial-order- based samplers are superior to previous Markov chain Monte Carlo methods, which sample DAGs either directly or via linear orders on the nodes. The results also suggest that the convergence rate of the estimators based on AIS are competitive to those of MC3. Thus AIS is the preferred method, as it enables easier large- scale parallelization and, in addition, supplies good probabilistic lower bound guarantees for the marginal likelihood of the model.", "pdf_url": "http://jmlr.org/papers/volume17/15-140/15-140.pdf"}, "Estimation from Pairwise Comparisons: Sharp Minimax Bounds with Topology Dependence": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-189.html", "header": "Estimation from Pairwise Comparisons: Sharp Minimax Bounds with Topology Dependence", "author": "Nihar B. Shah, Sivaraman Balakrishnan, Joseph Bradley, Abhay Parekh, Kannan Ramch, ran, Martin J. Wainwright", "time": "17(58):1\u221247, 2016.", "abstract": "Data in the form of pairwise comparisons arises in many domains, including preference elicitation, sporting competitions, and peer grading among others. We consider parametric ordinal models for such pairwise comparison data involving a latent vector $w^* \\in \\mathbb{R}^d$ that represents the \u00c3\u00a2\u00c2\u0080\u00c2\u009cqualities\u00c3\u00a2\u00c2\u0080\u00c2\u009d of the $d$ items being compared; this class of models includes the two most widely used parametric models---the Bradley-Terry-Luce (BTL) and the Thurstone models. Working within a standard minimax framework, we provide tight upper and lower bounds on the optimal error in estimating the quality score vector $w^*$ under this class of models. The bounds depend on the topology of the comparison graph induced by the subset of pairs being compared, via the spectrum of the Laplacian of the comparison graph. Thus, in settings where the subset of pairs may be chosen, our results provide principled guidelines for making this choice. Finally, we compare these error rates to those under cardinal measurement models and show that the error rates in the ordinal and cardinal settings have identical scalings apart from constant pre- factors.", "pdf_url": "http://jmlr.org/papers/volume17/15-189/15-189.pdf"}, "Domain-Adversarial Training of Neural Networks": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-239.html", "header": "Domain-Adversarial Training of Neural Networks", "author": "Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00c3\u00a7ois Laviolette, Mario March, Victor Lempitsky", "time": "17(59):1\u221235, 2016.", "abstract": "", "pdf_url": "http://jmlr.org/papers/volume17/15-239/15-239.pdf"}, "Probabilistic Low-Rank Matrix Completion from Quantized Measurements": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-273.html", "header": "Probabilistic Low-Rank Matrix Completion from Quantized Measurements", "author": "Sonia A. Bhaskar", "time": "17(60):1\u221234, 2016.", "abstract": "We consider the recovery of a low rank real-valued matrix $M$ given a subset of noisy discrete (or quantized) measurements. Such problems arise in several applications such as collaborative filtering, learning and content analytics, and sensor network localization. We consider constrained maximum likelihood estimation of $M$, under a constraint on the entry- wise infinity-norm of $M$ and an exact rank constraint. We provide upper bounds on the Frobenius norm of matrix estimation error under this model. Previous theoretical investigations have focused on binary (1-bit) quantizers, and been based on convex relaxation of the rank. Compared to the existing binary results, our performance upper bound has faster convergence rate with matrix dimensions when the fraction of revealed observations is fixed. We also propose a globally convergent optimization algorithm based on low rank factorization of $M$ and validate the method on synthetic and real data, with improved performance over previous methods.", "pdf_url": "http://jmlr.org/papers/volume17/15-273/15-273.pdf"}, "DSA: Decentralized Double Stochastic Averaging Gradient Algorithm": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-292.html", "header": "DSA: Decentralized Double Stochastic Averaging Gradient Algorithm", "author": "Aryan Mokhtari, Alejandro Ribeiro", "time": "17(61):1\u221235, 2016.", "abstract": "This paper considers optimization problems where nodes of a network have access to summands of a global objective. Each of these local objectives is further assumed to be an average of a finite set of functions. The motivation for this setup is to solve large scale machine learning problems where elements of the training set are distributed to multiple computational elements. The decentralized dou", "pdf_url": "http://jmlr.org/papers/volume17/15-292/15-292.pdf"}, "The Statistical Performance of Collaborative Inference": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-346.html", "header": "The Statistical Performance of Collaborative Inference", "author": "G\u00c3\u00a9rard Biau, Kevin Bleakley, Beno\u00c3\u00aet Cadre", "time": "17(62):1\u221229, 2016.", "abstract": "The statistical analysis of massive and complex data sets will require the development of algorithms that depend on distributed computing and collaborative inference. Inspired by this, we propose a collaborative framework that aims to estimate the unknown mean $\\theta$ of a random variable $X$. In the model we present, a certain number of calculation units, distributed across a communication network represented by a graph, participate in the estimation of $\\theta$ by sequentially receiving independent data from $X$ while exchanging messages via a stochastic matrix $A$ defined over the graph. We give precise conditions on the matrix $A$ under which the statistical precision of the individual units is comparable to that of a (gold standard) virtual centralized estimate, even though each unit does not have access to all of the data. We show in particular the fundamental role played by both the non-trivial eigenvalues of $A$ and the Ramanujan class of expander graphs, which provide remarkable performance for moderate algorithmic cost.", "pdf_url": "http://jmlr.org/papers/volume17/15-346/15-346.pdf"}, "Convergence of an Alternating Maximization Procedure": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-392.html", "header": "Convergence of an Alternating Maximization Procedure", "author": "Andreas Andresen, Vladimir Spokoiny", "time": "17(63):1\u221253, 2016.", "abstract": "We derive two convergence results for a sequential alternating maximization procedure to approximate the maximizer of random functionals such as the realized log likelihood in MLE estimation. We manage to show that the sequence attains the same deviation properties as shown for the profile M-estimator by Andresen and Spokoiny (2013), that means a finite sample Wilks and Fisher theorem. Further under slightly stronger smoothness constraints on the random functional we can show nearly linear convergence to the global maximizer if the starting point for the procedure is well chosen.", "pdf_url": "http://jmlr.org/papers/volume17/15-392/15-392.pdf"}, "StructED: Risk Minimization in Structured Prediction": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-531.html", "header": "StructED: Risk Minimization in Structured Prediction", "author": "Yossi Adi, Joseph Keshet", "time": "17(64):1\u22125, 2016.", "abstract": "Structured tasks are distinctive: each task has its own measure of performance, such as the word error rate in speech recognition, the BLEU score in machine translation, the NDCG score in information retrieval, or the intersection-over-union score in visual object segmentation. This paper presents StructED, a software package for learning structured prediction models with training methods that aimed at optimizing the task measure of performance. The package was written in Java and released under the MIT license. It can be downloaded from   adiyoss.github.io/StructED .", "pdf_url": "http://jmlr.org/papers/volume17/15-531/15-531.pdf"}, "Bayesian Policy Gradient and Actor-Critic Algorithms": {"volumn": 17, "url": "http://jmlr.org/papers/v17/10-245.html", "header": "Bayesian Policy Gradient and Actor-Critic Algorithms", "author": "Mohammad Ghavamzadeh, Yaakov Engel, Michal Valko", "time": "17(66):1\u221253, 2016.", "abstract": "Policy gradient methods are reinforcement learning algorithms that adapt a parameterized policy by following a performance gradient estimate. Many conventional policy gradient methods use Monte-Carlo techniques to estimate this gradient. The policy is improved by adjusting the parameters in the direction of the gradient estimate. Since Monte-Carlo methods tend to have high variance, a large number of samples is required to attain accurate estimates, resulting in slow convergence. In this paper, we first propose a Bayesian framework for policy gradient, based on modeling the policy gradient as a Gaussian process. This reduces the number of samples needed to obtain accurate gradient estimates. Moreover, estimates of the natural gradient as well as a measure of the uncertainty in the gradient estimates, namely, the gradient covariance, are provided at little extra cost. Since the proposed Bayesian framework considers system trajectories as its basic observable unit, it does not require the dynamics within trajectories to be of any particular form, and thus, can be easily extended to partially observable problems. On the downside, it cannot take advantage of the Markov property when the system is Markovian. To address this issue, we proceed to supplement our Bayesian policy gradient framework with a new actor-critic learning model in which a Bayesian class of non- parametric critics, based on Gaussian process temporal difference learning, is used. Such critics model the action- value function as a Gaussian process, allowing Bayes' rule to be used in computing the posterior distribution over action-value functions, conditioned on the observed data. Appropriate choices of the policy parameterization and of the prior covariance (kernel) between action-values allow us to obtain closed-form expressions for the posterior distribution of the gradient of the expected return with respect to the policy parameters. We perform detailed experimental comparisons of the proposed Bayesian policy gradient and actor-critic algorithms with classic Monte-Carlo based policy gradient methods, as well as with each other, on a number of reinforcement learning problems.", "pdf_url": "http://jmlr.org/papers/volume17/10-245/10-245.pdf"}, "Practical Kernel-Based Reinforcement Learning": {"volumn": 17, "url": "http://jmlr.org/papers/v17/13-134.html", "header": "Practical Kernel-Based Reinforcement Learning", "author": "Andr\u00c3\u00a9 M.S. Barreto, Doina Precup, Joelle Pineau", "time": "17(67):1\u221270, 2016.", "abstract": "Kernel-based reinforcement learning  (KBRL) stands out among approximate reinforcement learning algorithms for its strong theoretical guarantees. By casting the learning problem as a local kernel approximation, KBRL provides a way of computing a decision policy which converges to a unique solution and is statistically consistent. Unfortunately, the model constructed by KBRL grows with the number of sample transitions, resulting in a computational cost that precludes its application to large-scale or on-line domains. In this paper we introduce an algorithm that turns KBRL into a practical reinforcement learning tool.  Kernel-based stochastic factorization  (KBSF) builds on a simple idea: when a transition probability matrix is represented as the product of two stochastic matrices, one can swap the factors of the multiplication to obtain another transition matrix, potentially much smaller than the original, which retains some fundamental properties of its precursor. KBSF exploits such an insight to compress the information contained in KBRL's model into an approximator of fixed size. This makes it possible to build an approximation considering both the difficulty of the problem and the associated computational cost. KBSF's computational complexity is linear in the number of sample transitions, which is the best one can do without discarding data. Moreover, the algorithm's simple mechanics allow for a fully incremental implementation that makes the amount of memory used independent of the number of sample transitions. The result is a kernel-based reinforcement learning algorithm that can be applied to large-scale problems in both off-line and on-line regimes. We derive upper bounds for the distance between the value functions computed by KBRL and KBSF using the same data. We also prove that it is possible to control the magnitude of the variables appearing in our bounds, which means that, given enough computational resources, we can make KBSF's value function as close as desired to the value function that would be computed by KBRL using the same set of sample transitions. The potential of our algorithm is demonstrated in an extensive empirical study in which KBSF is applied to difficult tasks based on real-world data. Not only does KBSF solve problems that had never been solved before, but it also significantly outperforms other state-of-the-art reinforcement learning algorithms on the tasks studied.", "pdf_url": "http://jmlr.org/papers/volume17/13-134/13-134.pdf"}, "An Information-Theoretic Analysis of Thompson Sampling": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-087.html", "header": "An Information-Theoretic Analysis of Thompson Sampling", "author": "Daniel Russo, Benjamin Van Roy", "time": "17(68):1\u221230, 2016.", "abstract": "We provide an information-theoretic analysis of Thompson sampling that applies across a broad range of online optimization problems in which a decision-maker must learn from partial feedback. This analysis inherits the simplicity and elegance of information theory and leads to regret bounds that scale with the entropy of the optimal-action distribution. This strengthens preexisting results and yields new insight into how information improves performance.", "pdf_url": "http://jmlr.org/papers/volume17/14-087/14-087.pdf"}, "Compressed Gaussian Process for Manifold Regression": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-230.html", "header": "Compressed Gaussian Process for Manifold Regression", "author": "Rajarshi Guhaniyogi, David B. Dunson", "time": "17(69):1\u221226, 2016.", "abstract": "Nonparametric regression for large numbers of features ($p$) is an increasingly important problem. If the sample size $n$ is massive, a common strategy is to partition the feature space, and then separately apply simple models to each partition set. This is not ideal when $n$ is modest relative to $p$, and we propose an alternative approach relying on random compression of the feature vector combined with Gaussian process regression. The proposed approach is particularly motivated by the setting in which the response is conditionally independent of the features given the projection to a low dimensional manifold. Conditionally on the random compression matrix and a smoothness parameter, the posterior distribution for the regression surface and posterior predictive distributions are available analytically. Running the analysis in parallel for many random compression matrices and smoothness parameters, model averaging is used to combine the results. The algorithm can be implemented rapidly even in very large $p$ and moderately large $n$ nonparametric regression, has strong theoretical justification, and is found to yield state of the art predictive performance.", "pdf_url": "http://jmlr.org/papers/volume17/14-230/14-230.pdf"}, "On the Characterization of a Class of Fisher-Consistent Loss Functions and its Application to Boosting": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-306.html", "header": "On the Characterization of a Class of Fisher-Consistent Loss Functions and its Application to Boosting", "author": "Matey Neykov, Jun S. Liu, Tianxi Cai", "time": "17(70):1\u221232, 2016.", "abstract": "Accurate classification of categorical outcomes is essential in a wide range of applications. Due to computational issues with minimizing the empirical 0/1 loss, Fisher consistent losses have been proposed as viable proxies. However, even with smooth losses, direct minimization remains a daunting task. To approximate such a minimizer, various boosting algorithms have been suggested. For example, with exponential loss, the AdaBoost algorithm (Freund and Schapire, 1995) is widely used for two- class problems and has been extended to the multi-class setting (Zhu et al., 2009). Alternative loss functions, such as the logistic and the hinge losses, and their corresponding boosting algorithms have also been proposed (Zou et al., 2008; Wang, 2012).  In this paper we demonstrate that a broad class of losses, including non-convex functions, achieve Fisher consistency, and in addition can be used for explicit estimation of the conditional class probabilities. Furthermore, we provide a generic boosting algorithm that is not loss-specific. Extensive simulation results suggest that the proposed boosting algorithms could outperform existing methods with properly chosen losses and bags of weak learners.", "pdf_url": "http://jmlr.org/papers/volume17/14-306/14-306.pdf"}, "Exact Inference on Gaussian Graphical Models of Arbitrary Topology using Path-Sums": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-445.html", "header": "Exact Inference on Gaussian Graphical Models of Arbitrary Topology using Path-Sums", "author": "P.-L. Giscard, Z. Choo, S. J. Thwaite, D. Jaksch", "time": "17(71):1\u221219, 2016.", "abstract": "We present the path-sum formulation for exact statistical inference of marginals on Gaussian graphical models of arbitrary topology. The path-sum formulation gives the covariance between each pair of variables as a branched continued fraction of finite depth and breadth. Our method originates from the closed- form resummation of infinite families of terms of the walk-sum representation of the covariance matrix. We prove that the path- sum formulation always exists for models whose covariance matrix is positive definite: i.e. it is valid for both walk-summable and non-walk-summable graphical models of arbitrary topology. We show that for graphical models on trees the path-sum formulation is equivalent to Gaussian belief propagation. We also recover, as a corollary, an existing result that uses determinants to calculate the covariance matrix. We show that the path-sum formulation formulation is valid for arbitrary partitions of the inverse covariance matrix. We give detailed examples demonstrating our results.", "pdf_url": "http://jmlr.org/papers/volume17/14-445/14-445.pdf"}, "Challenges in multimodal gesture recognition": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-468.html", "header": "Challenges in multimodal gesture recognition", "author": "Sergio Escalera, Vassilis Athitsos, Isabelle Guyon", "time": "17(72):1\u221254, 2016.", "abstract": "This paper surveys the state of the art on multimodal gesture recognition and introduces the JMLR special topic on gesture recognition 2011-2015. We began right at the start of the \\kinect revolution when inexpensive infrared cameras providing image depth recordings became available. We published papers using this technology and other more conventional methods, including regular video cameras, to record data, thus providing a good overview of uses of machine learning and computer vision using multimodal data in this area of application. Notably, we organized a series of challenges and made available several datasets we recorded for that purpose, including tens of thousands of videos, which are available to conduct further research. We also overview recent state of the art works on gesture recognition based on a proposed taxonomy for gesture recognition, discussing challenges and future lines of research.", "pdf_url": "http://jmlr.org/papers/volume17/14-468/14-468.pdf"}, "An Emphatic Approach to the Problem of Off-policy Temporal-Difference Learning": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-488.html", "header": "An Emphatic Approach to the Problem of Off-policy Temporal-Difference Learning", "author": "Richard S. Sutton, A. Rupam Mahmood, Martha White", "time": "17(73):1\u221229, 2016.", "abstract": "In this paper we introduce the idea of improving the performance of parametric temporal-difference (TD) learning algorithms by selectively emphasizing or de-emphasizing their updates on different time steps. In particular, we show that varying the emphasis of linear TD($\\lambda$)'s updates in a particular way causes its expected update to become stable under off-policy training. The only prior model-free TD methods to achieve this with per- step computation linear in the number of function approximation parameters are the gradient-TD family of methods including TDC, GTD($\\lambda$), and GQ$\\lambda$). Compared to these methods, our  emphatic TD($\\lambda$)  is simpler and easier to use; it has only one learned parameter vector and one step-size parameter. Our treatment includes general state- dependent discounting and bootstrapping functions, and a way of specifying varying degrees of interest in accurately valuing different states.", "pdf_url": "http://jmlr.org/papers/volume17/14-488/14-488.pdf"}, "Learning Algorithms for Second-Price Auctions with Reserve": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-499.html", "header": "Learning Algorithms for Second-Price Auctions with Reserve", "author": "Mehryar Mohri, Andres Munoz Medina", "time": "17(74):1\u221225, 2016.", "abstract": "Second-price auctions with reserve play a critical role in the revenue of modern search engine and popular online sites since the revenue of these companies often directly depends on the outcome of such auctions. The choice of the reserve price is the main mechanism through which the auction revenue can be influenced in these electronic markets. We cast the problem of selecting the reserve price to optimize revenue as a learning problem and present a full theoretical analysis dealing with the complex properties of the corresponding loss function. We further give novel algorithms for solving this problem and report the results of several experiments in both synthetic and real-world data demonstrating their effectiveness.", "pdf_url": "http://jmlr.org/papers/volume17/14-499/14-499.pdf"}, "Distributed Coordinate Descent Method for Learning with Big Data": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-001.html", "header": "Distributed Coordinate Descent Method for Learning with Big Data", "author": "Peter Richt\u00c3\u00a1rik, Martin Tak\u00c3\u00a1\u00c4\u008d", "time": "17(75):1\u221225, 2016.", "abstract": "In this paper we develop and analyze Hydra: HYbriD cooRdinAte descent method for solving loss minimization problems with big data. We initially partition the coordinates (features) and assign each partition to a different node of a cluster. At every iteration, each node picks a random subset of the coordinates from those it owns, independently from the other computers, and in parallel computes and applies updates to the selected coordinates based on a simple closed-form formula. We give bounds on the number of iterations sufficient to approximately solve the problem with high probability, and show how it depends on the data and on the partitioning. We perform numerical experiments with a LASSO instance described by a 3TB matrix.", "pdf_url": "http://jmlr.org/papers/volume17/15-001/15-001.pdf"}, "Scaling-up Empirical Risk Minimization: Optimization of Incomplete $U$-statistics": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-012.html", "header": "Scaling-up Empirical Risk Minimization: Optimization of Incomplete $U$-statistics", "author": "Stephan Cl\u00c3\u00a9men\u00c3\u00a7on, Igor Colin, Aur\u00c3\u00a9lien Bellet", "time": "17(76):1\u221236, 2016.", "abstract": "In a wide range of statistical learning problems such as ranking, clustering or metric learning among others, the risk is accurately estimated by $U$-statistics of degree $d\\geq 1$, i.e. functionals of the training data with low variance that take the form of averages over $k$-tuples. From a computational perspective, the calculation of such statistics is highly expensive even for a moderate sample size $n$, as it requires averaging $O(n^d)$ terms. This makes learning procedures relying on the optimization of such data functionals hardly feasible in practice. It is the major goal of this paper to show that, strikingly, such empirical risks can be replaced by drastically computationally simpler Monte-Carlo estimates based on $O(n)$ terms only, usually referred to as  incomplete $U$-statistics , without damaging the $O_{\\mathbb{P}}(1/\\sqrt{n})$ learning rate of  Empirical Risk Minimization  (ERM) procedures. For this purpose, we establish uniform deviation results describing the error made when approximating a $U$-process by its incomplete version under appropriate complexity assumptions. Extensions to model selection, fast rate situations and various sampling techniques are also considered, as well as an application to stochastic gradient descent for ERM. Finally, numerical examples are displayed in order to provide strong empirical evidence that the approach we promote largely surpasses more naive subsampling techniques.", "pdf_url": "http://jmlr.org/papers/volume17/15-012/15-012.pdf"}, "Iterative Regularization for Learning with Convex Loss Functions": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-115.html", "header": "Iterative Regularization for Learning with Convex Loss Functions", "author": "Junhong Lin, Lorenzo Rosasco, Ding-Xuan Zhou", "time": "17(77):1\u221238, 2016.", "abstract": "We consider the problem of supervised learning with convex loss functions and propose a new form of iterative regularization based on the subgradient method. Unlike other regularization approaches, in iterative regularization no constraint or penalization is considered, and generalization is achieved by (early) stopping an empirical iteration. We consider a nonparametric setting, in the framework of reproducing kernel Hilbert spaces, and prove consistency and finite sample bounds on the excess risk under general regularity conditions. Our study provides a new class of efficient regularized learning algorithms and gives insights on the interplay between statistics and optimization in machine learning.", "pdf_url": "http://jmlr.org/papers/volume17/15-115/15-115.pdf"}, "Latent Space Inference of Internet-Scale Networks": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-142.html", "header": "Latent Space Inference of Internet-Scale Networks", "author": "Qirong Ho, Junming Yin, Eric P. Xing", "time": "17(78):1\u221241, 2016.", "abstract": "The rise of Internet-scale networks, such as web graphs and social media with hundreds of millions to billions of nodes, presents new scientific opportunities, such as overlapping community detection to discover the structure of the Internet, or to analyze trends in online social behavior. However, many existing probabilistic network models are difficult or impossible to deploy at these massive scales. We propose a scalable approach for modeling and inferring latent spaces in Internet-scale networks, with an eye towards overlapping community detection as a key application. By applying a succinct representation of networks as a bag of triangular motifs, developing a parsimonious statistical model, deriving an efficient stochastic variational inference algorithm, and implementing it as a distributed cluster program via the Petuum parameter server system, we demonstrate overlapping community detection on real networks with up to 100 million nodes and 1000 communities on 5 machines in under 40 hours. Compared to other state-of-the-art probabilistic network approaches, our method is several orders of magnitude faster, with competitive or improved accuracy at overlapping community detection.", "pdf_url": "http://jmlr.org/papers/volume17/15-142/15-142.pdf"}, "Patient Risk Stratification with Time-Varying Parameters: A Multitask Learning Approach": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-177.html", "header": "Patient Risk Stratification with Time-Varying Parameters: A Multitask Learning Approach", "author": "Jenna Wiens, John Guttag, Eric Horvitz", "time": "17(79):1\u221223, 2016.", "abstract": "The proliferation of electronic health records (EHRs) frames opportunities for using machine learning to build models that help healthcare providers improve patient outcomes. However, building useful risk stratification models presents many technical challenges including the large number of factors (both intrinsic and extrinsic) influencing a patient's risk of an adverse outcome and the inherent evolution of that risk over time. We address these challenges in the context of learning a risk stratification model for predicting which patients are at risk of acquiring a  Clostridium difficile  infection (CDI). We take a novel data-centric approach, leveraging the contents of EHRs from nearly 50,000 hospital admissions. We show how, by adapting techniques from multitask learning, we can learn models for patient risk stratification with unprecedented classification performance. Our model, based on thousands of variables, both time-varying and time-invariant, changes over the course of a patient admission. Applied to a held out set of approximately 25,000 patient admissions, we achieve an area under the receiver operating characteristic curve of 0.81 (95% CI 0.78-0.84). The model has been integrated into the health record system at a large hospital in the US, and can be used to produce daily risk estimates for each inpatient. While more complex than traditional risk stratification methods, the widespread development and use of such data-driven models could ultimately enable cost-effective, targeted prevention strategies that lead to better patient outcomes.", "pdf_url": "http://jmlr.org/papers/volume17/15-177/15-177.pdf"}, "Multiplicative Multitask Feature Learning": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-234.html", "header": "Multiplicative Multitask Feature Learning", "author": "Xin Wang, Jinbo Bi, Shipeng Yu, Jiangwen Sun, Minghu Song", "time": "17(80):1\u221233, 2016.", "abstract": "We investigate a general framework of multiplicative multitask feature learning which decomposes individual task's model parameters into a multiplication of two components. One of the components is used across all tasks and the other component is task-specific. Several previous methods can be proved to be special cases of our framework. We study the theoretical properties of this framework when different regularization conditions are applied to the two decomposed components. We prove that this framework is mathematically equivalent to the widely used multitask feature learning methods that are based on a joint regularization of all model parameters, but with a more general form of regularizers. Further, an analytical formula is derived for the across-task component as related to the task- specific component for all these regularizers, leading to a better understanding of the shrinkage effects of different regularizers. Study of this framework motivates new multitask learning algorithms. We propose two new learning formulations by varying the parameters in the proposed framework. An efficient blockwise coordinate descent algorithm is developed suitable for solving the entire family of formulations with rigorous convergence analysis. Simulation studies have identified the statistical properties of data that would be in favor of the new formulations. Extensive empirical studies on various classification and regression benchmark data sets have revealed the relative advantages of the two new formulations by comparing with the state of the art, which provides instructive insights into the feature learning problem with multiple tasks.", "pdf_url": "http://jmlr.org/papers/volume17/15-234/15-234.pdf"}, "The Benefit of Multitask Representation Learning": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-242.html", "header": "The Benefit of Multitask Representation Learning", "author": "Andreas Maurer, Massimiliano Pontil, Bernardino Romera-Paredes", "time": "17(81):1\u221232, 2016.", "abstract": "We discuss a general method to learn data representations from multiple tasks. We provide a justification for this method in both settings of multitask learning and learning-to-learn. The method is illustrated in detail in the special case of linear feature learning. Conditions on the theoretical advantage offered by multitask representation learning over independent task learning are established. In particular, focusing on the important example of half-space learning, we derive the regime in which multitask representation learning is beneficial over independent task learning, as a function of the sample size, the number of tasks and the intrinsic data dimensionality. Other potential applications of our results include multitask feature learning in reproducing kernel Hilbert spaces and multilayer, deep networks.", "pdf_url": "http://jmlr.org/papers/volume17/15-242/15-242.pdf"}, "Model-free Variable Selection in Reproducing Kernel Hilbert Space": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-390.html", "header": "Model-free Variable Selection in Reproducing Kernel Hilbert Space", "author": "Lei Yang, Shaogao Lv, Junhui Wang", "time": "17(82):1\u221224, 2016.", "abstract": "Variable selection is popular in high-dimensional data analysis to identify the truly informative variables. Many variable selection methods have been developed under various model assumptions. Whereas success has been widely reported in literature, their performances largely depend on validity of the assumed models, such as the linear or additive models. This article introduces a model-free variable selection method via learning the gradient functions. The idea is based on the equivalence between whether a variable is informative and whether its corresponding gradient function is substantially non-zero. The proposed variable selection method is then formulated in a framework of learning gradients in a flexible reproducing kernel Hilbert space. The key advantage of the proposed method is that it requires no explicit model assumption and allows for general variable effects. Its asymptotic estimation and selection consistencies are studied, which establish the convergence rate of the estimated sparse gradients and assure that the truly informative variables are correctly identified in probability. The effectiveness of the proposed method is also supported by a variety of simulated examples and two real-life examples.", "pdf_url": "http://jmlr.org/papers/volume17/15-390/15-390.pdf"}, "Lenient Learning in Independent-Learner Stochastic Cooperative Games": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-417.html", "header": "Lenient Learning in Independent-Learner Stochastic Cooperative Games", "author": "Ermo Wei, Sean Luke", "time": "17(84):1\u221242, 2016.", "abstract": "We introduce the  Lenient Multiagent Reinforcement Learning 2  (LMRL2) algorithm for independent-learner stochastic cooperative games. LMRL2 is designed to overcome a pathology called  relative overgeneralization , and to do so while still performing well in games with stochastic transitions, stochastic rewards, and miscoordination. We discuss the existing literature, then compare LMRL2 against other algorithms drawn from the literature which can be used for games of this kind: traditional (\u00c3\u00a2\u00c2\u0080\u00c2\u009cDistributed\u00c3\u00a2\u00c2\u0080\u00c2\u009d) Q-learning, Hysteretic Q-learning, WoLF-PHC, SOoN, and (for repeated games only) FMQ. The results show that LMRL2 is very effective in both of our measures (complete and correct policies), and is found in the top rank more often than any other technique. LMRL2 is also easy to tune: though it has many available parameters, almost all of them stay at default settings. Generally the algorithm is optimally tuned with a single parameter, if any. We then examine and discuss a number of side-issues and options for LMRL2.", "pdf_url": "http://jmlr.org/papers/volume17/15-417/15-417.pdf"}, "Structure-Leveraged Methods in Breast Cancer Risk Prediction": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-444.html", "header": "Structure-Leveraged Methods in Breast Cancer Risk Prediction", "author": "Jun Fan, Yirong Wu, Ming Yuan, David Page, Jie Liu, Irene M. Ong, Peggy Peissig, Elizabeth Burnside", "time": "17(85):1\u221215, 2016.", "abstract": "Predicting breast cancer risk has long been a goal of medical research in the pursuit of precision medicine. The goal of this study is to develop novel penalized methods to improve breast cancer risk prediction by leveraging structure information in electronic health records. We conducted a retrospective case- control study, garnering 49 mammography descriptors and 77 high- frequency/low-penetrance single-nucleotide polymorphisms (SNPs) from an existing personalized medicine data repository. Structured mammography reports and breast imaging features have long been part of a standard electronic health record (EHR), and genetic markers likely will be in the near future. Lasso and its variants are widely used approaches to integrated learning and feature selection, and our methodological contribution is to incorporate the dependence structure among the features into these approaches. More specifically, we propose a new methodology by combining group penalty and $\\ell^p$ ($1\\leq p\\leq2$) fusion penalty to improve breast cancer risk prediction, taking into account structure information in mammography descriptors and SNPs. We demonstrate that our method provides benefits that are both statistically significant and potentially significant to people's lives.", "pdf_url": "http://jmlr.org/papers/volume17/15-444/15-444.pdf"}, "L1-Regularized Least Squares for Support Recovery of High Dimensional Single Index Models with Gaussian Designs": {"volumn": 17, "url": "http://jmlr.org/papers/v17/16-006.html", "header": "L1-Regularized Least Squares for Support Recovery of High Dimensional Single Index Models with Gaussian Designs", "author": "Matey Neykov, Jun S. Liu, Tianxi Cai", "time": "17(87):1\u221237, 2016.", "abstract": "It is known that for a certain class of single index models (SIMs) $Y = f(X_{p \\times 1}^\\top\\beta_0, \\varepsilon)$, support recovery is impossible when $X \\sim \\mathcal{N}(0, I_{p \\times p})$ and a  model complexity adjusted sample size  is below a critical threshold. Recently, optimal algorithms based on Sliced Inverse Regression (SIR) were suggested. These algorithms work provably under the assumption that the design $X$ comes from an i.i.d. Gaussian distribution. In the present paper we analyze algorithms based on covariance screening and least squares with $L_1$ penalization (i.e. LASSO) and demonstrate that they can also enjoy optimal (up to a scalar) rescaled sample size in terms of support recovery, albeit under slightly different assumptions on $f$ and $\\varepsilon$ compared to the SIR based algorithms. Furthermore, we show more generally, that LASSO succeeds in recovering the signed support of $\\beta_0$ if $X \\sim \\mathcal{N}(0, \\Sigma)$, and the covariance $\\Sigma$ satisfies the irrepresentable condition. Our work extends existing results on the support recovery of LASSO for the linear model, to a more general class of SIMs.", "pdf_url": "http://jmlr.org/papers/volume17/16-006/16-006.pdf"}, "Spectral Ranking using Seriation": {"volumn": 17, "url": "http://jmlr.org/papers/v17/16-035.html", "header": "Spectral Ranking using Seriation", "author": "Fajwel Fogel, Alexandre d'Aspremont, Milan Vojnovic", "time": "17(88):1\u221245, 2016.", "abstract": "We describe a seriation algorithm for ranking a set of items given pairwise comparisons between these items. Intuitively, the algorithm assigns similar rankings to items that compare similarly with all others. It does so by constructing a similarity matrix from pairwise comparisons, using seriation methods to reorder this matrix and construct a ranking. We first show that this spectral seriation algorithm recovers the true ranking when all pairwise comparisons are observed and consistent with a total order. We then show that ranking reconstruction is still exact when some pairwise comparisons are corrupted or missing, and that seriation based spectral ranking is more robust to noise than classical scoring methods. Finally, we bound the ranking error when only a random subset of the comparions are observed. An additional benefit of the seriation formulation is that it allows us to solve semi-supervised ranking problems. Experiments on both synthetic and real datasets demonstrate that seriation based spectral ranking achieves competitive and in some cases superior performance compared to classical ranking methods.", "pdf_url": "http://jmlr.org/papers/volume17/16-035/16-035.pdf"}, "Sparsity and Error Analysis of Empirical Feature-Based Regularization Schemes": {"volumn": 17, "url": "http://jmlr.org/papers/v17/11-207.html", "header": "Sparsity and Error Analysis of Empirical Feature-Based Regularization Schemes", "author": "Xin Guo, Jun Fan, Ding-Xuan Zhou", "time": "17(89):1\u221234, 2016.", "abstract": "We consider a learning algorithm generated by a regularization scheme with a concave regularizer for the purpose of achieving sparsity and good learning rates in a least squares regression setting. The regularization is induced for linear combinations of empirical features, constructed in the literatures of kernel principal component analysis and kernel projection machines, based on kernels and samples. In addition to the separability of the involved optimization problem caused by the empirical features, we carry out sparsity and error analysis, giving bounds in the norm of the reproducing kernel Hilbert space, based on a priori conditions which do not require assumptions on sparsity in terms of any basis or system. In particular, we show that as the concave exponent $q$ of the concave regularizer increases to $1$, the learning ability of the algorithm improves. Some numerical simulations for both artificial and real MHC-peptide binding data involving the $\\ell^q$ regularizer and the SCAD penalty are presented to demonstrate the sparsity and error analysis.", "pdf_url": "http://jmlr.org/papers/volume17/11-207/11-207.pdf"}, "Estimating Diffusion Networks: Recovery Conditions, Sample Complexity and Soft-thresholding Algorithm": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-430.html", "header": "Estimating Diffusion Networks: Recovery Conditions, Sample Complexity and Soft-thresholding Algorithm", "author": "Manuel Gomez-Rodriguez, Le Song, Hadi Daneshm, Bernhard Sch\u00c3\u00b6lkopf", "time": "17(90):1\u221229, 2016.", "abstract": "Information spreads across social and technological networks, but often the network structures are hidden from us and we only observe the traces left by the diffusion  processes, called  cascades . Can we recover the hidden network structures from these observed cascades? What kind of cascades and how many cascades  do we need? Are there some network structures which are more difficult than others to recover? Can we design efficient inference algorithms with provable  guarantees? Despite the increasing availability of cascade data and methods for inferring networks from these data, a thorough theoretical understanding of the above questions  remains largely unexplored in the literature. In this paper, we investigate the network structure inference problem for a general family of continuous- time diffusion models  using an $\\ell_1$-regularized likelihood maximization framework.   We show that, as long as the cascade sampling process satisfies a natural incoherence condition, our framework can recover the correct network structure with high probability if we observe $O(d^3 \\log N)$ cascades, where $d$ is the maximum number of parents of a node and $N$ is the total number of nodes. Moreover, we develop a  simple and efficient soft-thresholding network inference algorithm which demonstrate the match between our theoretical prediction and empirical results. In practice, this new algorithm also outperforms other alternatives in terms of the accuracy of recovering hidden diffusion networks.", "pdf_url": "http://jmlr.org/papers/volume17/14-430/14-430.pdf"}, "Rounding-based Moves for Semi-Metric Labeling": {"volumn": 17, "url": "http://jmlr.org/papers/v17/14-454.html", "header": "Rounding-based Moves for Semi-Metric Labeling", "author": "M. Pawan Kumar, Puneet K. Dokania", "time": "17(91):1\u221242, 2016.", "abstract": "Semi-metric labeling is a special case of energy minimization for pairwise Markov random fields. The energy function consists of arbitrary unary potentials, and pairwise potentials that are proportional to a given semi-metric distance function over the label set. Popular methods for solving semi-metric labeling include (i) move-making algorithms, which iteratively solve a minimum $st$-cut problem; and (ii) the linear programming ( LP) relaxation based approach. In order to convert the fractional solution of the LP relaxation to an integer solution, several randomized rounding procedures have been developed in the literature. We consider a large class of parallel rounding procedures, and design move-making algorithms that closely mimic them. We prove that the multiplicative bound of a move-making algorithm exactly matches the approximation factor of the corresponding rounding procedure for any arbitrary distance function. Our analysis includes all known results for move- making algorithms as special cases.", "pdf_url": "http://jmlr.org/papers/volume17/14-454/14-454.pdf"}, "Rate Optimal Denoising of Simultaneously Sparse and Low Rank Matrices": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-134.html", "header": "Rate Optimal Denoising of Simultaneously Sparse and Low Rank Matrices", "author": "Dan Yang, Zongming Ma, Andreas Buja", "time": "17(92):1\u221227, 2016.", "abstract": "We study minimax rates for denoising simultaneously sparse and low rank matrices in high dimensions. We show that an iterative thresholding algorithm achieves (near) optimal rates adaptively under mild conditions for a large class of loss functions. Numerical experiments on synthetic datasets also demonstrate the competitive performance of the proposed method.", "pdf_url": "http://jmlr.org/papers/volume17/15-134/15-134.pdf"}, "Hierarchical Relative Entropy Policy Search": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-188.html", "header": "Hierarchical Relative Entropy Policy Search", "author": "Christian Daniel, Gerhard Neumann, Oliver Kroemer, Jan Peters", "time": "17(93):1\u221250, 2016.", "abstract": "Many reinforcement learning (RL) tasks, especially in robotics, consist of multiple sub-tasks that are strongly structured. Such task structures can be exploited by incorporating hierarchical policies that consist of gating networks and sub-policies. However, this concept has only been partially explored for real world settings and complete methods, derived from first principles, are needed. Real world settings are challenging due to large and continuous state-action spaces that are prohibitive for exhaustive sampling methods. We define the problem of learning sub-policies in continuous state action spaces as finding a hierarchical policy that is composed of a high-level gating policy to select the low-level sub-policies for execution by the agent. In order to efficiently share experience with all sub-policies, also called inter-policy learning, we treat these sub-policies as latent variables which allows for distribution of the update information between the sub-policies. We present three different variants of our algorithm, designed to be suitable for a wide variety of real world robot learning tasks and evaluate our algorithms in two real robot learning scenarios as well as several simulations and comparisons.", "pdf_url": "http://jmlr.org/papers/volume17/15-188/15-188.pdf"}, "Convex Regression with Interpretable Sharp Partitions": {"volumn": 17, "url": "http://jmlr.org/papers/v17/15-344.html", "header": "Convex Regression with Interpretable Sharp Partitions", "author": "Ashley Petersen, Noah Simon, Daniela Witten", "time": "17(94):1\u221231, 2016.", "abstract": "We consider the problem of predicting an outcome variable on the basis of a small number of covariates, using an interpretable yet non-additive model. We propose  convex regression with interpretable sharp partitions  (CRISP) for this task. CRISP partitions the covariate space into blocks in a data- adaptive way, and fits a mean model within each block. Unlike other par", "pdf_url": "http://jmlr.org/papers/volume17/15-344/15-344.pdf"}}