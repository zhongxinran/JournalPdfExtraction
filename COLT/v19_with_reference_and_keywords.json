{"Preface": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Preface", "abstract": "Preface to the Proceedings of the 24th Annual Conference on Learning Theory June 9-11, 2011, Budapest, Hungary.", "pdf_url": "http://proceedings.mlr.press/v19/kakade11a/kakade11a.pdf", "keywords": []}, "Regret Bounds for the Adaptive Control of Linear Quadratic Systems": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Regret Bounds for the Adaptive Control of Linear Quadratic Systems", "abstract": "We study the average cost Linear Quadratic (LQ) control problem with unknown model parameters, also known as the adaptive control problem in the control community. We design an algorithm and prove that apart from logarithmic factors its regret up to time T is O(\\sqrtT).Unlike previous approaches that use a forced-exploration scheme, we construct a high-probability confidence set around the model parameters and design an algorithm that plays optimistically with respect to this confidence set. The construction of the confidence set is based on the recent results from online least-squares estimation and leads to improved worst-case regret bound for the proposed algorithm.To the best of our knowledge this is the the first time that a regret bound is derived for the LQ control problem. %(That O(\\sqrtT) is a minimax optimal rate follows from the existing lower bounds for linear bandit problems.)", "pdf_url": "http://proceedings.mlr.press/v19/abbasi-yadkori11a/abbasi-yadkori11a.pdf", "keywords": [], "reference": "Y. Abbasi-Yadkori, D. Pal, and Cs. Szepesv\u00b4ari.  Online least squares estimation with self-normalized processes: An application to bandit problems. Arxiv preprint http://arxiv.org/abs/1102.2670, 2011.  B. D. O. Anderson and J. B. Moore. Linear Optimal Control. Prentice-Hall, 1971.  P. Auer. Using confidence bounds for exploitation-exploration trade-o\ufb00s. Journal of Ma-  chine Learning Research, 3:397-422, 2003. ISSN 1533-7928.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite time analysis of the multiarmed bandit  problem. Machine Learning, 47(2-3):235-256, 2002.  P. Auer, R. Ortner, and Cs. Szepesv\u00b4ari.  Improved rates for the stochastic continuum- armed bandit problem. In Proceedings of the 20th Annual Conference on Learning Theory (COLT-07), pages 454-468, 2007.  P. Auer, T. Jaksch, and R. Ortner. Near-optimal regret bounds for reinforcement learning.  Journal of Machine Learning Research, 11:1563\u20141600, 2010.  P. L. Bartlett and A. Tewari. REGAL: A regularization based algorithm for reinforcement learning in weakly communicating MDPs. In Proceedings of the 25th Annual Conference on Uncertainty in Artificial Intelligence, 2009.  A. Becker, P. R. Kumar, and C. Z. Wei. Adaptive control with the stochastic approximation algorithm: Geometry and convergence. IEEE Trans. on Automatic Control, 30(4):330- 338, 1985.  D. Bertsekas. Dynamic Programming. Prentice-Hall, 1987.  D. P. Bertsekas. Dynamic Programming and Optimal Control. Athena Scientific, 2nd edition,  2001.  S. Bittanti and M. C. Campi. Adaptive control of linear time invariant systems: the \u201cbet on the best\u201d principle. Communications in Information and Systems, 6(4):299-320, 2006.  R. I. Brafman and M. Tennenholtz. R-MAX - a general polynomial time algorithm for near-optimal reinforcement learning. Journal of Machine Learning Research, 3:213-231, 2002.  M. C. Campi and P. R. Kumar. Adaptive linear quadratic Gaussian control: the cost-biased approach revisited. SIAM Journal on Control and Optimization, 36(6):1890-1907, 1998.  H. Chen and L. Guo. Optimal adaptive control and consistent parameter estimates for armax model with quadratic cost. SIAM Journal on Control and Optimization, 25(4): 845-867, 1987.  16   Abbasi-Yadkori Szepesv\u00b4ari  Plugging in this gives the final bound, which, by Lemma 4, holds with probability 1 \u2212 \u03b4.  References  Y. Abbasi-Yadkori, D. Pal, and Cs. Szepesv\u00b4ari.  Online least squares estimation with self-normalized processes: An application to bandit problems. Arxiv preprint http://arxiv.org/abs/1102.2670, 2011.  B. D. O. Anderson and J. B. Moore. Linear Optimal Control. Prentice-Hall, 1971.  P. Auer. Using confidence bounds for exploitation-exploration trade-o\ufb00s. Journal of Ma-  chine Learning Research, 3:397-422, 2003. ISSN 1533-7928.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite time analysis of the multiarmed bandit  problem. Machine Learning, 47(2-3):235-256, 2002.  P. Auer, R. Ortner, and Cs. Szepesv\u00b4ari.  Improved rates for the stochastic continuum- armed bandit problem. In Proceedings of the 20th Annual Conference on Learning Theory (COLT-07), pages 454-468, 2007.  P. Auer, T. Jaksch, and R. Ortner. Near-optimal regret bounds for reinforcement learning.  Journal of Machine Learning Research, 11:1563\u20141600, 2010.  P. L. Bartlett and A. Tewari. REGAL: A regularization based algorithm for reinforcement learning in weakly communicating MDPs. In Proceedings of the 25th Annual Conference on Uncertainty in Artificial Intelligence, 2009.  A. Becker, P. R. Kumar, and C. Z. Wei. Adaptive control with the stochastic approximation algorithm: Geometry and convergence. IEEE Trans. on Automatic Control, 30(4):330- 338, 1985.  D. Bertsekas. Dynamic Programming. Prentice-Hall, 1987.  D. P. Bertsekas. Dynamic Programming and Optimal Control. Athena Scientific, 2nd edition,  2001.  S. Bittanti and M. C. Campi. Adaptive control of linear time invariant systems: the \u201cbet on the best\u201d principle. Communications in Information and Systems, 6(4):299-320, 2006.  R. I. Brafman and M. Tennenholtz. R-MAX - a general polynomial time algorithm for near-optimal reinforcement learning. Journal of Machine Learning Research, 3:213-231, 2002.  M. C. Campi and P. R. Kumar. Adaptive linear quadratic Gaussian control: the cost-biased approach revisited. SIAM Journal on Control and Optimization, 36(6):1890-1907, 1998.  H. Chen and L. Guo. Optimal adaptive control and consistent parameter estimates for armax model with quadratic cost. SIAM Journal on Control and Optimization, 25(4): 845-867, 1987. Regret Bounds for the Adaptive Control of Linear Quadratic Systems  H. Chen and J. Zhang. Identification and adaptive control for systems with unknown orders, delay, and coe\ufb03cients. Automatic Control, IEEE Transactions on, 35(8):866 -877, August 1990.  V. Dani and T. P. Hayes. Robbing the bandit: Less regret in online geometric optimiza- tion against an adaptive adversary. In 16th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 937-943, 2006.  V. Dani, T. P. Hayes, and S. M. Kakade. Stochastic linear optimization under bandit  feedback. COLT-2008, pages 355-366, 2008.  C. Fiechter. Pac adaptive control of linear systems. In in Proceedings of the 10th Annual  Conference on Computational Learning Theory, ACM, pages 72-80. Press, 1997.  S. M. Kakade. On the sample complexity of reinforcement learning. PhD thesis, Gatsby  Computational Neuroscience Unit, University College London, 2003.  S. M. Kakade, M. J. Kearns, and J. Langford. Exploration in metric state spaces. T. Fawcett and N. Mishra, editors, ICML 2003, pages 306-312. AAAI Press, 2003.  In  M. Kearns and S. P. Singh. Near-optimal performance for reinforcement learning in poly- nomial time. In J. W. Shavlik, editor, ICML 1998, pages 260-268. Morgan Kau\ufb00mann, 1998.  R. Kleinberg. Nearly tight bounds for the continuum-armed bandit problem. In Advances  in Neural Information Processing Systems, pages 697-704, 2005.  R. Kleinberg, A. Slivkins, and E. Upfal. Multi-armed bandits in metric spaces. In Pro- ceedings of the 40th annual ACM symposium on Theory of computing, pages 681-690, 2008.  T. L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6:4-22, 1985.  T. L. Lai and C. Z. Wei. Least squares estimates in stochastic regression models with applications to identification and control of dynamic systems. The Annals of Statistics, 10(1):pp. 154-166, 1982a.  T. L. Lai and C. Z. Wei. Least squares estimates in stochastic regression models with applications to identification and control of dynamic systems. The Annals of Statistics, 10(1):154-166, 1982b.  T. L. Lai and C. Z. Wei. Asymptotically e\ufb03cient self-tuning regulators. SIAM Journal on  Control and Optimization, 25:466-481, March 1987.  T. L. Lai and Z. Ying. E\ufb03cient recursive estimation and adaptive control in stochastic  regression and armax models. Statistica Sinica, 16:741-772, 2006.  P. Rusmevichientong and J. N. Tsitsiklis. Linearly parameterized bandits. Mathematics of  Operations Research, 35(2):395-411, 2010. Abbasi-Yadkori Szepesv\u00b4ari  H. A. Simon. dynamic programming under uncertainty with a quadratic criterion function.  Econometrica, 24(1):74-81, 1956.  A. L. Strehl and M. L. Littman. Online linear regression and its application to model-based  reinforcement learning. In NIPS, pages 1417-1424, 2008.  A. L. Strehl, L. Li, E. Wiewiora, J. Langford, and M. L. Littman. PAC model-free rein-  forcement learning. In ICML, pages 881-888, 2006.  I. Szita and Cs. Szepesv\u00b4ari. Model-based reinforcement learning with nearly tight explo-  ration complexity bounds. In ICML 2010, pages 1031-1038, 2010.  "}, "Blackwell Approachability and No-Regret Learning are Equivalent": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Blackwell Approachability and No-Regret Learning are Equivalent", "abstract": "We consider the celebrated Blackwell Approachability Theorem for two-player games with vector payoffs. Blackwell himself previously showed that the theorem implies the existence of a \u201cno-regret\u201d algorithm for a simple online learning problem. We show that this relationship is in fact much stronger, that Blackwell\u2019s result is equivalent to, in a very strong sense, the problem of regret minimization for Online Linear Optimization. We show that any algorithm for one such problem can be efficiently converted into an algorithm for the other. We provide one novel application of this reduction: the first \\emphefficient algorithm for calibrated forecasting.", "pdf_url": "http://proceedings.mlr.press/v19/abernethy11b/abernethy11b.pdf", "keywords": [], "reference": "J. Abernethy, A. Agarwal, P.L. Bartlett, and A. Rakhlin. A stochastic view of optimal regret through minimax duality. In Proceedings of the 22nd Annual Conference on Learning Theory, 2009.  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of  Mathematicians, volume 3, pages 336-338, 1954.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6(1):18, 1956.  Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006. ISBN 0521841089, 9780521841085.  A. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association,  77:605-613, 1982.  E. Even-Dar, R. Kleinberg, S. Mannor, and Y. Mansour. Online learning for global cost  functions. In 22nd Annual Conference on Learning Theory (COLT), 2009.  D. P Foster. A proof of calibration via blackwell\u2019s approachability theorem. Games and  Economic Behavior, 29(1-2):7378, 1999.  D. P Foster and R. V Vohra. Asymptotic calibration. Biometrika, 85(2):379, 1998.  Y. Freund and R. Schapire. A desicion-theoretic generalization of on-line learning and an application to boosting. In Computational learning theory, pages 23-37. Springer, 1995.  D. Fudenberg and D. K Levine. An easier way to calibrate* 1. Games and economic  behavior, 29(1-2):131137, 1999.  Games, 3:97-139, 1957.  J. Hannan. Approximation to Bayes risk in repeated play. Contributions to the Theory of  S. Hart and A. Mas-Colell. A simple adaptive procedure leading to correlated equilibrium.  Econometrica, 68(5):11271150, 2000.  E. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex opti-  mization. Machine Learning, 69(2):169-192, 2007. ISSN 0885-6125.  Elad Hazan. The convex optimization approach to regret minimization. In To appear in  Optimization for Machine Learning. MIT Press, 2010.  S. Mannor and N. Shimkin. Regret minimization in repeated matrix games with variable stage duration. Games and Economic Behavior, 63(1):227-258, 2008. ISSN 0899-8256.  Shie Mannor and Gilles Stoltz. A Geometric Proof of Calibration. arXiv, Dec 2009. URL  http://arxiv.org/abs/0912.3604.  J. Von Neumann, O. Morgenstern, H. W Kuhn, and A. Rubinstein. Theory of games and  economic behavior. Princeton university press Princeton, NJ, 1947.  45   Blackwell Approachability and No-Regret Learning are Equivalent  References  J. Abernethy, A. Agarwal, P.L. Bartlett, and A. Rakhlin. A stochastic view of optimal regret through minimax duality. In Proceedings of the 22nd Annual Conference on Learning Theory, 2009.  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of  Mathematicians, volume 3, pages 336-338, 1954.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6(1):18, 1956.  Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006. ISBN 0521841089, 9780521841085.  A. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association,  77:605-613, 1982.  E. Even-Dar, R. Kleinberg, S. Mannor, and Y. Mansour. Online learning for global cost  functions. In 22nd Annual Conference on Learning Theory (COLT), 2009.  D. P Foster. A proof of calibration via blackwell\u2019s approachability theorem. Games and  Economic Behavior, 29(1-2):7378, 1999.  D. P Foster and R. V Vohra. Asymptotic calibration. Biometrika, 85(2):379, 1998.  Y. Freund and R. Schapire. A desicion-theoretic generalization of on-line learning and an application to boosting. In Computational learning theory, pages 23-37. Springer, 1995.  D. Fudenberg and D. K Levine. An easier way to calibrate* 1. Games and economic  behavior, 29(1-2):131137, 1999.  Games, 3:97-139, 1957.  J. Hannan. Approximation to Bayes risk in repeated play. Contributions to the Theory of  S. Hart and A. Mas-Colell. A simple adaptive procedure leading to correlated equilibrium.  Econometrica, 68(5):11271150, 2000.  E. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex opti-  mization. Machine Learning, 69(2):169-192, 2007. ISSN 0885-6125.  Elad Hazan. The convex optimization approach to regret minimization. In To appear in  Optimization for Machine Learning. MIT Press, 2010.  S. Mannor and N. Shimkin. Regret minimization in repeated matrix games with variable stage duration. Games and Economic Behavior, 63(1):227-258, 2008. ISSN 0899-8256.  Shie Mannor and Gilles Stoltz. A Geometric Proof of Calibration. arXiv, Dec 2009. URL  http://arxiv.org/abs/0912.3604.  J. Von Neumann, O. Morgenstern, H. W Kuhn, and A. Rubinstein. Theory of games and  economic behavior. Princeton university press Princeton, NJ, 1947. Abernethy Bartlett Hazan  V. Perchet. Calibration and internal no-regret with random signals.  In Proceedings of the 20th international conference on Algorithmic learning theory, pages 68-82. Springer- Verlag, 2009. ISBN 3642044131.  A. Rakhlin, K. Sridharan, and A. Tewari. Online Learning: Beyond Regret. Arxiv preprint  arXiv:1011.3168, 2010.  A. Sandroni, R. Smorodinsky, and R.V. Vohra. Calibration with many checking rules.  Mathematics of Operations Research, 28(1):141-153, 2003. ISSN 0364-765X.  S. Shalev-Shwartz and Y. Singer. Convex repeated games and Fenchel duality. Advances  in Neural Information Processing Systems, 19:1265, 2007. ISSN 1049-5258.  M. Sion. On general minimax theorems. Pacific J. Math, 8(1):171-176, 1958.  M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In  International Conference on Machine Learning, volume 20, page 928, 2003. "}, "Competitive Closeness Testing": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Competitive Closeness Testing", "abstract": "We test whether two sequences are generated by the same distributionor by two different ones.Unlike previous work, we make no assumptions on the distributions\u2019support size. Additionally, we compare our performance to thatof the best possible test.We describe an efficiently-computable algorithm based on\\emphpattern maximum likelihood that is near optimal whenever the bestpossible error probability is \\le\\exp(-14n^2/3)using length-n sequences.", "pdf_url": "http://proceedings.mlr.press/v19/acharya11a/acharya11a.pdf", "keywords": [], "reference": "[1] J. Acharya, H. Das, A. Orlitsky, S. Pan, and N.P. Santhanam. Classification using In Proceedings of IEEE Symposium on Information  pattern probability estimators. Theory, pages 1493-1497, 2010.  [2] T. Batu, L. Fortnow, R. Rubinfeld, W. D. Smith, and P. White. Testing that distri- butions are close. In FOCS \u201900: Proceedings of the 41st Annual Symposium on Foun- dations of Computer Science, page 259, Washington, DC, USA, 2000. IEEE Computer Society. ISBN 0-7695-0850-2.  [3] T. Batu, L. Fortnow, E. Fischer, R. Kumar, R. Rubinfeld, and P. White. Testing random variables for independence and identity. FOCS \u201901: Proceedings of the 42nd Annual Symposium on Foundations of Computer Science, page 442, 2001.  [4] Tugkan Batu. Testing properties of distributions. PhD thesis, Cornell University, 2001.  [5] T. Cover and J. Thomas. Elements of Information Theory. Wiley Interscience, 2nd  edition, 2006.  [6] A.K. Dhulipala and A. Orlitsky. Universal compression of markov and related sources over arbitrary alphabets. IEEE Transactions on Information Theory, 53:4182-4190, 2006.  [7] M. Gutman. Asymptotically optimal classification for multiple tests with empirically observed statistics. IEEE Transactions on Information Theory, 35:401-408, 1989.  [8] G.H. Hardy and S. Ramanujan. Asymptotic formulae in combinatory analysis. Pro-  ceedings of London Mathematics Society, 17(2):75-115, 1918.  [9] G.H. Hardy and E.M. Wright. An introduction to the theory of numbers. Oxford  University Press, 1985.  [10] B. Kelly, T. Tularak, A. B. Wagner, and P. Viswanath. Universal hypothesis testing In Proceedings of IEEE Symposium on Information  in the learning-limited regime. Theory, pages 1478-1482, 2010.  [11] E. L. Lehmann and Joseph P. Romano. Testing statistical hypotheses. Springer Texts  in Statistics. Springer, New York, third edition, 2005.  [12] J. Neyman and E. S. Pearson. On the problem of the most e\ufb03cient tests of statisti- cal hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231:289-337, 1933.  [13] A. Orlitsky and Shengjun Pan. The maximum likelihood probability of skewed patterns.  In Proceedings of IEEE Symposium on Information Theory, pages 1130-1134, 2009.  [14] A. Orlitsky, N.P. Santhanam, and J. Zhang. Universal compression of memoryless sources over unknown alphabets. IEEE Transactions on Information Theory, 50:1469- 1481, 2004.  63   Competitive Closeness Testing  References  [1] J. Acharya, H. Das, A. Orlitsky, S. Pan, and N.P. Santhanam. Classification using In Proceedings of IEEE Symposium on Information  pattern probability estimators. Theory, pages 1493-1497, 2010.  [2] T. Batu, L. Fortnow, R. Rubinfeld, W. D. Smith, and P. White. Testing that distri- butions are close. In FOCS \u201900: Proceedings of the 41st Annual Symposium on Foun- dations of Computer Science, page 259, Washington, DC, USA, 2000. IEEE Computer Society. ISBN 0-7695-0850-2.  [3] T. Batu, L. Fortnow, E. Fischer, R. Kumar, R. Rubinfeld, and P. White. Testing random variables for independence and identity. FOCS \u201901: Proceedings of the 42nd Annual Symposium on Foundations of Computer Science, page 442, 2001.  [4] Tugkan Batu. Testing properties of distributions. PhD thesis, Cornell University, 2001.  [5] T. Cover and J. Thomas. Elements of Information Theory. Wiley Interscience, 2nd  edition, 2006.  [6] A.K. Dhulipala and A. Orlitsky. Universal compression of markov and related sources over arbitrary alphabets. IEEE Transactions on Information Theory, 53:4182-4190, 2006.  [7] M. Gutman. Asymptotically optimal classification for multiple tests with empirically observed statistics. IEEE Transactions on Information Theory, 35:401-408, 1989.  [8] G.H. Hardy and S. Ramanujan. Asymptotic formulae in combinatory analysis. Pro-  ceedings of London Mathematics Society, 17(2):75-115, 1918.  [9] G.H. Hardy and E.M. Wright. An introduction to the theory of numbers. Oxford  University Press, 1985.  [10] B. Kelly, T. Tularak, A. B. Wagner, and P. Viswanath. Universal hypothesis testing In Proceedings of IEEE Symposium on Information  in the learning-limited regime. Theory, pages 1478-1482, 2010.  [11] E. L. Lehmann and Joseph P. Romano. Testing statistical hypotheses. Springer Texts  in Statistics. Springer, New York, third edition, 2005.  [12] J. Neyman and E. S. Pearson. On the problem of the most e\ufb03cient tests of statisti- cal hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231:289-337, 1933.  [13] A. Orlitsky and Shengjun Pan. The maximum likelihood probability of skewed patterns.  In Proceedings of IEEE Symposium on Information Theory, pages 1130-1134, 2009.  [14] A. Orlitsky, N.P. Santhanam, and J. Zhang. Universal compression of memoryless sources over unknown alphabets. IEEE Transactions on Information Theory, 50:1469- 1481, 2004. Acharya Das Jafarpour Orlitsky Pan  [15] A. Orlitsky, N.P. Santhanam, K. Viswanathan, and J. Zhang. Limit results on pattern  entropy. IEEE Transactions on Information Theory, 52:2954-2964, 2006.  [16] H. V. Poor. An introduction to signal detection and estimation. New York: Springer-  Verlag, 2nd edition, 1994.  [17] Sofya Raskhodnikova. Property Testing: Theory and Applications. PhD thesis, Mas-  sachusetts Institute of Technology, 2003.  [18] N.P. Santhanam, A. Orlitsky, and K. Viswanathan. New tricks for old dogs: Large alphabet probability estimation. In Information Theory Worskshop, pages 638-643, 2007.  [19] Paul Valiant. Testing symmetric properties of distributions. In STOC \u201908: Proceedings of the 40th annual ACM symposium on Theory of computing, pages 383-392, New York, NY, USA, 2008. ACM. ISBN 978-1-60558-047-0.  [20] J.H. van Lint and R.M. Wilson. A course in combinatorics. Cambridge University  Press, 2001.  [21] J. Ziv. On classification with empirically observed statistics and universal data com-  pression. IEEE Transactions on Information Theory, 34:278-286, 1988. Competitive Closeness Testing  "}, "Oracle inequalities for computationally budgeted model selection": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Oracle inequalities for computationally budgeted model selection", "abstract": "We analyze general model selection procedures using penalized  empirical loss minimization under computational constraints. While  classical model selection approaches do not consider computational  aspects of performing model selection, we argue that any practical  model selection procedure must not only trade off estimation and  approximation error, but also the effects of the computational  effort required to compute empirical minimizers for different  function classes. We provide a framework for analyzing such  problems, and we give algorithms for model selection under a  computational budget. These algorithms satisfy oracle inequalities  that show that the risk of the selected model is not much worse than  if we had devoted all of our computational budget to the best  function class.", "pdf_url": "http://proceedings.mlr.press/v19/agarwal11a/agarwal11a.pdf", "keywords": ["Model selection", "oracle inequalities", "computational budget"], "reference": "H. Akaike. A new look at the statistical model identification.  IEEE Transactions on  Automatic Control, 19(6):716-723, December 1974.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed  bandit problem. SIAM J. Comput., 32(1):48-77, 2003.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed  bandit problem. Mach. Learn., 47(2-3):235-256, 2002. ISSN 0885-6125.  A. R. Barron. Complexity regularization with application to artificial neural networks. In Nonparametric functional estimation and related topics, pages 561-576. Kluwer Aca- demic, 1991.  Andrew Barron, Lucien Birg\u00b4e, and Pascal Massart. Risk bounds for model selection via  penalization. Probability Theory and Related Fields, 113:301-413, 1999.  P. L. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: Risk bounds and  structural results. Journal of Machine Learning Research, 3:463-482, 2002.  P. L. Bartlett, S. Boucheron, and G. Lugosi. Model selection and error estimation. Machine  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Learning, 48:85-113, 2002.  Press, 2006.  R. M. Dudley. The sizes of compact subsets of Hilbert space and continuity of Gaussian  processes. Journal of Functional Analysis, 1:290-330, 1967.  R. M. Dudley. Central limit theorems for empirical measures. The Annals of Probability, 6  (6):899-929, 1978.  S. Geman and C. R. Hwang. Nonparametric maximum likelihood estimation by the method  of sieves. Annals of Statistics, 10:401-414, 1982.  T. L. Lai and Herbert Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances  in Applied Mathematics, 6:4-22, 1985.  G. Lugosi and M. Wegkamp. Complexity regularization via localized random penalties.  Annals of Statistics, 32(4):1679-1697, 2004.  C. L. Mallows. Some comments on Cp. Technometrics, 15(4):661-675, 1973. P. Massart. Concentration inequalities and model selection. In J. Picard, editor, Ecole d\u2019Et  de Probabilits de Saint-Flour XXXIII - 2003 Series. Springer, 2003.  A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approximation approach to stochastic programming. SIAM Journal on Optimization, 19(4):1574-1609, 2009.  David Pollard. Convergence of Stochastic Processes. Springer-Verlag, 1984. Jorma Rissanen. A universal prior for integers and estimation by minimum description  length. The Annals of Statistics, 11(2):416-431, 1983.  83   Computationally budgeted model selection  Acknowledgments  In performing this research, AA was supported by a Microsoft Research Fellowship, and JCD was supported by the National Defense Science and Engineering Graduate Fellowship (NDSEG) Program. AA and PB gratefully acknowledge the support of the NSF under award DMS-0830410.  References  H. Akaike. A new look at the statistical model identification.  IEEE Transactions on  Automatic Control, 19(6):716-723, December 1974.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed  bandit problem. SIAM J. Comput., 32(1):48-77, 2003.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed  bandit problem. Mach. Learn., 47(2-3):235-256, 2002. ISSN 0885-6125.  A. R. Barron. Complexity regularization with application to artificial neural networks. In Nonparametric functional estimation and related topics, pages 561-576. Kluwer Aca- demic, 1991.  Andrew Barron, Lucien Birg\u00b4e, and Pascal Massart. Risk bounds for model selection via  penalization. Probability Theory and Related Fields, 113:301-413, 1999.  P. L. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: Risk bounds and  structural results. Journal of Machine Learning Research, 3:463-482, 2002.  P. L. Bartlett, S. Boucheron, and G. Lugosi. Model selection and error estimation. Machine  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Learning, 48:85-113, 2002.  Press, 2006.  R. M. Dudley. The sizes of compact subsets of Hilbert space and continuity of Gaussian  processes. Journal of Functional Analysis, 1:290-330, 1967.  R. M. Dudley. Central limit theorems for empirical measures. The Annals of Probability, 6  (6):899-929, 1978.  S. Geman and C. R. Hwang. Nonparametric maximum likelihood estimation by the method  of sieves. Annals of Statistics, 10:401-414, 1982.  T. L. Lai and Herbert Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances  in Applied Mathematics, 6:4-22, 1985.  G. Lugosi and M. Wegkamp. Complexity regularization via localized random penalties.  Annals of Statistics, 32(4):1679-1697, 2004.  C. L. Mallows. Some comments on Cp. Technometrics, 15(4):661-675, 1973. P. Massart. Concentration inequalities and model selection. In J. Picard, editor, Ecole d\u2019Et  de Probabilits de Saint-Flour XXXIII - 2003 Series. Springer, 2003.  A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approximation approach to stochastic programming. SIAM Journal on Optimization, 19(4):1574-1609, 2009.  David Pollard. Convergence of Stochastic Processes. Springer-Verlag, 1984. Jorma Rissanen. A universal prior for integers and estimation by minimum description  length. The Annals of Statistics, 11(2):416-431, 1983. Agarwal Duchi Bartlett Levrard  V. N. Vapnik and A. Ya. Chervonenkis. Theory of pattern recognition. Nauka, Moscow,  1974. (In Russian).  "}, "Bandits, Query Learning, and the Haystack Dimension": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Bandits, Query Learning, and the Haystack Dimension", "abstract": "Motivated by multi-armed bandits (MAB) problems with a very large or even infinite number of arms, we consider the problem of finding a maximum of an unknown target function by querying the function at chosen inputs (or arms).We give an analysis of the query complexity of this problem, under the assumption that the payoff of each arm is given by a function belonging to a known, finite, but otherwise arbitrary function class. Our analysis centers on a new notion of function class complexity that we callthe \\emphhaystack dimension, which is used to prove the approximate optimality of a simple greedy algorithm. This algorithm is then usedas a subroutine in a \\parametric MAB algorithm, yielding provably near-optimal regret. We provide a generalization to the infinite cardinality setting, andcomment on how our analysis is connected to, and improves upon, existing results for query learning and generalized binary search.", "pdf_url": "http://proceedings.mlr.press/v19/amin11a/amin11a.pdf", "keywords": ["Multi-armed bandits", "learning theory"], "reference": "Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An e\ufb03cient algorithm for bandit linear optimization. In Proceedings of the 21th Annual Conference on Computational Learning Theory, 2008.  104   Amin Kearns Syed  at xn and nowhere else; (3) For all n \u2208 N, if i = (cid:100)log2 n(cid:101) then fn(xn) \u2265 (cid:15)i and fm(xn) < (cid:15)i for all m (cid:54)= n.  For the remainder of the proof fix (cid:15) > 0 and the smallest i \u2208 N such that (cid:15)i \u2264 (cid:15). We  , which su\ufb03ces to prove the theorem.  will show that \u03b8\u2212((cid:15)) = 1 and \u03b8+((cid:15)) \u2264 4 N(cid:15)i First, we claim that \u03b8\u2212((cid:15)) = 1. Let F + = arg inf F \u2286C((cid:15)) supx\u2208X inf y\u2208R  . Let n be the smallest integer such that fn \u2208 F +. Then each fm \u2208 F + has a distinct value at xn, by property 1. So inf y\u2208R |F +((cid:104)xn, y(cid:105) , 0)| = |F +|. Next, we claim that \u03b8+((cid:15)) \u2264 4 . N(cid:15)i Let Fi = {fn \u2208 F : i = (cid:100)log2 n(cid:101)}, and note that Fi \u2286 C((cid:15)) and |Fi| = N(cid:15)i 2 . For any x \u2208 X we have |Fi(x, 0)| \u2264 1, by property 2, and inf y\u2208R |Fi((cid:104)x, y(cid:105) , (cid:15))| \u2264 1, by property 3.  |F (x,(cid:15))\u222aF ((cid:104)x,y(cid:105),0)| |F |  12. Computational Complexity  Our results have so far ignored computational complexity. In general a function class F, for which finding the optimal query is computationally intractable, might nevertheless have small haystack dimension, admitting algorithms with low query complexity. Consider the following simple example. Let X = X1\u222aX2\u222aX3 where X1, X2, X3 are disjoint, |X1| = |X2| = n and X3 = 2n. Each function in F will attain its maximum on some action in X3. The location of that maximum, as in Example 2, will be encoded by X1 and X2. However, we will now encode the location cryptographically, with a function\u2019s behavior on X1 representing a public key, and a function\u2019s behavior on X2 representing the encrypted location of its maximum.  More precisely, let z be an n-bit number. For a pair of n  2 -bit primes p and q, let Npq = pq.  Also let e(z, Npq) = z2 mod Npq be z encrypted with public key Npq.  Now let fz,p,q be the function that gives the ith bit of Npq as output to the ith input of X1 and the ith bit of e(z, Npq) as output to the ith input of X2. On the zth input of X3, fz,p,q outputs a 2. On all other inputs of X3, fz,p,q outputs 0. Let F be the function class consisting of all functions fz,p,q for every pair of n  2 -bit primes p, q and n-bit integer z.  There exists an algorithm with query complexity O(n) for any f \u2217 \u2208 F. That algorithm queries each action in X1 \u222a X2, retrieving the public key Npq and the cypher e(z, Npq). Information-theoretically, the maximum of f \u2217 can be found in a single additional query. The algorithm may simply test every n-bit z(cid:48), checking if e(z, Npq) = e(z(cid:48), Npq). However, computing z is as hard as factorization (Kearns and Vazirani, 1994).  We thank Alex Slivkins and the anonymous reviewers for their helpful comments.  Acknowledgments  References  Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An e\ufb03cient algorithm for bandit linear optimization. In Proceedings of the 21th Annual Conference on Computational Learning Theory, 2008. Haystack Dimension  Kareem Amin, Michael Kearns, and Umar Syed. Graphical models for bandit problems. In  Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence, 2011.  Dana Angluin. Queries and concept learning. Machine Learning, 2(4):319-342, 1988.  S\u00b4ebastien Bubeck, R\u00b4emi Munos, Gilles Stoltz, and Csaba Szepesv\u00b4ari. Online optimization in X-armed bandits. In Advances in Neural Information Processing Systems 21, 2008.  Varsha Dani and Thomas P. Hayes. Robbing the bandit: Less regret in online geometric In Proceedings of the 17th Annual ACM-  optimization against an adaptive adversary. SIAM Symposium on Discrete Algorithms, 2006.  Abraham Flaxman, Adam Tauman Kalai, and H. Brendan McMahan. Online convex op- timization in the bandit setting: Gradient descent without a gradient. In Proceeding of the 16th Annual ACM-SIAM Symposium on Discrete Algorithms, 2005.  Tibor Heged\u00a8us. Generalized teaching dimensions and the query complexity of learning. In Proceedings of the 8th Annual Conference on Computational Learning Theory, 1995.  Michael Kearns and Umesh Vazirani. An Introduction to Computational Learning Theory.  MIT Press, 1994.  Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal. Multi-armed bandits in metric spaces. In Proceedings of the 40th Annual ACM Symposium on Theory of Computing, 2008.  John Langford and Tong Zhang. The epoch-greedy algorithm for contextual multi-armed  bandits. In Advances in Neural Information Processing Systems 20, 2007.  Tyler Lu, D\u00b4avid P\u00b4al, and Martin P\u00b4al. Showing relevant ads via Lipschitz context multi- armed bandits. In Proceedings of the 13th International Conference on Artificial Intelli- gence and Statistics, 2010.  Adam J. Mersereau, Paat Rusmevichientong, and John N. Tsitsiklis. A structured multi- armed bandit problem and the greedy policy. IEEE Transactions on Automatic Control, 54(12):2787-2802, 2009.  Rob Nowak. Noisy generalized binary search. In Advances in Neural Information Processing  Systems 22, 2009.  Aleksandrs Slivkins. Contextual bandits with similarity information. In Proceedings of the  24th Annual Conference on Computational Learning Theory, 2011.  Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. In Proceedings of the 27th International Conference on Machine Learning, 2008.  William Thompson. On the likelihood that one unknown probability exceeds another in  view of the evidence of two samples. Biometrika, 25(3-4):285-294, 1933. "}, "Minimax Policies for Combinatorial Prediction Games": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Minimax Policies for Combinatorial Prediction Games", "abstract": "We address the online linear optimization problem when theactions of the forecaster are represented by binary vectors.Our goal is to understand the magnitude of the minimax regretfor the worst possible set of actions. We study the problemunder three different assumptions for the feedback: full information, and the partial information models of theso-called \u201csemi-bandit\u201d, and \u201cbandit\u201d problems. We consider both L_\u221e-, and L_2-type of restrictions forthe losses assigned by the adversary.We formulate a general strategy using Bregman projections on top of a potential-based gradient descent, which  generalizes the ones studied in the series of papers \\citeGLLO07, DHK08, AHR08, CL09, HW09, KWK10, UNK10, KRS10 and \\citeAB10. We provide simpleproofs that recover most of the previous results. We propose new upper bounds for the semi-bandit game. Moreover we derive lower bounds for all three feedback assumptions. With the only exception of the bandit game, the upper and lower boundsare tight, up to a constant factor.Finally, we answer a question asked by \\citeKWK10 by showing that the exponentially weighted average forecaster is suboptimal against L_\u221e adversaries.", "pdf_url": "http://proceedings.mlr.press/v19/audibert11a/audibert11a.pdf", "keywords": [], "reference": "linear optimization. Omnipress, 2008.  11:2635\u20132686, 2010.  J. Abernethy and A. Rakhlin. Beating the adaptive bandit with high probability. In 22nd annual  conference on learning theory, 2009.  J. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An ef\ufb01cient algorithm for bandit In Rocco A. Servedio and Tong Zhang, editors, COLT, pages 263\u2013274.  J.-Y. Audibert and S. Bubeck. Regret bounds and minimax policies under partial monitoring. JMLR,  123   MINIMAX POLICIES FOR COMBINATORIAL PREDICTION GAMES  Third step: computation of KL(P\u2212i,\u03b1, Pi,\u03b1) with the chain rule for Kullback-Leibler divergence.  Note that since the forecaster is deterministic, the sequence of observed losses (up to time n) Wn \u2208 {0, 1, . . . , d}n uniquely determines the empirical distribution of plays qi n, and in particular the law of Ji,n conditionally to Wn is the same for any adversary. Thus, if we note Pn \u03b1 (respectively Pn \u2212i,\u03b1) the law of Wn when the forecaster plays against the \u03b1-adversary (respectively the (\u2212i, \u03b1)- adversary), then one can easily prove that KL(P\u2212i,\u03b1, Pi,\u03b1) \u2264 KL(Pn \u03b1). Now we use the chain rule for Kullback-Leibler divergence iteratively to introduce the laws Pt \u03b1 of the observed losses Wt up to time t. More precisely, we have,  \u2212i,\u03b1, Pn  KL(Pn  \u2212i,\u03b1, Pn  \u03b1) = KL(P1  \u2212i,\u03b1, P1  \u03b1) +  Pt\u22121 \u2212i,\u03b1(wt\u22121)KL(Pt  \u2212i,\u03b1(.|wt\u22121), Pt  \u03b1(.|wt\u22121))  = KL (cid:0)B\u2205, B(cid:48)  (cid:1) 1Ii,1=\u03b1i +  \u2205  Pt\u22121 \u2212i,\u03b1(wt\u22121)KL  Bwt\u22121, B(cid:48)  wt\u22121  (cid:16)  (cid:17)  ,  n (cid:88)  (cid:88)  t=2  wt\u22121\u2208{0,1,...,d}t\u22121  n (cid:88)  (cid:88)  t=2  wt\u22121:Ii,t=\u03b1i  where Bwt\u22121 and B(cid:48) wt\u22121 are sums of d/2 Bernoulli distributions with parameters in {1/2, 1/2 + \u03b5} and such that the number of Bernoullis with parameter 1/2 + \u03b5 in Bwt\u22121 is equal to the number of Bernoullis with parameter 1/2 + \u03b5 in B(cid:48) wt\u22121 plus one. Now using Lemma 24 (see "}, "Minimax Regret of Finite Partial-Monitoring Games in Stochastic Environments": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Minimax Regret of Finite Partial-Monitoring Games in Stochastic Environments", "abstract": "In a partial monitoring game, the learner repeatedly chooses an action, theenvironment responds with an outcome, and then the learner suffers a loss andreceives a feedback signal, both of which are fixed functions of the action andthe outcome. The goal of the learner is to minimize his regret, which is thedifference between his total cumulative loss and the total loss of the bestfixed action in hindsight.Assuming that the outcomes are generated in an i.i.d. fashion from an arbitrary andunknown probability distribution, we characterize the minimax regret of anypartial monitoring game with finitely many actions andoutcomes. It turns out that the minimax regret of any such game is either zero,\\widetilde\u0398(\\sqrtT), \u0398(T^2/3), or \u0398(T). We provide a computationally efficient learningalgorithm that achieves the minimax regret within logarithmic factor for any game.", "pdf_url": "http://proceedings.mlr.press/v19/bartok11a/bartok11a.pdf", "keywords": ["Online learning", "Imperfect feedback", "Regret analysis"], "reference": "Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An e\ufb03cient algorithm for bandit linear optimization. In Proceedings of the 21st Annual Conference on Learning Theory (COLT 2008), pages 263-273. Citeseer, 2008.  Alekh Agarwal, Peter Bartlett, and Max Dama. Optimal allocation strategies for the dark pool problem. In 13th International Conference on Artificial Intelligence and Statistics (AISTATS 2010), May 12-15, 2010, Chia Laguna Resort, Sardinia, Italy, 2010.  Andr\u00b4as Antos, G\u00b4abor Bart\u00b4ok, D\u00b4avid P\u00b4al, and Csaba Szepesv\u00b4ari. Toward a classification of  finite partial-monitoring games, 2011. http://arxiv.org/abs/1102.2041.  Jean-Yves Audibert and S\u00b4ebastien Bubeck. Minimax policies for adversarial and stochastic  bandits. In Proceedings of the 22nd Annual Conference on Learning Theory, 2009.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic  multiarmed bandit problem. SIAM Journal on Computing, 32(1):48-77, 2002.  G\u00b4abor Bart\u00b4ok, D\u00b4avid P\u00b4al, and Csaba Szepesv\u00b4ari. Toward a Classification of Finite Partial- Monitoring Games. In Proceedings of the 21st international conference on Algorithmic Learning Theory (ALT 2010), pages 224-238. Springer, 2010.  Nicol`o Cesa-Bianchi, G\u00b4abor Lugosi, and Gilles Stoltz. Minimizing regret with label e\ufb03cient prediction. IEEE Transactions on Information Theory, 51(6):2152-2162, June 2005.  Nicol\u00b4o Cesa-Bianchi, G\u00b4abor Lugosi, and Gilles Stoltz. Regret minimization under partial  monitoring. Mathematics of Operations Research, 31(3):562-580, 2006.  149   Minimax Regret of Finite Partial-Monitoring Games in Stochastic Environments  7. Discussion  In this we paper we classified all finite partial-monitoring games under stochastic envi- ronments, based on their minimax regret. We conjecture that our results extend to non- stochastic environments. This is the major open question that remains to be answered.  One question which we did not discuss so far is the computational e\ufb03ciency of our algorithm. The issue is twofold. The first computational question is how to e\ufb03ciently decide which of the four classes a given game (L, H) belongs to. The second question is the computational e\ufb03ciency of Balaton for a fixed easy game. Fortunately, in both cases an e\ufb03cient implementation is possible, i.e., in polynomial time by using a linear program solver (e.g., the ellipsoid method (Papadimitriou and Steiglitz, 1998)).  Another interesting open question is to investigate the dependence of regret on quantities other than T such as the number of actions, the number of outcomes, and more generally the structure of the loss and feedback matrices.  Finally, let us note that our results can be extended to a more general framework, similar to that of Pallavi et al. (2011), in which a game with N actions and M -dimensional outcome space is defined as a tuple G = (L, S1, . . . , SN ). The loss matrix is L \u2208 RN \u00d7M as before, but the outcome and the feedback are defined di\ufb00erently. The outcome y is an arbitrary vector from a bounded subset of RM and the feedback received by the learner upon choosing action i is Oi = Siy.  References  Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An e\ufb03cient algorithm for bandit linear optimization. In Proceedings of the 21st Annual Conference on Learning Theory (COLT 2008), pages 263-273. Citeseer, 2008.  Alekh Agarwal, Peter Bartlett, and Max Dama. Optimal allocation strategies for the dark pool problem. In 13th International Conference on Artificial Intelligence and Statistics (AISTATS 2010), May 12-15, 2010, Chia Laguna Resort, Sardinia, Italy, 2010.  Andr\u00b4as Antos, G\u00b4abor Bart\u00b4ok, D\u00b4avid P\u00b4al, and Csaba Szepesv\u00b4ari. Toward a classification of  finite partial-monitoring games, 2011. http://arxiv.org/abs/1102.2041.  Jean-Yves Audibert and S\u00b4ebastien Bubeck. Minimax policies for adversarial and stochastic  bandits. In Proceedings of the 22nd Annual Conference on Learning Theory, 2009.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic  multiarmed bandit problem. SIAM Journal on Computing, 32(1):48-77, 2002.  G\u00b4abor Bart\u00b4ok, D\u00b4avid P\u00b4al, and Csaba Szepesv\u00b4ari. Toward a Classification of Finite Partial- Monitoring Games. In Proceedings of the 21st international conference on Algorithmic Learning Theory (ALT 2010), pages 224-238. Springer, 2010.  Nicol`o Cesa-Bianchi, G\u00b4abor Lugosi, and Gilles Stoltz. Minimizing regret with label e\ufb03cient prediction. IEEE Transactions on Information Theory, 51(6):2152-2162, June 2005.  Nicol\u00b4o Cesa-Bianchi, G\u00b4abor Lugosi, and Gilles Stoltz. Regret minimization under partial  monitoring. Mathematics of Operations Research, 31(3):562-580, 2006. Bart\u00b4ok P\u00b4al Szepesv\u00b4ari  Thomas M. Cover and Joy A. Thomas. Elements of Information Theory. Wiley, New York,  second edition, 2006.  Abraham D. Flaxman, Adam Tauman Kalai, and H. Brendan McMahan. Online convex optimization in the bandit setting: gradient descent without a gradient. In Proceedings of the 16th annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2005), page 394. Society for Industrial and Applied Mathematics, 2005.  Robert Kleinberg and Tom Leighton. The value of knowing a demand curve: Bounds on regret for online posted-price auctions. In Proceedings of 44th Annual IEEE Symposium on Foundations of Computer Science 2003 (FOCS 2003), pages 594-605. IEEE, 2003.  Nick Littlestone and Manfred K. Warmuth. The weighted majority algorithm. Information  and Computation, 108:212-261, 1994.  G\u00b4abor Lugosi and Nicol`o Cesa-Bianchi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  University of Alberta, 2008.  V. Mnih. E\ufb03cient stopping rules. Master\u2019s thesis, Department of Computing Science,  V. Mnih, Cs. Szepesv\u00b4ari, and J.-Y. Audibert. Empirical Bernstein stopping.  In W. W. Cohen, A. McCallum, and S. T. Roweis, editors, ICML 2008, pages 672-679. ACM, 2008.  A. Pallavi, R. Zheng, and Cs. Szepesv\u00b4ari. Sequential learning for optimal monitoring of  multi-channel wireless networks. In INFOCOMM, 2011.  Christos H. Papadimitriou and Kenneth Steiglitz. Combinatorial optimization: algorithms  and complexity. Courier Dover Publications, New York, 1998.  Antonio Piccolboni and Christian Schindelhauer. Discrete prediction games with arbitrary feedback and loss. In Proceedings of the 14th Annual Conference on Computational Learn- ing Theory (COLT 2001), pages 208-223. Springer-Verlag, 2001.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of Twentieth International Conference on Machine Learning (ICML 2003), 2003. Minimax Regret of Finite Partial-Monitoring Games in Stochastic Environments  "}, "Sample Complexity Bounds for Differentially Private Learning": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Sample Complexity Bounds for Differentially Private Learning", "abstract": "This work studies the problem of privacy-preserving classification \u2013 namely, learning a classifier from sensitive data while preserving the privacy ofindividuals in the training set.In particular, the learning algorithm is required in this problem toguarantee differential privacy, a very strong notion of privacy that hasgained significant attention in recent years.A natural question to ask is: what is the sample requirement of a learningalgorithm that guarantees a certain level of privacy and accuracy?We address this question in the context of learning with infinite hypothesis classes whenthe data is drawn from a continuous distribution.We first show that even for very simple hypothesis classes, any algorithmthat uses a finite number of examples and guarantees differential privacymust fail to return an accurate classifier for at least some unlabeled datadistributions.This result is unlike the case with either finite hypothesis classes ordiscrete data domains, in which distribution-free private learning ispossible, as previously shown by \\citetKLNRS08.We then consider two approaches to differentially private learning that get around this lower bound.The first approach is to use prior knowledge about the unlabeled data distribution in the form of a reference distribution \\U chosen independently of the sensitive data. Given such a reference \\U, we provide an upper bound on the sample requirement that depends (among other things) on a measure of closenessbetween \\U and the unlabeled data distribution. Our upper bound appliesto the non-realizable as well as the realizable case. The second approachis to relax the privacy requirement, by requiring only label-privacy \u2013namely, that the only labels (and not the unlabeled parts of the examples)be considered sensitive information. An upper bound on the samplerequirement of learning with label privacy was shown by \\citetCDKMT06; inthis work, we show a lower bound.", "pdf_url": "http://proceedings.mlr.press/v19/chaudhuri11a/chaudhuri11a.pdf", "keywords": ["List of keywords"], "reference": "R. Agrawal and R. Srikant. Privacy-preserving data mining. SIGMOD Rec., 29(2):439\u2013450,  2000. ISSN 0163-5808. doi: http://doi.acm.org/10.1145/335191.335438.  Lars Backstrom, Cynthia Dwork, and Jon M. Kleinberg. Wherefore art thou r3579x?: anonymized social networks, hidden patterns, and structural steganography. In Carey L. Williamson, Mary Ellen Zurko, Peter F. Patel-Schneider, and Prashant J. Shenoy, editors, WWW, pages 181\u2013190. ACM, 2007. ISBN 978-1-59593-654-7.  K. Ball. An elementary introduction to modern convex geometry. In Silvio Levy, editor,  Flavors of Geometry, volume 31. 1997.  171   Sample Complexity Bounds for Differentially Private Learning  Theorem 12 Let H be a hypothesis class, D be a distribution over X , X be an i.i.d. sample from D of size m, and A be a learning algorithm that guarantees \u03b1-label privacy and outputs a hypothesis in H. Let d(cid:48)(cid:48) := ddim4(cid:15)(H, \u03c1D) \u2265 1. If (cid:15) \u2264 \u2206/2 and  m \u2264  (d(cid:48)(cid:48) \u2212 1) log 2 \u03b1  where \u2206 is the diameter of (H, \u03c1D), then there exists h\u2217 \u2208 H such that with probability at least 1/2 over the random choice of X and internal randomness of A, the hypothesis hA returned by A(SX,h\u2217) has classification error  Prx\u223cD [hA(x) (cid:54)= h\u2217(x)] > (cid:15).  In other words, any \u03b1-label private algorithm for learning a hypothesis in H with error at most (cid:15) \u2264 \u2206/2 must use at least (d(cid:48)(cid:48) \u2212 1) log(2)/\u03b1 examples. Theorem 12 uses ideas similar to those in (Beimel et al., 2010), but the result is stronger in that it applies to \u03b1-label privacy and continuous data domains. A detailed proof is provided in "}, "Tight conditions for consistent variable selection in high dimensional nonparametric regression": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Tight conditions for consistent variable selection in high dimensional nonparametric regression", "abstract": "We address the issue of variable selection in the regression model with very high ambient dimension, \\textiti.e., when the number of covariates is very large. The main focus is on the situation where the number of relevant covariates, called intrinsic dimension, is much smaller than the ambient dimension. Without assuming any parametric form of the underlying regression function, we get tight conditions making it possible to consistently estimate the set of relevant variables. These conditions relate the intrinsic dimension to the ambient dimension and to the sample size.  The procedure that is provably consistent under these tight conditions is simple and is based on comparing the empirical Fourier coefficients with an appropriately chosen threshold value.", "pdf_url": "http://proceedings.mlr.press/v19/comminges11a/comminges11a.pdf", "keywords": ["List of keywords"], "reference": "Hirotsugu Akaike. Information theory and an extension of the maximum likelihood principle. In Second International Symposium on Information Theory (Tsahkadsor, 1971), pages 267-281. Akad\u00b4emiai Kiad\u00b4o, Budapest, 1973.  Pierre Alquier. Iterative feature selection in least square regression estimation. Ann. Inst.  Henri Poincar\u00b4e Probab. Stat., 44(1):47-88, 2008.  198   Comminges Dalalyan  Let us stress now that, all over this work, we have deliberately avoided any discussion on the computational aspects of the variable selection in nonparametric regression. The goal in this paper was to investigate the possibility of consistent recovery without paying attention to the complexity of the selection procedure. This lead to some conditions that could be considered a benchmark for assessing the properties of sparsity pattern estimators. As for the estimator proposed in Section 3, it is worth noting that its computational complexity is not always prohibitively large. A recommended strategy is to compute the coe\ufb03cients (cid:98)\u03b8k in a stepwise manner; at each step K = 1, 2, . . . , d\u2217 only the coe\ufb03cients (cid:98)\u03b8k with (cid:107)k(cid:107)0 = K need to be computed and compared with the threshold. If some (cid:98)\u03b8k exceeds the threshold, then all the covariates X j corresponding to nonzero coordinates of k are considered as relevant. We can stop this computation as soon as the number of covariates classified as relevant attains d\u2217. While the worst-case complexity of this procedure is exponential, there are many functions f for which the complexity of the procedure will be polynomial in d. For example, this is the case for additive models in which f(x) = f1(xi1) + . . . + fd\u2217(xid\u2217 ) for some univariate functions f1, . . . , fd\u2217.  Note also that in the present study we focused exclusively on the consistency of variable selection without paying any attention to the consistency of regression function estimation. A thorough analysis of the latter problem being left to a future work, let us simply remark that in the case of fixed d\u2217, under the conditions of Theorem 2, it is straightforward to construct a consistent estimator of the regression function. In fact, it su\ufb03ces to use a projection estimator with a properly chosen truncation parameter on the set of relevant variables. The situation is much more delicate in the case when the sparsity d\u2217 grows to infinity along with the sample size n. Presumably, condition (10) is no longer su\ufb03cient for consistently estimating the regression function. The rationale behind this conjecture is that the minimax rate of convergence for estimating f in our context, if we assume in addition that the set of relevant variables is known, is equal n\u22122/(2+d\u2217) = exp(\u22122 log n/(2 + d\u2217)). If the left hand side of (10) is equal to a constant and log log d = o(log n), then the aforementioned minimax rate does not tend to zero, making thus the estimator inconsistent. This heuristical argument shows that there is still some work to do for getting tight conditions ensuring the consistent estimation of the regression function in the high dimensional set-up.  The authors acknowledge the support of the French Agence Nationale de la Recherche (ANR) under the grant PARCIMONIE.  Acknowledgments  References  Hirotsugu Akaike. Information theory and an extension of the maximum likelihood principle. In Second International Symposium on Information Theory (Tsahkadsor, 1971), pages 267-281. Akad\u00b4emiai Kiad\u00b4o, Budapest, 1973.  Pierre Alquier. Iterative feature selection in least square regression estimation. Ann. Inst.  Henri Poincar\u00b4e Probab. Stat., 44(1):47-88, 2008. Consistent variable selection in nonparametric regression  Francis Bach. High-dimensional non-linear variable selection through hierarchical kernel  learning. Technical report, arXiv:0909.0844, 2009.  Karine Bertin and Guillaume Lecu\u00b4e. Selection of variables and dimension reduction in  high-dimensional non-parametric regression. Electron. J. Stat., 2:1224-1241, 2008.  Peter J. Bickel, Ya\u2019acov Ritov, and Alexandre B. Tsybakov. Hierarchical selection of vari- ables in sparse high-dimensional regression. Borrowing Strength: Theory Powering Ap- plications - A Festschrift for Lawrence D. Brown. IMS Collections, 6:56-69, 2010.  Florentina Bunea and Adrian Barbu. Dimension reduction and variable selection in case control studies via regularized likelihood optimization. Electron. J. Stat., 3:1257-1287, 2009.  Jean Dieudonn\u00b4e. Calcul infinit\u00b4esimal. Hermann, Paris, 1968.  David Donoho and Jiashun Jin. Feature selection by higher criticism thresholding achieves the optimal phase diagram. Philos. Trans. R. Soc. Lond. Ser. A Math. Phys. Eng. Sci., 367(1906):4449-4470, 2009. With electronic supplementary materials available online.  Jianqing Fan, Richard Samworth, and Yichao Wu. Ultrahigh dimensional feature selection:  beyond the linear model. J. Mach. Learn. Res., 10:2013-2038, 2009.  Robert M. Fano. Transmission of information: A statistical theory of communications. The  M.I.T. Press, Cambridge, Mass., 1961.  Rodolphe Jenatton, Jean-Yves Audibert, and Francis Bach. Structured variable selection  with sparsity-inducing norms. Technical report, arXiv:0904.3523, 2009.  John La\ufb00erty and Larry Wasserman. Rodeo: sparse, greedy nonparametric regression. Ann.  Statist., 36(1):28-63, 2008.  Beatrice Laurent and Pascal Massart. Adaptive estimation of a quadratic functional by  model selection. Ann. Statist., 28(5):1302-1338, 2000.  Karim Lounici, Massimiliano Pontil, Alexandre B. Tsybakov, and Sara van de Geer. inference under group sparsity. Technical report,  Oracle inequalities and optimal arXiv:1007.1771, 2010.  Colin L. Mallows. Some comments on Cp. Technometrics, 15:661-675, Nov. 1973.  James Mazo and Andrew Odlyzko. Lattice points in high-dimensional spheres. Monatsh.  Math., 110(1):47-61, 1990.  Methodol., 72(4):417-473, 2010.  Nicolai Meinshausen and Peter Bhlmann. Stability selection. J. R. Stat. Soc. Ser. B Stat.  Guillaume Obozinski, Martin J. Wainwright, and Michael I. Jordan. High-dimensional  union support recovery in multivariate. The Annals of Statistics, to appear, 2011. Comminges Dalalyan  Pradeep Ravikumar, Martin J. Wainwright, and John D. La\ufb00erty. High-dimensional Ising model selection using (cid:96)1-regularized logistic regression. Ann. Statist., 38(3):1287-1319, 2010.  Gideon Schwarz. Estimating the dimension of a model. Ann. Statist., 6(2):461-464, 1978.  James G. Scott and James O. Berger. Bayes and empirical-Bayes multiplicity adjustment  in the variable-selection problem. Ann. Statist., 38(5):2587-2619, 2010.  Robert Tibshirani. Regression shrinkage and selection via the lasso. J. Roy. Statist. Soc.  Ser. B, 58(1):267-288, 1996.  Jo-Anne Ting, Aaron D\u2019Souza, Sethu Vijayakumar, and Stefan Schaal. E\ufb03cient learning and feature selection in high-dimensional regression. Neural Comput., 22(4):831-886, 2010.  Alexandre B. Tsybakov.  Introduction to nonparametric estimation. Springer Series in  Statistics. Springer, New York, 2009.  Larry Wasserman and Kathryn Roeder. High-dimensional variable selection. Ann. Statist.,  37(5A):2178-2201, 2009.  Statist., 38(2):894-942, 2010.  Cun-Hui Zhang. Nearly unbiased variable selection under minimax concave penalty. Ann.  Tong Zhang. On the consistency of feature selection using greedy least squares regression.  J. Mach. Learn. Res., 10:555-568, 2009.  Peng Zhao and Bin Yu. On model selection consistency of Lasso. J. Mach. Learn. Res., 7:  2541-2563, 2006.  Peng Zhao, Guilherme Rocha, and Bin Yu. The composite absolute penalties family for  grouped and hierarchical variable selection. Ann. Statist., 37(6A):3468-3497, 2009.  "}, "Multiclass Learnability and the ERM principle": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Multiclass Learnability and the ERM principle", "abstract": "Multiclass learning is an area of growing practical relevance, for which thecurrently available theory is still far from providing satisfactoryunderstanding.  We study the learnability of multiclass prediction, and deriveupper and lower bounds on the sample complexity of multiclass hypothesisclasses in different learning models: batch/online, realizable/unrealizable,full information/bandit feedback.  Our analysis reveals a surprisingphenomenon: In the multiclass setting, in sharp contrast to binaryclassification, not all Empirical Risk Minimization (ERM) algorithms areequally successful. We show that there exist hypotheses classes for which someERM learners have lower sample complexity than others. Furthermore, there areclasses that are learnable by some ERM learners, while other ERM learner willfail to learn them. We propose a principle for designing good ERM learners, anduse this principle to prove tight bounds on the sample complexity of learning\\em symmetric multiclass hypothesis classes (that is, classes that areinvariant under any permutation of label names). We demonstrate the relevanceof the theory by analyzing the sample complexity of two widely used hypothesisclasses: generalized linear multiclass models and reduction trees. We also obtainsome practically relevant conclusions.", "pdf_url": "http://proceedings.mlr.press/v19/daniely11a/daniely11a.pdf", "keywords": ["List of keywords"], "reference": "P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2):235-256, 2002.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R.E. Schapire. The nonstochastic multiarmed  bandit problem. SICOMP: SIAM Journal on Computing, 32, 2003.  S. Ben-David, N. Cesa-Bianchi, D. Haussler, and P. Long. Characterizations of learnability for classes of {0, . . . , n}-valued functions. Journal of Computer and System Sciences, 50: 74-86, 1995.  S. Ben-David, D. Pal, , and S. Shalev-Shwartz. Agnostic online learning. In COLT, 2009.  A. Beygelzimer, J. Langford, and P. Ravikumar. Multiclass classification with filter trees.  Preprint, June, 2007.  CoRR, 2009.  Alina Beygelzimer, John Langford, and Pradeep Ravikumar. Error-correcting tournaments.  M. Collins. Discriminative training methods for hidden Markov models: Theory and ex- periments with perceptron algorithms. In Conference on Empirical Methods in Natural Language Processing, 2002.  224   Daniely Sabato Ben-David Shalev-Shwartz  Conjecture 26 There exists a constant C such that, for every hypothesis class H \u2286 Y X ,  mr  H((cid:15), \u03b4) \u2264 C  (cid:32)  (cid:15) ) + ln( 1 dN (H) ln( 1 \u03b4 ) (cid:15)  (cid:33)  In light of theorem 7 and the fact that there are cases where dG \u2265 log2(|Y| \u2212 1)dN , in order to prove the conjecture we will have to find a learning algorithm that is not just an arbitrary ERM learner. So far, all the general upper bounds that we are aware of are valid for any ERM learner. Understanding how to select among ERM learners is fundamental as it teaches us what is the correct way to learn. We suspect that such an understanding might lead to improved bounds in the binary case as well. We hope that our examples from section 2.4 and our result for symmetric classes will prove to be the first steps in the search for the best ERM.  Another direction is the study of learnability conditions for additional hypotheses classes. Section 5 shows that some well known multiclass constructions have surprisingly similar sample complexity properties. It is of practical significance and theoretical interest to study learnability conditions for other constructions, and especially to develop a fuller understanding of the relationship between di\ufb00erent constructions, in a manner that could guide an informed choice of a hypothesis class.  Sivan Sabato is supported by the Adams Fellowship Program of the Israel Academy of Sciences and Humanities.  Acknowledgments  References  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2):235-256, 2002.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R.E. Schapire. The nonstochastic multiarmed  bandit problem. SICOMP: SIAM Journal on Computing, 32, 2003.  S. Ben-David, N. Cesa-Bianchi, D. Haussler, and P. Long. Characterizations of learnability for classes of {0, . . . , n}-valued functions. Journal of Computer and System Sciences, 50: 74-86, 1995.  S. Ben-David, D. Pal, , and S. Shalev-Shwartz. Agnostic online learning. In COLT, 2009.  A. Beygelzimer, J. Langford, and P. Ravikumar. Multiclass classification with filter trees.  Preprint, June, 2007.  CoRR, 2009.  Alina Beygelzimer, John Langford, and Pradeep Ravikumar. Error-correcting tournaments.  M. Collins. Discriminative training methods for hidden Markov models: Theory and ex- periments with perceptron algorithms. In Conference on Empirical Methods in Natural Language Processing, 2002. Multiclass Learnability and the ERM principle  K. Crammer and Y. Singer. Ultraconservative online algorithms for multiclass problems.  Journal of Machine Learning Research, 3:951-991, 2003.  R. O. Duda and P. E. Hart. Pattern Classification and Scene Analysis. Wiley, 1973.  Michael Fink, Shai Shalev-Shwartz, Yoram Singer, and Shimon Ullman. Online multi- class learning by interclass hypothesis sharing. In International Conference on Machine Learning, 2006.  J. Fox. Applied Regression Analysis, Linear Models, and Related Methods. SAGE Publica-  tions, 1997.  Y. Freund and R.E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119-139, August 1997.  T.J. Hastie and R.J. Tibshirani. Generalized additive models. Chapman & Hall, 1995.  S.M. Kakade, S. Shalev-Shwartz, and A. Tewari. E\ufb03cient bandit algorithms for online  multiclass prediction. In International Conference on Machine Learning, 2008.  N. Littlestone. Learning when irrelevant attributes abound. In FOCS, pages 68-77, October  1987.  B. K. Natarajan. On learning sets and functions. Mach. Learn., 4:67-97, 1989.  R. E. Schapire and Y. Singer. Improved boosting algorithms using confidence-rated predic-  tions. Machine Learning, 37(3):1-40, 1999.  S. Shalev-Shwartz, O. Shamir, N. Srebro, and K. Sridharan. Learnability, stability and uniform convergence. The Journal of Machine Learning Research, 11:2635-2670, 2010.  B. Taskar, C. Guestrin, and D. Koller. Max-margin markov networks. In NIPS, 2003.  V. N. Vapnik. Statistical Learning Theory. Wiley, 1998.  V.N. Vapnik. The Nature of Statistical Learning Theory. Springer, 1995.  "}, "Mixability is Bayes Risk Curvature Relative to Log Loss": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Mixability is Bayes Risk Curvature Relative to Log Loss", "abstract": "Mixability of a loss governs the best possible performance when\taggregating expert predictions with respect to that loss. The\tdetermination of the mixability constant for binary losses is\tstraightforward but opaque. In the binary case we make this \ttransparent and simpler by\tcharacterising mixability in terms of the second derivative of the\tBayes risk of proper losses.  We then extend this result to\tmulticlass proper losses where there are few existing results.  We\tshow that mixability is governed by the Hessian of the Bayes risk,\trelative to the Hessian of the Bayes risk for log loss. We\tconclude by comparing our result to other work that bounds\tprediction performance in terms of the geometry of the Bayes risk.\tAlthough all calculations are for proper losses, we also show how\tto carry the results across to improper losses.", "pdf_url": "http://proceedings.mlr.press/v19/vanerven11a/vanerven11a.pdf", "keywords": ["mixability", "regret bounds", "probability estimation", "proper losses"], "reference": "Jacob Abernethy, Alekh Agarwal, Peter L. Bartlett, and Alexander Rakhlin. A stochastic In Proceedings of the 22nd Annual  view of optimal regret through minimax duality. Conference on Learning Theory, 2009.  Nicol`o Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  246   Van Erven, Reid and Williamson  A function h is concave if and only if  h is convex. Thus h is concave if and only  \u2212 h(x0) + Dh(x0)  h(x)  \u2264  (x  \u00b7  \u2212  x0),  x, x0.  \u2200  2. The concavity of h is equivalent to the following holding for all  Let h(x) = f (x) x, x0:  \u03b1  x (cid:107)  (cid:107)  \u2212  (cid:107)  x  \u03b1  \u2264  2 (cid:107) 2 \u03b1 x (cid:107) (cid:107) f (x0) (cid:107) \u2212 f (x0) + Df (x0)  f (x0) f (x0) x0 \u03b1 (cid:107)  \u2264  (cid:107)  \u03b1  \u2212  x0 x0 \u2212 (cid:107) 2 + Df (x0)  \u03b1  (cid:107)  2 + (Df (x0) 2 + Df (x0) (x \u00b7 x0) + \u03b1  (cid:107)  (x  \u00b7 \u2212 x0) + \u03b1 2 x0  2\u03b1x0) x0) 2 x (cid:107)  (cid:107)  \u2212 (x  \u2212 x (cid:107)  \u2212  (cid:107)  \u00b7  \u2212  x0)  (x  \u00b7  \u2212  \u2212  \u2212 2\u03b1x0 2\u03b1x0  \u00b7  \u00b7  x0)  (x  \u2212 x + 2\u03b1  x0  2 (cid:107)  (cid:107)  f (x)  f (x)  f (x)  f (x)  (22).  \u2212  \u2212  \u2264  \u2264  \u21d4  \u21d4  \u21d4  \u21d4  \u2212  \u2212  (cid:107) \u00b7 (cid:107)  \u21d0\u21d2  2\u03b1I (cid:52) 0  Thus f is \u03b1-\ufb02at if and only if H(f  \u03b1 Hf (cid:52) 2\u03b1I. Hence requiring  2) is negative semidefinite, which is equivalent L is \u03b1-\ufb02at is a constraint on the to Hf 2\u03b1I. However our main result curvature of L relative to a \ufb02at surface: L is \u03b1-\ufb02at i\ufb00 HL (cid:60) \u2212 shows that the mixability constant (which is the best possible constant one can have in a bound such as (1)) is governed by the curvature of \u02dcL normalised by the curvature of \u02dcLlog. The necessity of comparison with log loss is not that surprising in light of the observations 17.9). regarding mixability by Gr\u00a8unwald (2007, \u00a7  \u2212  5. Conclusion  We have characterised the mixability constant for strictly proper multiclass losses (and shown how the result also applies to improper losses). The result shows in a precise and intuitive way the e\ufb00ect of the choice of loss function on the performance of an aggregating forecaster and the special role played by Log-loss in such settings.  Acknowledgments  This work was supported by the Australian Research Council and NICTA through backing Australia\u2019s ability. Some of the work was done while all the authors were visiting Microsoft Research, Cambridge and some was done while Tim van Erven was visiting ANU and NICTA. It was also supported in part by the IST Programme of the European Community, under the PASCAL2 Network of Excellence, IST-2007-216886. This publication only re\ufb02ects the authors\u2019 views.  References  Jacob Abernethy, Alekh Agarwal, Peter L. Bartlett, and Alexander Rakhlin. A stochastic In Proceedings of the 22nd Annual  view of optimal regret through minimax duality. Conference on Learning Theory, 2009.  Nicol`o Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006. Mixability is Bayes Risk Curvature Relative to Log Loss  Alexey Chernov, Yuri Kalnishkan, Fedor Zhdanov, and Vladimir Vovk. Supermartingales in prediction with expert advice. Theoretical Computer Science, 411:2647-2669, 2010.  Paul K. Fackler. Notes on matrix calculus. North Carolina State University, 2005.  Wendell H. Fleming. Functions of Several Variables. Springer, 1977.  Peter D. Gr\u00a8unwald. The Minimum Description Length Principle. MIT Press, Cambridge,  MA, 2007.  Peter D. Gr\u00a8unwald and A. Phillip Dawid. Game theory, maximum entropy, minimum discrepancy and robust Bayesian decision theory. The Annals of Statistics, 32(4):1367- 1433, 2004.  David Haussler, Jyrki Kivinen, and Manfred K. Warmuth. Sequential prediction of individ- ual sequences under general loss functions. IEEE Transactions on Information Theory, 44(5):1906-1925, 1998.  Jean-Baptiste Hiriart-Urruty and Claude Lemar\u00b4echal. Convex Analysis and Minimization  Algorithms: Part I: Fundamentals. Springer, Berlin, 1993.  Roger A. Horn and Charles R. Johnson. Matrix analysis. Cambridge University Press, 1985.  Yuri Kalnishkan and Michael V. Vyugin. On the absence of predictive complexity for some In Proceedings of the 13th International Conference on Algorithmic Learning games. Theory, volume 2533 of Lecture Notes in Artificial Intelligence, pages 164-172. Springer- Verlag, 2002a.  Yuri Kalnishkan and Michael V. Vyugin. Mixability and the existence of weak complexities. In The 15th Annual Conference on Computational Learning Theory (COLT 2002), volume 2375 of Lecture Notes in Artificial Intelligence, pages 105-120. Springer-Verlag, 2002b.  Yuri Kalnishkan and Michael V. Vyugin. The weak aggregating algorithm and weak mixa-  bility. Journal of Computer and System Sciences, 74:1228-1244, 2008.  Yuri Kalnishkan, Volodya Vovk, and Michael V. Vyugin. Loss functions, complexities, and  the Legendre transformation. Theoretical Computer Science, 313:195-207, 2004.  Jan R. Magnus and Heinz Neudecker. Matrix Di\ufb00erential Calculus with Applications in  Statistics and Econometrics (revised edition). John Wiley & Sons, Ltd., 1999.  Mark D. Reid and Robert C. Williamson. Composite binary losses. Journal of Machine  Learning Research, 11:2387-2422, 2010.  Mark D. Reid and Robert C. Williamson.  Information, divergence and risk for binary  experiments. Journal of Machine Learning Research, 12:731-817, March 2011.  John A. Thorpe. Elementary Topics in Di\ufb00erential Geometry. Springer, 1979.  Volodya Vovk. Aggregating strategies. In Proceedings of the Third Annual Workshop on  Computational Learning Theory (COLT), pages 371-383, 1990. Van Erven, Reid and Williamson  Volodya Vovk. A game of prediction with expert advice.  In Proceedings of the Eighth  Annual Conference on Computational Learning Theory, pages 51-60. ACM, 1995.  Volodya Vovk and Fedor Zhdanov. Prediction with expert advice for the Brier game. Journal  of Machine Learning Research, 10:2445-2471, 2009.  "}, "Distribution-Independent Evolvability of Linear Threshold Functions": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Distribution-Independent Evolvability of Linear Threshold Functions", "abstract": "Valiant\u2019s model of evolvability models the evolutionary process of acquiring useful functionality as a restricted form of learning from random examples \\citepValiant:09.Linear threshold functions and their various subclasses, such as conjunctions and decision lists, play a fundamental role in learning theory and hence their evolvabilityhas been the primary focus of research on Valiant\u2019s framework. One of the main open problems regarding the model is whether conjunctions are evolvable distribution-independently\\citepFeldmanValiant:08colt. We show that the answer is negative. Our proof is based on a new combinatorial parameter of a concept class that lower-bounds the complexity of learning fromcorrelations.We contrast the lower bound with a proof that linear threshold functions having a non-negligible margin on the data points are evolvable distribution-independently via a simple mutationalgorithm. Our algorithm relies on a non-linear loss function being used to select the hypotheses instead of 0-1 loss in Valiant\u2019s original definition. The proof of evolvabilityrequires that the loss function satisfies several mild conditions that are, for example, satisfied by the quadratic loss function studied in several other works \\citepMichael:07,Feldman:09sqd,Valiantp:11manu. An important property of our evolution algorithm is monotonicity, that is the algorithm guaranteesevolvability without any decreases in performance. Previously, monotone evolvability was only shown for conjunctions with quadratic loss \\citepFeldman:09sqd or when the distribution on the domain is severely restricted \\citepMichael:07,Feldman:09sqd,KanadeVV:10.", "pdf_url": "http://proceedings.mlr.press/v19/feldman11b/feldman11b.pdf", "keywords": ["Evolvability", "statistical query dimension", "conjunction", "halfspace", "linear threshold function", "quadratic loss"], "reference": "N. Bshouty and V. Feldman. On using extended statistical queries to avoid membership  queries. Journal of Machine Learning Research, 2:359-395, 2002. ISSN 1533-7928.  H. Buhrman, N. Vereshchagin, and R. de Wolf. On computation and communication with In Proceedings of IEEE Conference on Computational Complexity, pages  small bias. 24-32, 2007.  D. Diochnos and G. Tur\u00b4an. On evolvability: The swapping algorithm, product distributions, and covariance. In Proceedings of Stochastic Algorithms: Foundations and Applications (SAGA), pages 74-88, 2009.  270   Feldman  initiated by Forster (2002) and Forster et al. (2003) (see Linial et al., 2007; Sherstov, 2007; Linial and Shraibman, 2009, for some recent results). The inverse of the optimal margin is referred to as the margin complexity of a concept class (Linial et al., 2007). Besides its importance to machine learning, it has several connections to fundamental quantities in communication complexity (Goldmann et al., 1992; Sherstov, 2007; Linial and Shraibman, 2009). We cannot invoke this measure directly to upper-bound the complexity of using our evolution algorithm since margin complexity disregards the computational complexity of the embedding function. But given an e\ufb03cient embedding function the application of our evolution algorithm becomes straightforward.  Corollary 19 Let C be a concept class over domain X, X (cid:48) \u2286 Bn and \u03b3 > 1/q(n) for some polynomial q(\u00b7). If there exists an e\ufb03ciently computable embedding of C over X to HS\u03b3(X (cid:48)) over X (cid:48), then C is evolvable monotonically with any well-behaved loss function.  5. Conclusions and Open Problems  Our lower bound in Section 3 provides strong hardness results for learning that is limited to observing the accuracy (or alternatively, Boolean loss performance) of hypotheses. In particular, it implies that evolvability in Valiant\u2019s original model is severely limited unless the distribution over the domain is strongly restricted. An interesting direction for fur- ther work would be to find a complete characterization of distribution independent CSQ learnability (as was recently achieved for SQ learnability (Simon, 2007; Feldman, 2009b; Sz\u00a8or\u00b4enyi, 2009)). Potentially simpler questions left open in this work are whether conjunc- tion are CSQ learnable to constant accuracy (say 1/4) and whether the lower bound for conjunctions can be strengthened from a quasi-polynomial to an exponential number of queries.  At the same time results of Section 4 demonstrate that the limitation of Boolean loss can be overcome by using a real-valued hypotheses with a non-linear loss function. The evolution algorithm we described is based on the first mutation algorithm that is simple, general and robust enough to be a plausible candidate for biological evolution. It would be interesting to know if similar result can be proved for other SQ learnable concept classes (e.g. general linear threshold functions) and whether the result can be extended to more general loss functions.  References  N. Bshouty and V. Feldman. On using extended statistical queries to avoid membership  queries. Journal of Machine Learning Research, 2:359-395, 2002. ISSN 1533-7928.  H. Buhrman, N. Vereshchagin, and R. de Wolf. On computation and communication with In Proceedings of IEEE Conference on Computational Complexity, pages  small bias. 24-32, 2007.  D. Diochnos and G. Tur\u00b4an. On evolvability: The swapping algorithm, product distributions, and covariance. In Proceedings of Stochastic Algorithms: Foundations and Applications (SAGA), pages 74-88, 2009. Evolvability of LTF  V. Feldman. Evolvability from learning algorithms. In Proceedings of STOC, pages 619-628,  2008.  V. Feldman. Robustness of evolvability. In Proceedings of COLT, pages 277-292, 2009a.  V. Feldman. A complete characterization of statistical query learning with applications to  evolvability. In Proceedings of FOCS, pages 375-384, 2009b.  V. Feldman and L. G. Valiant. The learning power of evolution. In Proceedings of COLT,  pages 513-514, 2008.  J. Forster. A linear lower bound on the unbounded error probabilistic communication  complexity. Journal of Computer and System Sciences, 65(4):612-625, 2002.  J. Forster, N. Schmitt, H.U. Simon, and T. Suttorp. Estimating the optimal margins of  embeddings in euclidean half spaces. Machine Learning, 51(3):263-281, 2003.  Y. Freund. Boosting a weak learning algorithm by majority. Information and Computation,  121(2):256-285, 1995.  M. Goldmann, J. H\u02daastad, and A. Razborov. Majority gates vs. general weighted threshold  gates. Computational Complexity, 2:277-300, 1992.  J. Jackson. An e\ufb03cient membership-query algorithm for learning DNF with respect to the  uniform distribution. Journal of Computer and System Sciences, 55:414-440, 1997.  B. Jacobson, 2007. Personal communication with L. Valiant.  V. Kanade, L. G. Valiant, and J. Wortman Vaughan. Evolution with drifting targets. In  Proceedings of COLT, pages 155-167, 2010.  M. Kearns. E\ufb03cient noise-tolerant learning from statistical queries. Journal of the ACM,  45(6):983-1006, 1998.  M. Kearns and L. Valiant. Cryptographic limitations on learning boolean formulae and  finite automata. Journal of the ACM, 41(1):67-95, 1994.  M. Kearns, R. Schapire, and L. Sellie. Toward e\ufb03cient agnostic learning. Machine Learning,  17(2-3):115-141, 1994.  A. Klivans and R. Servedio. Learning DNF in time 2  System Sciences, 68(2):303-318, 2004.  \u02dcO(n1/3). Journal of Computer and  N. Linial and A. Shraibman. Learning complexity vs communication complexity. Combi-  natorics, Probability & Computing, 18(1-2):227-245, 2009.  N. Linial, S. Mendelson, G. Schechtman, and A. Shraibman. Complexity measures of sign  matrices. Combinatorica, 27(4):439-463, 2007.  N. Littlestone. Learning quickly when irrelevant attributes abound: a new linear-threshold  algorithm. Machine Learning, 2:285-318, 1987. Feldman  L. Michael. Evolving decision lists. Manuscript, 2007.  F. Rosenblatt. The perceptron: a probabilistic model for information storage and organi-  zation in the brain. Psychological Review, 65:386-407, 1958.  R. Schapire. The strength of weak learnability. Machine Learning, 5(2):197-227, 1990.  A. A. Sherstov. Halfspace matrices. In Proceedings of Conference on Computational Com-  plexity, pages 83-95, 2007.  H. Simon. A characterization of strong learnability in the statistical query model.  In Proceedings of Symposium on Theoretical Aspects of Computer Science, pages 393-404, 2007.  B. Sz\u00a8or\u00b4enyi. Characterizing statistical query learning:simplified notions and proofs. In ALT,  pages 186-200, 2009.  1984.  ECCC, 2006.  L. G. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134-1142,  L. G. Valiant. Evolvability. Journal of the ACM, 56(1):3.1-3.21, 2009. Earlier version in  P. Valiant. Distribution free evolvability of real functions over all convex loss functions.  Unpublished manuscript, 2011. "}, "Lower Bounds and Hardness Amplification for Learning Shallow Monotone Formulas": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Lower Bounds and Hardness Amplification for Learning Shallow Monotone Formulas", "abstract": "Much work has been done on learning various classes of \u201csimple\"monotone functions under the uniform distribution.In this paper we give the first unconditional lower bounds for learningproblems of this sort by showing that polynomial-time algorithms cannotlearn shallow monotone Boolean formulas under the uniform distributionin the well-studied Statistical Query (SQ) model.We introduce a new approach to understanding the learnability of \u201csimple\u201d monotone functions that is based ona recent characterization of Strong SQ learnability by \\citetSimon-2007Using the characterization we first show that depth-3 monotone formulas of size n^o(1) cannot be learned byany polynomial-time SQ algorithm to accuracy 1 -1/(\\log n)^\u03a9(1).  We then build on this result to show thatdepth-4 monotone formulas of size n^o(1) cannot be learned evento a certain \\frac 1 2 + o(1) accuracy in polynomial time.  Thisimproved hardness is achieved using a general technique that weintroduce for amplifying the hardness of \u201cmildly hard\u201d learningproblems in either the PAC or SQ framework. Thishardness amplification for learning builds on the ideas in the work of\\citetODonnell-2002on hardness amplification forapproximating functions using small circuits, and is applicable to a number of other contexts.Finally, we demonstrate that our approach can also be used to reduce the well-known open problem of learning juntas to learning of depth-3 monotone formulas.\\ignoreText version:Much work has been done on learning various classes of \u201csimple\"monotone functions under the uniform distribution.In this paper we give the first unconditional lower bounds for learningproblems of this sort by showing that polynomial-time algorithms cannotlearn constant-depth monotone Boolean formulas under the uniform distributionin the well-studied Statistical Query model.Using a recent characterization of Strong Statistical Querylearnability due to Feldman (FOCS 2009), we first show thatdepth-3 monotone formulas of size n^o(1) cannot be learned byany polynomial-time Statistical Query algorithm to accuracy 1 -1/(\\log n)^\u03a9(1).  We then build on this result to show thatdepth-4 monotone formulas of size n^o(1) cannot be learned evento a certain 1/2 + o(1) accuracy in polynomial time.  Thisimproved hardness is achieved using a general technique that weintroduce for amplifying the hardness of \u201cmildly hard\u201d learningproblems in either the PAC or Statistical Query framework. Thishardness amplification for learning builds on the ideas in the work ofO\u2019Donnell (STOC 2002) on hardness amplification forapproximating functions using small circuits, and is applicable to a number of other contexts.Finally, we demonstrate that our technique can also be used to reduce the well-known open problem of learning juntas to learning of depth-3 monotone formulas.", "pdf_url": "http://proceedings.mlr.press/v19/feldman11a/feldman11a.pdf", "keywords": ["statistical query learning", "Boolean formulas", "statistical query dimension", "hardness of learning"], "reference": "K. Amano and A. Maruoka. On learning monotone boolean functions under the uniform distribution. In Proceedings of the 13th International Conference on Algorithmic Learning Theory (ALT), pages 57-68, 2002.  Avrim Blum. Learning a function of r relevant variables.  In Proc. of the 16th Annual Conference on Computational Learning Theory (COLT), volume 2777 of Lecture Notes in Computer Science, pages 731-733. Springer-Verlag, 2003.  Avrim Blum, Merrick L. Furst, Je\ufb00rey Jackson, Michael J. Kearns, Yishay Mansour, and Steven Rudich. Weakly learning DNF and characterizing statistical query learning us- ing Fourier analysis. In Proc. 26th Annual ACM Symposium on Theory of Computing (STOC), pages 253-262. ACM Press, 1994.  Avrim Blum, Carl Burch, and John Langford. On learning monotone boolean functions. In Proc. 39th IEEE Symposium on Foundations of Computer Science (FOCS), pages 408-415. IEEE Computer Society Press, 1998.  Avrim Blum, Adam Kalai, and Hal Wasserman. Noise-tolerant learning, the parity problem, and the statistical query model. Journal of the ACM, 50(4):506-519, July 2003. Prelim. ver. in Proc. of STOC\u201900 .  Avrim Blum, Cynthia Dwork, Frank McSherry, and Kobbi Nissim. Practical privacy: the  SuLQ framework. In PODS, pages 128-138, 2005.  D. Boneh and R. Lipton. Amplification of weak learning over the uniform distribution. In Proceedings of the Sixth Annual Workshop on Computational Learning Theory, pages 347-351, 1993.  Nader H. Bshouty and Vitaly Feldman. On using extended statistical queries to avoid membership queries. Journal of Machine Learning Research, 2:359-395, 2002. Prelim. ver. in Proc. of COLT\u201901 .  Nader H. Bshouty and Christino Tamon. On the Fourier spectrum of monotone functions.  Journal of the ACM, 43(4):747-770, 2006.  T. Bylander. Learning noisy linear threshold functions. Available at:  http://ringer.cs.utsa.edu/research/AI/bylander/pubs/pubs.html, 1998.  Tom Bylander. Learning linear threshold functions in the presence of classification noise. In Proc. of the 7th Annual Conference on Computational Learning Theory (COLT), pages 340-347, 1994.  D. Dachman-Soled, H. Lee, T. Malkin, R. Servedio, A. Wan, and H. Wee. Optimal crypto- graphic hardness of learning monotone functions. In Proc. 35th International Colloquium on Algorithms, Languages and Programming (ICALP), pages 36-47, 2008.  John Dunagan and Santosh Vempala. A simple polynomial-time rescaling algorithm for solving linear programs. In Proc. 36th Annual ACM Symposium on Theory of Computing (STOC), pages 315-320. ACM Press, 2004.  289   Lower Bounds . . . for Learning Shallow Monotone Formulas  References  K. Amano and A. Maruoka. On learning monotone boolean functions under the uniform distribution. In Proceedings of the 13th International Conference on Algorithmic Learning Theory (ALT), pages 57-68, 2002.  Avrim Blum. Learning a function of r relevant variables.  In Proc. of the 16th Annual Conference on Computational Learning Theory (COLT), volume 2777 of Lecture Notes in Computer Science, pages 731-733. Springer-Verlag, 2003.  Avrim Blum, Merrick L. Furst, Je\ufb00rey Jackson, Michael J. Kearns, Yishay Mansour, and Steven Rudich. Weakly learning DNF and characterizing statistical query learning us- ing Fourier analysis. In Proc. 26th Annual ACM Symposium on Theory of Computing (STOC), pages 253-262. ACM Press, 1994.  Avrim Blum, Carl Burch, and John Langford. On learning monotone boolean functions. In Proc. 39th IEEE Symposium on Foundations of Computer Science (FOCS), pages 408-415. IEEE Computer Society Press, 1998.  Avrim Blum, Adam Kalai, and Hal Wasserman. Noise-tolerant learning, the parity problem, and the statistical query model. Journal of the ACM, 50(4):506-519, July 2003. Prelim. ver. in Proc. of STOC\u201900 .  Avrim Blum, Cynthia Dwork, Frank McSherry, and Kobbi Nissim. Practical privacy: the  SuLQ framework. In PODS, pages 128-138, 2005.  D. Boneh and R. Lipton. Amplification of weak learning over the uniform distribution. In Proceedings of the Sixth Annual Workshop on Computational Learning Theory, pages 347-351, 1993.  Nader H. Bshouty and Vitaly Feldman. On using extended statistical queries to avoid membership queries. Journal of Machine Learning Research, 2:359-395, 2002. Prelim. ver. in Proc. of COLT\u201901 .  Nader H. Bshouty and Christino Tamon. On the Fourier spectrum of monotone functions.  Journal of the ACM, 43(4):747-770, 2006.  T. Bylander. Learning noisy linear threshold functions. Available at:  http://ringer.cs.utsa.edu/research/AI/bylander/pubs/pubs.html, 1998.  Tom Bylander. Learning linear threshold functions in the presence of classification noise. In Proc. of the 7th Annual Conference on Computational Learning Theory (COLT), pages 340-347, 1994.  D. Dachman-Soled, H. Lee, T. Malkin, R. Servedio, A. Wan, and H. Wee. Optimal crypto- graphic hardness of learning monotone functions. In Proc. 35th International Colloquium on Algorithms, Languages and Programming (ICALP), pages 36-47, 2008.  John Dunagan and Santosh Vempala. A simple polynomial-time rescaling algorithm for solving linear programs. In Proc. 36th Annual ACM Symposium on Theory of Computing (STOC), pages 315-320. ACM Press, 2004. Feldman Lee Servedio  V. Feldman. A complete characterization of statistical query learning with applications to  evolvability. CoRR, abs/1002.3183, 2010. Prelim. ver. in Proc. of FOCS\u201909 .  Vitaly Feldman. Evolvability from learning algorithms. In Proc. 40th Annual ACM Sym-  posium on Theory of Computing (STOC). ACM Press, 2008.  T. Hancock and Y. Mansour. Learning monotone k-\u00b5 DNF formulas on product distri- In Proceedings of the Fourth Annual Conference on Computational Learning  butions. Theory, pages 179-193, 1991.  R. Impagliazzo. Hard-core distributions for somewhat hard problems. In Proceedings of the Thirty-Sixth Annual Symposium on Foundations of Computer Science, pages 538-545, 1995.  Je\ufb00rey C. Jackson, Homin K. Lee, Rocco A. Servedio, and Andrew Wan. Learning random monotone DNF. In 11th International Workshop on Approximation Algorithms for Com- binatorial Optimization Problems and 12th International Workshop on Randomization and Computation (RANDOM-APPROX), pages 483-497. Springer-Verlag, 2008.  Shiva Prasad Kasiviswanathan, Homin K. Lee, Kobbi Nissim, Sofya Raskhodnikova, and  Adam Smith. What can we learn privately? In FOCS, pages 531-540, 2008.  Michael J. Kearns. E\ufb03cient noise-tolerant learning from statistical queries. Journal of the  ACM, 45(6):983-1006, 1998. Prelim. ver. in Proc. of STOC\u201993 .  Michael J. Kearns, Ming Li, and Leslie G. Valiant. Learning Boolean formulas. Journal of  the ACM, 41(6):1298-1328, 1994. Prelim. ver. in Proc. of STOC\u201987 .  Maria M. Klawe, Wolfgang J. Paul, Nicholas Pippenger, and Mihalis Yannakakis. On In Proc. 16th Annual ACM Symposium on  monotone formulae with restricted depth. Theory of Computing (STOC), pages 480-487. ACM Press, 1984.  Adam Klivans and Rocco A. Servedio. Boosting and hard-core sets. Machine Learning, 53  (3):217-238, 2003. Prelim. ver. in Proc. of FOCS\u201999 .  Adam R. Klivans and Alexander A. Sherstov. Unconditional lower bounds for learning intersections of halfspaces. In Proc. of the 19th Annual Conference on Computational Learning Theory (COLT), 2006.  E. Mossel and R. O\u2019Donnell. On the noise sensitivity of monotone functions. Random  Structures and Algorithms, 23(3):333-350, 2003.  Elchanan Mossel, Ryan O\u2019Donnell, and Rocco A. Servedio. Learning functions of k relevant variables. SIAM Journal on Computing, 37(3):421-434, 2007. Prelim. ver. in Proc. of STOC\u201903 .  R. O\u2019Donnell and R. Servedio. Learning monotone decision trees in polynomial time. SIAM  J. Comput., 37(3):827-844, 2007.  Ryan O\u2019Donnell. Hardness amplification within NP. Journal of Computer and System  Sciences, 69(1):68-94, 2004. Prelim. ver. in Proc. of STOC\u201902 . Lower Bounds . . . for Learning Shallow Monotone Formulas  Ryan O\u2019Donnell and Karl Wimmer. KKL, Kruskal-Katona, and monotone nets. In Proc. 50th IEEE Symposium on Foundations of Computer Science (FOCS). IEEE Computer Society Press, 2009.  Y. Sakai and A. Maruoka. Learning monotone log-term DNF formulas under the uniform  distribution. Theory of Computing Systems, 33:17-33, 2000.  Robert E. Schapire. The strength of weak learnability. Machine Learning, 5:197-227, 1990.  Prelim. ver. in Proc. of FOCS\u20191989 .  Robert E. Schapire. The boosting approach to machine learning: An overview. In MSRI  Workshop on Nonlinear Estimation and Classification, 2001.  R. Servedio. Smooth boosting and learning with malicious noise. Journal of Machine  Learning Research, 4:633-648, 2003.  R. Servedio. On learning monotone DNF under product distributions. Information and  Computation, 193(1):57-74, 2004.  Alexander A. Sherstov. Communication complexity under product and nonproduct distri- butions. Computational Complexity, Annual IEEE Conference on, 0:64-70, 2008. ISSN 1093-0159. doi: http://doi.ieeecomputersociety.org/10.1109/CCC.2008.10.  Hans Ulrich Simon. A characterization of strong learnability in the statistical query model. In Proc. 24th Annual Symposium on Theoretical Aspects of Computer Science (STACS), pages 393-404, 2007.  B. Sz\u00a8or\u00b4enyi. Characterizing statistical query learning:simplified notions and proofs. In ALT,  pages 186-200, 2009.  Luca Trevisan. List decoding using the XOR lemma.  In Proc. 44th IEEE Symposium on Foundations of Computer Science (FOCS), pages 126-135. IEEE Computer Society Press, 2003.  Luca Trevisan. On uniform amplification of hardness in NP. In Proc. 37th Annual ACM  Symposium on Theory of Computing (STOC), pages 31-38. ACM Press, 2005.  Luca Trevisan. Personal communication, 2010.  Luca Trevisan, Madhur Tulsiani, and Salil P. Vadhan. Regularity, boosting, and e\ufb03ciently simulating every high-entropy distribution. In Proc. 24th Annual IEEE Conference on Computational Complexity (CCC), pages 126-136. IEEE Computer Society Press, 2009.  Leslie G. Valiant. Evolvability. Journal of the ACM, 56(1):3.1-3.21, 2009.  Ke Yang. New lower bounds for statistical query learning. Journal of Computer and System  Sciences, 70(4):485-509, 2005. Prelim. ver. in Proc. of COLT\u201902 . "}, "Complexity-Based Approach to Calibration with Checking Rules": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Complexity-Based Approach to Calibration with Checking Rules", "abstract": "We consider the problem of forecasting a sequence of outcomes from an unknown source. The quality of the forecaster is measured by a family of checking rules. We prove upper bounds on the value of the associated game, thus certifying the existence of a calibrated strategy for the forecaster. We show that complexity of the family of checking rules can be captured by the notion of a sequential cover introduced in \\citepRakSriTew10a. Various natural assumptions on the class of checking rules are considered, including finiteness of Vapnik-Chervonenkis and Littlestone\u2019s dimensions.", "pdf_url": "http://proceedings.mlr.press/v19/foster11a/foster11a.pdf", "keywords": [], "reference": "J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and no-regret learning are equivalent. In Proceedings of the 24th Annual Conference on Learning Theory, 2011.  S. Ben-David, D. Pal, and S. Shalev-Shwartz. Agnostic online learning. In Proceedings of  the 22th Annual Conference on Learning Theory, 2009.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  77(379):605-610, 1982.  A. P. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association,  V. de la Pe\u02dcna and E. Gin\u00b4e. Decoupling: From Dependence to Independence. Springer, 1998.  D. P. Foster and R. V. Vohra. Calibrated learning and correlated equilibrium. Games and  Economic Behavior, 21(1-2):40-55, October 1997.  D. P. Foster and R. V. Vohra. Asymptotic calibration. Biometrika, 85(2):379, 1998.  P.W. Goldberg and M.R. Jerrum. Bounding the Vapnik-Chervonenkis dimension of concept classes parameterized by real numbers. Machine Learning, 18(2):131-148, 1995. ISSN 0885-6125.  S. Kakade, M. Kearns, J. Langford, and L. Ortiz. Correlated equilibria in graphical games. In Proceedings of the 4th ACM Conference on Electronic Commerce, pages 42-47. ACM, 2003. ISBN 158113679X.  S. M. Kakade and D. P. Foster. Deterministic calibration and nash equilibrium. Journal of Computer and System Sciences, 74(1):115 - 130, 2008. ISSN 0022-0000. Learning Theory 2004.  E. Kalai, E. Lehrer, and R. Smorodinsky. Calibrated Forecasting and Merging. Games and  Economic Behavior, 29(1-2):151-169, 1999. ISSN 0899-8256.  E. Lehrer. The game of normal numbers. Mathematics of Operations Research, 29(2):  259-265, 2004. ISSN 0364-765X.  310   Foster Rakhlin Sridharan Tewari  \u221a  For p \u2264 2, (cid:107) \u00b7 (cid:107)2 \u2264 (cid:107) \u00b7 (cid:107)p and thus the condition (cid:107)dt(cid:107)p \u2264 1 implies (cid:107)dt(cid:107)2 \u2264 1. Further, k. Thus, ck = 8k. Now, for the case \u221a  k(cid:107) \u00b7 (cid:107)2 and so (cid:107) \u00b7 (cid:107)p \u2265 (cid:15) implies (cid:107) \u00b7 (cid:107)2 \u2265 (cid:15)/ k(cid:107) \u00b7 (cid:107)p and thus we set B =  k, leading to the value ck = 8k.  (cid:107) \u00b7 (cid:107)p \u2264 p \u2265 2, (cid:107) \u00b7 (cid:107)2 \u2264  \u221a  \u221a  A. Rakhlin gratefully acknowledges the support of NSF under grant CAREER DMS-0954737 and Dean\u2019s Research Fund.  Acknowledgments  References  J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and no-regret learning are equivalent. In Proceedings of the 24th Annual Conference on Learning Theory, 2011.  S. Ben-David, D. Pal, and S. Shalev-Shwartz. Agnostic online learning. In Proceedings of  the 22th Annual Conference on Learning Theory, 2009.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  77(379):605-610, 1982.  A. P. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association,  V. de la Pe\u02dcna and E. Gin\u00b4e. Decoupling: From Dependence to Independence. Springer, 1998.  D. P. Foster and R. V. Vohra. Calibrated learning and correlated equilibrium. Games and  Economic Behavior, 21(1-2):40-55, October 1997.  D. P. Foster and R. V. Vohra. Asymptotic calibration. Biometrika, 85(2):379, 1998.  P.W. Goldberg and M.R. Jerrum. Bounding the Vapnik-Chervonenkis dimension of concept classes parameterized by real numbers. Machine Learning, 18(2):131-148, 1995. ISSN 0885-6125.  S. Kakade, M. Kearns, J. Langford, and L. Ortiz. Correlated equilibria in graphical games. In Proceedings of the 4th ACM Conference on Electronic Commerce, pages 42-47. ACM, 2003. ISBN 158113679X.  S. M. Kakade and D. P. Foster. Deterministic calibration and nash equilibrium. Journal of Computer and System Sciences, 74(1):115 - 130, 2008. ISSN 0022-0000. Learning Theory 2004.  E. Kalai, E. Lehrer, and R. Smorodinsky. Calibrated Forecasting and Merging. Games and  Economic Behavior, 29(1-2):151-169, 1999. ISSN 0899-8256.  E. Lehrer. The game of normal numbers. Mathematics of Operations Research, 29(2):  259-265, 2004. ISSN 0364-765X. Calibration with Checking Rules  N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold  algorithm. Machine Learning, 2(4):285-318, 04 1988.  S. Mannor and G. Stoltz. A geometric proof of calibration. Mathematics of Operations  Research, 35(4):721-727, 2010. doi: 10.1287/moor.1100.0465.  D. Oakes. Self-calibrating priors do not exist. Journal of the American Statistical Associa-  tion, 80(390):339-339, 1985. ISSN 0162-1459.  W. Olszewski and A. Sandroni. A nonmanipulable test. Annals of Statistics, 37(2):1013-  1039, 2009.  I. Pinelis. Optimum bounds for the distributions of martingales in Banach spaces. The  Annals of Probability, 22(4):1679-1706, 1994.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Random averages, combinatorial parameters, and learnability. In NIPS, 2010a. Full version available at arXiv:1006.1138.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Beyond regret. ArXiv preprint  arXiv:1011.3168v2, 2010b.  A. Sandroni, R. Smorodinsky, and R.V. Vohra. Calibration with many checking rules.  Mathematics of Operations Research, 28(1):141-153, 2003. ISSN 0364-765X.  H.P. Young. Strategic learning and its limits. Oxford University Press, USA, 2004. ISBN  0199269181. Foster Rakhlin Sridharan Tewari  "}, "Concentration-Based Guarantees  for Low-Rank Matrix Reconstruction": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Concentration-Based Guarantees  for Low-Rank Matrix Reconstruction", "abstract": "We consider the problem of approximately reconstructing a partially-observed,   approximately low-rank matrix.  This problem has received much  attention lately, mostly using the trace-norm as a surrogate to the  rank.  Here we study low-rank matrix reconstruction using both the  trace-norm, as well as the less-studied max-norm, and present  reconstruction guarantees based on existing analysis on the  Rademacher complexity of the unit balls of these norms. We show how  these are superior in several ways to recently published guarantees  based on specialized analysis.", "pdf_url": "http://proceedings.mlr.press/v19/foygel11a/foygel11a.pdf", "keywords": ["Matrix completion", "low-rank matrices", "trace norm", "nuclear norm", "max norm", "Rademacher complexity"], "reference": "925-936, 2010.  P. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: Risk bounds and structural results. In Computational Learning Theory, pages 224-240. Springer, 2001.  E.J. Candes and Y. Plan. Matrix completion with noise. Proceedings of the IEEE, 98(6):  E.J. Cand`es and B. Recht. Exact matrix completion via convex optimization. Foundations  of Computational Mathematics, 9(6):717-772, 2009.  E.J. Candes and T. Tao. The power of convex relaxation: Near-optimal matrix completion.  IEEE Transactions on Information Theory, 56(5):2053-2080, 2010.  A. Chistov and D. Grigoriev. Complexity of quantifier elimination in the theory of alge- braically closed fields. In Proceedings of the 11th Symposium on Mathematical Foun- dations of Computer Science, volume 176 of Lecture Notes in Computer Science, pages 17-31. Springer, 1984.  M. Fazel, H. Hindi, and S.P. Boyd. A rank minimization heuristic with application to In Proceedings of the 2001 American Control  minimum order system approximation. Conference, volume 6, pages 4734-4739. IEEE, 2002.  R.H. Keshavan, A. Montanari, and S. Oh. Matrix completion from noisy entries. Journal  of Machine Learning Research, 11:2057-2078, 2010.  V. Koltchinskii, A.B. Tsybakov, and K. Lounici. Nuclear norm penalization and optimal  rates for noisy low rank matrix completion. arXiv:1011.6256, 2010.  T. Lee, A. Shraibman, and R. Spalek. A direct product theorem for discrepancy. In 23rd Annual IEEE Conference on Computational Complexity (CCC\u201908), pages 71-80. IEEE, 2008.  331   Concentration-Based Guaranteesfor Low-Rank Matrix Reconstruction  \u2022 Pointing out that the max-norm can yield superior reconstruction guarantees over the  more commonly used trace-norm.  \u2022 Studying the issue of sampling with and without replacement, and establishing rig- orous generic results relating the two settings. This has been done before for exact recovery (Recht, 2009), but is done here for the more delicate situation of approximate recovery of either M or Y .  The main deficiency of our approach is a worse dependence on the approximation parameter (cid:15), when \u03c3 > 0 (i.e. the approximately low rank case) and (cid:15) = o(\u03c32) (i.e. estimation error less then approximation error). Although this dependence is tight for general classes with bounded Rademacher complexity, we do not know if it can be improved in Theorem 6. In particular, we do not know whether the less favorable dependence is a consequence of not relying on zero-mean i.i.d. noise, or not relying on M having low-rank (instead of only assuming low max-norm), or on relying only on the Rademacher complexity of the class of low max-norm matrices\u2014perhaps better bounds can be obtained with a more careful analysis.  References  925-936, 2010.  P. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: Risk bounds and structural results. In Computational Learning Theory, pages 224-240. Springer, 2001.  E.J. Candes and Y. Plan. Matrix completion with noise. Proceedings of the IEEE, 98(6):  E.J. Cand`es and B. Recht. Exact matrix completion via convex optimization. Foundations  of Computational Mathematics, 9(6):717-772, 2009.  E.J. Candes and T. Tao. The power of convex relaxation: Near-optimal matrix completion.  IEEE Transactions on Information Theory, 56(5):2053-2080, 2010.  A. Chistov and D. Grigoriev. Complexity of quantifier elimination in the theory of alge- braically closed fields. In Proceedings of the 11th Symposium on Mathematical Foun- dations of Computer Science, volume 176 of Lecture Notes in Computer Science, pages 17-31. Springer, 1984.  M. Fazel, H. Hindi, and S.P. Boyd. A rank minimization heuristic with application to In Proceedings of the 2001 American Control  minimum order system approximation. Conference, volume 6, pages 4734-4739. IEEE, 2002.  R.H. Keshavan, A. Montanari, and S. Oh. Matrix completion from noisy entries. Journal  of Machine Learning Research, 11:2057-2078, 2010.  V. Koltchinskii, A.B. Tsybakov, and K. Lounici. Nuclear norm penalization and optimal  rates for noisy low rank matrix completion. arXiv:1011.6256, 2010.  T. Lee, A. Shraibman, and R. Spalek. A direct product theorem for discrepancy. In 23rd Annual IEEE Conference on Computational Complexity (CCC\u201908), pages 71-80. IEEE, 2008. Foygel Srebro  S. Negahban and M.J. Wainwright. Restricted strong convexity and weighted matrix com-  pletion: Optimal bounds with noise. arXiv:1009.2118, 2010.  B. Recht. A simpler approach to matrix completion. arXiv:0910.0651, 2009.  R. Salakhutdinov and N. Srebro. Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm. Advances in Neural Information Processing Systems, 23: 2056-2064, 2010.  Y. Seginer. The expected norm of random matrices. Combinatorics, Probability and Com-  puting, 9(2):149-166, 2000.  A.A. Sherstov. Halfspace matrices. In 22nd Annual IEEE Conference on Computational  Complexity (CCC\u201907), pages 83-95. IEEE, 2007.  N. Srebro and A. Shraibman. Rank, trace-norm and max-norm. 18th Annual Conference  on Learning Theory (COLT), pages 545-560, 2005.  N. Srebro, J.D.M. Rennie, and T.S. Jaakkola. Maximum-margin matrix factorization. Ad-  vances in Neural Information Processing Systems, 17:1329-1336, 2005.  N. Srebro, K. Sridharan, and A. Tewari. Smoothness, low noise and fast rates. Advances  in Neural Information Processing Systems, 23:2199-2207, 2010.  J.A. Tropp. User-friendly tail bounds for sums of random matrices. arXiv:1004.4389, 2010. Concentration-Based Guaranteesfor Low-Rank Matrix Reconstruction  "}, "On the Consistency of Multi-Label Learning": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "On the Consistency of Multi-Label Learning", "abstract": "Multi-label learning has attracted much attention during the past few years. Many multi-label learning approaches have been developed, mostly working with surrogate loss functions since multi-label loss functions are usually difficult to optimize directly owing to non-convexity and discontinuity. Though these approaches are effective, to the best of our knowledge, there is no theoretical result on the convergence of risk of the learned functions to the Bayes risk. In this paper, focusing on two well-known multi-label loss functions, i.e., \\textitranking loss and \\textithamming loss, we prove a necessary and sufficient condition for the consistency of multi-label learning based on surrogate loss functions. Our results disclose that, surprisingly, none convex surrogate loss is consistent with the ranking loss. Inspired by the finding, we introduce the \\textitpartial ranking loss, with which some surrogate functions are consistent. For hamming loss, we show that some recent multi-label learning approaches are inconsistent even for deterministic multi-label classification, and give a surrogate loss function which is consistent for the deterministic case. Finally, we discuss on the consistency of learning approaches which address multi-label learning by decomposing into a set of binary classification problems.", "pdf_url": "http://proceedings.mlr.press/v19/gao11a/gao11a.pdf", "keywords": ["Consistency", "multi-label learning", "surrogate loss", "ranking loss", "hamming loss"], "reference": "P. L. Bartlett, M. I. Jordan, and J. D. McAuli\ufb00e. Convexity, classification, and risk bounds.  Journal of the American Statistical Association, 101(473):138-156, 2006.  M. R. Boutell, J. Luo, X. Shen, and C.M. Brown. Learning multi-label scene classification.  Pattern Recognition, 37(9):1757-1771, 2004.  D. Cossock and T. Zhang. Statistical analysis of bayes optimal subset ranking.  IEEE  Transactions on Information Theory, 54(11):5140-5154, 2008.  O. Dekel, C. Manning, and Y. Singer. Log-linear models for label ranking. In S. Thrun, L. K. Saul, and B. Sch\u00a8olkopf, editors, Advances in Neural Information Processing Systems 16. MIT Press, Cambridge, MA, 2004.  K. Dembczy\u00b4nski, W. W. Cheng, and E. H\u00a8ullermeier. Bayes optimal multilabel classification via probabilistic classifier chains. In Proceedings of the 27th International Conference on Machine Learning, pages 279-286, Haifa, Israel, 2010.  J. C. Duchi, L. W. Mackey, and M. I. Jordan. On the consistency of ranking algorithms. In Proceedings of the 27th International Conference on Machine Learning, pages 327-334, Haifa, Israel, 2010.  A. Elissee\ufb00 and J. Weston. A kernel method for multi-labelled classification. In T. G. Diet- terich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems 14, pages 681-687. MIT Press, Cambridge, MA, 2002.  N. Ghamrawi and A. McCallum. Collective multi-label classification. In Proceedings of the 14th ACM International Conference on Information and Knowledge Management, pages 195-200, Bremen, Germany, 2005.  S. Godbole and S. Sarawagi. Discriminative methods for multi-labeled classification. In Proceedings of the 8th Pacific-Asia Conference on Knowledge Discovery and Data Mining, pages 22-30, Sydney, Austrialia, 2004.  B. Hariharan, L. Zelnik-Manor, S. Vishwanathan, and M. Varma. Large scale max-margin multi-label classification with priors. In Proceedings of the 27th International Conference on Machine Learning, pages 423-430, Haifa, Israel, 2010.  D. Hsu, S. M. Kakade, J. Langford, and T. Zhang. Multi-label prediction via compressed sensing. In Y. Bengio, D. Schuurmans, J. La\ufb00erty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems 22, pages 772-780. MIT Press, Cambridge, MA, 2009.  357   On the Consistency of Multi-Label Learning  Acknowledgments  The authors want to thank the anonymous reviewers for their helpful comments and sug- gestions, and Tong Zhang for reading a preliminary version. This research was supported by the National Fundamental Research Program of China (2010CB327903), the National Science Foundation of China (61073097) and the Jiangsu Science Foundation (BK2008018).  References  P. L. Bartlett, M. I. Jordan, and J. D. McAuli\ufb00e. Convexity, classification, and risk bounds.  Journal of the American Statistical Association, 101(473):138-156, 2006.  M. R. Boutell, J. Luo, X. Shen, and C.M. Brown. Learning multi-label scene classification.  Pattern Recognition, 37(9):1757-1771, 2004.  D. Cossock and T. Zhang. Statistical analysis of bayes optimal subset ranking.  IEEE  Transactions on Information Theory, 54(11):5140-5154, 2008.  O. Dekel, C. Manning, and Y. Singer. Log-linear models for label ranking. In S. Thrun, L. K. Saul, and B. Sch\u00a8olkopf, editors, Advances in Neural Information Processing Systems 16. MIT Press, Cambridge, MA, 2004.  K. Dembczy\u00b4nski, W. W. Cheng, and E. H\u00a8ullermeier. Bayes optimal multilabel classification via probabilistic classifier chains. In Proceedings of the 27th International Conference on Machine Learning, pages 279-286, Haifa, Israel, 2010.  J. C. Duchi, L. W. Mackey, and M. I. Jordan. On the consistency of ranking algorithms. In Proceedings of the 27th International Conference on Machine Learning, pages 327-334, Haifa, Israel, 2010.  A. Elissee\ufb00 and J. Weston. A kernel method for multi-labelled classification. In T. G. Diet- terich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems 14, pages 681-687. MIT Press, Cambridge, MA, 2002.  N. Ghamrawi and A. McCallum. Collective multi-label classification. In Proceedings of the 14th ACM International Conference on Information and Knowledge Management, pages 195-200, Bremen, Germany, 2005.  S. Godbole and S. Sarawagi. Discriminative methods for multi-labeled classification. In Proceedings of the 8th Pacific-Asia Conference on Knowledge Discovery and Data Mining, pages 22-30, Sydney, Austrialia, 2004.  B. Hariharan, L. Zelnik-Manor, S. Vishwanathan, and M. Varma. Large scale max-margin multi-label classification with priors. In Proceedings of the 27th International Conference on Machine Learning, pages 423-430, Haifa, Israel, 2010.  D. Hsu, S. M. Kakade, J. Langford, and T. Zhang. Multi-label prediction via compressed sensing. In Y. Bengio, D. Schuurmans, J. La\ufb00erty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems 22, pages 772-780. MIT Press, Cambridge, MA, 2009. Gao Zhou  Y. Lin. Support vector machines and the bayes rule in classification. Data Mining and  Knowledge Discovery, 6(3):259-275, 2002.  J. Petterson and T. Caetano. Reverse multi-label learning. In J. La\ufb00erty, C. K. I. Williams, J. Shawe-Taylor, R. S. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23, pages 1912-1920. MIT Press, Cambridge, MA, 2010.  G.-J. Qi, X.-S. Hua, Y. Rui, J. Tang, T. Mei, and H.-J. Zhang. Correlative multi-label video annotation. In Proceedings of the 15th ACM International Conference on Multimedia, pages 17-26, Augsburg, Germany, 2007.  R. T. Rockafellar. Convex Analysis. Princeton University Press, Princeton, NJ, 1997.  R. E. Schapire and Y. Singer. BoosTexter: A boosting-based system for text categorization.  Machine Learning, 39(2):135-168, 2000.  I. Steinwart. Consistency of support vector machines and other regularized kernel classifiers.  IEEE Transactions on Information Theory, 51(1):128-142, 2005.  B. Taskar, C. Guestrin, and D. Koller. Max-margin markov networks. In S. Thrun, L. Saul, and B. Sch\u00a8olkopf, editors, Advances in Neural Information Processing Systems 16. MIT Press, Cambridge, MA, 2004.  A. Tewari and P. L. Bartlett. On the consistency of multiclass classification methods.  Journal of Machine Learning Research, 8:1007-1025, 2007.  F. Xia, T. Y. Liu, J. Wang, W. Zhang, and H. Li. Listwise approach to learning to rank: Theory and algorithm. In Proceedings of the 25th International Conference on Machine Learning, pages 1192-1199, Helsinki, Finland, 2008.  M.-L. Zhang and Z.-H. Zhou. Multi-label neural network with applications to functional ge- nomics and text categorization. IEEE Transactions on Knowledge and Data Engineering, 18(10):1338-1351, 2006.  M.-L. Zhang and Z.-H. Zhou. ML-KNN: A lazy learning approach to multi-label learning.  Pattern Recognition, 40(7):2038-2048, 2007.  T. Zhang. Statistical analysis of some multi-category large margin classification methods.  Journal of Machine Learning Research, 5:1225-1251, 2004a.  T. Zhang. Statistical behavior and consistency of classification methods based on convex  risk minimization. Annals of Statistics, 32(1):56-85, 2004b.  Z.-H. Zhou and M.-L. Zhang. Multi-instance multi-label learning with application to scene classification. In B. Sch\u00a8olkopf, J. Platt, and T. Hofmann, editors, Advances in Neural Information Processing Systems 19, pages 1609-1616. MIT Press, Cambridge, MA, 2007. "}, "The KL-UCB Algorithm for Bounded Stochastic Bandits and Beyond": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "The KL-UCB Algorithm for Bounded Stochastic Bandits and Beyond", "abstract": "This paper presents a finite-time analysis of the KL-UCB algorithm, an online, horizon-free  index policy for stochastic bandit problems.  We prove two distinct results: first, for arbitrary bounded rewards, the KL-UCB algorithm  satisfies a uniformly better regret bound than UCB and its variants; second, in the special case of  Bernoulli rewards, it reaches the lower bound of Lai and Robbins.  Furthermore, we show that simple adaptations of the KL-UCB algorithm are also optimal for  specific classes of (possibly unbounded) rewards, including those generated from exponential  families of distributions.  A large-scale numerical study comparing KL-UCB with its main competitors (UCB, MOSS,  UCB-Tuned, UCB-V, DMED) shows that KL-UCB is remarkably efficient and stable, including for short time horizons. KL-UCB is also the only method that always performs better  than the basic UCB policy.  Our regret bounds rely on deviations results of independent interest which are stated and proved  in the Appendix. As a by-product, we also obtain an improved regret bound for the standard UCB  algorithm.", "pdf_url": "http://proceedings.mlr.press/v19/garivier11a/garivier11a.pdf", "keywords": ["List of keywords"], "reference": "R. Agrawal. Sample mean based index policies with O(log n) regret for the multi-armed  bandit problem. Advances in Applied Probability, 27(4):1054-1078, 1995.  J-Y. Audibert and S. Bubeck. Regret bounds and minimax policies under partial monitor-  ing. Journal of Machine Learning Resaerch, 11:2785-2836, 2010.  J-Y. Audibert, R. Munos, and Cs. Szepesv\u00b4ari. Exploration-exploitation trade-o\ufb00 using variance estimates in multi-armed bandits. Theoretical Computer Science, 410(19), 2009.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine Learning, 47(2):235-256, 2002.  A.N. Burnetas and M.N. Katehakis. Optimal adaptive policies for Markov decision pro-  cesses. Mathematics of Operations Research, pages 222-255, 1997.  C.J. Clopper and E.S. Pearson. The use of confidence of fiducial limits illustration in the  case of the binomial. Biometrika, 26:404-413, 1934.  E. Even-Dar, S. Mannor, and Y. Mansour. PAC bounds for multi-armed bandit and Markov decision processes. In Conf. Comput. Learning Theory (Sydney, Australia, 2002), volume 2375 of Lecture Notes in Comput. Sci., pages 255-270. Springer, Berlin, 2002.  S. Filippi. Optimistic strategies in Reinforcement Learning (in French). PhD thesis, Telecom  ParisTech, 2010. URL http://tel.archives-ouvertes.fr/tel-00551401/.  S. Filippi, O. Capp\u00b4e, and A. Garivier. Optimism in reinforcement learning and Kullback- Leibler divergence. In Allerton Conf. on Communication, Control, and Computing, Mon- ticello, US, 2010.  J.C. Gittins. Bandit processes and dynamic allocation indices. Journal of the Royal Statis-  tical Society, Series B, 41(2):148-177, 1979.  J. Honda and A. Takemura. An asymptotically optimal bandit algorithm for bounded support models. In T. Kalai and M. Mohri, editors, Conf. Comput. Learning Theory, Haifa, Israel, 2010.  T.L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6(1):4-22, 1985.  373   KL-UCB: bounded bandits, and beyond  7. Conclusion  The self-normalized deviation bound of Theorems 10 and 11, together with the new analysis In presented in Section 6, allowed us to design and analyze improved UCB algorithms. this approach, only an upper-bound of the deviations (more precisely, of the exponential moments) of the rewards is required, which makes it possible to obtain versatile policies satisfying interesting regret bounds for large classes of reward distributions. The resulting index policies are simple, fast, and very e\ufb03cient in practice, even for small time horizons.  References  R. Agrawal. Sample mean based index policies with O(log n) regret for the multi-armed  bandit problem. Advances in Applied Probability, 27(4):1054-1078, 1995.  J-Y. Audibert and S. Bubeck. Regret bounds and minimax policies under partial monitor-  ing. Journal of Machine Learning Resaerch, 11:2785-2836, 2010.  J-Y. Audibert, R. Munos, and Cs. Szepesv\u00b4ari. Exploration-exploitation trade-o\ufb00 using variance estimates in multi-armed bandits. Theoretical Computer Science, 410(19), 2009.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine Learning, 47(2):235-256, 2002.  A.N. Burnetas and M.N. Katehakis. Optimal adaptive policies for Markov decision pro-  cesses. Mathematics of Operations Research, pages 222-255, 1997.  C.J. Clopper and E.S. Pearson. The use of confidence of fiducial limits illustration in the  case of the binomial. Biometrika, 26:404-413, 1934.  E. Even-Dar, S. Mannor, and Y. Mansour. PAC bounds for multi-armed bandit and Markov decision processes. In Conf. Comput. Learning Theory (Sydney, Australia, 2002), volume 2375 of Lecture Notes in Comput. Sci., pages 255-270. Springer, Berlin, 2002.  S. Filippi. Optimistic strategies in Reinforcement Learning (in French). PhD thesis, Telecom  ParisTech, 2010. URL http://tel.archives-ouvertes.fr/tel-00551401/.  S. Filippi, O. Capp\u00b4e, and A. Garivier. Optimism in reinforcement learning and Kullback- Leibler divergence. In Allerton Conf. on Communication, Control, and Computing, Mon- ticello, US, 2010.  J.C. Gittins. Bandit processes and dynamic allocation indices. Journal of the Royal Statis-  tical Society, Series B, 41(2):148-177, 1979.  J. Honda and A. Takemura. An asymptotically optimal bandit algorithm for bounded support models. In T. Kalai and M. Mohri, editors, Conf. Comput. Learning Theory, Haifa, Israel, 2010.  T.L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6(1):4-22, 1985. Garivier Capp\u00b4e  O-A. Maillard, R. Munos, and G. Stoltz. A finite-time analysis of multi-armed bandits problems with kullback-leibler divergences. In Conf. Comput. Learning Theory, Budapest, Hungary, 2011.  P. Massart. Concentration inequalities and model selection, volume 1896 of Lecture Notes in Mathematics. Springer, Berlin, 2007. Lectures from the 33rd Summer School on Probability Theory held in Saint-Flour, July 6-23, 2003.  "}, "Sparsity Regret Bounds for Individual Sequences in Online Linear Regression": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Sparsity Regret Bounds for Individual Sequences in Online Linear Regression", "abstract": "We consider the problem of online linear regression on arbitrary deterministic sequences when the ambient dimension d can be much larger than the number of time rounds T. We introduce the notion of sparsity regret bound, which is a deterministic online counterpart of recent risk bounds derived in the stochastic setting under a sparsity scenario. We prove such regret bounds for an online-learning algorithm called SeqSEW and based on exponential weighting and data-driven truncation. In a second part we apply a parameter-free version of this algorithm on i.i.d. data and derive risk bounds of the same flavor as in \\citetDaTsy08SEW,DaTsy10MirrorAveraging but which solve two questions left open therein. In particular our risk bounds are adaptive (up to a logarithmic factor) to the unknown variance of the noise if the latter is Gaussian.", "pdf_url": "http://proceedings.mlr.press/v19/gerchinovitz11a/gerchinovitz11a.pdf", "keywords": ["Individual Sequences", "Sparsity", "Online Linear Regression", "Regret Bounds"], "reference": "J.-Y. Audibert. Fast learning rates in statistical inference through aggregation. Ann.  Statist., 37(4):1591-1646, 2009.  P. Auer, N. Cesa-Bianchi, and C. Gentile. Adaptive and self-confident on-line learning  algorithms. J. Comp. Sys. Sci., 64:48-75, 2002.  393   Sparsity Regret Bounds for Individual Sequences  Proposition 10 (A consequence of Prop. 1 of Dalalyan and Tsybakov 2011) Assume that sup1(cid:54)j(cid:54)d (cid:107)\u03d5j(cid:107)\u221e < \u221e and that the set of assumptions (21) above hold true. Then, for every R > 0 and \u03b7 (cid:54) , the mirror averaging aggregate (cid:98)fT : X \u2192 R defined in Dalalyan and Tsybakov (2011, Equations (1) and (3)) satisfies  (cid:54)R (cid:107)u \u00b7 \u03d5 \u2212 f (cid:107)2 \u221e  2\u03c32 + 2 sup(cid:107)u(cid:107)1  (cid:17)\u22121  (cid:16)  E  (cid:20)(cid:119) (cid:119) (cid:119)f \u2212 (cid:98)fT  (cid:21)  (cid:119) 2 (cid:119) (cid:119)  L2  (cid:54)  (cid:40)  (cid:107)f \u2212 u \u00b7 \u03d5(cid:107)2  L2 +  4 (cid:107)u(cid:107)0 \u03b7(T + 1)  (cid:32)  \u221a  ln  1 +  (cid:33)(cid:41)  dT (cid:107)u(cid:107)1 (cid:107)u(cid:107)0  inf (cid:54)R\u22122d\u03c4  (cid:107)u(cid:107)1  +  4 dT  d (cid:88)  j=1  (cid:107)\u03d5j(cid:107)2  L2 +  1 \u03b7(T + 1)  .  We can now discuss the two questions left open by Dalalyan and Tsybakov (2011). Despite the similarity of the two bounds, the sparsity oracle inequality stated in Propo- sition 10 above only holds for vectors u within (cid:96)1-balls of finite radii. The authors thus asked in Dalalyan and Tsybakov (2011, Section 4.2) whether it was possible to extend the infimum to the whole Rd space. Our results show that, thanks to data-driven truncation, the answer is positive.  The second open question, which was raised in Dalalyan and Tsybakov (2011, Section 5.1, Remark 6), deals with the prior knowledge of the variance factor \u03c32 of the noise. The latter is indeed required by their algorithm for the choice of the inverse temperature parameter \u03b7. The authors thus asked whether adaptivity to \u03c32 was possible. Our sparsity oracle inequality (22) above provides a positive answer (up to a ln T factor).  Remark 11 Similar adaptivity results hold in the regression model with fixed design; see the full version of this paper (Gerchinovitz, 2011, Section 5.2). The framework of prediction of individual sequences thus seems to o\ufb00er a unifying setting to address tuning issues both in the random and in the fixed design regression models.  Acknowledgments  The author would like to thank Arnak Dalalyan, Gilles Stoltz, and Pascal Massart for their helpful comments and suggestions. The author acknowledges the support of the French Agence Nationale de la Recherche (ANR), under grant PARCIMONIE (http://www.proba. jussieu.fr/ANR/Parcimonie), and of the IST Programme of the European Community, un- der the PASCAL2 Network of Excellence, IST-2007-216886.  References  J.-Y. Audibert. Fast learning rates in statistical inference through aggregation. Ann.  Statist., 37(4):1591-1646, 2009.  P. Auer, N. Cesa-Bianchi, and C. Gentile. Adaptive and self-confident on-line learning  algorithms. J. Comp. Sys. Sci., 64:48-75, 2002. Gerchinovitz  K. S. Azoury and M. K. Warmuth. Relative loss bounds for on-line density estimation with  the exponential family of distributions. Mach. Learn., 43(3):211-246, 2001.  G. Biau, K. Bleakley, L. Gy\u00a8orfi, and G. Ottucs\u00b4ak. Nonparametric sequential prediction of  time series. J. Nonparametr. Stat., 22(3-4):297-317, 2010.  L. Birg\u00b4e and P. Massart. Gaussian model selection. J. Eur. Math. Soc., 3:203-268, 2001.  F. Bunea, A. B. Tsybakov, and M. H. Wegkamp. Aggregation for regression learning.  Technical report, 2004. Available at http://arxiv.org/abs/math/0410214.  F. Bunea, A. B. Tsybakov, and M. H. Wegkamp. Aggregation and sparsity via (cid:96)1 penal- In Proceedings of the 19th Annual Conference on Learning Theory  ized least squares. (COLT\u201906), pages 379-391, 2006.  F. Bunea, A. B. Tsybakov, and M. H. Wegkamp. Aggregation for Gaussian regression. Ann.  Statist., 35(4):1674-1697, 2007.  O. Catoni. Statistical learning theory and stochastic optimization. Springer, New York,  2004.  Press, 2006.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  N. Cesa-Bianchi, Y. Mansour, and G. Stoltz. Improved second-order bounds for prediction  with expert advice. Mach. Learn., 66(2/3):321-352, 2007.  A. Dalalyan and A. B. Tsybakov. Aggregation by exponential weighting and sharp oracle in- equalities. In Proceedings of the 20th Annual Conference on Learning Theory (COLT\u201907), pages 97-111, 2007.  A. Dalalyan and A. B. Tsybakov. Aggregation by exponential weighting, sharp PAC-  Bayesian bounds and sparsity. Mach. Learn., 72(1-2):39-61, 2008.  A. Dalalyan and A. B. Tsybakov. Sparse regression learning by aggregation and Langevin In Proceedings of the 22nd Annual Conference on Learning Theory  Monte-Carlo. (COLT\u201909), pages 83-92, 2009.  A. Dalalyan and A. B. Tsybakov. Mirror averaging with sparsity priors. Bernoulli, 2011.  To appear. Available at http://hal.archives-ouvertes.fr/hal-00461580/.  J. C. Duchi, S. Shalev-Shwartz, Y. Singer, and A. Tewari. Composite objective mirror descent. In Proceedings of the 23rd Annual Conference on Learning Theory (COLT\u201910), pages 14-26, 2010.  Y. Freund, R. E. Schapire, Y. Singer, and M. K. Warmuth. Using and combining predic- tors that specialize. In Proceedings of the 29th annual ACM Symposium on Theory of Computing (STOC\u201997), pages 334-343, 1997.  S. Gerchinovitz. Sparsity regret bounds for individual sequences in online linear regression.  Technical report, 2011. Available at http://arxiv.org/abs/1101.1057. Sparsity Regret Bounds for Individual Sequences  L. Gy\u00a8orfi and G. Ottucs\u00b4ak. Sequential prediction of unbounded stationary time series. IEEE  Trans. Inform. Theory, 53(5):1866-1872, 2007.  L. Gy\u00a8orfi, M. Kohler, A. Krzy\u02d9zak, and H. Walk. A distribution-free theory of nonparametric  regression. Springer Series in Statistics. Springer-Verlag, New York, 2002.  S. M. Kakade and A. Tewari. On the generalization ability of online strongly convex In Advances in Neural Information Processing Systems 21  programming algorithms. (NIPS\u201908), pages 801-808. 2009.  J. Kivinen and M. K. Warmuth. Averaging expert predictions. In Proceedings of the 4th European Conference on Computational Learning Theory (EuroCOLT\u201999), pages 153- 167, 1999.  J. Langford, L. Li, and T. Zhang. Sparse online learning via truncated gradient. J. Mach.  Learn. Res., 10:777-801, 2009.  G. Raskutti, M. J. Wainwright, and B. Yu. Minimax rates of convergence for high- dimensional regression under (cid:96)q-ball sparsity. In Proceedings of the 47th annual Allerton conference on communication, control, and computing (Allerton\u201909), pages 251-257, 2009.  M. W. Seeger. Bayesian inference and optimal design for the sparse linear model. J. Mach.  Learn. Res., 9:759-813, 2008.  S. Shalev-Shwartz and A. Tewari. Stochastic methods for (cid:96)1-regularized loss minimiza- tion. In Proceedings of the 26th Annual International Conference on Machine Learning (ICML\u201909), pages 929-936, 2009.  V. Vovk. Competitive on-line statistics. Internat. Statist. Rev., 69:213-248, 2001.  L. Xiao. Dual averaging methods for regularized stochastic learning and online optimization.  J. Mach. Learn. Res., 11:2543-2596, 2010. "}, "Safe Learning:    bridging the gap between Bayes, MDL and statistical learning theory via  empirical convexity": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Safe Learning:    bridging the gap between Bayes, MDL and statistical learning theory via  empirical convexity", "abstract": "We extend Bayesian MAP and Minimum Description Length (MDL) learning by testing whether the data can be substantially more compressed by a mixture of the MDL/MAP distribution with another element of themodel, and adjusting the learning rate if this is the case. While standard Bayes and MDL can fail to converge ifthe model is wrong, the resulting \u201csafe\u201d estimator continues toachieve good rates with wrong models. Moreover, when applied toclassification and regression models as considered in statisticallearning theory, the approach achieves optimal rates under, e.g.,Tsybakov\u2019s conditions, and reveals new situations in which we canpenalize by (- \\log \\text\\sc prior)/n rather than \\sqrt(- \\log \\text\\sc prior)/n.", "pdf_url": "http://proceedings.mlr.press/v19/grunwald11a/grunwald11a.pdf", "keywords": [], "reference": "2004.  J.Y. Audibert. PAC-Bayesian statistical learning theory. PhD thesis, Universit\u00b4e Paris VI,  A.R. Barron and T.M. Cover. Minimum complexity density estimation. IEEE Transactions  on Information Theory, 37(4):1034-1054, 1991.  A. Blumer, A. Ehrenfeucht, D. Haussler, and M. Warmuth. Occam\u2019s razor. Information  Processing Letters, 24:377-380, 1987.  L. Breiman. Statistical modeling: the two cultures (with discussion). Statistical Science,  16(3):199 -215, 2001.  O. Catoni. PAC-Bayesian Supervised Classification. Lecture Notes-Monograph Series. IMS,  2007.  2007.  A.P. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association,  77:605-611, 1982. Discussion: pages 611-613.  J.L. Doob. Application of the theory of martingales. In Le Calcul de Probabilit\u00b4es et ses Applications. Colloques Internationaux du Centre National de la Recherche Scientifique, pages 23-27, Paris, 1949.  P. Gr\u00a8unwald. The Minimum Description Length Principle. MIT Press, Cambridge, MA,  P. Gr\u00a8unwald and J. Langford. Suboptimal behavior of Bayes and MDL in classification under misspecification. Machine Learning, 66(2-3):119-149, 2007. DOI 10.1007/s10994- 007-0716-7.  P. D. Gr\u00a8unwald. Viewing all models as \u201cprobabilistic\u201d. In Proceedings of the Twelfth ACM  Conference on Computational Learning Theory (COLT\u2019 99), pages 171-182, 1999.  415   Safe Learning  than the original w. As a result, the safe estimator \u02d8psafe defined relative to w(cid:48) rather than w will e\ufb00ectively choose simpler distributions (with higher w(p)) for the same data, but all occurrences of V in our theorems can be replaced by V \u03c1, which can lead to a serious improvement in the size of conv-lack. A related idea is to consider the \u03b2 in predictor models F as in (2) as an additional parameter, to be equipped with a prior and fitted to the data. Since q and \u02d8p in Theorem 1 may then refer to di\ufb00erent predictors with di\ufb00erent \u03b2\u2019s, \u03b2 will act as a \u2018local\u2019 learning rate whereas \u03b7, shared by all distributions, is a \u2018global\u2019 learning rate. Preliminary investigations suggest that this leads to better bounds in some cases.  Acknowledgments  Supported in part by the IST Programme of the EU, under the PASCAL NoE, IST-2002- 506778. I would like to thank Andrew Barron, Tim van Erven and Rui Castro for some very useful discussions.  References  2004.  J.Y. Audibert. PAC-Bayesian statistical learning theory. PhD thesis, Universit\u00b4e Paris VI,  A.R. Barron and T.M. Cover. Minimum complexity density estimation. IEEE Transactions  on Information Theory, 37(4):1034-1054, 1991.  A. Blumer, A. Ehrenfeucht, D. Haussler, and M. Warmuth. Occam\u2019s razor. Information  Processing Letters, 24:377-380, 1987.  L. Breiman. Statistical modeling: the two cultures (with discussion). Statistical Science,  16(3):199 -215, 2001.  O. Catoni. PAC-Bayesian Supervised Classification. Lecture Notes-Monograph Series. IMS,  2007.  2007.  A.P. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association,  77:605-611, 1982. Discussion: pages 611-613.  J.L. Doob. Application of the theory of martingales. In Le Calcul de Probabilit\u00b4es et ses Applications. Colloques Internationaux du Centre National de la Recherche Scientifique, pages 23-27, Paris, 1949.  P. Gr\u00a8unwald. The Minimum Description Length Principle. MIT Press, Cambridge, MA,  P. Gr\u00a8unwald and J. Langford. Suboptimal behavior of Bayes and MDL in classification under misspecification. Machine Learning, 66(2-3):119-149, 2007. DOI 10.1007/s10994- 007-0716-7.  P. D. Gr\u00a8unwald. Viewing all models as \u201cprobabilistic\u201d. In Proceedings of the Twelfth ACM  Conference on Computational Learning Theory (COLT\u2019 99), pages 171-182, 1999. Gr\u00a8unwald  B. Kleijn and A. van der Vaart. Misspecification in infinite-dimensional Bayesian statistics.  Annals of Statistics, 34(2), 2006.  J.Q. Li. Estimation of Mixture Models. PhD thesis, Yale University, New Haven, CT, 1999.  E. Mammen and A.B. Tsybakov. Smooth discrimination analysis. Annals of Statistics, 27:  D. McAllester. PAC-Bayesian stochastic model selection. Machine Learning, 51(1):5-21,  A.B. Tsybakov. Optimal aggregation of classifiers in statistical learning. Annals of Statistics,  Tong Zhang. From (cid:15)-entropy to KL entropy: analysis of minimum information complexity  density estimation. Annals of Statistics, 34(5):2180-2210, 2006.  1808-1829, 1999.  2003.  32:135-166, 2004.  "}, "Beyond the regret minimization barrier: an optimal algorithm for stochastic strongly-convex optimization": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Beyond the regret minimization barrier: an optimal algorithm for stochastic strongly-convex optimization", "abstract": "We give a novel algorithm for stochastic strongly-convex optimization in thegradient oracle model which returns an O(\\frac1T)-approximate solutionafter T gradient updates. This rate of convergence is optimal in the gradientoracle model. This improves upon the previously known best rate ofO(\\frac\\log(T)T), which was obtained by applying an onlinestrongly-convex optimization algorithm with regret O(\\log(T)) to the batchsetting.We complement this result by proving that any algorithm has expected regret of\u03a9(\\log(T)) in the online stochastic strongly-convex optimizationsetting. This lower bound holds even in the full-information setting whichreveals more information to the algorithm than just gradients. This shows thatany online-to-batch conversion is inherently suboptimal for stochasticstrongly-convex optimization. This is the first formal evidence that onlineconvex optimization is strictly more difficult than batch stochastic convexoptimization.", "pdf_url": "http://proceedings.mlr.press/v19/hazan11a/hazan11a.pdf", "keywords": ["Stochastic Optimization", "Regret Minimization"], "reference": "Jacob Abernethy, Alekh Agarwal, Peter L. Bartlett, and Alexander Rakhlin. A stochastic  view of optimal regret through minimax duality. In COLT, 2009.  Alekh Agarwal, Peter L. Bartlett, Pradeep Ravikumar, and Martin J. Wainwright. Information-theoretic lower bounds on the oracle complexity of convex optimization. In arXiv:1009.0571v1, 2010.  Dimitri P. Bertsekas. Nonlinear Programming. Athena Scientific, 2nd edition, September  1999. ISBN 1886529000.  L\u00b4eon Bottou and Olivier Bousquet. The tradeo\ufb00s of large scale learning. In NIPS, 2007.  Nicol`o Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  Elad Hazan and Satyen Kale. An optimal algorithm for stochastic strongly-convex opti-  mization. June 2010. URL http://arxiv.org/abs/1006.2425.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online  convex optimization. Machine Learning, 69(2-3):169-192, 2007.  Anatoli Juditsky and Yuri Nesterov. Primal-dual subgradient methods for minimizing uni- formly convex functions. August 2010. URL http://hal.archives-ouvertes.fr/docs/ 00/50/89/33/PDF/Strong-hal.pdf.  Arkadi S. Nemirovski and David B. Yudin. Problem complexity and method e\ufb03ciency in  optimization. John Wiley UK/USA, 1983.  Erik Ordentlich and Thomas M. Cover. The cost of achieving the best portfolio in hindsight.  Math. Oper. Res., 23:960-982, November 1998.  Shai Shalev-Shwartz and Nathan Srebro. SVM optimization: inverse dependence on training  set size. In ICML, pages 928-935, 2008.  Shai Shalev-Shwartz, Ohad Shamir, Karthik Sridharan, and Nati Srebro. Stochastic convex  optimization. In COLT, 2009.  Eiji Takimoto and Manfred K. Warmuth. The minimax strategy for gaussian density esti-  mation. In COLT, pages 100-106, 2000.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.  In ICML, pages 928-936, 2003.  436   Hazan Kale  We thank an anonymous referee for several useful suggestions.  Acknowledgments  References  Jacob Abernethy, Alekh Agarwal, Peter L. Bartlett, and Alexander Rakhlin. A stochastic  view of optimal regret through minimax duality. In COLT, 2009.  Alekh Agarwal, Peter L. Bartlett, Pradeep Ravikumar, and Martin J. Wainwright. Information-theoretic lower bounds on the oracle complexity of convex optimization. In arXiv:1009.0571v1, 2010.  Dimitri P. Bertsekas. Nonlinear Programming. Athena Scientific, 2nd edition, September  1999. ISBN 1886529000.  L\u00b4eon Bottou and Olivier Bousquet. The tradeo\ufb00s of large scale learning. In NIPS, 2007.  Nicol`o Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  Elad Hazan and Satyen Kale. An optimal algorithm for stochastic strongly-convex opti-  mization. June 2010. URL http://arxiv.org/abs/1006.2425.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online  convex optimization. Machine Learning, 69(2-3):169-192, 2007.  Anatoli Juditsky and Yuri Nesterov. Primal-dual subgradient methods for minimizing uni- formly convex functions. August 2010. URL http://hal.archives-ouvertes.fr/docs/ 00/50/89/33/PDF/Strong-hal.pdf.  Arkadi S. Nemirovski and David B. Yudin. Problem complexity and method e\ufb03ciency in  optimization. John Wiley UK/USA, 1983.  Erik Ordentlich and Thomas M. Cover. The cost of achieving the best portfolio in hindsight.  Math. Oper. Res., 23:960-982, November 1998.  Shai Shalev-Shwartz and Nathan Srebro. SVM optimization: inverse dependence on training  set size. In ICML, pages 928-935, 2008.  Shai Shalev-Shwartz, Ohad Shamir, Karthik Sridharan, and Nati Srebro. Stochastic convex  optimization. In COLT, 2009.  Eiji Takimoto and Manfred K. Warmuth. The minimax strategy for gaussian density esti-  mation. In COLT, pages 100-106, 2000.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.  In ICML, pages 928-936, 2003. "}, "A Close Look to Margin Complexity and Related Parameters": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "A Close Look to Margin Complexity and Related Parameters", "abstract": "Concept classes can canonically be represented by sign-matrices,i.e., by matrices with entries 1 and -1. The question whethera sign-matrix (concept class) A can be learned by a machine that performs large margin classification is closely related to the\u201cmargin complexity\u201d associated with A. We consider severalvariants of margin complexity, reveal how they are relatedto each other, and we reveal how they are related to other notions of learning-theoretic relevance like SQ-dimension, CSQ-dimension,and the Forster bound.", "pdf_url": "http://proceedings.mlr.press/v19/kallweit11a/kallweit11a.pdf", "keywords": [], "reference": "Farid Alizadeh. Interior point methods to semidefinite programming with applications to  combinatorial optimization. SIAM Journal on Optimization, 5(13), 1995.  Rosa I. Arriaga and Santosh Vempala. An algorithmic theory of learning: Robust concepts and random projection. In Proceedings of the 40\u2019th Annual Symposium on the Foundations of Computer Science, pages 616-623, 1999.  Javed A. Aslam and Scott E. Decatur. General bounds on statistical query learning and PAC learning with noise via hypothesis boosting. Information and Computation, 141(2): 85-118, 1998.  Shai Ben-David, Nadav Eiron, and Hans U. Simon. Limitations of learning via embeddings  in euclidean half-spaces. Journal of Machine Learning Research, 3:441-461, 2002.  Avrim Blum, Adam Kalai, and Hal Wasserman. Noise-tolerant learning, the parity problem, and the statistical query model. Journal of the Association on Computing Machinery, 50 (4):506-519, 2003.  5. Because of the Boosting-result by Aslam and Decatur (1998) weak learners can be transformed into  strong learners in this model without much loss of e\ufb03ciency.  6. Furthermore note the connection to using hinge-loss in soft-margin optimization problems.  454   Kallweit Simon  pq(cid:62), which is the special case where Y has rank 1). Now maxY mcY (A) = mc(A) is the appropriate complexity measure, and the learning goal is to achieve a reasonably large hard margin for every possible target concept. Because of the polynomial relation between mc(A) and the CSQ-dimension, the learning goal can be achieved i\ufb00 the concept class is distribution-independently weakly learnable in the CSQ model.  Feldman (2008) has shown that there exist classes (e.g., Boolean decision lists) which are distribution independently (weakly or strongly)5 learnable in the SQ model but not (not even weakly) in the CSQ model. This also shows that maxp,q mcp,q(A) and maxY mcY (A) are not polynomially related. (There is even an exponential gap.) Thus imposing the rank 1 constraint on Y makes much of a di\ufb00erence.  Open Problems: The level of distribution-independent SQ-learning is located somewhere between (b) and (c). It would be interesting to find a combinatorial parameter (or another variant of margin optimization?) that characterizes this level. A parameter of this kind must be lower-bounded by the SQ-dimension and upper-bounded by the CSQ-dimension. It would furthermore be interesting to find a concept class that separates distribution- independent SQ-learning from SQ-learning w.r.t. the hardest fixed distribution. The correspondence between maximization of the average margin and typical soft-margin optimization problems would be more convincing if we replaced \u03b3i,j(A|A) by min{\u03b3i,j(A|A), \u03b3} for some \u03b3 > 0 so that few extremely large margin parameters cannot provide compensation for many small or negative margin parameters.6 It would be interesting to know whether results similar to the ones in this paper can be shown for this \u201caverage clipped margin\u201d.  References  Farid Alizadeh. Interior point methods to semidefinite programming with applications to  combinatorial optimization. SIAM Journal on Optimization, 5(13), 1995.  Rosa I. Arriaga and Santosh Vempala. An algorithmic theory of learning: Robust concepts and random projection. In Proceedings of the 40\u2019th Annual Symposium on the Foundations of Computer Science, pages 616-623, 1999.  Javed A. Aslam and Scott E. Decatur. General bounds on statistical query learning and PAC learning with noise via hypothesis boosting. Information and Computation, 141(2): 85-118, 1998.  Shai Ben-David, Nadav Eiron, and Hans U. Simon. Limitations of learning via embeddings  in euclidean half-spaces. Journal of Machine Learning Research, 3:441-461, 2002.  Avrim Blum, Adam Kalai, and Hal Wasserman. Noise-tolerant learning, the parity problem, and the statistical query model. Journal of the Association on Computing Machinery, 50 (4):506-519, 2003.  5. Because of the Boosting-result by Aslam and Decatur (1998) weak learners can be transformed into  strong learners in this model without much loss of e\ufb03ciency.  6. Furthermore note the connection to using hinge-loss in soft-margin optimization problems. A Close Look to Margin Complexity and Related Parameters  Nader H. Bshouty and Vitaly Feldman. On using extended statistical queries to avoid  membership queries. Journal of Machine Learning Research, 2:359-395, 2002.  Thorsten Doliwa, Michael Kallweit, and Hans U. Simon. Dimension and margin bounds for re\ufb02ection-invariant kernels. In Proceedings of the 21st Annual Conference on Learning Theory, pages 157-167, 2008.  Vitaly Feldman. Evolvability from learning algorithms. In Proceedings of the 2008 ACM  International Symposium on Theory of Computing, pages 619-628, 2008.  J\u00a8urgen Forster. A linear lower bound on the unbounded error communication complexity.  Journal of Computer and System Sciences, 65(4):612-625, 2002.  J\u00a8urgen Forster and Hans U. Simon. On the smallest possible dimension and the largest possible margin of linear arrangements representing given concept classes. Theoretical Computer Science, 350(1):40-48, 2006.  W. B. Johnson and J. Lindenstrauss. Extensions of Lipschitz mapping into Hilbert spaces.  Contemp. Math., 26:189-206, 1984.  Michael Kearns. E\ufb03cient noise-tolerant learning from statistical queries. Journal of the  Association on Computing Machinery, 45(6):983-1006, 1998.  Troy Lee and Adi Shraibman. Lower bounds in communication complexity. Foundations  and Trends in Theoretical Computer Science, 3(4):263-399, 2009.  Nati Linial, Shahar Mendelson, Gideon Schechtman, and Adi Shraibman. Complexity mea-  sures of sign matrices. Combinatorica, 27(4):439-463, 2007.  Alexander Sherstov. Halfspace matrices. Computational Complexity, 17(2):149-178, 2008.  Leslie G. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134-  Leslie G. Valiant. Evolvability. Journal of the Association on Computing Machinery, 56(1):  1142, 1984.  3:1-3:21, 2009.  "}, "Maximum Likelihood vs. Sequential Normalized Maximum Likelihood  in On-line Density Estimation": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Maximum Likelihood vs. Sequential Normalized Maximum Likelihood  in On-line Density Estimation", "abstract": "The paper considers sequential prediction of individual sequences  with log loss (online density estimation) using an exponential  family of distributions. We first analyze the regret of the maximum  likelihood (\u201cfollow the leader\u201d) strategy. We find that this  strategy is (1) suboptimal and (2) requires an additional assumption  about boundedness of the data sequence. We then show that both  problems can be be addressed by adding the currently predicted  outcome to the calculation of the maximum likelihood, followed by  normalization of the distribution.  The strategy obtained in this  way is known in the literature as the \\emphsequential normalized    maximum likelihood or \\emphlast-step minimax strategy. We show  for the first time that for general exponential families, the regret  is bounded by the familiar (k/2) \\log n and thus optimal up to  O(1).  We also show the relationship to the Bayes strategy with  Jeffreys\u2019 prior.", "pdf_url": "http://proceedings.mlr.press/v19/kotlowski11a/kotlowski11a.pdf", "keywords": ["List of keywords"], "reference": "K. Azoury and M. Warmuth. Relative loss bounds for on-line density estimation with the exponential family of distributions. Journal of Machine Learning, 43(3):211-246, 2001.  O.E. Barndor\ufb00-Nielsen. Information and Exponential Families in Statistical Theory. Wiley,  Chichester, UK, 1978.  A. Barron, J. Rissanen, and B. Yu. The minimum description length principle in coding  and modeling. IEEE Transactions on Information Theory, 44(6):2743-2760, 1998.  S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004.  N. Cesa-Bianchi and G. Lugosi. Worst-case bounds for the logarithmic loss of predictors.  Journal of Machine Learning, 43(3):247-264, 2001.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning and Games. Cambridge University  Press, 2006.  Thomas M. Cover and Joy A. Thomas. Elements of Information Theory. John Wiley, 1991.  Sanjoy Dasgupta and Daniel Hsu. On-line estimation with the multivariate gaussian distri-  bution. In Conference on Learning Theory (COLT \u201907), 2007.  A.P. Dawid. Present position and potential developments: Some personal views, statistical  theory, the prequential approach. J. Royal Stat.Soc., Ser. A, 147(2):278-292, 1984.  Y. Freund. Predicting a binary sequence almost as well as the optimal biased coin.  In  Computational Learning Theory (COLT\u2019 96), pages 89-98, 1996.  P. Gr\u00a8unwald and W. Kot(cid:32)lowski. Prequential plug-in codes that achieve optimal redundancy rates even if the model is wrong. In The IEEE International Symposium on Information Theory (ISIT \u201910), 2010.  P. D. Gr\u00a8unwald. The Minimum Description Length Principle. MIT Press, Cambridge, MA,  2007.  P. D. Gr\u00a8unwald and S. de Rooij. Asymptotic log-loss of prequential maximum likelihood  codes. In Conference on Learning Theory (COLT 2005), pages 652-667, 2005.  E. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex opti-  mization. Machine Learning, 69(2-3):169-192, 2007.  W. Kot(cid:32)lowski, P. Gr\u00a8unwald, and S. de Rooij. Following the \ufb02attened leader. In Conference  on Learning Theory (COLT \u201910), 2010.  474   Kot(cid:32)lowski Gr\u00a8unwald  In future work, we plan to work on the two open questions posed in the paper: (1) Is is possible to relax the condition that the model is constrained to the compact subset of the parameter space by conditioning the regret on the outcome from the first iteration? (2) When is SNML equal to Bayes with Je\ufb00reys\u2019 prior and is there any general relationship between the worst-case regrets of the two?  References  K. Azoury and M. Warmuth. Relative loss bounds for on-line density estimation with the exponential family of distributions. Journal of Machine Learning, 43(3):211-246, 2001.  O.E. Barndor\ufb00-Nielsen. Information and Exponential Families in Statistical Theory. Wiley,  Chichester, UK, 1978.  A. Barron, J. Rissanen, and B. Yu. The minimum description length principle in coding  and modeling. IEEE Transactions on Information Theory, 44(6):2743-2760, 1998.  S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004.  N. Cesa-Bianchi and G. Lugosi. Worst-case bounds for the logarithmic loss of predictors.  Journal of Machine Learning, 43(3):247-264, 2001.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning and Games. Cambridge University  Press, 2006.  Thomas M. Cover and Joy A. Thomas. Elements of Information Theory. John Wiley, 1991.  Sanjoy Dasgupta and Daniel Hsu. On-line estimation with the multivariate gaussian distri-  bution. In Conference on Learning Theory (COLT \u201907), 2007.  A.P. Dawid. Present position and potential developments: Some personal views, statistical  theory, the prequential approach. J. Royal Stat.Soc., Ser. A, 147(2):278-292, 1984.  Y. Freund. Predicting a binary sequence almost as well as the optimal biased coin.  In  Computational Learning Theory (COLT\u2019 96), pages 89-98, 1996.  P. Gr\u00a8unwald and W. Kot(cid:32)lowski. Prequential plug-in codes that achieve optimal redundancy rates even if the model is wrong. In The IEEE International Symposium on Information Theory (ISIT \u201910), 2010.  P. D. Gr\u00a8unwald. The Minimum Description Length Principle. MIT Press, Cambridge, MA,  2007.  P. D. Gr\u00a8unwald and S. de Rooij. Asymptotic log-loss of prequential maximum likelihood  codes. In Conference on Learning Theory (COLT 2005), pages 652-667, 2005.  E. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex opti-  mization. Machine Learning, 69(2-3):169-192, 2007.  W. Kot(cid:32)lowski, P. Gr\u00a8unwald, and S. de Rooij. Following the \ufb02attened leader. In Conference  on Learning Theory (COLT \u201910), 2010. ML vs. SNML in On-line Density Estimation  M. Raginsky, R. F. Marcia, S. Jorge, and R. Willett. Sequential probability assignment via online convex programming using exponential families. In IEEE International Symposium on Information Theory, 2009.  J. Rissanen. Fisher information and stochastic complexity. IEEE Trans. Information The-  ory, IT-42(1):40-47, 1996.  J. Rissanen and T. Roos. Conditional NML universal models. In Information Theory and  Applications Workshop (ITA-07), pages 337-341, 2007.  T. Roos and J. Rissanen. On sequentially normalized maximum likelihood models.  In Workshop on Information Theoretic Methods in Science and Engineering (WITMSE-08), 2008.  Y. Shtarkov. Universal sequential coding of single messages. Problems of Information  Transmission, 23(3):175-186, 1987.  E. Takimoto and M. Warmuth. The last-step minimax algorithm. In Conference on Algo-  rithmic Learning Theory (ALT \u201900), 2000. "}, "A New Algorithm for Compressed Counting with Applications in Shannon Entropy Estimation in Dynamic Data": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "A New Algorithm for Compressed Counting with Applications in Shannon Entropy Estimation in Dynamic Data", "abstract": "Efficient estimation of the moments and Shannon entropy of data streams is an important task in modern machine learning and data mining.  To estimate the Shannon entropy, it suffices to accurately estimate the \u03b1-th  moment with \u2206= |1-\u03b1|\\approx0. To guarantee that the error of estimated Shannon entropy is within a \u03bd-additive factor, the method of \\em symmetric stable random projections requires O\\left(\\frac1\u03bd^2\u2206^2\\right) samples, which is extremely expensive. The first paper\u00a0\\citepProc:Li_SODA09 in \\em Compressed Counting (CC), based on \\em skewed-stable random projections, supplies a substantial improvement by reducing the sample complexity to O\\left(\\frac1\u03bd^2\u2206\\right), which is still  expensive. The followup work\u00a0\\citepProc:Li_UAI09 provides a  practical algorithm, which is however  difficult to analyze theoretically.In this paper, we propose a new   accurate algorithm for Compressed Counting, whose sample complexity is only O\\left(\\frac1\u03bd^2\\right) for \u03bd-additive Shannon entropy estimation. The constant factor for this bound is merely about 6.  In addition, we prove that our algorithm achieves an upper bound of the Fisher information and in fact it is  close to 100%  statistically optimal.  An empirical study is  conducted to verify the accuracy of our algorithm.", "pdf_url": "http://proceedings.mlr.press/v19/li11a/li11a.pdf", "keywords": ["Data Streams", "Entropy Estimation", "Maximally-Skewed Stable Random Projections"], "reference": "Charu C. Aggarwal, Jiawei Han, Jianyong Wang, and Philip S. Yu. On demand classification  of data streams. In KDD, pages 503-508, Seattle, WA, 2004.  Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the  frequency moments. In STOC, pages 20-29, Philadelphia, PA, 1996.  Lakshminath Bhuvanagiri and Sumit Ganguly. Estimating entropy over data streams. In  ESA, pages 148-159, Zurich, Switzerland, 2006.  Daniela Brauckho\ufb00, Bernhard Tellenbach, Arno Wagner, Martin May, and Anukool Lakhina. Impact of packet sampling on anomaly detection metrics. In IMC, pages 159- 164, Rio de Janeriro, Brazil, 2006.  Amit Chakrabarti, Khanh Do Ba, and S. Muthukrishnan. Estimating entropy and entropy  norm on data streams. Internet Mathematics, 3(1):63-78, 2006.  494   Li Zhang  7. Conclusion  Many machine learning (e.g., neural computation, graph estimation) and data mining (e.g., anomaly detection) problems require estimating the Shannon entropy. When the data are dynamic (e.g., data streams), e\ufb03cient estimation of the Shannon entropy using small space has been a challenging problem. It is known that we can approximate the Shannon entropy using the \u03b1-th frequency moment of the stream with \u03b1 very close to 1, if the estimator of the moment is accurate enough with variance proportional to O(\u22062), where \u2206 = |1 \u2212 \u03b1|. Our paper provides such a practical estimator. Our method is an ideal solution to the problem of entropy estimation when the data streams follow the strict-Turnstile model.  For \u03bd-additive Shannon entropy estimation, the sample complexity of the algorithm is only O (cid:0) 1 (cid:1). The constant factor for this bound is merely about 6. In addition, we prove \u03bd2 that our algorithm achieves an upper bound of the Fisher information and in fact it is close to 100% statistically optimal. An empirical study is also conducted to verify the accuracy of our algorithm.  Further research: To further reduce the processing cost in order to better accommodate high-rate data streams, it is desirable to replace the dense matrix of skewed stable variables by a sparse matrix of Pareto-type variables. This is closely related to the prior study of very sparse symmetric stable random projections (Li, 2007). However, the extension to CC requires further work.  Acknowledgments  The authors thank the anonymous reviewers for their constructive comments. Ping Li\u2019s research is partially supported by the National Science Foundation (DMS-0808864), the O\ufb03ce of Naval Research (YIP-N000140910911), and a gift from Google. Cun-Hui Zhang\u2019s research is partially supported by the National Science Foundation (DMS-0804626, DMS- 0906420) and the National Security Agency (H98230-09-1-0006, H98230-11-1-0205).  References  Charu C. Aggarwal, Jiawei Han, Jianyong Wang, and Philip S. Yu. On demand classification  of data streams. In KDD, pages 503-508, Seattle, WA, 2004.  Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the  frequency moments. In STOC, pages 20-29, Philadelphia, PA, 1996.  Lakshminath Bhuvanagiri and Sumit Ganguly. Estimating entropy over data streams. In  ESA, pages 148-159, Zurich, Switzerland, 2006.  Daniela Brauckho\ufb00, Bernhard Tellenbach, Arno Wagner, Martin May, and Anukool Lakhina. Impact of packet sampling on anomaly detection metrics. In IMC, pages 159- 164, Rio de Janeriro, Brazil, 2006.  Amit Chakrabarti, Khanh Do Ba, and S. Muthukrishnan. Estimating entropy and entropy  norm on data streams. Internet Mathematics, 3(1):63-78, 2006. Compressed Counting for Entropy Estimation  Amit Chakrabarti, Graham Cormode, and Andrew McGregor. A near-optimal algorithm for computing the entropy of a stream. In SODA, pages 328-335, New Orleans, Louisiana, 2007.  John M. Chambers, C. L. Mallows, and B. W. Stuck. A method for simulating stable random  variables. Journal of the American Statistical Association, 71(354):340-344, 1976.  Carlotta Domeniconi and Dimitrios Gunopulos. Incremental support vector machine con-  struction. In ICDM, pages 589-592, San Jose, CA, 2001.  Laura Feinstein, Dan Schnackenberg, Ravindra Balupari, and Darrell Kindred. Statistical approaches to DDoS attack detection and response. In DARPA Information Survivability Conference and Exposition, pages 303-314, 2003.  Izrail S. Gradshteyn and Iosif M. Ryzhik. Table of Integrals, Series, and Products. Academic  Press, New York, fifth edition, 1994.  Sudipto Guha, Andrew McGregor, and Suresh Venkatasubramanian. Streaming and sub- linear approximation of entropy and information distances. In SODA, pages 733 - 742, Miami, FL, 2006.  Anupam Gupta, John D. La\ufb00erty, Han Liu, Larry A. Wasserman, and Min Xu. Forest  density estimation. In COLT, pages 394-406, Haifa, Israel, 2010.  Nicholas J. A. Harvey, Jelani Nelson, and Krzysztof Onak. Sketching and streaming entropy  via approximation theory. In FOCS, 2008a.  Nicholas J. A. Harvey, Jelani Nelson, and Krzysztof Onak. Streaming algorithms for esti-  mating entropy. In ITW, 2008b.  M E. Havrda and F. Charv\u00b4at. Quantification methods of classification processes: Concept  of structural \u03b1-entropy. Kybernetika, 3:30-35, 1967.  Monika R. Henzinger, Prabhakar Raghavan, and Sridhar Rajagopalan. Computing on Data  Streams. American Mathematical Society, Boston, MA, USA, 1999.  Piotr Indyk. Stable distributions, pseudorandom generators, embeddings, and data stream  computation. Journal of ACM, 53(3):307-323, 2006.  Anukool Lakhina, Mark Crovella, and Christophe Diot. Mining anomalies using tra\ufb03c  feature distributions. In SIGCOMM, pages 217-228, Philadelphia, PA, 2005.  Ashwin Lall, Vyas Sekar, Mitsunori Ogihara, Jun Xu, and Hui Zhang. Data streaming algorithms for estimating entropy of network tra\ufb03c. In SIGMETRICS, pages 145-156, Saint Malo, France, 2006.  Ping Li. Very sparse stable random projections for dimension reduction in l\u03b1 (0 < \u03b1 \u2264 2)  norm. In KDD, San Jose, CA, 2007.  Ping Li. Estimators and tail bounds for dimension reduction in l\u03b1 (0 < \u03b1 \u2264 2) using stable  random projections. In SODA, pages 10 - 19, San Francisco, CA, 2008. Li Zhang  Ping Li. Compressed counting. In SODA, New York, NY, 2009a.  Ping Li. Improving compressed counting. In UAI, Montreal, CA, 2009b.  Ping Li and Kenneth W. Church. A sketch algorithm for estimating two-way and multi-way associations. Computational Linguistics (Preliminary results appeared in HLT/EMNLP 2005), 33(3):305-354, 2007.  Ping Li and Trevor J. Hastie. A unified near-optimal estimator for dimension reduction in l\u03b1 (0 < \u03b1 \u2264 2) using stable random projections. In NIPS, Vancouver, BC, Canada, 2007.  Ping Li, Kenneth W. Church, and Trevor J. Hastie. One sketch for all: Theory and appli- cations of conditional random sampling. In NIPS (Preliminary results appeared in NIPS 2006), Vancouver, BC, Canada, 2008.  Ping Li, Michael Mahoney, and Yiyuan She. Approximating higher-order distances using  random projections. In UAI, 2010.  Qiaozhu Mei and Kenneth Church. Entropy of search logs: How hard is search? with  personalization? with backo\ufb00? In WSDM, pages 45 - 54, Palo Alto, CA, 2008.  S. Muthukrishnan. Data streams: Algorithms and applications. Foundations and Trends  in Theoretical Computer Science, 1:117-236, 2 2005.  Liam Paninski. Estimation of entropy and mutual information. Neural Comput., 15(6):  1191-1253, 2003.  Alfred R\u00b4enyi. On measures of information and entropy. In The 4th Berkeley Symposium on  Mathematics, Statistics and Probability 1960, pages 547-561, 1961.  Constantino Tsallis. Possible generalization of boltzmann-gibbs statistics. Journal of Sta-  tistical Physics, 52:479-487, 1988.  Kuai Xu, Zhi-Li Zhang, and Supratik Bhattacharyya. Profiling internet backbone tra\ufb03c: behavior models and applications. In SIGCOMM \u201905: Proceedings of the 2005 conference on Applications, technologies, architectures, and protocols for computer communications, pages 169-180, Philadelphia, Pennsylvania, USA, 2005.  Qiang Yang and Xindong Wu. 10 challeng problems in data mining research. International  Journal of Information Technology and Decision Making, 5(4):597-604, 2006.  Haiquan Zhao, Ashwin Lall, Mitsunori Ogihara, Oliver Spatscheck, Jia Wang, and Jun Xu. A data streaming algorithm for estimating entropies of od \ufb02ows. In IMC, San Diego, CA, 2007.  Haiquan Zhao, Nan Hua, Ashwin Lall, Ping Li, Jia Wang, and Jun Xu. Towards a universal  sketch for origin-destination network measurements. Technical report, 2010. "}, "A Finite-Time Analysis of Multi-armed Bandits Problems with Kullback-Leibler Divergences": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "A Finite-Time Analysis of Multi-armed Bandits Problems with Kullback-Leibler Divergences", "abstract": "We consider a Kullback-Leibler-based algorithm for the stochastic multi-armed bandit problem in the case of distributions with finite supports(not necessarily known beforehand), whose asymptotic regret matches the lower bound of \\citetBurnetas96. Our contribution is to provide a finite-time analysis of this algorithm;we get bounds whose main terms are smaller than the ones of previously known algorithms with finite-time analyses (like UCB-type algorithms).", "pdf_url": "http://proceedings.mlr.press/v19/maillard11a/maillard11a.pdf", "keywords": ["Multi-armed bandit problem", "finite-time analysis", "Kullback-Leibler divergence", "Sanov\u2019s lemma"], "reference": "J-Y. Audibert, R. Munos, and C. Szepesvari. Exploration-exploitation trade-o\ufb00 using vari- ance estimates in multi-armed bandits. Theoretical Computer Science, 410:1876-1902, 2009.  J.Y. Audibert and S. Bubeck. Regret bounds and minimax policies under partial monitoring.  Journal of Machine Learning Research, 11:2635-2686, 2010.  P. Auer and R. Ortner. UCB revisited: Improved regret bounds for the stochastic multi-  armed bandit problem. Periodica Mathematica Hungarica, 61(1-2):55-65, 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite time analysis of the multiarmed bandit  problem. Machine Learning, 47(2-3):235-256, 2002.  A.N. Burnetas and M.N. Katehakis. Optimal adaptive policies for sequential allocation  problems. Advances in Applied Mathematics, 17(2):122-142, 1996.  Y. Chow and H. Teicher. Probability Theory. Springer, 1988.  I.H. Dinwoodie. Mesures dominantes et th\u00b4eor`eme de Sanov. Annales de l\u2019Institut Henri  Poincar\u00b4e - Probabilit\u00b4es et Statistiques, 28(3):365-373, 1992.  S. Filippi. Strat\u00b4egies optimistes en apprentissage par renforcement. PhD thesis, T\u00b4el\u00b4ecom  ParisTech, 2010.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and  beyond. In Proceedings of COLT, 2011.  A. Garivier and F. Leonardi. Context tree selection: A unifying view. Stochastic Processes  and their Applications, 2011. In press.  J. Honda and A. Takemura. An asymptotically optimal bandit algorithm for bounded  support models. In Proceedings of COLT, pages 67-79, 2010a.  J. Honda and A. Takemura. An asymptotically optimal policy for finite support models in  the multiarmed bandit problem. arXiv:0905.2776, 2010b.  T. L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6:4-22, 1985.  O.-A. Maillard, R. Munos, and G. Stoltz. A finite-time analysis of multi-armed bandits prob- lems with Kullback-Leibler divergences. 2011. URL http://hal.archives-ouvertes. fr/inria-00574987/.  H. Robbins. Some aspects of the sequential design of experiments. Bulletin of the American  Mathematics Society, 58:527-535, 1952.  514   Maillard Munos Stoltz  References  J-Y. Audibert, R. Munos, and C. Szepesvari. Exploration-exploitation trade-o\ufb00 using vari- ance estimates in multi-armed bandits. Theoretical Computer Science, 410:1876-1902, 2009.  J.Y. Audibert and S. Bubeck. Regret bounds and minimax policies under partial monitoring.  Journal of Machine Learning Research, 11:2635-2686, 2010.  P. Auer and R. Ortner. UCB revisited: Improved regret bounds for the stochastic multi-  armed bandit problem. Periodica Mathematica Hungarica, 61(1-2):55-65, 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite time analysis of the multiarmed bandit  problem. Machine Learning, 47(2-3):235-256, 2002.  A.N. Burnetas and M.N. Katehakis. Optimal adaptive policies for sequential allocation  problems. Advances in Applied Mathematics, 17(2):122-142, 1996.  Y. Chow and H. Teicher. Probability Theory. Springer, 1988.  I.H. Dinwoodie. Mesures dominantes et th\u00b4eor`eme de Sanov. Annales de l\u2019Institut Henri  Poincar\u00b4e - Probabilit\u00b4es et Statistiques, 28(3):365-373, 1992.  S. Filippi. Strat\u00b4egies optimistes en apprentissage par renforcement. PhD thesis, T\u00b4el\u00b4ecom  ParisTech, 2010.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and  beyond. In Proceedings of COLT, 2011.  A. Garivier and F. Leonardi. Context tree selection: A unifying view. Stochastic Processes  and their Applications, 2011. In press.  J. Honda and A. Takemura. An asymptotically optimal bandit algorithm for bounded  support models. In Proceedings of COLT, pages 67-79, 2010a.  J. Honda and A. Takemura. An asymptotically optimal policy for finite support models in  the multiarmed bandit problem. arXiv:0905.2776, 2010b.  T. L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6:4-22, 1985.  O.-A. Maillard, R. Munos, and G. Stoltz. A finite-time analysis of multi-armed bandits prob- lems with Kullback-Leibler divergences. 2011. URL http://hal.archives-ouvertes. fr/inria-00574987/.  H. Robbins. Some aspects of the sequential design of experiments. Bulletin of the American  Mathematics Society, 58:527-535, 1952. "}, "Robust approachability and regret minimization in games with partial monitoring": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Robust approachability and regret minimization in games with partial monitoring", "abstract": "Approachability has become a standard tool in analyzing learning algorithms in the adversarial online learning setup.We develop a variant of approachability for games where there is ambiguity in the obtained reward that belongs to a set, rather than being a single vector. Using this variant we tackle the problem of approachability in games with partial monitoring and develop simple and efficientalgorithms (i.e., with constant per-step complexity) for this setup.We finally consider external and internal regret in repeated games with partial monitoring, for which we deriveregret-minimizing strategies based on approachability theory.", "pdf_url": "http://proceedings.mlr.press/v19/mannor11a/mannor11a.pdf", "keywords": ["Approchability", "partial monitoring", "regret", "adversarial learning"], "reference": "J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learn- ing are equivalent. In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory (COLT\u201911). Omnipress, 2011.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6:1-8, 1956a.  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of  Mathematicians, 1954, Amsterdam, vol. III, pages 336-338, 1956b.  A. Blum and Y. Mansour. From external to internal regret. Journal of Machine Learning  Research, 8:1307-1324, 2007.  Press, 2006.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  N. Cesa-Bianchi, G. Lugosi, and G. Stoltz. Regret minimization under partial monitoring.  Mathematics of Operations Research, 31:562-580, 2006.  D. Foster and R. Vohra. Regret in the on-line decision problem. Games and Economic  Behavior, 29:7-36, 1999.  S. Hart and A. Mas-Colell. A simple adaptive procedure leading to correlated equilibrium.  Econometrica, 68:1127-1150, 2000.  S. Hart and A. Mas-Colell. A general class of adaptive strategies. Journal of Economic  Theory, 98:26-54, 2001.  E. Lehrer and E. Solan. Learning to play partially-specified equilibrium. Mimeo, 2007.  534   Mannor Perchet Stoltz  Lemma 17 Given a polytope C, the (r, H)-approachability of C and the (cid:0)rC, H(cid:1)-approachability of Rd \u2212 are equivalent in the sense that all strategies for one problem translates to a strategy for the other problem.  In addition, Condition 1 holds for (r, H) and C if and only if it holds for (cid:0)rC, H(cid:1) and  Rd \u2212.  Via the lemma above, Theorem 16 indicates that Condition 1 for (r, H) and C is a  su\ufb03cient condition for the (r, H)-approachability of C and provides a strategy to do so.  4.3.3. Approachability of general convex sets in the case of general games  A general closed convex set can always be approximated arbitrarily well by a polytope (where the number of vertices of the latter however increases as the quality of the approx- imation does). There, via a doubling trick, Condition 1 is also seen to be su\ufb03cient to (r, H)-approach any general closed convex set C, However, the computational complexity of the resulting strategy is much larger: the per-round complexity increases over time (as the numbers of vertices of the approximating polytopes do).  References  J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learn- ing are equivalent. In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory (COLT\u201911). Omnipress, 2011.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6:1-8, 1956a.  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of  Mathematicians, 1954, Amsterdam, vol. III, pages 336-338, 1956b.  A. Blum and Y. Mansour. From external to internal regret. Journal of Machine Learning  Research, 8:1307-1324, 2007.  Press, 2006.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  N. Cesa-Bianchi, G. Lugosi, and G. Stoltz. Regret minimization under partial monitoring.  Mathematics of Operations Research, 31:562-580, 2006.  D. Foster and R. Vohra. Regret in the on-line decision problem. Games and Economic  Behavior, 29:7-36, 1999.  S. Hart and A. Mas-Colell. A simple adaptive procedure leading to correlated equilibrium.  Econometrica, 68:1127-1150, 2000.  S. Hart and A. Mas-Colell. A general class of adaptive strategies. Journal of Economic  Theory, 98:26-54, 2001.  E. Lehrer and E. Solan. Learning to play partially-specified equilibrium. Mimeo, 2007. Robust approachability and regret minimization in games with partial monitoring  G. Lugosi, S. Mannor, and G. Stoltz. Strategies for prediction under imperfect monitor- ing. Mathematics of Operations Research, 33:513-528, 2008. An extended abstract was presented at COLT\u201907.  S. Mannor and N. Shimkin. On-line learning with imperfect monitoring.  In Proceed- ings of the Sixteenth Annual Conference on Learning Theory (COLT\u201903), pages 552-567. Springer, 2003.  S. Mannor and N. Shimkin. Regret minimization in repeated matrix games with variable  stage duration. Games and Economic Behavior, 63(1):227-258, 2008.  S. Mannor, J. Tsitsiklis, and J. Y. Yu. Online learning with sample path constraints. Journal  of Machine Learning Research, 10(Mar):569-590, 2009.  S. Mannor, V. Perchet, and G. Stoltz. Robust approachability and regret minimization in games with partial monitoring. 2011a. URL http://hal.archives-ouvertes.fr/ hal-00595695.  S. Mannor, V. Perchet, and G. Stoltz. Corrigendum to \u201cRobust approachability and 2011b. URL http://hal.  regret minimization in games with partial monitoring\u201d. archives-ouvertes.fr/hal-00617554.  J.-F. Mertens, S. Sorin, and S. Zamir. Repeated games. Technical Report no. 9420, 9421,  9422, Universit\u00b4e de Louvain-la-Neuve, 1994.  V. Perchet. Calibration and internal no-regret with random signals. In Proceedings of the Twentieth International Conference on Algorithmic Learning Theory (ALT\u201909), pages 68-82, 2009.  V. Perchet. Approachability of convex sets in games with partial monitoring. Journal of  Optimization Theory and Applications, 149:665-677, 2011a.  V. Perchet. Internal regret with partial monitoring calibration-based optimal algorithms.  Journal of Machine Learning Research, 2011b. In press.  A. Piccolboni and C. Schindelhauer. Discrete prediction games with arbitrary feedback and In Proceedings of the Fourteenth Annual Conference on Computational Learning  loss. Theory (COLT\u201901), pages 208-223, 2001.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Beyond regret. In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory (COLT\u201911). Omnipress, 2011.  J. Rambau and G. Ziegler. Projections of polytopes and the generalized Baues conjecture.  Discrete and Computational Geometry, 16:215-237, 1996.  A. Rustichini. Minimizing regret: The general case. Games and Economic Behavior, 29:  224-243, 1999. Mannor Perchet Stoltz  Acknowledgments  Shie Mannor was partially supported by the ISF under contract 890015. Vianney Perchet benefited from the support of the ANR under grant ANR-10-BLAN 0112. Gilles Stoltz acknowledges support from the French National Research Agency (ANR) under grant EX- PLO/RA (\u201cExploration-exploitation for e\ufb03cient resource allocation\u201d) and by the PAS- CAL2 Network of Excellence under EC grant no. 506778. "}, "The Rate of Convergence of Adaboost": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "The Rate of Convergence of Adaboost", "abstract": "The AdaBoost algorithm of \\citetFreundSc97 was designed to combine  many \u201cweak\u201d hypotheses that perform slightly better than a random  guess into a \u201cstrong\u201d hypothesis that has very low error.  We  study the rate at which AdaBoost iteratively converges to the  minimum of the \u201cexponential loss\u201d with a fast rate of  convergence. Our proofs do not require a weak-learning assumption,  nor do they require that minimizers of the exponential loss are  finite. Specifically, our first result shows that at iteration t,  the exponential loss of AdaBoost\u2019s computed parameter vector will be  at most \\varepsilon more than that of any parameter vector of  \\ell_1-norm bounded by B in a number of rounds that is bounded  by a polynomial in B and 1/\\varepsilon. We also provide rate  lower bound examples showing a polynomial dependence on these  parameters is necessary.  Our second result is that within  C/\\varepsilon iterations, AdaBoost achieves a value of the  exponential loss that is at most \\varepsilon more than the best  possible value, where C depends on the dataset. We show that this  dependence of the rate on \\varepsilon is optimal up to constant  factors, i.e. at least \u03a9(1/\\varepsilon) rounds are necessary  to achieve within \\varepsilon of the optimal exponential loss.", "pdf_url": "http://proceedings.mlr.press/v19/mukherjee11a/mukherjee11a.pdf", "keywords": ["AdaBoost", "optimization", "coordinate descent", "convergence rate"], "reference": "Peter L. Bartlett and Mikhail Traskin. AdaBoost is consistent. Journal of Machine Learning  Research, 8:2347-2368, 2007.  Peter J. Bickel, Ya\u2019acov Ritov, and Alon Zakai. Some theory for generalized boosting  algorithms. Journal of Machine Learning Research, 7:705-732, 2006.  553   The Rate of Convergence of AdaBoost  the desired properties.  Applying Lemma 14 to the sequence \u03b7\u2217  (t) yields some convex combination \u03b7\u2020 having margin at least \u03b3 > 0 (for some \u03b3) on A and zero margin on its complement, proving Item 1 of the Decomposition Lemma. The next lemma proves Item 2.  Lemma 15 There is a (finite) combination \u03b7\u2217 which achieves the same margins on F as the optimal solution.  Proof The existence of \u03b7\u2020 with properties as in Lemma 14 implies that the optimal loss is the same whether considering all the examples, or just examples in F . Therefore it su\ufb03ces to show the existence of finite \u03b7\u2217 that achieves loss K on F , that is, (cid:96)\u03b7\u2217(F ) = K.  Recall MF denotes the matrix M restricted to the rows corresponding to examples in F . Let ker MF = {x : MF x = 0} be the null-space of MF . Let \u03b7(t) be the projection of \u03b7\u2217 (t) onto the orthogonal subspace of ker MF . Then the losses (cid:96)\u03b7(t)(F ) = (cid:96)\u03b7\u2217 (t)(F ) converge to the opti- mal loss K. If MF is identically zero, then each \u03b7(t) = 0, and then \u03b7\u2217 = 0 has loss K on F . F MF . Then (cid:107)M \u03b7(t)(cid:107) \u2265 \u03bb(cid:107)\u03b7(t)(cid:107). Otherwise, let \u03bb2 be the smallest positive eigenvalue of M T By the definition of finite margin set, inf t\u2192\u221e (cid:96)\u03b7(t)(F ) = inf t\u2192\u221e (cid:96)\u03b7\u2217 (t)(F ) > 0. Therefore, the margins (cid:107)M \u03b7(t)(cid:107) are bounded, and hence the \u03b7(t) are also bounded in norm. Therefore they have a (finite) limit point \u03b7\u2217 which must have loss K over F .  As a corollary, we prove Item 3.  Lemma 16 There is a constant \u00b5max < \u221e, such that for any combination \u03b7 that achieves bounded loss on the finite-margin set, (cid:96)\u03b7(F ) \u2264 m, the margin (M \u03b7)i for any example i in F lies in the bounded interval [\u2212 ln m, \u00b5max] .  Proof The loss (cid:96)\u03b7(F ) at most m implies no margin may be less than \u2212 ln m. If Item 3 of the Decomposition Lemma were false, then for some example x \u2208 F there exists a sequence of combinations of weak classifiers, whose tth element achieves more than margin t on x but has loss at most m on F . Applying Lemma 13 we can find a subsequence \u03bb(t) whose tail achieves zero-loss on some non-empty subset S of F containing x, and bounded margins in F \\ S. Applying Lemma 14 to \u03bb(t) we get some convex combination \u03bb\u2020 which has positive margins on S and zero margin on F \\ S. Let \u03b7\u2217 be as in Lemma 15, a finite combination achieving the optimal loss on F . Then \u03b7\u2217 + \u221e \u00b7 \u03bb\u2020 achieves the same loss on every example in F \\ S as the optimal solution \u03b7\u2217, but zero loss for examples in S. This solution is strictly better than \u03b7\u2217 on F , a contradiction to the optimality of \u03b7\u2217.  References  Peter L. Bartlett and Mikhail Traskin. AdaBoost is consistent. Journal of Machine Learning  Research, 8:2347-2368, 2007.  Peter J. Bickel, Ya\u2019acov Ritov, and Alon Zakai. Some theory for generalized boosting  algorithms. Journal of Machine Learning Research, 7:705-732, 2006. Mukherjee Rudin Schapire  Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University  Leo Breiman. Prediction games and arcing classifiers. Neural Computation, 11(7):1493-  Press, 2004.  1517, 1999.  Rich Caruana and Alexandru Niculescu-Mizil. An empirical comparison of supervised learn- ing algorithms. In Proceedings of the 23rd International Conference on Machine Learning, 2006.  Michael Collins, Robert E. Schapire, and Yoram Singer. Logistic regression, AdaBoost and  Bregman distances. Machine Learning, 48(1/2/3), 2002.  Marcus Frean and Tom Downs. A simple cost function for boosting. Technical report, Department of Computer Science and Electrical Engineering, University of Queensland, 1998.  Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119-139, August 1997.  Jerome Friedman, Trevor Hastie, and Robert Tibshirani. Additive logistic regression: A  statistical view of boosting. Annals of Statistics, 28(2):337-374, April 2000.  Jerome H. Friedman. Greedy function approximation: A gradient boosting machine. Annals  of Statistics, 29(5), October 2001.  David G. Luenberger and Yinyu Ye. Linear and nonlinear programming. Springer, third  edition, 2008.  Z. Q. Luo and P. Tseng. On the convergence of the coordinate descent method for convex di\ufb00erentiable minimization. Journal of Optimization Theory and Applications, 72(1): 7-35, January 1992.  Llew Mason, Jonathan Baxter, Peter Bartlett, and Marcus Frean. Functional gradient In Advances in Large Margin Classifiers. MIT  techniques for combining hypotheses. Press, 1999.  Llew Mason, Jonathan Baxter, Peter Bartlett, and Marcus Frean. Boosting algorithms as  gradient descent. In Advances in Neural Information Processing Systems 12, 2000.  T. Onoda, G. R\u00a8atsch, and K.-R. M\u00a8uller. An asymptotic analysis of AdaBoost in the binary classification case. In Proceedings of the 8th International Conference on Artificial Neural Networks, pages 195-200, 1998.  G. R\u00a8atsch, T. Onoda, and K.-R. M\u00a8uller. Soft margins for AdaBoost. Machine Learning, 42  (3):287-320, 2001.  Gunnar R\u00a8atsch and Manfred K. Warmuth. E\ufb03cient margin maximizing with boosting.  Journal of Machine Learning Research, 6:2131-2152, 2005. The Rate of Convergence of AdaBoost  Gunnar R\u00a8atsch, Sebastian Mika, and Manfred K. Warmuth. On the convergence of lever-  aging. In Advances in Neural Information Processing Systems 14, 2002.  Cynthia Rudin, Robert E. Schapire, and Ingrid Daubechies. Analysis of boosting algorithms  using the smooth margin function. Annals of Statistics, 35(6):2723-2768, 2007.  Robert E. Schapire. The convergence rate of AdaBoost. In The 23rd Conference on Learning  Theory, 2010. open problem.  Robert E. Schapire and Yoram Singer. Improved boosting algorithms using confidence-rated  predictions. Machine Learning, 37(3):297-336, December 1999.  Shai Shalev-Shwartz and Yoram Singer. On the equivalence of weak learnability and linear separability: New relaxations and e\ufb03cient boosting algorithms. In 21st Annual Confer- ence on Learning Theory, 2008.  Xindong Wu, Vipin Kumar, J. Ross Quinlan, Joydeep Ghosh, Qiang Yang, Hiroshi Motoda, Geo\ufb00rey J. McLachlan, Angus Ng, Bing Liu, Philip S. Yu, Zhi-Hua Zhou, Michael Stein- bach, David J. Hand, and Dan Steinberg. Top 10 algorithms in data mining. Knowledge and Information Systems, 14(1):1-37, 2008.  Tong Zhang and Bin Yu. Boosting with early stopping: Convergence and consistency.  Annals of Statistics, 33(4):1538-1579, 2005. Mukherjee Rudin Schapire  Lemma 17 To get within \u03b5 < 0.1 of the optimum loss on the dataset in Table 2, AdaBoost takes at least 0.22/\u03b5 steps.  Proof Note that optimum loss is 2/3, and we are bounding the number of rounds necessary to get within (2/3) + \u03b5 loss for \u03b5 < 0.1. We begin by showing that for rounds t \u2265 3, the edge achieved is 1/t. First observe that the edges in rounds 1 and 2 are 1/3 and 1/2. Our claim will follow from the following stronger claim. Let wt c denote the normalized-losses (adding up to 1) or weights on examples a, b, c at the beginning of round t, and \u03b4t the edge in round t. Then for t \u2265 2,  a, wt  b, wt  1. Either 1/2 = wt  a or 1/2 = wt b.  2. \u03b4t+1 = \u03b4t/(1 + \u03b4t).  Proof by induction. Base case may be checked. Suppose the inductive assumption holds for t. Assume without loss of generality that 1/2 = wt c. Then in round t, ha c/(1 + 2wt gets picked, the edge \u03b4t = 2wt c). Hence, in round t + 1 hb gets picked and we get edge \u03b4t+1 = 2wt c) = \u03b4t/(1 + \u03b4t). Proof follows by induction. Note the recurrence on \u03b4t yields \u03b4t = 1/t for t \u2265 3.  b > wt c/2)/(1/2 + wt  b = 1/2, wt+1  c, and wt+1  c/(1 + 2wt  c = (wt  c) = wt  a > wt  Next we find the loss after each iteration. The loss after T rounds is  and can be computed as follows. Notice that in the following list  (cid:112)  1 \u2212 (1/3)2  1 \u2212 1/t2  T (cid:89)  (cid:112)  i=2  1 \u2212 (1/2)2 = (1 \u00b7 3)/(2 \u00b7 2), 1 \u2212 (1/3)2 = (2 \u00b7 4)/(3 \u00b7 3), 1 \u2212 (1/4)2 = (3 \u00b7 5)/(4 \u00b7 4), . . . = . . . ,  the middle denominator (3\u00b73) gets canceled by the right term of the first numerator and the left term of the third denominator. Continuing this way, the product till term 1 \u2212 (1/T )2 is (1/2) {(T + 1)/T }. Therefore the loss after round T is (2/3)(cid:112)1 + 1/T \u2265 (2/3) + (2/9)T , for T \u2265 3. Since the error after 3 rounds is still at least (2/3) + 0.1 the Lemma holds for \u03b5 < 0.1.  Lemma 18 Suppose u0, u1, . . . , are non-negative numbers satisfying  for some non-negative constants c0, c1. Then, for any t,  ut \u2212 ut+1 \u2265 c0u1+c1  ,  t  1 uc1 t  \u2212  1 uc1 0  \u2265 c1c0t. The Rate of Convergence of AdaBoost  Proof By induction on t. The base case is an identity. Assume Lemma holds for t. Then,  1 uc1 t+1  \u2212  \u2265  1 uc1 0  (cid:18) 1 uc1 t+1  \u2212  1 uc1 t  (cid:19)  +  (cid:18) 1 uc1 t  \u2212  1 uc1 0  (cid:19)  \u2265  1 uc1 t+1  \u2212  1 uc1 t  + c0t, (by induction).  Thus it su\ufb03ces to show  1 uc1 t+1  \u2212  1 uc1 t  \u2265 c1c0 \u21d0\u21d2  (cid:19)c1  (cid:18) ut ut+1  \u2265 1 + c1c0uc1  t \u21d0  Since 1 + c1c0uc1  t \u2264 (1 + c0uc1  t )c1, and (1 + c0uc1  t ) (1 \u2212 c0uc1  1 (1 \u2212 c0uc1  t )c1 \u2265 1 + c1c0uc1 t . t ) < 1, the inequality holds. "}, "Online Learning: Beyond Regret": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Online Learning: Beyond Regret", "abstract": "We study online learnability of a wide class of problems, extending the results of \\citeRakSriTew10 to general notions of performance measure well beyond external regret. Our framework simultaneously captures such well-known notions as internal and general \u03a6-regret, learning with non-additive global cost functions, Blackwell\u2019s approachability, calibration of forecasters, and more. We show that learnability in all these situations is due to control of the same three quantities: a martingale convergence term, a term describing the ability to perform well if future is known, and  a generalization of sequential Rademacher complexity, studied in \\citeRakSriTew10. Since we directly study complexity of the problem instead of focusing on efficient algorithms, we are able to improve and extend many known results which have been previously derived via an algorithmic construction.", "pdf_url": "http://proceedings.mlr.press/v19/rakhlin11a/rakhlin11a.pdf", "keywords": [], "reference": "J. Abernethy, A. Agarwal, P. Bartlett, and A. Rakhlin. A stochastic view of optimal regret In Proceedings of the 22nd Annual Conference on Learning  through minimax duality. Theory, 2009.  S. Ben-David, D. Pal, and S. Shalev-Shwartz. Agnostic online learning. In Proceedings of  the 22nd Annual Conference on Learning Theory, 2009.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6:1-8, 1956.  A. Blum and Y. Mansour. From external to internal regret.  In Proceedings of the 18th  Annual Conference on Learing Theory, pages 621-636. Springer, 2005.  O. Bousquet and M. K. Warmuth. Tracking a small set of experts by mixing past posteriors.  Journal of Machine Learning Research, 3:363-396, 2002.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  77(379):605-610, 1982.  A.P. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association,  E. Even-Dar, R. Kleinberg, S. Mannor, and Y. Mansour. Online learning for global cost functions. In Proceedings of the 22nd Annual Conference on Learning Theory, 2009.  D. P. Foster and R. V. Vohra. Calibrated learning and correlated equilibrium. Games and  Economic Behavior, 21(1-2):40-55, October 1997.  E. Gin\u00b4e and J. Zinn. Some limit theorems for empirical processes. Ann. Prob., 12(4):  929-989, 1984.  P.W. Goldberg and M.R. Jerrum. Bounding the Vapnik-Chervonenkis dimension of concept  classes parameterized by real numbers. Machine Learning, 18(2):131-148, 1995.  G.J. Gordon, A. Greenwald, and C. Marks. No-regret learning in convex games. In Pro- ceedings of the 25th International Conference on Machine learning, pages 360-367. ACM, 2008.  577   Beyond Regret  where the last inequality is because ((cid:15)txt((cid:15)))T t=1 is a martingale di\ufb00erence sequence. In the last inequality the supremum is over distributions M of [\u22121, 1]k-valued martingale di\ufb00erence sequences {dt}t\u2208N. For (cid:96)p norms we recover the rates in Even-Dar et al. (2009), specifically for (cid:96)\u221e norm the bound is 6(cid:112)log(k)/T  We thank Dean Foster for many insightful discussions about calibration and Blackwell\u2019s approachability. A. Rakhlin gratefully acknowledges the support of NSF under grant CA- REER DMS-0954737 and Dean\u2019s Research Fund.  Acknowledgments  References  J. Abernethy, A. Agarwal, P. Bartlett, and A. Rakhlin. A stochastic view of optimal regret In Proceedings of the 22nd Annual Conference on Learning  through minimax duality. Theory, 2009.  S. Ben-David, D. Pal, and S. Shalev-Shwartz. Agnostic online learning. In Proceedings of  the 22nd Annual Conference on Learning Theory, 2009.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6:1-8, 1956.  A. Blum and Y. Mansour. From external to internal regret.  In Proceedings of the 18th  Annual Conference on Learing Theory, pages 621-636. Springer, 2005.  O. Bousquet and M. K. Warmuth. Tracking a small set of experts by mixing past posteriors.  Journal of Machine Learning Research, 3:363-396, 2002.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  77(379):605-610, 1982.  A.P. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association,  E. Even-Dar, R. Kleinberg, S. Mannor, and Y. Mansour. Online learning for global cost functions. In Proceedings of the 22nd Annual Conference on Learning Theory, 2009.  D. P. Foster and R. V. Vohra. Calibrated learning and correlated equilibrium. Games and  Economic Behavior, 21(1-2):40-55, October 1997.  E. Gin\u00b4e and J. Zinn. Some limit theorems for empirical processes. Ann. Prob., 12(4):  929-989, 1984.  P.W. Goldberg and M.R. Jerrum. Bounding the Vapnik-Chervonenkis dimension of concept  classes parameterized by real numbers. Machine Learning, 18(2):131-148, 1995.  G.J. Gordon, A. Greenwald, and C. Marks. No-regret learning in convex games. In Pro- ceedings of the 25th International Conference on Machine learning, pages 360-367. ACM, 2008. Rakhlin Sridharan Tewari  E. Hazan and S. Kale. Computational equivalence of fixed points and no regret algorithms,  and convergence to equilibria. In NIPS, 2007.  M. Herbster and M. K. Warmuth. Tracking the best expert. Machine Learning, 32(2):  151-178, 1998.  Theory, 31(2):253-268, 2003.  E. Lehrer. Approachability in infinite dimensional spaces. International Journal of Game  N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold  algorithm. Machine Learning, 2(4):285-318, 04 1988.  S. Mannor and G. Stoltz. A geometric proof of calibration. Mathematics of Operations  Research, 35(4):721-727, 2010.  J.-F. Mertens, S. Sorin, and S. Zamir. Repeated games: Part A Background material.  Technical Report 9420, CORE, Universite Catholique de Louvain, 1994.  I. Pinelis. Optimum bounds for the distributions of martingales in Banach spaces. Ann.  Prob., 22(4):1679-1706, 1994.  ics, 20(3):326-350, 1975.  G. Pisier. Martingales with values in uniformly convex spaces. Israel Journal of Mathemat-  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Random averages, combinatorial parameters, and learnability. In NIPS, 2010a. Full version available at arXiv:1006.1138.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Beyond regret. ArXiv preprint  arXiv:1011.3168v2, 2010b.  G. Stoltz and G. Lugosi. Learning correlated equilibria in games with compact sets of  strategies. Games and Economic Behavior, 59(1):187-208, 2007.  M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In  Proceedings of the 20th International Conference on Machine Learning, 2003. Beyond Regret  "}, "Neyman-Pearson classification under a strict constraint": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Neyman-Pearson classification under a strict constraint", "abstract": "Motivated by problems of anomaly detection, this paper implements the Neyman-Pearson paradigm to deal with asymmetric errors in binary classification with a convex loss. Given a finite collection of classifiers, we combine them and obtain a new classifier  that satisfies simultaneously the two following properties with high probability: (i), its probability of type\u00a0I error is below a pre-specified level and (ii), it has probability of type \u00a0II error close to the minimum possible. The proposed classifier is obtained by minimizing an empirical objective subject to an empirical constraint. The novelty of the method is that the classifier output by this problem is shown to satisfy the original constraint on type\u00a0I error. This strict enforcement of the constraint has interesting consequences on the control of the type\u00a0II error and we develop new techniques to handle this situation.  Finally, connections with chance constrained optimization are evident and are investigated.", "pdf_url": "http://proceedings.mlr.press/v19/rigollet11a/rigollet11a.pdf", "keywords": [], "reference": "P. Bartlett, M. Jordan, and J. Mcauli\ufb00e. Convexity, classification, and risk bounds. Journal  of the American Statistical Association, 2006.  Aharon Ben-Tal, Laurent El Ghaoui, and Arkadi Nemirovski. Robust optimization. Prince- ton Series in Applied Mathematics. Princeton University Press, Princeton, NJ, 2009.  G. Blanchard, G. Lee, and C. Scott. Semi-supervised novelty detection. J. Mach. Learn.  Res., 11:2973-3009, Nov 2010.  St\u00b4ephane Boucheron, Olivier Bousquet, and G\u00b4abor Lugosi. Theory of classification: a survey  of some recent advances. ESAIM Probab. Stat., 9:323-375, 2005.  Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge University Press,  Cambridge, 2004.  Giuseppe C. Calafiore and Marco C. Campi. The scenario approach to robust control design.  IEEE Trans. Automat. Control, 51(5):742-753, 2006.  A. Cannon, J. Howse, D. Hush, and C. Scovel. Learning with the neyman-pearson and  min-max criteria. Technical Report LA-UR-02-2951, 2002.  A. Cannon, J. Howse, D. Hush, and C. Scovel. Simple classifiers. Technical Report LA-UR-  03-0193, 2003.  D. Casasent and X. Chen. Radial basis function neural networks for nonlinear fisher dis- crimination and neyman-pearson classification. Neural Networks, 16(5-6):529 - 535, 2003.  Luc Devroye, L\u00b4aszl\u00b4o Gy\u00a8orfi, and G\u00b4abor Lugosi. A probabilistic theory of pattern recognition, volume 31 of Applications of Mathematics (New York). Springer-Verlag, New York, 1996.  M. Han, D. Chen, and Z. Sun. Analysis to neyman-pearson classification with convex loss  function. Analysis in Theory and Applications, 24(1):18-28, 2008.  V. Koltchinskii. Oracle Inequalities in Empirical Risk Minimization and Sparse Recovery Problems Oracle Inequalities in Empirical Risk Minimization and Sparse Recovery Prob- lems, volume 2033 of Lecture Notes in Mathematics. Springer, Berlin, 2011. Lectures from the 38th Summer School on Probability Theory held in Saint-Flour, July 2008.  Constantino M. Lagoa, Xiang Li, and Mario Sznaier. Probabilistically constrained lin- ear programs and risk-adjusted controller design. SIAM J. Optim., 15(3):938-951 (elec- tronic), 2005.  E. L. Lehmann and Joseph P. Romano. Testing statistical hypotheses. Springer Texts in  Statistics. Springer, New York, third edition, 2005.  Arkadi Nemirovski and Alexander Shapiro. Convex approximations of chance constrained  programs. SIAM J. Optim., 17(4):969-996, 2006.  612   Rigollet Tong  References  P. Bartlett, M. Jordan, and J. Mcauli\ufb00e. Convexity, classification, and risk bounds. Journal  of the American Statistical Association, 2006.  Aharon Ben-Tal, Laurent El Ghaoui, and Arkadi Nemirovski. Robust optimization. Prince- ton Series in Applied Mathematics. Princeton University Press, Princeton, NJ, 2009.  G. Blanchard, G. Lee, and C. Scott. Semi-supervised novelty detection. J. Mach. Learn.  Res., 11:2973-3009, Nov 2010.  St\u00b4ephane Boucheron, Olivier Bousquet, and G\u00b4abor Lugosi. Theory of classification: a survey  of some recent advances. ESAIM Probab. Stat., 9:323-375, 2005.  Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge University Press,  Cambridge, 2004.  Giuseppe C. Calafiore and Marco C. Campi. The scenario approach to robust control design.  IEEE Trans. Automat. Control, 51(5):742-753, 2006.  A. Cannon, J. Howse, D. Hush, and C. Scovel. Learning with the neyman-pearson and  min-max criteria. Technical Report LA-UR-02-2951, 2002.  A. Cannon, J. Howse, D. Hush, and C. Scovel. Simple classifiers. Technical Report LA-UR-  03-0193, 2003.  D. Casasent and X. Chen. Radial basis function neural networks for nonlinear fisher dis- crimination and neyman-pearson classification. Neural Networks, 16(5-6):529 - 535, 2003.  Luc Devroye, L\u00b4aszl\u00b4o Gy\u00a8orfi, and G\u00b4abor Lugosi. A probabilistic theory of pattern recognition, volume 31 of Applications of Mathematics (New York). Springer-Verlag, New York, 1996.  M. Han, D. Chen, and Z. Sun. Analysis to neyman-pearson classification with convex loss  function. Analysis in Theory and Applications, 24(1):18-28, 2008.  V. Koltchinskii. Oracle Inequalities in Empirical Risk Minimization and Sparse Recovery Problems Oracle Inequalities in Empirical Risk Minimization and Sparse Recovery Prob- lems, volume 2033 of Lecture Notes in Mathematics. Springer, Berlin, 2011. Lectures from the 38th Summer School on Probability Theory held in Saint-Flour, July 2008.  Constantino M. Lagoa, Xiang Li, and Mario Sznaier. Probabilistically constrained lin- ear programs and risk-adjusted controller design. SIAM J. Optim., 15(3):938-951 (elec- tronic), 2005.  E. L. Lehmann and Joseph P. Romano. Testing statistical hypotheses. Springer Texts in  Statistics. Springer, New York, third edition, 2005.  Arkadi Nemirovski and Alexander Shapiro. Convex approximations of chance constrained  programs. SIAM J. Optim., 17(4):969-996, 2006. Neyman-Pearson classification  Andr\u00b4as Pr\u00b4ekopa. Stochastic programming, volume 324 of Mathematics and its Applications.  Kluwer Academic Publishers Group, Dordrecht, 1995.  Philippe Rigollet and Xin Tong. Neyman-pearson classification, convexity and stochastic  constraints. arXiv:1102.5750, February 2011.  R. Tyrrell Rockafellar. Convex analysis. Princeton Landmarks in Mathematics. Princeton University Press, Princeton, NJ, 1997. Reprint of the 1970 original, Princeton Paperbacks.  R.E. Schapire. The strength of weak learnability. Machine learning, 5(2):197-227, 1990.  C. Scott. Comparison and design of neyman-pearson classifiers, 2005. Manuscript.  C. Scott. Performance measures for neyman-pearson classification. IEEE Transactions on  Information Theory, 53(8):2852-2863, 2007.  C. Scott and R. Nowak. A neyman-pearson approach to statistical learning. IEEE Trans-  actions on Information Theory, 51(11):3806-3819, 2005. "}, "Sequential Event Prediction with Association Rules": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Sequential Event Prediction with Association Rules", "abstract": "We consider a supervised learning problem in which data are revealed sequentially and the goal is to determine what will next be revealed. In the context of this problem, algorithms based on association rules have a distinct advantage over classical statistical and machine learning methods; however, there has not previously been a theoretical foundation established for using association rules in supervised learning. We present two simple algorithms that incorporate association rules, and provide generalization guarantees on these algorithms based on algorithmic stability analysis from statistical learning theory. We include a discussion of the strict minimum support threshold often used in association rule mining, and introduce an \u201cadjusted confidence\u201d measure that provides a weaker minimum support condition that has advantages over the strict minimum support. The paper brings together ideas from statistical learning theory, association rule mining and Bayesian analysis.", "pdf_url": "http://proceedings.mlr.press/v19/rudin11a/rudin11a.pdf", "keywords": ["statistical learning theory", "algorithmic stability", "association rules", "sequence prediction"], "reference": "Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In Proc. 20th Int\u2019l Conf. Very Large Data Bases, (VLDB), pages 487-499. Morgan Kauf- mann, 1994.  Rakesh Agrawal, Tomasz Imielinski, and Arun Swami. Mining association rules between sets of items in large databases. In Proc. ACM SIGMOD Int\u2019l Conf. on Management of Data, pages 207-216, 1993.  Olivier Bousquet and Andr\u00b4e Elissee\ufb00. Stability and generalization. Journal of Machine  Learning Research, 2:499-526, 2002.  John S. Breese, David Heckerman, and Carl Myers Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In Proc. Uncertainty in Artificial Intelligence (UAI), pages 43-52, 1998.  Edith Cohen, Mayur Datar, Shinji Fujiwara, Aristides Gionis, Piotr Indyk, Rajeev Motwani, Je\ufb00rey D. Ullman, and Cheng Yang. Finding interesting associations without support pruning. IEEE Trans. Knowl. Data Eng., 13(1):64-78, 2001.  Michelle Keim Condli\ufb00, David D. Lewis, David Madigan, and Christian Posse. Bayesian mixed-e\ufb00ects models for recommender systems. In ACM SIGIR Workshop on Recom- mender Systems: Algorithms and Evaluation, 1999.  Luc Devroye and T. J. Wagner. Distribution-free performance bounds for potential function  rules. IEEE Transactions on Information Theory, 25(5):601-604, 1979.  632   Rudin Letham Salleb-Aouissi Kogan Madigan  where we allow the predictions to alter the sequence in which items are placed into the basket (Letham et al., 2011).  6. Conclusion  This work synthesizes tools from several fields to analyze association rules in a supervised learning framework. This analysis is necessarily di\ufb00erent from that of classical supervised learning analysis; association rules provide two mechanisms for generalization: a large sam- ple, and a minimum support of rules. We considered two simple algorithms, both that create a bound on the support, regulating a tradeo\ufb00 between accuracy on the training set and generalization ability. We have also demonstrated that the adjusted confidence intro- duced here has several advantages over the minimum support threshold that is commonly considered in association rule mining.  Acknowledgments  C. Rudin is also at the Center for Computational Learning Systems, Columbia University. This work was performed partly while E. Kogan was at Fresh Direct. We would like to acknowledge support for this project from the National Science Foundation under grant IIS-1053407.  References  Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In Proc. 20th Int\u2019l Conf. Very Large Data Bases, (VLDB), pages 487-499. Morgan Kauf- mann, 1994.  Rakesh Agrawal, Tomasz Imielinski, and Arun Swami. Mining association rules between sets of items in large databases. In Proc. ACM SIGMOD Int\u2019l Conf. on Management of Data, pages 207-216, 1993.  Olivier Bousquet and Andr\u00b4e Elissee\ufb00. Stability and generalization. Journal of Machine  Learning Research, 2:499-526, 2002.  John S. Breese, David Heckerman, and Carl Myers Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In Proc. Uncertainty in Artificial Intelligence (UAI), pages 43-52, 1998.  Edith Cohen, Mayur Datar, Shinji Fujiwara, Aristides Gionis, Piotr Indyk, Rajeev Motwani, Je\ufb00rey D. Ullman, and Cheng Yang. Finding interesting associations without support pruning. IEEE Trans. Knowl. Data Eng., 13(1):64-78, 2001.  Michelle Keim Condli\ufb00, David D. Lewis, David Madigan, and Christian Posse. Bayesian mixed-e\ufb00ects models for recommender systems. In ACM SIGIR Workshop on Recom- mender Systems: Algorithms and Evaluation, 1999.  Luc Devroye and T. J. Wagner. Distribution-free performance bounds for potential function  rules. IEEE Transactions on Information Theory, 25(5):601-604, 1979. Sequential Event Prediction with Association Rules  William DuMouchel and Daryl Pregibon. Empirical bayes screening for multi-item associa- tions. In Proc. ACM SIGKDD Int\u2019l Conf. on Knowl. Discovery and Data Mining, pages 67-76, 2001.  A. Frank and A. Asuncion. UCI machine learning repository, 2010. URL http://archive.  ics.uci.edu/ml.  Xiangji Huang, Aijun An, Nick Cercone, and Gary Promhouse. Discovery of interesting association rules from Livelink web log data. In Proc. IEEE Int\u2019l Conf. on Data Mining (ICDM), 2002.  Xiang-Rong Jiang and Le Gruenwald. Microarray gene expression data association rules  mining based on BSC-tree and FIS-tree. Data & Knowl. Eng., 53(1):3-29, 2005.  Yun Sing Koh. Mining non-coincidental rules without a user defined support threshold. In Advances in Knowl. Discovery and Data Mining, 12th Pacific-Asia Conf., (PAKDD), pages 910-915, 2008.  Ron Kohavi, Llew Mason, Rajesh Parekh, and Zijian Zheng. Lessons and challenges from  mining retail e-commerce data. Machine Learning, 57(1-2):83-113, 2004.  R.D. Lawrence, G.S. Almasi, V. Kotlyar, M.S. Viveros, and S.S. Duri. Personalization of supermarket product recommendations. Data Mining and Knowledge Discovery, 5(1-2): 11-32, 2001.  Ben Letham, Cynthia Rudin, and David Madigan. A supervised ranking approach to  sequential event prediction. In Preparation, 2011.  Jinyan Li, Xiuzhen Zhang, Guozhu Dong, Kotagiri Ramamohanarao, and Qun Sun. E\ufb03cient mining of high confidence association rules without support thresholds. In Proc. Principles of Data Mining and Knowledge Discovery (PKDD), pages 406-411, 1999.  Weiyang Lin, Sergio A. Alvarez, and Carolina Ruiz. E\ufb03cient adaptive-support association rule mining for recommender systems. Data Mining and Knowledge Discovery, 6(1): 83-105, 2002.  Bing Liu, Wynne Hsu, and Yiming Ma.  Integrating classification and association rule mining. In Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining (KDD), 1998.  Tyler McCormick, Cynthia Rudin, and David Madigan. A hierarchical model for association rule mining of sequential events: An approach to automated medical symptom prediction. SSRN eLibrary, 2011. URL http://ssrn.com/paper=1736062.  W. H. Rogers and T. J. Wagner. A finite sample distribution-free performance bound for  local discrimination rules. Annals of Statistics, 6(3):506-514, 1978.  Cynthia Rudin, Benjamin Letham, Eugene Kogan, and David Madigan. A learning theory  framework for association rules and sequential events. In Preparation, 2011. Rudin Letham Salleb-Aouissi Kogan Madigan  Adriano Veloso, Humberto Mossri de Almeida, Marcos Andr\u00b4e Gon\u00b8calves, and Wagner Meira Jr. Learning to rank at query-time using association rules. In Proc. Int\u2019l ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 267-274, 2008.  Ke Wang, Yu He, David W. Cheung, and Francis Y. L. Chin. Mining confident rules without support requirement. In Proc. Conf. on Information and Knowledge Management (CIKM), pages 89-96, 2001. "}, "Optimal aggregation of affine estimators": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Optimal aggregation of affine estimators", "abstract": "We consider  the problem of combining  a (possibly uncountably infinite) set of affine estimators innon-parametric regression model with heteroscedastic Gaussian noise. Focusing on the exponentially weighted aggregate,  we prove a PAC-Bayesian type inequality that leadsto sharp oracle inequalities in discrete but also in continuous settings. The framework is general enough to cover the combinations of various procedures such asleast square regression, kernel ridge regression, shrinking estimators and many other estimators used in the literature on statistical inverse problems. As aconsequence, we show that the proposed aggregateprovides an adaptive estimator in the exact minimax sense without neither discretizing the range of tuningparameters nor splitting the set of observations. We also illustrate numerically the good performance achievedby the exponentially weighted aggregate.", "pdf_url": "http://proceedings.mlr.press/v19/salmon11a/salmon11a.pdf", "keywords": ["List of keywords"], "reference": "P. Alquier and K. Lounici. Pac-bayesian bounds for sparse regression estimation with exponen-  tial weights. Electron. J. Statist., 5:127-145, 2010.  647  00.20.40.60.81\u22122024Signal Length: n=102400.20.40.60.81\u22122024Noisy function : \u03c3=1 and PSNR=800.20.40.60.81\u22122024Denoised by EWA (PSNR=19.64)00.20.40.60.81\u22122024Denoised by BJS (PSNR=16.8) URE (PSNR=19.59), ST (PSNR=15.16)  BJSUREST OPTIMAL AGGREGATION OF AFFINE ESTIMATORS  Figure 4: Piece-Regular. The first row is the true signal (left) and a noisy version corrupted by Gaussian noise with standard deviation \u03c3 = 1 (right). The second row gives denoised version obtained by EWA (left) and by BJS, ST and URE (right). The PSNR is com- puted by the formula PSNR = 10 log10  (cid:161)max( f )2/MSE(cid:162).  6. Summary and future work  In this paper, we have addressed the problem of aggregating a set of affine estimators in the context of regression with fixed design and heteroscedastic noise. Under some assumptions on the constituent estimators, we have proven that the EWA with a suitably chosen temperature parameter satisfies PAC-Bayesian type inequality, from which different types of oracle inequal- ities have been deduced. All these inequalities are with leading constant one and with rate- optimal residual term. As a by-product of our results, we have shown that EWA applied to the family of Pinsker\u2019s estimators produces an estimator, which is adaptive in the exact minimax sense. Next in our agenda is carrying out an experimental evaluation of the proposed aggregate using the approximation schemes described by Dalalyan and Tsybakov (2009), Rigollet and Tsy- bakov (2011) and Alquier and Lounici (2010). It will also be interesting to extend the results of this work to the case of the unknown noise variance in the same vein as in Giraud (2008).  The authors acknowledge the support of the French Agence Nationale de la Recherche (ANR) under the grant PARCIMONIE.  Acknowledgments  References  P. Alquier and K. Lounici. Pac-bayesian bounds for sparse regression estimation with exponen-  tial weights. Electron. J. Statist., 5:127-145, 2010.00.20.40.60.81\u22122024Signal Length: n=102400.20.40.60.81\u22122024Noisy function : \u03c3=1 and PSNR=800.20.40.60.81\u22122024Denoised by EWA (PSNR=19.64)00.20.40.60.81\u22122024Denoised by BJS (PSNR=16.8) URE (PSNR=19.59), ST (PSNR=15.16)  BJSUREST SALMON DALALYAN  n  EWA  URE  BJS  ST  EWA  URE  BJS  ST512204851220485122048  Blocks  HeaviSine  0.051 (0.42) -0.052 (0.35) -0.050 (0.36) -0.007 (0.42)  -0.060 (0.19) -0.079 (0.19) -0.059 (0.23) -0.051 (0.25)  0.038 (0.37) 0.010 (0.36) -0.002 (0.30) 0.007 (0.34)  0.245 (0.39) 0.302 (0.50) 0.299 (0.46) 0.362 (0.57)  0.247 (0.42) 0.215 (0.39) 0.240 (0.36) 0.278 (0.48)  0.294 (0.47) 0.293 (0.51) 0.300 (0.45) 0.312 (0.50)  9.617 (1.78) 13.807 (2.16) 19.984 (2.68) 28.948 (3.31)  1.155 (0.57) 2.064 (0.86) 3.120 (1.20) 4.858 (1.42)  6.933 (1.54) 9.712 (1.76) 13.656 (2.25) 19.113 (2.68)  4.846 (1.29) 9.256 (1.70) 17.569 (2.17) 30.447 (2.96)  3.966 (1.12) 5.889 (1.36) 8.685 (1.64) 12.667 (2.03)  5.644 (1.20) 9.977 (1.67) 16.790 (2.06) 27.315 (2.61)  Ramp  Doppler  13.233 0.212 (2.11) (0.31) 17.080 0.205 (2.29) (0.39) 21.862 0.270 (2.92) (0.41) 28.733 0.234 (0.42) (3.19) Piece-Regular 8.883 0.248 (1.76) (0.40) 12.147 0.237 (2.28) (0.37) 15.207 0.291 (2.18) (0.46) 21.543 0.283 (2.47) (0.54) Piece-Polynomial 12.201 (1.81) 17.765 (2.72) 23.321 (2.96) 31.550 (3.05)  0.203 (0.37) 0.312 (0.49) 0.321 (0.48) 0.314 (0.49)  0.062 (0.35) -0.100 (0.30) -0.107 (0.35) -0.150 (0.34)  -0.069 (0.32) -0.105 (0.30) -0.092 (0.34) -0.059 (0.34)  0.017 (0.37) -0.078 (0.35) -0.026 (0.38) -0.007 (0.41)  6.036 (1.23) 12.620 (1.75) 23.006 (2.35) 38.671 (3.02)  4.879 (1.20) 9.793 (1.64) 16.798 (2.13) 27.387 (2.77)  3.988 (1.19) 9.031 (1.62) 17.565 (2.28) 29.461 (2.95)  Table 1: Comparison of several adaptive methods on the six (non-smooth) signals of inter- est. For each signal length n and each method, we give the average value of n \u00d7 (MSE \u2212 MSEOracle) and the corresponding standard deviation below, for 1000 replica- tions of the experiment. Negative values indicate that in some cases the EWA proce- dure has a smaller risk than that of the best linear estimator used for the aggregation, which is possible since the EWA itself is not a linear estimator.  Y. Amit and D. Geman. Shape quantization and recognition with randomized trees. Neural  Comput., 9:1545-1588, October 1997.  S. Arlot and F. Bach. Data-driven calibration of linear estimators with minimal penalties. In  J-Y. Audibert. Fast learning rates in statistical inference through aggregation. Ann. Statist., 37  F. Bach. Consistency of the group lasso and multiple kernel learning. J. Mach. Learn. Res., 9:  Y. Baraud, Ch. Giraud, and S. Huet. Estimator selection in the gaussian setting. submitted, 2010.  NIPS, pages 46-54, 2009.  (4):1591-1646, 2009.  1179-1225, 2008. OPTIMAL AGGREGATION OF AFFINE ESTIMATORS  n  EWA  URE  BJS  ST  EWA  URE  BJS  ST512204851220485122048  Blocks  HeaviSine  0.387 (0.43) 0.170 (0.20) 0.162 (0.18) 0.120 (0.17)  0.217 (0.16) 0.206 (0.18) 0.179 (0.18) 0.162 (0.15)  0.162 (0.16) 0.150 (0.18) 0.146 (0.18) 0.141 (0.20)  0.216 (0.40) 0.209 (0.41) 0.226 (0.41) 0.220 (0.37)  0.207 (0.42) 0.221 (0.43) 0.200 (0.50) 0.189 (0.37)  0.200 (0.38) 0.215 (0.38) 0.211 (0.39) 0.221 (0.43)  0.216 (0.24) 0.650 (0.25) 1.282 (0.44) 1.574 (0.55)  1.399 (0.54) 0.024 (0.26) 0.113 (0.27) 0.421 (0.27)  0.339 (0.24) 0.425 (0.23) 0.935 (0.33) 1.316 (0.42)  2.278 (0.98) 3.193 (1.07) 4.507 (1.28) 6.107 (1.55)  2.496 (0.96) 3.045 (1.10) 3.905 (1.27) 5.019 (1.53)  2.770 (1.00) 3.658 (1.20) 4.815 (1.35) 6.432 (1.54)  Doppler  1.608 0.237 (0.73) (0.40) 1.200 0.250 (0.48) (0.44) 1.842 0.229 (0.86) (0.45) 1.864 0.229 (0.40) (1.07) Piece-Regular 2.120 (1.09) 2.045 (1.17) 1.251 (0.70) 1.650 (1.12)  0.279 (0.49) 0.248 (0.45) 0.228 (0.41) 0.223 (0.42)  0.257 (0.48) 0.243 (0.46) 0.236 (0.47) 0.210 (0.39)  1.486 (0.68) 1.865 (0.84) 1.547 (1.02) 2.246 (1.15)  0.214 (0.23) 0.165 (0.20) 0.147 (0.19) 0.138 (0.20)  0.269 (0.27) 0.216 (0.20) 0.183 (0.20) 0.145 (0.19)  0.215 (0.25) 0.170 (0.20) 0.179 (0.20) 0.165 (0.20)  2.777 (1.04) 3.682 (1.24) 5.043 (1.43) 6.584 (1.58)  2.053 (0.95) 2.883 (1.13) 3.780 (1.37) 4.992 (1.42)  2.649 (1.01) 3.683 (1.20) 5.017 (1.38) 6.628 (1.70)  Ramp  Piece-Polynomial  Table 2: Comparison of several adaptive methods on the six smoothed signals of inter- est. length n and each method, we give the average value of n(MSE \u2212 MSEOracle) and the corresponding standard deviation below, for 1000 repli- cations of the experiment.  For each signal  A. R. Barron, L. Birg\u00e9, and P. Massart. Risk bounds for model selection via penalization. Probab.  Theory Related Fields, 113(3):301-413, 1999.  L. Breiman. Bagging predictors. Mach. Learn., 24(2):123-140, 1996.  A. Buades, B. Coll, and J-M. Morel. A review of image denoising algorithms, with a new one.  Multiscale Model. Simul., 4(2):490-530, 2005.  F. Bunea, A. B. Tsybakov, and M. H. Wegkamp. Aggregation for Gaussian regression. Ann.  Statist., 35(4):1674-1697, 2007.  T. T. Cai. Adaptive wavelet estimation: a block thresholding and oracle inequality approach.  Ann. Statist., 27(3):898-924, 1999. ISSN 0090-5364.  O. Catoni. Statistical learning theory and stochastic optimization, volume 1851 of Lecture Notes  in Mathematics. Springer-Verlag, Berlin, 2004. SALMON DALALYAN  L. Cavalier, G. K. Golubev, D. Picard, and A. B. Tsybakov. Oracle inequalities for inverse prob-  lems. Ann. Statist., 30(3):843-874, 2002.  A. Cohen. All admissible linear estimates of the mean vector. The Annals of Mathematical  Statistics, 37(2):458-463, 1966. ISSN 00034851.  A. S. Dalalyan and J. Salmon. Sharp oracle inequalities for aggregation of affine estimators.  Technical Report arXiv:1104.3969v2 [math.ST], April 2011.  A. S. Dalalyan and A. B. Tsybakov. Aggregation by exponential weighting, sharp oracle inequal-  ities and sparsity. In COLT, pages 97-111, 2007.  A. S. Dalalyan and A. B. Tsybakov. Aggregation by exponential weighting, sharp pac-bayesian  bounds and sparsity. Mach. Learn., 72(1-2):39-61, 2008.  A. S. Dalalyan and A. B. Tsybakov. Sparse regression learning by aggregation and Langevin  Monte-Carlo. In COLT, 2009.  81(3):425-455, 1994.  D. L. Donoho and I. M. Johnstone. Ideal spatial adaptation by wavelet shrinkage. Biometrika,  D. L. Donoho and I. M. Johnstone. Adapting to unknown smoothness via wavelet shrinkage. J.  Amer. Statist. Assoc., 90(432):1200-1224, 1995.  S. Y. Efromovich. On nonparametric regression for IID observations in a general setting. Ann.  Statist., 24(3):1125-1144, 1996.  S. Y. Efromovich and M. S. Pinsker. A self-training algorithm for nonparametric filtering. Av-  tomat. i Telemekh., 1(11):58-65, 1984.  S. Y. Efromovich and M. S. Pinsker. Sharp-optimal and adaptive estimation for heteroscedastic  nonparametric regression. Statist. Sinica, 6(4):925-942, 1996.  Y. Freund. Boosting a weak learning algorithm by majority. In Proceedings of the third annual  workshop on Computational learning theory, COLT, pages 202-216, 1990.  E. I. George. Minimax multiple shrinkage estimation. Ann. Statist., 14(1):188-205, 1986.  Ch. Giraud. Mixing least-squares estimators when the variance is unknown. Bernoulli, 14(4):  1089-1107, 2008.  G. K. Golubev. Nonparametric estimation of smooth densities of a distribution in L_2. Problemy  Peredachi Informatsii, 28(1):52-62, 1992.  Y. Golubev. On universal oracle inequalities related to high-dimensional linear models. Ann.  Statist., 38(5):2751-2780, 2010.  Statist., 28(3):681-712, 2000.  A. B. Juditsky and A. S. Nemirovski. Functional aggregation for nonparametric regression. Ann.  A. B. Juditsky and A. S. Nemirovski. Nonparametric denoising of signals with unknown local  structure. I. Oracle inequalities. Appl. Comput. Harmon. Anal., 27(2):157-179, 2009. OPTIMAL AGGREGATION OF AFFINE ESTIMATORS  G. R. G. Lanckriet, N. Cristianini, P. Bartlett, L. El Ghaoui, and M. Jordan. Learning the kernel matrix with semidefinite programming. J. Mach. Learn. Res., 5:27-72 (electronic), 2003/04.  G. Lecu\u00e9. Optimal rates of aggregation in classification under low noise assumption. Bernoulli,  G. Leung. Information Theory and Mixing Least Squares Regression. PhD thesis, Yale University,  G. Leung and A. R. Barron.  Information theory and mixing least-squares regressions.  IEEE  Trans. Inf. Theory, 52(8):3396-3410, 2006.  K. Lounici. Generalized mirror averaging and D-convex aggregation. Math. Methods Statist., 16  A. S. Nemirovski. Topics in non-parametric statistics, volume 1738 of Lecture Notes in Math.  13(4):1000-1022, 2007.  2004.  (3):246-259, 2007.  Springer, Berlin, 2000.  Inf., 16(2):52-68, 1980.  M. S. Pinsker. Optimal filtration of square-integrable signals in Gaussian noise. Probl. Peredachi  Ph. Rigollet and A. B. Tsybakov. Linear and convex aggregation of density estimators. Math.  Methods Statist., 16(3):260-280, 2007.  Ph. Rigollet and A. B. Tsybakov. Exponential screening and optimal rates of sparse estimation.  Ann. Statist., 39(2):731-471, 2011.  J. Salmon and E. Le Pennec. NL-Means and aggregation procedures. In ICIP, pages 2977-2980,  2009.  J. Shawe-Taylor and N. Cristianini. An introduction to support vector machines : and other  kernel-based learning methods. Cambridge University Press, 2000.  C. M. Stein. Estimation of the mean of a multivariate normal distribution. Ann. Statist., 9(6):  1135-1151, 1981.  A. B. Tsybakov. Optimal rates of aggregation. In COLT, pages 303-313, 2003.  A. B. Tsybakov. Introduction to nonparametric estimation. Springer, New York, 2009.  Y. Yang. Combining different procedures for adaptive regression. J. Multivariate Anal., 74(1):  135-161, 2000.  783-809, 2003.  2004.  Y. Yang. Regression with multiple candidate models: selecting or mixing? Statist. Sinica, 13(3):  Y. Yang. Aggregating regression procedures to improve performance. Bernoulli, 10(1):25-47,  M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. J. R.  Stat. Soc. Ser. B Stat. Methodol., 68(1):49-67, 2006. SALMON DALALYAN  T. Zhang. Information-theoretic upper and lower bounds for statistical estimation. IEEE Trans.  Inform. Theory, 52(4):1307-1321, 2006. ISSN 1557-9654.  "}, "Collaborative Filtering with the Trace Norm: Learning, Bounding, and Transducing": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Collaborative Filtering with the Trace Norm: Learning, Bounding, and Transducing", "abstract": "Trace-norm regularization is a widely-used and successful approach for collaborative filtering and matrix completion. However, its theoretical understanding is surprisingly weak, and despite previous attempts, there are no distribution-free, non-trivial learning guarantees currently known. In this paper, we bridge this gap by providing such guarantees, under mild assumptions which correspond to collaborative filtering as performed in practice. In fact, we claim that previous difficulties partially stemmed from a mismatch betweenthe standard learning-theoretic modeling of collaborative filtering, and its practical application. Our results also shed some light on the issue of collaborative filtering with bounded models, which enforce predictions to lie within a certain range. In particular, we provide experimental and theoretical evidence that such models lead to a modest yet significant improvement.", "pdf_url": "http://proceedings.mlr.press/v19/shamir11a/shamir11a.pdf", "keywords": ["Collaborative Filtering", "Trace-Norm Regularization", "Transductive Learning", "Sample Complexity"], "reference": "9:1019-1048, 2008.  F. Bach. Consistency of trace-norm minimization. Journal of Machine Learning Research,  O. Bousquet Boucheron, S. and G. Lugosi. Theory of classification: A survey of some recent  advances. ESAIM: Probability and Statistics, 9:323 - 375, 2005.  E. Cand`es and B. Recht. Exact matrix completion via convex optimization. Foundations  of Computational Mathematics, 9, 2009.  E. Cand`es and T. Tao. The power of convex relaxation: Near-optimal matrix completion.  IEEE Trans. Inform. Theory, 56(5):2053-2080, 2009.  Ran El-Yaniv and Dmitry Pechyoni. Transductive rademacher complexity and its applica-  tions. Journal of AI Research, 35:193-234, 2009.  M. Jaggi and M. Sulovsk\u00b4y. A simple algorithm for nuclear norm regularized problems. In  ICML, 2010.  L. Kozma, A. Ilin, and T. Raiko. Binary principal component analysis in the net\ufb02ix collab-  orative filtering task. In IEEE MLSP Workshop, 2009.  R. Lata(cid:32)la. Some estimates of norms of random matrices. Proceedings of the AMS, 133(5):  1273-1282, 2005.  J. Lee, B. Recht, R. Salakhutdinov, N. Srebro, and J. Tropp. Practical large-scale optimiza-  tion for max-norm regularization. In NIPS, 2010.  674   Shamir Shalev-Shwartz  which applies to all the settings we have discussed earlier. Currently, we do not know how to bridge this gap. Another issue is understanding the implications of our analysis to other types of matrix regularization, such as weighted trace-norm (Salakhutdinov and Srebro (2010)).  As to the use of bounded models, we note that although they seem beneficial in our experiments, they can also lead to non-convex optimization problems. While this did not seem to hurt performance in our experiments, it might be more harmful in other datasets of applications. One possible way to enforce boundeded predictions while maintaining con- vexity is using \u221e-norm constraints, as in Thm. 4. Minimizing the average loss with respect to such constraints is a convex optimization problem, and can be done with a generic SDP solver. However, a generic solver won\u2019t scale to large datasets. Thus, designing an e\ufb03cient convex optimization algorithm, which combines trace-norm and \u221e-norm constraints, is a potentially useful, yet non-trivial challenge.  We thank Nati Srebro and Ruslan Salakhutdinov for helpful discussions, as well as the anonymous reviewers for valuable comments.  Acknowledgements  References  9:1019-1048, 2008.  F. Bach. Consistency of trace-norm minimization. Journal of Machine Learning Research,  O. Bousquet Boucheron, S. and G. Lugosi. Theory of classification: A survey of some recent  advances. ESAIM: Probability and Statistics, 9:323 - 375, 2005.  E. Cand`es and B. Recht. Exact matrix completion via convex optimization. Foundations  of Computational Mathematics, 9, 2009.  E. Cand`es and T. Tao. The power of convex relaxation: Near-optimal matrix completion.  IEEE Trans. Inform. Theory, 56(5):2053-2080, 2009.  Ran El-Yaniv and Dmitry Pechyoni. Transductive rademacher complexity and its applica-  tions. Journal of AI Research, 35:193-234, 2009.  M. Jaggi and M. Sulovsk\u00b4y. A simple algorithm for nuclear norm regularized problems. In  ICML, 2010.  L. Kozma, A. Ilin, and T. Raiko. Binary principal component analysis in the net\ufb02ix collab-  orative filtering task. In IEEE MLSP Workshop, 2009.  R. Lata(cid:32)la. Some estimates of norms of random matrices. Proceedings of the AMS, 133(5):  1273-1282, 2005.  J. Lee, B. Recht, R. Salakhutdinov, N. Srebro, and J. Tropp. Practical large-scale optimiza-  tion for max-norm regularization. In NIPS, 2010. Collaborative Filtering with the Trace Norm  H. Ma, H. Yang, M. Lyu, and I. King. Sorec: social recommendation using probabilistic  matrix factorization. In CIKM, 2008.  R. Meir and T. Zhang. Generalization error bounds for bayesian mixture algorithms. Journal  of Machine Learning Research, 4:839-860, 2003.  S. Negahban and M. Wainwright. Restricted strong convexity and weighted matrix com-  pletion: Optimal bounds with noise. arXiv:1009.2118, 2010.  M. Piotte and M. Chabbert. The pragmatic theory solution to the net\ufb02ix grand Available at http://www.netflixprize.com/assets/GrandPrize2009_BPC_  prize. PragmaticTheory.pdf, 2009.  R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. In NIPS, 2007.  R. Salakhutdinov and N. Srebro. Collaborative filtering in a non-uniform world: Learning  with the weighted trace norm. In NIPS, 2010.  Yoav Seginer. The expected norm of random matrices. Combinatorics, Probability & Com-  puting, 9(2):149-166, 2000.  N. Srebro and A. Shraibman. Rank, trace-norm and max-norm. In COLT, 2005.  N. Srebro, J. Rennie, and T. Jaakkola. Maximum-margin matrix factorization. In NIPS,  N. Srebro, K. Sridharan, and A. Tewari. Smoothness, low-noise and fast rates. In NIPS,  2004.  2010.  K. Toh and S. Yun. An accelerated proximal gradient algorithm for nuclear norm regularized  least squares problems. Optimization Online, 2009.  V. Vapnik. Statistical Learning Theory. Wiley, 1998.  "}, "Contextual Bandits with Similarity Information": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Contextual Bandits with Similarity Information", "abstract": "In a multi-armed bandit (MAB) problem, an online algorithm makes a sequence of choices. In each round it chooses from a time-invariant set of alternatives and receives the payoff associated with this alternative. While the case of small strategy sets is by now well-understood, a lot of recent work has focused on MAB problems with exponentially or infinitely large  strategy sets, where one needs to assume extra structure in order to make the problem tractable. In particular, recent literature considered information on similarity between arms.We consider similarity information in the setting of \\emphcontextual bandits, a natural extension of the basic MAB problem where before each round an algorithm is given the \\emphcontext \u2013 a hint about the payoffs in this round. Contextual bandits are directly motivated by placing advertisements on webpages, one of the crucial problems in sponsored search. A particularly simple way to represent similarity information in the contextual bandit setting is via a \\emphsimilarity distance between the context-arm pairs which bounds from above the difference between the respective expected payoffs.Prior work on contextual bandits with similarity uses \u201cuniform\u201d partitions of the similarity space, so that each context-arm pair is approximated by the closest pair in the partition. Algorithms based on \u201cuniform\u201d partitions disregard the structure of the payoffs and the context arrivals, which is potentially wasteful. We present algorithms that are based on \\em adaptive partitions, and take advantage of \u201cbenign\u201d payoffs and context arrivals without sacrificing the worst-case performance. The central idea is to maintain a finer partition in high-payoff regions of the similarity space and in popular regions of the context space. Our results apply to several other settings, e.g. MAB with constrained temporal change\u00a0\\citepDynamicMAB-colt08 and sleeping bandits\u00a0\\citepsleeping-colt08.", "pdf_url": "http://proceedings.mlr.press/v19/slivkins11a/slivkins11a.pdf", "keywords": [], "reference": "Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the Dark: An E\ufb03cient Algo-  rithm for Bandit Linear Optimization. In 21th COLT, pages 263-274, 2008.  Rajeev Agrawal. The continuum-armed bandit problem. SIAM J. Control and Optimization, 33(6):  1926-1951, 1995.  Peter Auer. Using confidence bounds for exploitation-exploration trade-o\ufb00s. J. of Machine Learning  Research (JMLR), 3:397-422, 2002. Preliminary version in 41st IEEE FOCS, 2000.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2-3):235-256, 2002a. Preliminary version in 15th ICML, 1998.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multi- armed bandit problem. SIAM J. Comput., 32(1):48-77, 2002b. Preliminary version in 36th IEEE FOCS, 1995.  Peter Auer, Ronald Ortner, and Csaba Szepesv\u00b4ari. Improved Rates for the Stochastic Continuum-  Armed Bandit Problem. In 20th COLT, pages 454-468, 2007.  Baruch Awerbuch and Robert Kleinberg. Online linear optimization and adaptive routing. J. of Computer and System Sciences, 74(1):97-114, February 2008. Preliminary version in 36th ACM STOC, 2004.  S\u00b4ebastien Bubeck and R\u00b4emi Munos. Open Loop Optimistic Planning. In 23rd COLT, pages 477-489,  S\u00b4ebastien Bubeck, R\u00b4emi Munos, Gilles Stoltz, and Csaba Szepesvari. Online Optimization in X-  Armed Bandits. In NIPS, pages 201-208, 2008.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, learning, and games. Cambridge Univ. Press,  2010.  2006.  Wei Chu, Lihong Li, Lev Reyzin, and Robert E. Schapire. Contextual Bandits with Linear Payo\ufb00  Functions. In 14th, 2011.  Varsha Dani, Thomas P. Hayes, and Sham Kakade. The Price of Bandit Information for Online  Optimization. In 20th NIPS, 2007.  Abraham Flaxman, Adam Kalai, and H. Brendan McMahan. Online Convex Optimization in the Bandit Setting: Gradient Descent without a Gradient. In 16th ACM-SIAM SODA, pages 385-394, 2005.  Anupam Gupta, Robert Krauthgamer, and James R. Lee. Bounded geometries, fractals, and low-  distortion embeddings. In 44th IEEE FOCS, pages 534-543, 2003.  Elad Hazan and Satyen Kale. Better algorithms for benign bandits. In 20th ACM-SIAM SODA,  Elad Hazan and Nimrod Megiddo. Online Learning with Prior Information. In 20th COLT, pages  pages 38-47, 2009.  499-513, 2007.  699   Contextual Bandits with Similarity Information  help with the manuscript. Also, comments from anonymous COLT reviewers have been tremendously useful.  References  Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the Dark: An E\ufb03cient Algo-  rithm for Bandit Linear Optimization. In 21th COLT, pages 263-274, 2008.  Rajeev Agrawal. The continuum-armed bandit problem. SIAM J. Control and Optimization, 33(6):  1926-1951, 1995.  Peter Auer. Using confidence bounds for exploitation-exploration trade-o\ufb00s. J. of Machine Learning  Research (JMLR), 3:397-422, 2002. Preliminary version in 41st IEEE FOCS, 2000.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2-3):235-256, 2002a. Preliminary version in 15th ICML, 1998.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multi- armed bandit problem. SIAM J. Comput., 32(1):48-77, 2002b. Preliminary version in 36th IEEE FOCS, 1995.  Peter Auer, Ronald Ortner, and Csaba Szepesv\u00b4ari. Improved Rates for the Stochastic Continuum-  Armed Bandit Problem. In 20th COLT, pages 454-468, 2007.  Baruch Awerbuch and Robert Kleinberg. Online linear optimization and adaptive routing. J. of Computer and System Sciences, 74(1):97-114, February 2008. Preliminary version in 36th ACM STOC, 2004.  S\u00b4ebastien Bubeck and R\u00b4emi Munos. Open Loop Optimistic Planning. In 23rd COLT, pages 477-489,  S\u00b4ebastien Bubeck, R\u00b4emi Munos, Gilles Stoltz, and Csaba Szepesvari. Online Optimization in X-  Armed Bandits. In NIPS, pages 201-208, 2008.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, learning, and games. Cambridge Univ. Press,  2010.  2006.  Wei Chu, Lihong Li, Lev Reyzin, and Robert E. Schapire. Contextual Bandits with Linear Payo\ufb00  Functions. In 14th, 2011.  Varsha Dani, Thomas P. Hayes, and Sham Kakade. The Price of Bandit Information for Online  Optimization. In 20th NIPS, 2007.  Abraham Flaxman, Adam Kalai, and H. Brendan McMahan. Online Convex Optimization in the Bandit Setting: Gradient Descent without a Gradient. In 16th ACM-SIAM SODA, pages 385-394, 2005.  Anupam Gupta, Robert Krauthgamer, and James R. Lee. Bounded geometries, fractals, and low-  distortion embeddings. In 44th IEEE FOCS, pages 534-543, 2003.  Elad Hazan and Satyen Kale. Better algorithms for benign bandits. In 20th ACM-SIAM SODA,  Elad Hazan and Nimrod Megiddo. Online Learning with Prior Information. In 20th COLT, pages  pages 38-47, 2009.  499-513, 2007. Slivkins  Robert Kleinberg. Nearly tight bounds for the continuum-armed bandit problem. In 18th NIPS,  2004.  Robert Kleinberg. Online Decision Problems with Large Strategy Sets. PhD thesis, MIT, 2005.  Robert Kleinberg and Aleksandrs Slivkins. Sharp Dichotomies for Regret Minimization in Metric  Spaces. In 21st ACM-SIAM SODA, 2010.  Robert Kleinberg, Alexandru Niculescu-Mizil, and Yogeshwer Sharma. Regret bounds for sleeping  experts and bandits. In 21st COLT, pages 425-436, 2008a.  Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal. Multi-Armed Bandits in Metric Spaces. In  40th ACM STOC, pages 681-690, 2008b.  Levente Kocsis and Csaba Szepesvari. Bandit Based Monte-Carlo Planning. In 17th ECML, pages  282-293, 2006.  T.L. Lai and Herbert Robbins. Asymptotically e\ufb03cient Adaptive Allocation Rules. Advances in  Applied Mathematics, 6:4-22, 1985.  John Langford and Tong Zhang. The Epoch-Greedy Algorithm for Contextual Multi-armed Bandits.  In 21st NIPS, 2007.  COLT, 2009.  Alessandro Lazaric and R\u00b4emi Munos. Hybrid Stochastic-Adversarial On-line Learning.  In 22nd  Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. A contextual-bandit approach to  personalized news article recommendation. In 19th, 2010.  Lihong Li, Wei Chu, John Langford, and Xuanhui Wang. Unbiased o\ufb04ine evaluation of contextual-  bandit-based news article recommendation algorithms. In 4th, 2011.  Tyler Lu, D\u00b4avid P\u00b4al, and Martin P\u00b4al. Showing Relevant Ads via Lipschitz Context Multi-Armed  Bandits. In 14th, 2010.  Odalric-Ambrym Maillard and R\u00b4emi Munos. Online Learning in Adversarial Lipschitz Environments.  In ECML PKDD, pages 305-320, 2010.  H. Brendan McMahan and Matthew Streeter. Tighter Bounds for Multi-Armed Bandits with Expert  Advice. In 22nd COLT, 2009.  R\u00b4emi Munos and Pierre-Arnaud Coquelin. Bandit algorithms for tree search. In 23rd UAI, 2007.  Sandeep Pandey, Deepak Agarwal, Deepayan Chakrabarti, and Vanja Josifovski. Bandits for Tax-  onomies: A Model-based Approach. 2007.  Filip Radlinski, Robert Kleinberg, and Thorsten Joachims. Learning diverse rankings with multi-  armed bandits. In 25th ICML, pages 784-791, 2008.  Philippe Rigollet and Assaf Zeevi. Nonparametric Bandits with Covariates. In 23rd COLT, pages  54-66, 2010.  58:527-535, 1952.  Herbert Robbins. Some Aspects of the Sequential Design of Experiments. Bull. Amer. Math. Soc.,  Aleksandrs Slivkins and Eli Upfal. Adapting to a Changing Environment: the Brownian Restless  Bandits. In 21st COLT, pages 343-354, 2008. Contextual Bandits with Similarity Information  Aleksandrs Slivkins, Filip Radlinski, and Sreenivas Gollapudi. Learning optimally diverse rankings  over large document collections. In 27th ICML, pages 983-990, 2010.  Chih-Chun Wang, Sanjeev R. Kulkarni, and H. Vincent Poor. Bandit problems with side observa-  tions. IEEE Trans. on Automatic Control, 50(3):338355, 2005.  Yizao Wang, Jean-Yves Audibert, and R\u00b4emi Munos. Algorithms for Infinitely Many-Armed Bandits.  In NIPS, pages 1729-1736, 2008.  Michael Woodroofe. A one-armed bandit problem with a concomitant variable. J. Amer. Statist.  Assoc., 74(368), 1979. "}, "Adaptive Density Level Set Clustering": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Adaptive Density Level Set Clustering", "abstract": "Clusters are often defined to be the connected components of a density level set.Unfortunately, this definition depends on a level that needs to be user specifiedby some means. In this paper we present a simple algorithm that is able to asymptotically determinethe optimal level, that is, the level at which there is the first split in the cluster treeof the data generating distribution. We further show that this algorithm asymptotically recoversthe corresponding connected components. Unlike previous work, our analysis does not require strong assumptions on the density such as continuity or even smoothness.", "pdf_url": "http://proceedings.mlr.press/v19/steinwart11a/steinwart11a.pdf", "keywords": ["Clustering", "Density Level Sets"], "reference": "Zoology, 17:144\u2013150, 1968.  J.W. Carmichael, G.A. George, and R.S. Julius. Finding natural clusters. Systematic  K. Chaudhuri and S. Dasgupta. Rates of convergence for the cluster tree. In J. La\ufb00erty, C.K.I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23, pages 343\u2013351. 2010.  A. Cuevas and R. Fraiman. A plug-in approach to support estimation. Ann. Statist., 25:  2300\u20132312, 1997.  A. Cuevas, M. Febrero, and R. Fraiman. Estimating the number of clusters. The Canadian  Journal of Statistics, 28:367\u2013382, 2000.  L. Devroye, L. Gy\u00a8or\ufb01, and G. Lugosi. A Probabilistic Theory of Pattern Recognition.  Springer, New York, 1996.  J. A. Hartigan. Clustering Algorithms. John Wiley & Sons, New York, 1975.  J.A. Hartigan. Consistency of single linkage for high-density clusters. J. Amer. Statist.  Assoc., 76:388\u2013394, 1981.  M. Maier, M. Hein, and U. von Luxburg. Generalized density clustering. Optimal construc- tion of k-nearest neighbor graphs for identifying noisy clusters, 410:1749\u20131764, 2009.  P. Rigollet. Generalization error bounds in semi-supervised classi\ufb01cation under the cluster  assumption. J. Mach. Learn. Res., 8:1369\u20131392, 2007.  A. Rinaldo and L. Wasserman. Generalized density clustering. Ann. Statist., 38:2678\u20132722,  2010.  W. Stuetzle. Estimating the cluster tree of a density by analyzing the minimal spanning  tree of a sample. Journal of Classi\ufb01cation, 20:25\u201347, 2003.  W. Stuetzle and R. Nugent. A generalized single linkage method for estimating the cluster tree of a density. Journal of Computational and Graphical Statistics, 19:397\u2013418, 2010.  Appendix A. Proofs related to the de\ufb01nition of level sets  Proof of Lemma 1 The second inclusion has already been shown in (2), and hence it \u02da{h \u2265 \u03c1} and an open set su\ufb03ces to show the \ufb01rst. To show the \ufb01rst inclusion we \ufb01x an x \u2208 U with x \u2208 U . Then  \u02da{h \u2265 \u03c1} \u2229 U is open and non-empty, and hence supp \u00b5 = X yields  \u00b5\u03c1(U ) = \u00b5(cid:0){h \u2265 \u03c1} \u2229 U (cid:1) \u2265 \u00b5(cid:0) \u02da{h \u2265 \u03c1} \u2229 U (cid:1) > 0 .  720   Steinwart  Acknowledgments  I like to thank Michael Eisermann for many fruitful discussions.  References  Zoology, 17:144-150, 1968.  J.W. Carmichael, G.A. George, and R.S. Julius. Finding natural clusters. Systematic  K. Chaudhuri and S. Dasgupta. Rates of convergence for the cluster tree. In J. La\ufb00erty, C.K.I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23, pages 343-351. 2010.  A. Cuevas and R. Fraiman. A plug-in approach to support estimation. Ann. Statist., 25:  2300-2312, 1997.  A. Cuevas, M. Febrero, and R. Fraiman. Estimating the number of clusters. The Canadian  Journal of Statistics, 28:367-382, 2000.  L. Devroye, L. Gy\u00a8orfi, and G. Lugosi. A Probabilistic Theory of Pattern Recognition.  Springer, New York, 1996.  J. A. Hartigan. Clustering Algorithms. John Wiley & Sons, New York, 1975.  J.A. Hartigan. Consistency of single linkage for high-density clusters. J. Amer. Statist.  Assoc., 76:388-394, 1981.  M. Maier, M. Hein, and U. von Luxburg. Generalized density clustering. Optimal construc- tion of k-nearest neighbor graphs for identifying noisy clusters, 410:1749-1764, 2009.  P. Rigollet. Generalization error bounds in semi-supervised classification under the cluster  assumption. J. Mach. Learn. Res., 8:1369-1392, 2007.  A. Rinaldo and L. Wasserman. Generalized density clustering. Ann. Statist., 38:2678-2722,  2010.  W. Stuetzle. Estimating the cluster tree of a density by analyzing the minimal spanning  tree of a sample. Journal of Classification, 20:25-47, 2003.  W. Stuetzle and R. Nugent. A generalized single linkage method for estimating the cluster tree of a density. Journal of Computational and Graphical Statistics, 19:397-418, 2010.  "}, "Agnostic KWIK learning and efficient approximate reinforcement learning": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Agnostic KWIK learning and efficient approximate reinforcement learning", "abstract": "A popular approach in reinforcement learning is to use a model-based algorithm, i.e., an algorithm that utilizes a model learner to learn an approximate model to the  environment.It has been shown that  such a model-based learner is efficient  if the model learner is efficient  in the so-called \u201cknows what it knows\u201d  (KWIK)  framework.A major limitation of the standard KWIK framework is that, by its very definition, it covers only the case when the (model) learner can represent  the actual environment with no errors.In this paper, we study the agnostic KWIK learning model, where we relax this assumption by allowing nonzero approximation errors. We show that with the new definition  an efficient model learner still leads to an efficient reinforcement learning algorithm.At the same time, though, we find that learning within the new framework can be substantially slower as compared to the standard framework, even in the case of simple learning problems.", "pdf_url": "http://proceedings.mlr.press/v19/szita11a/szita11a.pdf", "keywords": ["KWIK learning", "agnostic learning", "reinforcement learning", "PAC-MDP"], "reference": "Peter Auer, Thomas Jaksch, and Ronald Ortner. Near-optimal regret bounds for reinforce-  ment learning. In NIPS, pages 89-96, 2008.  Ronen I. Brafman and Moshe Tennenholtz. A near-optimal polynomial time algorithm for learning in certain classes of stochastic games. Artificial Intelligence, 121(1-2):31-47, 2000.  Ronen I. Brafman and Moshe Tennenholtz. R-MAX - a general polynomial time algorithm  for near-optimal reinforcement learning. In IJCAI, pages 953-958, 2001.  Kai Lai Chung. A course in probability theory. Academic Press, 3 edition, 2001.  Carlos Diuk, Andre Cohen, and Michael L. Littman. An object-oriented representation for  e\ufb03cient reinforcement learning. In ICML, pages 240-247, 2008.  Joseph L. Doob. Stochastic processes. John Wiley & Sons, 1953.  Claude-Nicolas Fiechter. E\ufb03cient reinforcement learning. In COLT, pages 88-97, 1994.  David A. Freedman. On tail probabilities for martingales. The Annals of Probability, 3(1):  100-118, 1975.  Sham M. Kakade. On the Sample Complexity of Reinforcement Learning. PhD thesis,  University College London, 2003.  Michael Kearns and Satinder Singh. Near-optimal reinforcement learning in polynomial  time. Machine Learning, 49(2-3):209-232, 2002.  770   Szita Szepesv\u00b4ari  bound on the expected immediate rewards (condition (a)) holds by assumption, just like the measurability condition (b) and that the action selected at time t is sampled from \u03c0t(\u00b7|st) (condition (c)). The condition on the accuracy of the planner (condition (d)) was assumed as a condition of this theorem. The accuracy condition (e) holds with emodel = rD + (cid:15) on G by the choice of G, while the optimism condition (f) is met because of the use of the optimistic wrapper (in fact, because of this wrapper, Q\u03c0 (s, a) = Vmax holds for any \u02c6Mt (s, a) (cid:54)\u2208 Kt). Also, condition (g) is met because the learn method of MDPLearner is not called when (st, at) \u2208 Kt, hence in that case gt+1 = gt and thus \u03c0t+1 = \u03c0t. Finally, on G, B = B(\u03b4) bounds the number of times (st, at) (cid:54)\u2208 Kt happens. Therefore, by the conclusion of Theorem 5.1, with probability at least 1 \u2212 2\u03b4, the number of 5emodel/(1 \u2212 \u03b3) + eplan- \u221a mistakes is bounded by 2Vmax(1\u2212\u03b3)L  , where L =  2B + 3)  B + (  (cid:113)  (cid:27)  (cid:26)  (cid:1)  log (cid:0) L \u03b4  (cid:1) + 6 log (cid:0) L \u03b4  emodel  max(1, (cid:100)(1 \u2212 \u03b3)\u22121 log(Vmax(1 \u2212 \u03b3)/emodel)(cid:101)). Plugging in the value emodel = rD + (cid:15) gives the final bound.  References  Peter Auer, Thomas Jaksch, and Ronald Ortner. Near-optimal regret bounds for reinforce-  ment learning. In NIPS, pages 89-96, 2008.  Ronen I. Brafman and Moshe Tennenholtz. A near-optimal polynomial time algorithm for learning in certain classes of stochastic games. Artificial Intelligence, 121(1-2):31-47, 2000.  Ronen I. Brafman and Moshe Tennenholtz. R-MAX - a general polynomial time algorithm  for near-optimal reinforcement learning. In IJCAI, pages 953-958, 2001.  Kai Lai Chung. A course in probability theory. Academic Press, 3 edition, 2001.  Carlos Diuk, Andre Cohen, and Michael L. Littman. An object-oriented representation for  e\ufb03cient reinforcement learning. In ICML, pages 240-247, 2008.  Joseph L. Doob. Stochastic processes. John Wiley & Sons, 1953.  Claude-Nicolas Fiechter. E\ufb03cient reinforcement learning. In COLT, pages 88-97, 1994.  David A. Freedman. On tail probabilities for martingales. The Annals of Probability, 3(1):  100-118, 1975.  Sham M. Kakade. On the Sample Complexity of Reinforcement Learning. PhD thesis,  University College London, 2003.  Michael Kearns and Satinder Singh. Near-optimal reinforcement learning in polynomial  time. Machine Learning, 49(2-3):209-232, 2002. Agnostic KWIK learning  Lihong Li. A Unifying Framework for Computational Reinforcement Learning Theory. PhD thesis, Department of Computer Science, Rutgers University, New Brunswick, NJ, USA, 2009.  Lihong Li and Michael L. Littman. Reducing reinforcement learning to kwik online regres-  sion. Annals of Mathematics and Artificial Intelligence, 58(3-4):217-237, 2010.  Lihong Li, Michael L. Littman, and Thomas J. Walsh. Knows what it knows: A framework  for self-aware learning. In ICML, pages 568-575, 2008.  Lihong Li, Michael L. Littman, Thomas J. Walsh, and Alexander L. Strehl. Knows what it knows: A framework for self-aware learning. Machine Learning, 82(3):399-443, 2011a.  Lihong Li, Michael L. Littman, Thomas J. Walsh, and Alexander L. Strehl. Knows what it  knows: a framework for self-aware learning. Machine learning, 82:399-443, 2011b.  Martin .L. Puterman. Markov Decision Processes \u2014 Discrete Stochastic Dynamic Program-  ming. John Wiley & Sons, Inc., New York, NY, 2005.  Alexander L. Strehl. Model-based reinforcement learning in factored-state MDPs. In IEEE  ADPRL, pages 103-110, 2007.  Alexander L. Strehl and Michael L. Littman. A theoretical analysis of model-based interval In Proceedings of the 22nd international conference on Machine learning,  estimation. pages 856-863, 2005.  Alexander L. Strehl and Michael L. Littman. Online linear regression and its application  to model-based reinforcement learning. In NIPS, 2007.  Alexander L. Strehl, Lihong Li, and Michael L. Littman. Incremental model-based learners  with formal learning-time guarantees. In UAI, pages 485-493, 2006.  Alexander L. Strehl, Carlos Diuk, and Michael L. Littman. E\ufb03cient structure learning in  factored-state MDPs. In AAAI, pages 645-650, 2007.  Alexander L. Strehl, Lihong Li, and Michael L. Littman. Reinforcement learning in finite MDPs: PAC analysis. The Journal of Machine Learning Research, 10:2413-2444, 2009.  Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction. MIT  Press, Cambridge, 1998.  Csaba Szepesv\u00b4ari. Algorithms for Reinforcement Learning. Synthesis Lectures on Artificial  Intelligence and Machine Learning. Morgan & Claypool Publishers, 2010.  Istv\u00b4an Szita and Andr\u00b4as L\u02ddorincz. The many faces of optimism: a unifying approach. In  ICML, pages 1048-1055, 2008.  Istv\u00b4an Szita and Csaba Szepesv\u00b4ari. Model-based reinforcement learning with nearly tight  exploration complexity bounds. In ICML, pages 1031-1038, June 2010. Szita Szepesv\u00b4ari  Thomas J. Walsh, Sergiu Goschin, and Michael Littman. Integrating sample-based planning and model-based reinforcement learning. In Proceedings of the 24th AAAI Conference on Artificial Intelligence, 2010. "}, "The Sample Complexity of Dictionary Learning": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "The Sample Complexity of Dictionary Learning", "abstract": "A large set of signals can sometimes be described sparsely using a dictionary, that is, every element can be represented as a linear combination of few elements from the dictionary.  Algorithms for various signal processing applications, including classification, denoising and signal separation, learn a dictionary from a given set of signals to be represented. Can we expect that the error in representing by such a dictionary a previously unseen signal from the same source will be of similar magnitude as those for the given examples?We assume signals are generated from a fixed distribution, and study these questions from a statistical learning theory perspective. We develop generalization bounds on the quality of the learned dictionary for two types of constraints on the coefficient selection, as measured by the expected L_2 error in representation when the dictionary is used.For the case of l_1 regularized coefficient selection we provide a generalization bound of the order of O\\left(\\sqrtnp\\ln(m \u03bb)/m\\right), where n is the dimension, p is the number of elements in the dictionary, \u03bbis a bound on the l_1 norm of the coefficient vector and m is the number of samples, which complements existing results.For the case of representing a new signal as a combination of at most k dictionary elements, we provide a bound ofthe order O(\\sqrtnp\\ln(m k)/m) under an assumption on the closeness to orthogonality of the dictionary (low Babel function).We further show that this assumption holds for \\em most dictionaries in high dimensions in a strong probabilistic sense.Our results also include bounds that converge as 1/m, not previously known for this problem.We provide similar results in a general setting using kernels with weak smoothness requirements.", "pdf_url": "http://proceedings.mlr.press/v19/vainsencher11a/vainsencher11a.pdf", "keywords": ["statistical machine learning", "dictionary learning", "generalization bounds", "signal processing", "kernel methods"], "reference": "Michal Aharon, Michael Elad, and Alfred M. Bruckstein. K-SVD: An algorithm for de- signing overcomplete dictionaries for sparse representation. IEEE Transactions on Signal Processing, 54(11):4311-4322, 2006.  Martin Anthony and Peter L. Bartlett. Neural network learning: Theoretical foundations.  Cambridge University Press, 1999.  Peter L. Bartlett, Tam\u00b4as Linder, and G\u00b4abor Lugosi. The minimax distortion redundancy in empirical quantizer design. IEEE Transactions on Information theory, 44(5):1802-1813, 1998.  Peter L. Bartlett, Olivier Bousquet, and Shahar Mendelson. Local Rademacher complexi-  ties. Ann. Statist., 33:1497-1537, 2005.  G\u00b4erard Biau, Luc Devroye, and G\u00b4abor Lugosi. On the performance of clustering in Hilbert  spaces. IEEE Transactions on Information Theory, 54(2):781-790, 2008.  Gilles Blanchard, Olivier Bousquet, and Laurent Zwald. Statistical properties of kernel  principal component analysis. Machine Learning, 66(2):259-294, 2007.  788   Vainsencher Mannor Bruckstein  only logarithmically dependent on the l1 norm of the coe\ufb03cient vector widens the set of applicable approaches to penalization. Second, in the particular case of k sparse represen- tation, we have shown that the Babel function is a key property for the generalization of dictionaries. It might thus be useful to modify dictionary learning algorithms so that they obtain dictionaries with low Babel functions, possibly through regularization or through certain convex relaxations. Third, mistake bounds (e.g., Mairal et al. 2010) on the quality of the solution to the coe\ufb03cient finding optimization problem may lead to generalization bounds for practical algorithms, by tying such algorithms to k sparse representation.  The upper bounds presented here invite complementary lower bounds. The existing lower bounds for k = 1 (vector quantization) and for k = p (representation using PCA di- rections) are applicable, but do not capture the geometry of general k sparse representation, and in particular do not clarify the e\ufb00ective dimension of the unrestricted class of dictio- naries for it. We have not excluded the possibility that the class of unrestricted dictionaries has the same dimension as that of those with a small Babel function. The best upper bound we know for the larger class, being the trivial one of order O (cid:0)(cid:0)p (cid:1)n2(cid:14) m), leaves a significant k gap for future exploration.  We view the dependence on \u00b5k\u22121 from an \u201calgorithmic luckiness\u201d perspective (Herbrich and Williamson, 2003): if the data is described by a dictionary with low Babel function the generalization bounds are encouraging.  We thank Shahar Mendelson for helpful discussions. A.B. was partly supported by the European Communitys FP7-FET program, SMALL project, under grant agreement no. 225913. S.M and D.V. were partially supported by the ISF under contract 890015.  Acknowledgments  References  Michal Aharon, Michael Elad, and Alfred M. Bruckstein. K-SVD: An algorithm for de- signing overcomplete dictionaries for sparse representation. IEEE Transactions on Signal Processing, 54(11):4311-4322, 2006.  Martin Anthony and Peter L. Bartlett. Neural network learning: Theoretical foundations.  Cambridge University Press, 1999.  Peter L. Bartlett, Tam\u00b4as Linder, and G\u00b4abor Lugosi. The minimax distortion redundancy in empirical quantizer design. IEEE Transactions on Information theory, 44(5):1802-1813, 1998.  Peter L. Bartlett, Olivier Bousquet, and Shahar Mendelson. Local Rademacher complexi-  ties. Ann. Statist., 33:1497-1537, 2005.  G\u00b4erard Biau, Luc Devroye, and G\u00b4abor Lugosi. On the performance of clustering in Hilbert  spaces. IEEE Transactions on Information Theory, 54(2):781-790, 2008.  Gilles Blanchard, Olivier Bousquet, and Laurent Zwald. Statistical properties of kernel  principal component analysis. Machine Learning, 66(2):259-294, 2007. The Sample Complexity of Dictionary Learning  Alfred M. Bruckstein, David L. Donoho, and Michael Elad. From sparse solutions of systems of equations to sparse modeling of signals and images. SIAM Review, 51(1):34-81, 2009.  Emmanuel J. Candes and Terence Tao. Near-optimal signal recovery from random projec- tions: Universal encoding strategies? IEEE Transactions on Information Theory, 52(12): 5406-5425, 2006.  Scott S. Chen, David L. Donoho, and Michael A. Saunders. Atomic decomposition by basis  pursuit. SIAM Review, 43(1):129-159, 2001.  Sheng Chen, Stephen A. Billings, and Wan Luo. Orthogonal least squares methods and their application to non-linear system identification. International Journal of Control, 50 (5):1873-1896, 1989.  Felipe Cucker and Stephen Smale. On the mathematical foundations of learning. Bull.  Amer. Math. Soc, 39(1):1-50, 2002.  Geo\ufb00 Davis, St`ephane Mallat, and Marco Avellaneda. Adaptive greedy approximations.  Constructive approximation, 13(1):57-98, 1997.  David L. Donoho and Michael Elad. Optimally sparse representation in general (nonorthog- onal) dictionaries via (cid:96)1 minimization. Proceedings of the National Academy of Sciences, 100(5):2197-2202, 2003.  Richard J. Du\ufb03n and Albert C. Schaeer. A class of nonharmonic Fourier series. Trans.  Amer. Math. Soc, 72:341-366, 1952.  Ralf Herbrich and Robert Williamson. Algorithmic luckiness. Journal of Machine Learning  Research, 3:175-212, 2003.  Roger A. Horn and Charles R. Johnson. Matrix analysis. Cambridge University Press, 1990.  Kenneth Kreutz-Delgado, Joseph F. Murray, Bhaskar D. Rao, Kjersti Engan, Te-Won Lee, and Terrance J. Sejnowski. Dictionary learning algorithms for sparse representation. Neural computation, 15(2):349-396, 2003.  Honglak Lee, Alexis Battle, Rajat Raina, and Andrew Y. Ng. E\ufb03cient sparse coding algorithms. In Advances in Neural Information Processing Systems 19, pages 801-808. MIT Press, Cambridge, MA, 2007.  Michael S. Lewicki, Terrence J. Sejnowski, and Howard Hughes. Learning overcomplete  representations. Neural Computation, 12:337-365, 1998.  Julien Mairal, Francis Bach, Jean Ponce, and Guillermo Sapiro. Online learning for matrix factorization and sparse coding. Journal of Machine Learning Research, 11:19-60, 2010.  Andreas Maurer and Massimiliano Pontil. K-dimensional coding schemes in hilbert spaces.  IEEE Transactions on Information Theory, 56:5839-5846, November 2010.  Shahar Mendelson. A few notes on statistical learning theory. Advanced Lectures on Machine  Learning, pages 1-40, 2003. Vainsencher Mannor Bruckstein  Bruno A. Olshausen and David J. Fieldt. Sparse coding with an overcomplete basis set: a  strategy employed by V1. Vision Research, 37:3311-3325, 1997.  Gabriel Peyr\u00b4e. Sparse modeling of textures. Journal of Mathematical Imaging and Vision,  34(1):17-31, 2009.  Matan Protter and Michael Elad. Sparse and redundant representations and motion- estimation-free algorithm for video denoising. Wavelets XII. Proceedings of the SPIE, 6701:43, 2007.  John Shawe-Taylor and Nello Cristianini. Kernel methods for pattern analysis. Cambridge  University Press, 2004.  John Shawe-Taylor, Christopher K. I. Williams, Nello Cristianini, and Jaz Kandola. On the eigenspectrum of the Gram matrix and the generalization error of kernel-PCA. IEEE Transactions on Information Theory, 51(7):2510-2522, 2005.  Joel A. Tropp. Greed is good: Algorithmic results for sparse approximation. IEEE Trans-  actions on Information Theory, 50:2231-2242, 2004.  John Wright, Allen Y. Yang, Arvind Ganesh, S. Shankar Sastry, and Yi Ma. Robust face recognition via sparse representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, pages 210-227, 2008. "}, "Identifiability of Priors from Bounded Sample Sizes  with Applications to Transfer Learning": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Identifiability of Priors from Bounded Sample Sizes  with Applications to Transfer Learning", "abstract": "We explore a transfer learning setting, in which a finite sequence of target concepts are sampled independently with an unknown distribution from a known family.We study the total number of labeled examples required to learn all targets to an arbitrary specified expected accuracy, focusing on the asymptotics in the number of tasks and the desired accuracy.  Our primary interest is formally understanding the fundamental benefits of transfer learning, compared to learning each target independently from the others.Our approach to the transfer problem is general, in the sense that it can be used with a variety of learning protocols.  The key insight driving our approach is that the distribution of the target concepts is identifiable from the joint distribution over a number of random labeled data points equal the Vapnik-Chervonenkis dimension of the concept space.  This is not necessarily the case for the joint distribution over any smaller number of points.This work has particularly interesting implications when applied to active learning methods.", "pdf_url": "http://proceedings.mlr.press/v19/yang11a/yang11a.pdf", "keywords": ["Statistical Learning Theory", "Transfer Learning", "Bayesian Learning", "Active Learning"], "reference": "R. K. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks and  unlabeled data. Technical Report RC23462, IBM T.J. Watson Research Center, 2004.  M.-F. Balcan, S. Hanneke, and J. Wortman Vaughan. The true sample complexity of active learning.  Machine Learning, 80(2-3):111-139, September 2010.  J. Baxter. A bayesian/information theoretic model of learning to learn via multiple task sampling.  Machine Learning, 28:7-39, 1997.  J. Baxter. A model of inductive bias learning. Journal of Artificial Intelligence Research, 12:  149-198, 2000.  on Learning Theory, 2003.  S. Ben-David and R. Schuller. Exploiting task relatedness for multiple task learning. In Conference  J. G. Carbonell. Learning by analogy: Formulating and generalizing plans from past experience. In R. S. Michalski, J. G.Carbonell, and T. M. Mitchell, editors, Machine Learning, An Artificial Intelligence Approach. Tioga Press, Palo Alto, CA, 1983.  J. G. Carbonell. Derivational analogy: A theory of reconstructive problem solving and expertise acquisition. In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, Machine Learning, An Artificial Intelligence Approach, Volume II. Morgan Kaufmann, 1986.  R. Caruana. Multitask learning. Machine Learning, 28:41-75, 1997.  L. Devroye and G. Lugosi. Combinatorial Methods in Density Estimation. Springer, New York,  NY, USA, 2001.  805   TRANSFER LEARNING  5. Conclusions  We have shown that when learning a sequence of i.i.d. target concepts from a known VC class, with an unknown distribution from a known totally bounded family, transfer learning can lead to amortized expected sample complexity close to that achievable by an algorithm with direct knowl- edge of the the targets\u2019 distribution. Furthermore, the number of extra labeled examples per task, beyond what is needed for learning that task, is bounded by the VC dimension of the class. The key insight leading to this result is that the prior distribution is uniquely identifiable based on the joint distribution over the first VC dimension number of points. This is not necessarily the case for the distribution over any number of points less than the VC dimension. As a particularly interesting application, we note that in the context of active learning, transfer learning of this type can even lead to improvements in the asymptotic dependence on the desired error rate guarantee \u03b5 in the average expected sample complexity, and in particular can guarantee this average is o(1/\u03b5).  We extend our sincere thanks to Avrim Blum for several thought-provoking discussions on this topic.  Acknowledgments  References  R. K. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks and  unlabeled data. Technical Report RC23462, IBM T.J. Watson Research Center, 2004.  M.-F. Balcan, S. Hanneke, and J. Wortman Vaughan. The true sample complexity of active learning.  Machine Learning, 80(2-3):111-139, September 2010.  J. Baxter. A bayesian/information theoretic model of learning to learn via multiple task sampling.  Machine Learning, 28:7-39, 1997.  J. Baxter. A model of inductive bias learning. Journal of Artificial Intelligence Research, 12:  149-198, 2000.  on Learning Theory, 2003.  S. Ben-David and R. Schuller. Exploiting task relatedness for multiple task learning. In Conference  J. G. Carbonell. Learning by analogy: Formulating and generalizing plans from past experience. In R. S. Michalski, J. G.Carbonell, and T. M. Mitchell, editors, Machine Learning, An Artificial Intelligence Approach. Tioga Press, Palo Alto, CA, 1983.  J. G. Carbonell. Derivational analogy: A theory of reconstructive problem solving and expertise acquisition. In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, Machine Learning, An Artificial Intelligence Approach, Volume II. Morgan Kaufmann, 1986.  R. Caruana. Multitask learning. Machine Learning, 28:41-75, 1997.  L. Devroye and G. Lugosi. Combinatorial Methods in Density Estimation. Springer, New York,  NY, USA, 2001. YANG HANNEKE CARBONELL  T. Evgeniou and M. Pontil. Regularized multi-task learning.  In ACM SIGKDD Conference on  Knowledge Discovery and Data Mining, 2004.  T. Evgeniou, C. Micchelli, and M. Pontil. Learning multiple tasks with kernel methods. Journal of  Machine Learning Research, 6:615-637, 2005.  S. Hanneke. Theoretical Foundations of Active Learning. PhD thesis, Machine Learning Depart-  ment, School of Computer Science, Carnegie Mellon University, 2009.  J. Kolodner (Ed). Case-Based Learning. Kluwer Academic Publishers, The Netherlands, 1993.  C. Micchelli and M. Pontil. Kernels for multi-task learning. In Advances in Neural Information  Processing 18, 2004.  M. J. Schervish. Theory of Statistics. Springer, New York, NY, USA, 1995.  D. L. Silver. Selective Transfer of Neural Network Task Knowledge. PhD thesis, Computer Science,  University of Western Ontario, 2000.  S. Thrun. Is learning the n-th thing any easier than learning the first? In In Advances in Neural  Information Processing Systems 8, 1996.  V. Vapnik. Estimation of Dependencies Based on Empirical Data. Springer-Verlag, New York,  1982.  M. M. Veloso and J. G. Carbonell. Derivational analogy in prodigy: Automating case acquisition,  storage and utilization. Machine Learning, 10:249-278, 1993.  L. Yang, S. Hanneke, and J. Carbonell. The sample complexity of self-verifying bayesian active  learning. Technical Report CMU-ML-10-105, Carnegie Mellon University, 2010.  Y. G. Yatracos. Rates of convergence of minimum distance estimators and Kolmogorov\u2019s entropy.  The Annals of Statistics, 13:768-774, 1985. "}, "Does an Efficient Calibrated Forecasting Strategy Exist?": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Does an Efficient Calibrated Forecasting Strategy Exist?", "abstract": "We recall two previously-proposed notions of \\emphasymptotic calibration for a forecaster making a sequence of probability predictions. We note that the existence of efficient algorithms for calibrated forecasting holds only in the case of binary outcomes. We pose the question: do there exist such efficient algorithms for the general (non-binary) case?", "pdf_url": "http://proceedings.mlr.press/v19/abernethy11a/abernethy11a.pdf", "keywords": [], "reference": "9780521841085.  613, 1982.  J. Abernethy, P.L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learning are  equivalent. In Proceedings of the 24th Annual Conference on Learning Theory, 2011.  G.W. Brier. Verification of forecasts expressed in terms of probability. Monthly weather review, 78  (1):1-3, 1950. ISSN 1520-0493.  Nicolo Cesa-Bianchi and G`abor Lugosi. Prediction, Learning, and Games. 2006. ISBN 0521841089,  A. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association, 77:605-  D. P Foster and R. V Vohra. Asymptotic calibration. Biometrika, 85(2):379, 1998.  S.M. Kakade and D.P. Foster. Deterministic calibration and nash equilibrium. Journal of Computer  and System Sciences, 74(1):115-130, 2008.  S. Mannor and G. Stoltz. A geometric proof of calibration. Mathematics of Operations Research, 35(4):721-727, 2010. URL http://webee.technion.ac.il/people/shie/public/papers/J_ MShimkin03Bayes.pdf.  S. Mannor, J.S. Shamma, and G. Arslan. Online calibrated forecasts: Memory e\ufb03ciency versus  universality for learning in games. Machine Learning, 67(1):77-115, 2007. ISSN 0885-6125.  811   Efficient Calibration  in the table below, very little progress has been made towards e\ufb03cient algorithms that achieve calibration in general.  Binary (|K| = 2) Finite-alphabet (|K| = n > 2)  O(log 1  Strong (cid:15) ) time, O( 1 O(1/(cid:15)|K|) time/space  Weak  ?  (cid:15) ) space O(1) time/space  We use the term \u201ce\ufb03cient\u201d to denote an algorithm whose per-step complexity and memory requirements are poly in |K| and poly-logarithmic in (1/(cid:15)). Our concrete questions are:  1. Is there an e\ufb03cient time and memory algorithm for (cid:15)-strong calibration for |K| = 2?  2. Is there an e\ufb03cient time and memory algorithm for weak calibration for any |K|?  3. Is there an e\ufb03cient time and memory algorithm for strong calibrationfor any |K|?  Our best guess is that such an algorithm likely exists, for both the weak and strong case, in particular because we have not placed any restrictions on the rate at which the algorithm must achieve the calibration objective. On the other hand, the previously-discovered tricks which lead to e\ufb03cient calibrated forecasters may be very special to the binary case and we would not be surprised if no such e\ufb03cient algorithms exist when |K| > 2.  References  9780521841085.  613, 1982.  J. Abernethy, P.L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learning are  equivalent. In Proceedings of the 24th Annual Conference on Learning Theory, 2011.  G.W. Brier. Verification of forecasts expressed in terms of probability. Monthly weather review, 78  (1):1-3, 1950. ISSN 1520-0493.  Nicolo Cesa-Bianchi and G`abor Lugosi. Prediction, Learning, and Games. 2006. ISBN 0521841089,  A. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association, 77:605-  D. P Foster and R. V Vohra. Asymptotic calibration. Biometrika, 85(2):379, 1998.  S.M. Kakade and D.P. Foster. Deterministic calibration and nash equilibrium. Journal of Computer  and System Sciences, 74(1):115-130, 2008.  S. Mannor and G. Stoltz. A geometric proof of calibration. Mathematics of Operations Research, 35(4):721-727, 2010. URL http://webee.technion.ac.il/people/shie/public/papers/J_ MShimkin03Bayes.pdf.  S. Mannor, J.S. Shamma, and G. Arslan. Online calibrated forecasts: Memory e\ufb03ciency versus  universality for learning in games. Machine Learning, 67(1):77-115, 2007. ISSN 0885-6125. "}, "Bounds on Individual Risk for Log-loss Predictors": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Bounds on Individual Risk for Log-loss Predictors", "abstract": "In sequential prediction with log-loss as well as density estimationwith risk measured by KL divergence, one is often interested in the\\em expected instantaneous loss, or, equivalently, the \\em  individual risk at a given fixed sample size n. For Bayesianprediction and estimation methods, it is often easy to obtain boundson the \\em cumulative risk. Such results are based on bounding theindividual sequence regret, a technique that is very well known in theCOLT community. Motivated by the easiness of proofs for the cumulativerisk, our open problem is to use the results on cumulative risk to prove corresponding individual-risk bounds.", "pdf_url": "http://proceedings.mlr.press/v19/grunwald11b/grunwald11b.pdf", "keywords": [], "reference": "A.R. Barron. Information-theoretic characterization of Bayes performance and the choice of priors in parametric and nonparametric problems. In A.P. Dawid J.M. Bernardo, J.O. Berger and A.F.M. Smith, editors, Bayesian Statistics, volume 6, pages 27-52. Ox- ford University Press, Oxford, 1998.  O. Catoni. A mixture approach to universal model selection. preprint LMENS 97-30, 1997.  Available from http://www.dma.ens.fr/edition/preprints/Index.97.html.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning and Games. Cambridge University  J\u00a8urgen Forster and Manfred K. Warmuth. Relative expected instantaneous loss bounds.  Journal of Computer and System Sciences, 64(1):76-102, 2002.  P. D. Gr\u00a8unwald. The Minimum Description Length Principle. MIT Press, Cambridge, MA,  Press, 2006.  2007.  P. D. Gr\u00a8unwald and S. de Rooij. Asymptotic log-loss of prequential maximum likelihood  codes. In Conference on Learning Theory (COLT 2005), pages 652-667, 2005.  Y. Yang. Mixing strategies for density estimation. 28(1):75-87, 2000.  Tong Zhang. From (cid:15)-entropy to KL entropy: analysis of minimum information complexity  density estimation. 34(5):2180-2210, 2006.  816   Gr\u00a8unwald Kot(cid:32)lowski  of independent fair coin \ufb02ips, i.e. they are i.i.d. Bernoulli 1/2. In that case the risk at sample size 1 is 0, because the Bayesian predictive distribution based on the uniform prior and no data is P (X1 = 1) = 1/2. At sample size 2, the Bayesian predictive distribution is P (X2 = 1 | X1 = x) which is either 2/3 (if x = 1) or 1/3 (if x = 0). In both cases, the risk increases Barron (1998); Gr\u00a8unwald (2007). So increasing risk is possible. Still, no examples are known of substantially increasing risk at large n. Thus, maybe one might prove that some tight enough upper bound on the risk is still decreasing...  References  A.R. Barron. Information-theoretic characterization of Bayes performance and the choice of priors in parametric and nonparametric problems. In A.P. Dawid J.M. Bernardo, J.O. Berger and A.F.M. Smith, editors, Bayesian Statistics, volume 6, pages 27-52. Ox- ford University Press, Oxford, 1998.  O. Catoni. A mixture approach to universal model selection. preprint LMENS 97-30, 1997.  Available from http://www.dma.ens.fr/edition/preprints/Index.97.html.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning and Games. Cambridge University  J\u00a8urgen Forster and Manfred K. Warmuth. Relative expected instantaneous loss bounds.  Journal of Computer and System Sciences, 64(1):76-102, 2002.  P. D. Gr\u00a8unwald. The Minimum Description Length Principle. MIT Press, Cambridge, MA,  Press, 2006.  2007.  P. D. Gr\u00a8unwald and S. de Rooij. Asymptotic log-loss of prequential maximum likelihood  codes. In Conference on Learning Theory (COLT 2005), pages 652-667, 2005.  Y. Yang. Mixing strategies for density estimation. 28(1):75-87, 2000.  Tong Zhang. From (cid:15)-entropy to KL entropy: analysis of minimum information complexity  density estimation. 34(5):2180-2210, 2006. "}, "A simple multi-armed bandit algorithm with optimal variation-bounded regret": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "A simple multi-armed bandit algorithm with optimal variation-bounded regret", "abstract": "We pose the question of whether it is possible to design a simple, linear-time algorithm for the basic multi-armed bandit problem in the adversarial setting which has a regret bound of O(\\sqrtQ \\log T), where Q is the total quadratic variation of all the arms.", "pdf_url": "http://proceedings.mlr.press/v19/hazan11b/hazan11b.pdf", "keywords": [], "reference": "J. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An e\ufb03cient algorithm  for bandit linear optimization. In COLT, 2008.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed  bandit problem. SIAM J. Comput., 32(1):48-77, 2003. ISSN 0097-5397.  N. Cesa-Bianchi, Y. Mansour, and G. Stoltz. Improved second-order bounds for prediction  with expert advice. Mach. Learn., 66(2-3):321-352, 2007. ISSN 0885-6125.  818   Hazan Kale  of the quadratic variability as the variance in our data, and the di\ufb03culty of learning should be proportional to how much the data deviates from the mean rather than the length of the prediction sequence. As a special case, Q can be a constant independent of the data sequence, in which case we would like our regret to remain constant independent of the number of iterations (this is motivated by financial applications, as in (Hazan and Kale, 2009b)).  Recently, online learning algorithms that bound the regret as a function of Q rather than T have been developed. For the online linear optimization setting this was obtained in (Hazan and Kale, 2008), and for the MAB setting, the following theorem was proven in (Hazan and Kale, 2009a):  Theorem 1 There exists a polynomial-time MAB algorithm whose regret is bounded by O(n2\u221a  Q log T ).  Since our payo\ufb00s are bounded by one, it holds that Q \u2264 nT , and hence as T grows large the above bound is superior to the EXP3 bound (for certain ranges of Q). However, the algorithm used to obtain this bound is rather complicated: it is based on self-concordant barrier functions as regularizers, which were introduced to learning theory in (Abernethy et al., 2008), and applies to a more general setting of bandit online linear optimization than MAB. This technology makes the algorithm poly-time, but not nearly linear time and simple as EXP3. More importantly, the above bound is sub-optimal in terms of n.  The open question is to design a simple, linear-time algorithm for MAB  which has a regret bound of O(  Q log T ), hence improving upon EXP3.  \u221a  We conjecture that such an algorithm exists, and it should not use any self-concordance technology. Rather, it should be basic, perhaps based on the multiplicative updates method, and bear resemblence to EXP3. We note that EXP3 itself has \u2126( T ) regret, since it mixes with the uniform distribution every iteration to enable su\ufb03cient exploration. Hence, the desired algorithm should be a little di\ufb00erent from EXP3, incorporating just enough exploration proportional to the variation in the data.  \u221a  One possible feature of the new algorithm is to use an unbiased estimator for the payo\ufb00 vector ft constructed by estimating the empirical mean and the deviation from the mean separately, as done in (Hazan and Kale, 2009a). An unbiased estimator for the mean can be constructed using the reservoir sampling ideas in (Hazan and Kale, 2009a). The deviation from the mean can be computed using importance weighted sampling as in EXP3.  References  J. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An e\ufb03cient algorithm  for bandit linear optimization. In COLT, 2008.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed  bandit problem. SIAM J. Comput., 32(1):48-77, 2003. ISSN 0097-5397.  N. Cesa-Bianchi, Y. Mansour, and G. Stoltz. Improved second-order bounds for prediction  with expert advice. Mach. Learn., 66(2-3):321-352, 2007. ISSN 0885-6125. Variation-bounded Regret for multi-armed bandits  E. Hazan and S. Kale. Extracting certainty from uncertainty: Regret bounded by variation  in costs. In COLT, 2008.  E. Hazan and S. Kale. Better algorithms for benign bandits. In SODA, pages 38-47, 2009a.  E. Hazan and S. Kale. On stochastic and worst-case models for investing. In NIPS, 2009b. "}, "Minimax Algorithm for Learning Rotations": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Minimax Algorithm for Learning Rotations", "abstract": "It is unknown what is the most suitable regularization for rotation matrices and how to maintain uncertainty overrotations in an online setting.We propose to address these questions by studying the minimax algorithm for rotations and begin by working out the 2-dimensional case.", "pdf_url": "http://proceedings.mlr.press/v19/kotlowski11b/kotlowski11b.pdf", "keywords": [], "reference": "R. Arora. On learning rotations. In Y. Bengio, D. Schuurmans, J. La\ufb00erty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems 22, pages 55-63. MIT Press, 2009.  E. Hazan, S. Kale, and M. K. Warmuth. Learning rotations with little regret. In COLT  \u201910, June 2010. A corrigendum can be found at the conference website.  2. For n = 2, the algorithm of (Hazan et al., 2010) has a regret bound of 2  2T , whereas we show that the  minimax regret for learning rotations is  T .  \u221a  \u221a  823   Minimax for Rotations  last iteration: (cid:112)(cid:107)sT \u22121(cid:107)2 + 1. In the second to the last step  wT \u22121 = argmin w:(cid:107)w(cid:107)\u22641  max y:(cid:107)y(cid:107)=1  (cid:110)  \u2212w \u00b7 y +  (cid:107)sT \u22122 + y(cid:107)2 + 1  =  (cid:112)  (cid:111)  sT \u22122 (cid:112)(cid:107)sT \u22122(cid:107)2 + 2  and yT \u22121 is orthogonal to sT \u22122. Plugging wT \u22121 and yT \u22121 into the optimized expression leads to the worst-case regret increase in the last two iterations which is (cid:112)(cid:107)sT \u22122(cid:107)2 + 2. Continuing the backward induction, in the k-th step from the end, we optimize  wT \u2212k+1 = argmin w:(cid:107)w(cid:107)\u22641  max y:(cid:107)y(cid:107)=1  (cid:110)  (cid:112)  \u2212w \u00b7 y +  (cid:107)sT \u2212k + y(cid:107)2 + k \u2212 1  =  (cid:111)  sT \u2212k (cid:112)(cid:107)sT \u2212k(cid:107)2 + k  ,  and the worst-case regret increase in the last k iterations equals (cid:112)(cid:107)sT \u2212k(cid:107)2 + k. The value of the minimax regret can be obtained for k = T and is equal to  T .  \u221a  \u221a  Summarizing, we were able to prove that when the input xt is restricted to be a fixed T and does not depend on the dimension. The optimal vector, then the minimax regret is strategy for this case is to choose wt as the current \u201csu\ufb03cient statistic\u201d st\u22121 = (cid:80)t\u22121 q=1 yq times a shrinking factor that is related to the randomization. The worst-case data sequence for minimax algorithm is any sequence where the outcomes are always orthogonal to the current su\ufb03cient statistic (and the vector chosen by the optimal strategy).  For n = 2, the minimax regret for the fixed instance problem coincides with the minimax of the original rotation problem2 and the open problem is to determine the minimax regret for dimension n > 2.  Acknowledgments  This research was supported by NSF grant IIS-0917397.  References  R. Arora. On learning rotations. In Y. Bengio, D. Schuurmans, J. La\ufb00erty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems 22, pages 55-63. MIT Press, 2009.  E. Hazan, S. Kale, and M. K. Warmuth. Learning rotations with little regret. In COLT  \u201910, June 2010. A corrigendum can be found at the conference website.  2. For n = 2, the algorithm of (Hazan et al., 2010) has a regret bound of 2  2T , whereas we show that the  minimax regret for learning rotations is  T .  \u221a  \u221a "}, "Missing Information Impediments to Learnability": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Missing Information Impediments to Learnability", "abstract": "To what extent is learnability impeded when information is missing in learning instances? We present relevant known results and concrete open problems, in the context of a natural extension of the PAC learning model that accounts for arbitrarily missing information.", "pdf_url": "http://proceedings.mlr.press/v19/michael11a/michael11a.pdf", "keywords": ["PAC learning", "missing information", "masking process", "open problems"], "reference": "Michael Kearns and Umesh Vazirani. An Introduction to Computational Learning Theory.  The MIT Press, Cambridge, Massachusetts, U.S.A., 1994.  Loizos Michael. Autodidactic Learning and Reasoning. PhD thesis, School of Engineering  and Applied Sciences, Harvard University, U.S.A., May 2008.  Loizos Michael. Partial Observability and Learnability. Artificial Intelligence, 174(11):  639-669, July 2010.  Dale Schuurmans and Russell Greiner. Learning Default Concepts. In Proceedings of the Tenth Canadian Conference on Artificial Intelligence (AI\u201994), pages 99-106, May 1994.  Leslie Valiant. A Theory of the Learnable. Communications of the ACM, 27(11):1134-1142,  November 1984.  827   Missing Information Impediments to Learnability  Thus, the concept classes of conjunctions and linear thresholds (Kearns and Vazirani, 1994) are consistently learnable. Unlike what holds in the PAC learning model, a learning reduction cannot be readily employed to establish the learnability of k-CNFs for constant values of k \u2265 2. This holds because k-CNFs cannot be evaluated modularly on observations (unlike on examples). Indeed, the value of a certain conjunction of two subformulas on some observation may not be determinable only by the values of the subformulas (e.g., when they are undefined), but may require knowledge of the subformulas themselves. Hence:  Problem 3 Is the concept class C of 2-CNFs consistently learnable by a hypothesis class H? Is the question true for any concept class of formulas that are not modularly evaluatable?  The case of learning 3-CNFs presents an additional challenge when compared to the case of learning 2-CNFs, since the former formulas are not believed to be evaluatable e\ufb03ciently. Indeed, their evaluation on the observation \u2217n implies deciding their satisfiability. Hence:  Problem 4 Is the concept class C of 3-CNFs consistently learnable by a hypothesis class H? Is the question true for any concept class of formulas that are not e\ufb03ciently evaluatable?  Despite being a necessary condition, PAC learnability is not, by itself, a su\ufb03cient condi- tion for consistent learnability \u2014 at least not when the hypothesis class H and the concept class C are required to coincide, and the complexity condition RP (cid:54)= NP is assumed.  Theorem 5 The concept class C that comprises either parities or monotone-term 1-decision lists is not consistently learnable by the hypothesis class H = C, unless RP = NP.  The negative result holds despite C being PAC learnable by H = C (Kearns and Vazirani,  1994), and even when at most three attributes are masked in each observation. Hence:  Problem 6 Is the concept class C that comprises either parities or monotone-term 1- decision lists consistently learnable by a hypothesis class H that di\ufb00ers from C?  Refining the necessary and su\ufb03cient conditions for consistent learnability would help clarify which PAC learnability results remain true when information is missing arbitrarily, and, hence, which can be applied in realistic settings where the masking process is unknown.  References  Michael Kearns and Umesh Vazirani. An Introduction to Computational Learning Theory.  The MIT Press, Cambridge, Massachusetts, U.S.A., 1994.  Loizos Michael. Autodidactic Learning and Reasoning. PhD thesis, School of Engineering  and Applied Sciences, Harvard University, U.S.A., May 2008.  Loizos Michael. Partial Observability and Learnability. Artificial Intelligence, 174(11):  639-669, July 2010.  Dale Schuurmans and Russell Greiner. Learning Default Concepts. In Proceedings of the Tenth Canadian Conference on Artificial Intelligence (AI\u201994), pages 99-106, May 1994.  Leslie Valiant. A Theory of the Learnable. Communications of the ACM, 27(11):1134-1142,  November 1984. "}, "Monotone multi-armed bandit allocations": {"volumn": "v19", "url": "http://proceedings.mlr.press/v19/", "header": "Monotone multi-armed bandit allocations", "abstract": "We present a novel angle for multi-armed bandits (henceforth abbreviated MAB) which follows from the recent work on \\emphMAB mechanisms\u00a0\\citepMechMAB-ec09,DevanurK08,Transform-ec10. The new problem is, essentially, about designing MAB algorithms under an additional constraint motivated by their application to MAB mechanisms.This note is self-contained, although some familiarity with MAB is assumed; we refer the reader to\u00a0\\citeCesaBL-book for more background.", "pdf_url": "http://proceedings.mlr.press/v19/slivkins11b/slivkins11b.pdf", "keywords": [], "reference": "Aaron Archer and \u00b4Eva Tardos. Truthful mechanisms for one-parameter agents. In IEEE Symp. on  Foundations of Computer Science (FOCS), pages 482-491, 2001.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2-3):235-256, 2002a. Preliminary version in 15th ICML, 1998.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multi- armed bandit problem. SIAM J. Comput., 32(1):48-77, 2002b. Preliminary version in 36th IEEE FOCS, 1995.  Baruch Awerbuch and Robert Kleinberg. Online linear optimization and adaptive routing. Journal of Computer and System Sciences, 74(1):97-114, February 2008. Preliminary version appeared in 36th ACM STOC, 2004.  Moshe Babaio\ufb00, Yogeshwer Sharma, and Aleksandrs Slivkins. Characterizing truthful multi-armed bandit mechanisms. In 10th ACM Conf. on Electronic Commerce (EC), pages 79-88, 2009. Full version available at http://arxiv.org/abs/0812.2291.  Moshe Babaio\ufb00, Robert Kleinberg, and Aleksandrs Slivkins. Truthful mechanisms with implicit payment computation. In 11th ACM Conf. on Electronic Commerce (EC), pages 43-52, 2010. Best Paper Award. Full version available at http://arxiv.org/abs/1004.3630.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, learning, and games. Cambridge University  Press, 2006.  Nikhil Devanur and Sham M. Kakade. The price of truthfulness for pay-per-click auctions. In 10th  ACM Conf. on Electronic Commerce (EC), pages 99-106, 2009.  Roger B. Myerson. Optimal Auction Design. Mathematics of Operations Research, 6:58-73, 1981.  N. Nisan, T. Roughgarden, E. Tardos, and V. Vazirani (eds.). Algorithmic Game Theory. Cambridge  University Press., 2007.  Tim Roughgarden. An algorithmic game theory primer. IFIP International Conference on Theoret-  ical Computer Science (TCS). An invited survey., 2008.  Balasubramanian Sivan and Christopher A. Wilkens. Single-call mechanisms, 2010. Available at  http://arxiv.org/abs/1011.6134.  831   Monotone multi-armed bandit allocations  exploration and exploitation and has regret \u02dcO(T 2/3). This is in contrast to optimal MAB algorithms such as EXP3 (Auer et al., 2002b) that achieve regret \u02dcO( T ). We conjecture that EXP3-based MAB allocation rule is not ex-post monotone. It is not clear whether an MAB allocation rule with regret \u02dcO(  T ) can be ex-post monotone.  \u221a  \u221a  We thank Robert Kleinberg for his comments and suggestions.  Acknowledgments  References  Aaron Archer and \u00b4Eva Tardos. Truthful mechanisms for one-parameter agents. In IEEE Symp. on  Foundations of Computer Science (FOCS), pages 482-491, 2001.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2-3):235-256, 2002a. Preliminary version in 15th ICML, 1998.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multi- armed bandit problem. SIAM J. Comput., 32(1):48-77, 2002b. Preliminary version in 36th IEEE FOCS, 1995.  Baruch Awerbuch and Robert Kleinberg. Online linear optimization and adaptive routing. Journal of Computer and System Sciences, 74(1):97-114, February 2008. Preliminary version appeared in 36th ACM STOC, 2004.  Moshe Babaio\ufb00, Yogeshwer Sharma, and Aleksandrs Slivkins. Characterizing truthful multi-armed bandit mechanisms. In 10th ACM Conf. on Electronic Commerce (EC), pages 79-88, 2009. Full version available at http://arxiv.org/abs/0812.2291.  Moshe Babaio\ufb00, Robert Kleinberg, and Aleksandrs Slivkins. Truthful mechanisms with implicit payment computation. In 11th ACM Conf. on Electronic Commerce (EC), pages 43-52, 2010. Best Paper Award. Full version available at http://arxiv.org/abs/1004.3630.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, learning, and games. Cambridge University  Press, 2006.  Nikhil Devanur and Sham M. Kakade. The price of truthfulness for pay-per-click auctions. In 10th  ACM Conf. on Electronic Commerce (EC), pages 99-106, 2009.  Roger B. Myerson. Optimal Auction Design. Mathematics of Operations Research, 6:58-73, 1981.  N. Nisan, T. Roughgarden, E. Tardos, and V. Vazirani (eds.). Algorithmic Game Theory. Cambridge  University Press., 2007.  Tim Roughgarden. An algorithmic game theory primer. IFIP International Conference on Theoret-  ical Computer Science (TCS). An invited survey., 2008.  Balasubramanian Sivan and Christopher A. Wilkens. Single-call mechanisms, 2010. Available at  http://arxiv.org/abs/1011.6134. Slivkins  "}}