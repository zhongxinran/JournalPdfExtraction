{"Preface": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Preface", "abstract": "(No Abstract)", "pdf_url": "http://proceedings.mlr.press/v30/Shalev13.pdf", "keywords": []}, "Open Problem: Adversarial Multiarmed Bandits with Limited Advice ": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Open Problem: Adversarial Multiarmed Bandits with Limited Advice ", "abstract": "Adversarial multiarmed bandits with expert advice is one of the fundamental problems in studying the exploration-exploitation trade-off. It is known that if we observe the advice of all experts on every round we can achieve O\\left(\\sqrtKT \\ln N\\right) regret, where K is the number of arms, T is the number of game rounds, and N is the number of experts. It is also known that if we observe the advice of just one expert on every round, we can achieve regret of order O\\left(\\sqrtNT\\right). Our open problem is what can be achieved by asking M experts on every round, where 1", "pdf_url": "http://proceedings.mlr.press/v30/Seldin13.pdf", "keywords": ["Adversarial Multiarmed Bandits with Expert Advice", "EXP4"], "reference": "Jean-Yves Audibert and S\u00b4ebastien Bubeck. Regret bounds and minimax policies under partial  monitoring. Journal of Machine Learning Research, 11, 2010.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multi-  armed bandit problem. SIAM Journal of Computing, 32(1), 2002.  Alina Beygelzimer, John Langford, Lihong Li, Lev Reyzin, and Robert Schapire. Contextual bandit algorithms with supervised learning guarantees. In Proceedings on the International Conference on Artificial Intelligence and Statistics (AISTATS), 2011.  S\u00b4ebastien Bubeck and Nicol`o Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-  armed bandit problems. Foundations and Trends in Machine Learning, 5, 2012.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  Nicol`o Cesa-Bianchi, Shai Shalev-Shwartz, and Ohad Shamir. E\ufb03cient learning with partially ob-  served attributes. Journal of Machine Learning Research, 2011.  Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. A contextual-bandit approach to In Proceedings of the International Conference on  personalized news article recommendation. World Wide Web (WWW), 2010.  Yevgeny Seldin, Peter Bartlett, Koby Crammer, and Yasin Abbasi-Yadkori.  with limited advice and multiarmed bandits with paid observations. http://arxiv.org/abs/1304.3708, 2013.  Prediction Technical report,  3   Adversarial Multiarmed Bandits with Limited Advice  (cid:16)(cid:112)(N \u2212 M + 1)KT ln N  (cid:17)  O regret bound, which has a bit disappointing dependence on M (even though it would provide a continuous interpolation between asking one expert and asking all experts).  The problem of prediction with limited advice is related to label-e\ufb03cient prediction (Cesa-Bianchi and Lugosi, 2006; Audibert and Bubeck, 2010). In label-e\ufb03cient prediction all experts are queried on a subset of game rounds and in prediction with limited advice a subset of experts is queried on all game rounds. We note that the formulation of pre- diction with limited advice is substantially di\ufb00erent from learning with partially observed attributes (Cesa-Bianchi et al., 2011), but possibly some tools could be transferred between the settings.  Acknowledgements  This research was supported by an Australian Research Council Australian Laureate Fel- lowship (FL110100281). We gratefully acknowledge the support of the NSF through grant CCF-1115788.  References  Jean-Yves Audibert and S\u00b4ebastien Bubeck. Regret bounds and minimax policies under partial  monitoring. Journal of Machine Learning Research, 11, 2010.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multi-  armed bandit problem. SIAM Journal of Computing, 32(1), 2002.  Alina Beygelzimer, John Langford, Lihong Li, Lev Reyzin, and Robert Schapire. Contextual bandit algorithms with supervised learning guarantees. In Proceedings on the International Conference on Artificial Intelligence and Statistics (AISTATS), 2011.  S\u00b4ebastien Bubeck and Nicol`o Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-  armed bandit problems. Foundations and Trends in Machine Learning, 5, 2012.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  Nicol`o Cesa-Bianchi, Shai Shalev-Shwartz, and Ohad Shamir. E\ufb03cient learning with partially ob-  served attributes. Journal of Machine Learning Research, 2011.  Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. A contextual-bandit approach to In Proceedings of the International Conference on  personalized news article recommendation. World Wide Web (WWW), 2010.  Yevgeny Seldin, Peter Bartlett, Koby Crammer, and Yasin Abbasi-Yadkori.  with limited advice and multiarmed bandits with paid observations. http://arxiv.org/abs/1304.3708, 2013.  Prediction Technical report, \u2200h: \u02c6L0(h) = 0. for i = 1, 2, ... do  Let  Seldin Crammer Bartlett  qt(h) =  e\u2212\u03b7t \u02c6Lt\u22121(h) h e\u2212\u03b7t \u02c6Lt\u22121(h)  .  (cid:80)  Sample M experts without replacement, such that the probability of sampling expert h is \u02dcqt(h). (\u02dcqi(h) is specified in the analysis of the algorithm.) Let 1h t = 1 if expert h was sampled and 1h  t = 0 otherwise.  Get advice vectors \u03beh  t for the experts sampled.  Let  Draw action At according to pt and receive reward Rt \u2208 [0, 1].  pt(a) =  (cid:80) qt(h) \u02dcqt(h) \u03beh h (cid:80) qt(h) h \u02dcqt(h)  t (a)1h t 1h t  .  \u2200a : La  t =  1 \u2212 Rt pt(a)  1{At=a}.  \u2200h : Y h  t = \u03beh  t (At)LAt t  1 \u02dcqt(h)  1h t .  \u2200h : \u02c6Lt(h) =  t (cid:88)  i=1  Y h i .  end  Analysis  Algorithm 1: A general algorithm for multiarmed bandits with limited advice.  "}, "Open Problem: Fast Stochastic Exp-Concave Optimization  ": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Open Problem: Fast Stochastic Exp-Concave Optimization  ", "abstract": "Stochastic exp-concave optimization is an important primitive in machine learning that captures several fundamental problems, including linear regression, logistic regression and more. The exp-concavity property allows for fast convergence rates, as compared to general stochastic optimization.  However, current algorithms that attain such rates scale poorly with the dimension n and run in time O(n^4), even on very simple instances of the problem.  The question we pose is whether it is possible to obtain fast rates for exp-concave functions using more computationally-efficient algorithms.", "pdf_url": "http://proceedings.mlr.press/v30/Koren13.pdf", "keywords": [], "reference": "Elad Hazan and Satyen Kale. Beyond the regret minimization barrier: an optimal algo- rithm for stochastic strongly-convex optimization. Journal of Machine Learning Research- Proceedings Track, 19:421\u2013436, 2011.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online  convex optimization. Machine Learning, 69(2-3):169\u2013192, 2007.  Sham Kakade and Shai Shalev-Shwartz. Mind the duality gap: Logarithmic regret algo- rithms for online optimization. Advances in Neural Information Processing Systems 21, pages 1457\u20131464, 2009.  2. Here we assume that F is an expectation of exp-concave functions f (x, z) and the algorithm has access  to a gradient oracle of the form \u02c6gx = \u2207f (x, z) with z \u223c D.  2   Koren  However, the exp-concavity property of F allows for better convergence rates. A stan- dard online-to-batch conversion of the Online Newton Step (ONS) algorithm (Hazan et al., 2007) yields an algorithm2 that attains a rate of \u02dcO(n/\u03b5) for exp-concave functions. Never- theless, the runtime per iteration of this algorithm is O(n2), which implies a total runtime of \u02dcO(n3/\u03b5) ignoring projections. When considering the time required to compute a \u201cgen- eralized projection\u201d used by ONS, the runtime becomes as high as \u02dcO(n4/\u03b5), even for very simple domains K (such as the unit ball). For the technical details, refer to "}, "Open Problem: Lower bounds for Boosting with Hadamard Matrices ": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Open Problem: Lower bounds for Boosting with Hadamard Matrices ", "abstract": "Boosting algorithms can be viewed as a zero-sum game. At each iteration a new column / hypothesis is chosen from a game matrix representing the entire hypotheses class.  There are algorithms for which the gap between the value of the sub-matrix (the t columns chosen so far) and the value of the entire game matrix is O(\\sqrt\\frac\\log nt).  A matching lower bound has been shown for random game matrices for t up to n^\u03b1where \u03b1\u2208(0,\\frac12).  We conjecture that with Hadamard matrices we can build a certain game matrix for which the game value grows at the slowest possible rate for t up to a fraction of n.", "pdf_url": "http://proceedings.mlr.press/v30/Nie13.pdf", "keywords": [], "reference": "Ahron Ben-Tal, Tamar Margalit, and Arkadi Nemirovski. The ordered subsets mirror de- scent optimization method with applications to tomography. SIAM Journal on Optimiza- tion, 12(1):79-108, July 2001.  Yoav Freund. Boosting a weak learning algorithm by majority. Inform. Comput., 121(2):  256-285, September 1995. Also appeared in COLT90.  Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119-139, August 1997.  J. Kivinen, M. K. Warmuth, and P. Auer. The perceptron algorithm vs. winnow: linear vs. logarithmic mistake bounds when few input variables are relevant. Artificial Intelligence, 97:325-343, December 1997.  Philip Klein and Neal Young. On the number of iterations for dantzig-wolfe optimization and packing-covering approximation algorithms. In In Proceedings of the 7th International IPCO Conference, pages 320-327. Springer, 1999.  Arkadi Nemirovski and D Yudin. Problem Complexity and Method E\ufb03ciency in Optimiza-  tion. John Wiley and Sons, 1983.  Gunnar R\u00a8atsch and Manfred K. Warmuth. E\ufb03cient margin maximization with boosting.  J. Mach. Learn. Res., 6:2131-2152, December 2005.  M. K. Warmuth and S. V. N. Vishwanathan. Leaving the span. In P. Auer and R. Meir, editors, Proc. Annual Conf. Computational Learning Theory, number 3559 in Springer Lecture Notes in Artificial Intelligence, pages 365-380, Bertinoro, Italy, June 2005.  3   Lower Bounds for Boosting  Finally we have for t \u2264 n  2 , valD(H) \u2212 max \u02c6Ht Note that this weaker lower bound holds for a larger range of t (1 \u2264 t \u2264 n  lower bound of conjecture that the stronger lower bound holds for the larger range for our matrices:  2 ) than the stronger proven by Klein and Young (1999) for a restricted range. We first  (cid:113) log n t  (n\u22121)t \u2265  valD( \u02c6Ht) \u2265  (cid:113) n\u2212t  (cid:113) 1 2t .  Conjecture 1 There are fixed fractions c, c(cid:48) \u2208 (0, 1) and n0 such that the gap of \u02c6H is lower (cid:113) log n bounded as follows: \u2200n \u2265 n0 and log n \u2264 t \u2264 c n : valD( \u02c6H) \u2212 max \u02c6Ht . t  valD( \u02c6Ht) \u2265 c(cid:48)  We further conjecture that our modified Hadamard matrices give the largest gaps among all \u00b11 matrices with game value 0. We have verified this conjecture by tedious combinatorial arguments for n = 2, 4, 8 and t \u2264 n as well as for n = 2k and n \u2212 2 \u2264 t \u2264 n.  Conjecture 2 For any (n\u22121)\u00d7n dimensional \u00b11 valued matrix U satisfying valD(U) = 0, valD( \u02c6Ht) \u2264 maxUt valD(Ut), where the following inequality holds for 1 \u2264 t \u2264 n: max \u02c6Ht \u02c6Ht is any t column sub-matrix of \u02c6H and Ut is any t column sub-matrix of U.  References  Ahron Ben-Tal, Tamar Margalit, and Arkadi Nemirovski. The ordered subsets mirror de- scent optimization method with applications to tomography. SIAM Journal on Optimiza- tion, 12(1):79-108, July 2001.  Yoav Freund. Boosting a weak learning algorithm by majority. Inform. Comput., 121(2):  256-285, September 1995. Also appeared in COLT90.  Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119-139, August 1997.  J. Kivinen, M. K. Warmuth, and P. Auer. The perceptron algorithm vs. winnow: linear vs. logarithmic mistake bounds when few input variables are relevant. Artificial Intelligence, 97:325-343, December 1997.  Philip Klein and Neal Young. On the number of iterations for dantzig-wolfe optimization and packing-covering approximation algorithms. In In Proceedings of the 7th International IPCO Conference, pages 320-327. Springer, 1999.  Arkadi Nemirovski and D Yudin. Problem Complexity and Method E\ufb03ciency in Optimiza-  tion. John Wiley and Sons, 1983.  Gunnar R\u00a8atsch and Manfred K. Warmuth. E\ufb03cient margin maximization with boosting.  J. Mach. Learn. Res., 6:2131-2152, December 2005.  M. K. Warmuth and S. V. N. Vishwanathan. Leaving the span. In P. Auer and R. Meir, editors, Proc. Annual Conf. Computational Learning Theory, number 3559 in Springer Lecture Notes in Artificial Intelligence, pages 365-380, Bertinoro, Italy, June 2005. Nie Warmuth Vishwanathan Zhang  Manfred K. Warmuth, Karen A. Glocer, and S. V. N. Vishwanathan. Entropy regularized LPBoost. In Yoav Freund, Yoav L`aszl`o Gy\u00a8orfi, and Gy\u00a8orgy Tur`an, editors, Proc. Intl. Conf. Algorithmic Learning Theory, number 5254 in Lecture Notes in Artificial Intelli- gence, pages 256 - 271, Budapest, October 2008. Springer-Verlag. "}, "On the Complexity of Bandit and Derivative-Free Stochastic Convex Optimization": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "On the Complexity of Bandit and Derivative-Free Stochastic Convex Optimization", "abstract": "The problem of stochastic convex optimization with bandit feedback (in the learning community) or without knowledge of gradients (in the optimization community) has received much attention in recent years, in the form of algorithms and performance upper bounds. However, much less is known about the inherent complexity of these problems, and there are few lower bounds in the literature, especially for nonlinear functions. In this paper, we investigate the attainable error/regret in the bandit and derivative-free settings, as a function of the dimension d and the available number of queries T. We provide a precise characterization of the attainable performance for strongly-convex and smooth functions, which also imply a non-trivial lower bound for more general problems. Moreover, we prove that in both the bandit and derivative-free setting, the required number of queries must scale at least quadratically with the dimension. Finally, we show that on the natural class of quadratic functions, it is possible to obtain a \u201cfast\u201d O(1/T) error rate in terms of T, under mild assumptions, even without having access to gradients. To the best of our knowledge, this is the first such rate in a derivative-free stochastic setting, and holds despite previous results which seem to imply the contrary.", "pdf_url": "http://proceedings.mlr.press/v30/Shamir13.pdf", "keywords": ["Stochastic Convex Optimization", "Derivative-Free Optimization", "Bandit Convex Optimization", "Regret"], "reference": "bandits. In NIPS, 2011.  12  Y. Abbasi-Yadkori, D. P\u00b4al, and C. Szepesv\u00b4ari. Improved algorithms for linear stochastic  \u22120.500.5\u22120.0500.050.10.150.20.250.3 Shamir  Figure 1: The two solid blue lines represents Fe(w) as in Eq. (5), for e = 0.1 and e = \u22120.1, whereas the two dashed black lines represent two quadratic functions with similar minimum points. Close to the minima, Fe(w) and the quadratic functions behave rather similarly. However, as we increase |w|, the two quadratic functions become rather distinguishable, whereas Fe(w) become more and more indistinguishable for the two choices of e. Thus, distinguishing whether e = 0.1 or e = \u22120.1, based only on function values is of Fe(w), is much harder than the quadratic case  situations where these parameters scale with d. Finally, while this paper settles the case of strongly-convex and smooth functions, we still don\u2019t know what is the attainable per- formance for general convex functions, as well as the more specific case of strongly-convex (cid:16)(cid:112)d2/T (possibly non-smooth) functions. Our \u2126 lower bound still holds, but the ex- (cid:110) 4(cid:112)d2/T , (cid:112)d32/T  isting upper bounds are much larger: min  for convex functions, and  (cid:111)  (cid:17)  (cid:110) 3(cid:112)d2/T , (cid:112)d32/T  (cid:111)  for strongly-convex functions (see table 1). We don\u2019t know if the min lower bound or the existing upper bounds are tight. However, it is the current upper bounds which seem less \u201cnatural\u201d, and we suspect that they are the ones that can be considerably improved, using new algorithms which remain undiscovered.  We thank John Duchi, Satyen Kale, Robi Krauthgamer and the anonymous reviewers for helpful discussions and comments.  Acknowledgments  References  bandits. In NIPS, 2011.Y. Abbasi-Yadkori, D. P\u00b4al, and C. Szepesv\u00b4ari. Improved algorithms for linear stochastic  \u22120.500.5\u22120.0500.050.10.150.20.250.3 Complexity of Bandit and Derivative-Free Stochastic Convex Optimization  A. Agarwal, O. Dekel, and L. Xiao. Optimal algorithms for online convex optimization with  multi-point bandit feedback. In COLT, 2010.  A. Agarwal, D. Foster, D. Hsu, S. Kakade, and A. Rakhlin. Stochastic convex optimization  with bandit feedback. In NIPS, 2011.  E. Arias-Castro, E. Cand`es, and M. Davenport. On the fundamental limits of adaptive  sensing. CoRR, abs/1111.4646, 2011.  J.-Y. Audibert and S. Bubeck. Minimax policies for adversarial and stochastic bandits. In  COLT, 2009.  games. COLT, 2011.  J.-Y. Audibert, S. Bubeck, and G. Lugosi. Minimax policies for combinatorial prediction  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. Schapire. The nonstochastic multiarmed  bandit problem. SIAM J. Comput., 32(1):48-77, 2002.  S. Bubeck and N. Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed  bandit problems. CoRR, abs/1204.5721, 2012.  S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in finitely-armed and continuous-  armed bandits. Theoretical Computer Science, 412(19):1832-1852, 2011.  S. Bubeck, N. Cesa-Bianchi, and S. Kakade. Towards minimax policies for online linear  optimization with bandit feedback. In COLT, 2012.  N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge University  T. Cover and J. Thomas. Elements of information theory. Wiley, 2 edition, 2006.  A.B. Cybakov.  Introduction to nonparametric estimation. Springer series in statistics.  V. Dani, T. Hayes, and S. Kakade. The price of bandit information for online optimization.  V. Dani, T. Hayes, and S. Kakade. Stochastic linear optimization under bandit feedback.  A. Flaxman, A. Kalai, and B. McMahan. Online convex optimization in the bandit setting:  gradient descent without a gradient. In SODA, 2005.  E. Hazan and S. Kale. Beyond the regret minimization barrier: an optimal algorithm for  stochastic strongly-convex optimization. In COLT, 2011.  K. Jamieson, R. Nowak, and B. Recht. Query complexity of derivative-free optimization.  CoRR, abs/1209.2434, 2012.  S. Kullback. Information Theory and Statistics. Dover, 1959.  Press, 2006.  Springer, 2009.  In NIPS, 2007.  In COLT, 2008. Shamir  A. Nemirovsky and D. Yudin. Problem Complexity and Method E\ufb03ciency in Optimization.  Wiley-Interscience, 1983.  ECORE Discussion Paper, 2011.  Y. Nesterov. Random gradient-free minimization of convex functions. Technical Report 16,  A. Rakhlin, O. Shamir, and K. Sridharan. Making gradient descent optimal for strongly  convex stochastic optimization. In ICML, 2012.  S. Stich, C. M\u00a8uller, and B. G\u00a8artner. Optimization of convex functions with random pursuit.  CoRR, abs/1111.0194, 2011.  ICML, 2003.  M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In  "}, "A Theoretical Analysis of NDCG Type Ranking Measures": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "A Theoretical Analysis of NDCG Type Ranking Measures", "abstract": "Ranking has been extensively studied in information retrieval, machine learning and statistics. A central problem in ranking is to design a ranking measure for evaluation of ranking functions. State of the art leaning to rank methods often train a ranking function by using a ranking measure as the objective to maximize. In this paper we study, from a theoretical perspective, the widely used NDCG type ranking measures. We analyze the behavior of these ranking measures as the number of objects to rank getting large. We first show that, whatever the ranking function is, the standard NDCG which adopts a logarithmic discount, converges to 1 as the number of items to rank goes to infinity. On the first sight, this result seems to imply that NDCG cannot distinguish good and bad ranking functions, contradicting to the empirical success of NDCG in many applications. Our next main result is a theorem which shows that although NDCG converge to the same limit for all ranking functions, it has distinguishability for ranking functions in a strong sense. We then investigate NDCG with other possible discount. Specifically we characterize the class of feasible discount functions for NDCG. We also compare the limiting behavior and the power of distinguishability of these feasible NDCG type measures to the standard NDCG. We next turn to the cut-off version of NDCG, i.e., NDCG@k. The most popular NDCG@k uses a combination of a slow logarithmic decay and a hard cut-off as its discount. So a natural question is why not simply use a smooth discount with fast decay? We show that if the decay is too fast, then the NDCG measure does not have strong power of distinguishability and even not converge. Finally, feasible NDCG@k are also discussed.", "pdf_url": "http://proceedings.mlr.press/v30/Wang13.pdf", "keywords": ["Ranking", "Ranking measures", "NDCG", "Consistent Distinguishability"], "reference": "S. Agarwal, T. Graepel, R. Herbrich, S. Har-Peled, and D. Roth. Generalization bounds  for the area under an ROC curve. 2004.  A. Al-Maskari, M. Sanderson, and P. Clough. The relationship between IR e\ufb00ectiveness  measures and user satisfaction. In SIGIR, pages 773-774, 2007.  J.A. Aslam, E. Yilmaz, and V. Pavlu. The maximum entropy method for analyzing retrieval In Proceedings of the 28th annual international ACM SIGIR conference on  measures. Research and development in information retrieval, pages 27-34. ACM, 2005.  R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval, volume 82. Addison-  Wesley New York, 1999.  M.F. Balcan, N. Bansal, A. Beygelzimer, D. Coppersmith, J. Langford, and G.B. Sorkin. Robust reductions from ranking to classification. Machine learning, 72(1):139-153, 2008.  P.L. Bartlett, M.I. Jordan, and J.D. McAuli\ufb00e. Convexity, classification, and risk bounds.  Journal of the American Statistical Association, 101(473):138-156, 2006.  D. Bu\ufb00oni, C. Calauzenes, P. Gallinari, and N. Usunier. Learning scoring functions with order-preserving losses and standardized supervision. In Proceedings of the 28th Interna- tional Conference on Machine Learning, 2011.  C.J.C. Burges, R. Ragno, and Q. V. Le. Learning to rank with nonsmooth cost function- s. In Advances in Neural Information Processing Systems 19: Proceedings of the 2006 Conference, volume 19, page 193. The MIT Press, 2007.  Cl\u00b4ement Calauz`enes, Nicolas Usunier, and Patrick Gallinari. On the (non-)existence of convex, calibrated surrogate losses for ranking. In P. Bartlett, F.C.N. Pereira, C.J.C. Burges, L. Bottou, and K.Q. Weinberger, editors, Advances in Neural Information Pro- cessing Systems 25, pages 197-205. 2012.  Z. Cao, T. Qin, T.Y. Liu, M.F. Tsai, and H. Li. Learning to rank: from pairwise approach  to listwise approach. In ICML, pages 129-136, 2007.  O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded In Proceedings of the 18th ACM conference on Information and knowledge  relevance. management, pages 621-630. ACM, 2009.  St\u00b4ephan J.M. Cl\u00b4emen\u00b8con and Nicolas Vayatis. Empirical performance maximization for linear rank statistics. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Advances in Neural Information Processing Systems 21, pages 305-312. 2009.  28   Wang Wang Li He Chen Liu  Proof The proof is almost the same as the proof of Lemma 23  The theorem follows immediately from Lemma 33 and Lemma 34.  References  S. Agarwal, T. Graepel, R. Herbrich, S. Har-Peled, and D. Roth. Generalization bounds  for the area under an ROC curve. 2004.  A. Al-Maskari, M. Sanderson, and P. Clough. The relationship between IR e\ufb00ectiveness  measures and user satisfaction. In SIGIR, pages 773-774, 2007.  J.A. Aslam, E. Yilmaz, and V. Pavlu. The maximum entropy method for analyzing retrieval In Proceedings of the 28th annual international ACM SIGIR conference on  measures. Research and development in information retrieval, pages 27-34. ACM, 2005.  R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval, volume 82. Addison-  Wesley New York, 1999.  M.F. Balcan, N. Bansal, A. Beygelzimer, D. Coppersmith, J. Langford, and G.B. Sorkin. Robust reductions from ranking to classification. Machine learning, 72(1):139-153, 2008.  P.L. Bartlett, M.I. Jordan, and J.D. McAuli\ufb00e. Convexity, classification, and risk bounds.  Journal of the American Statistical Association, 101(473):138-156, 2006.  D. Bu\ufb00oni, C. Calauzenes, P. Gallinari, and N. Usunier. Learning scoring functions with order-preserving losses and standardized supervision. In Proceedings of the 28th Interna- tional Conference on Machine Learning, 2011.  C.J.C. Burges, R. Ragno, and Q. V. Le. Learning to rank with nonsmooth cost function- s. In Advances in Neural Information Processing Systems 19: Proceedings of the 2006 Conference, volume 19, page 193. The MIT Press, 2007.  Cl\u00b4ement Calauz`enes, Nicolas Usunier, and Patrick Gallinari. On the (non-)existence of convex, calibrated surrogate losses for ranking. In P. Bartlett, F.C.N. Pereira, C.J.C. Burges, L. Bottou, and K.Q. Weinberger, editors, Advances in Neural Information Pro- cessing Systems 25, pages 197-205. 2012.  Z. Cao, T. Qin, T.Y. Liu, M.F. Tsai, and H. Li. Learning to rank: from pairwise approach  to listwise approach. In ICML, pages 129-136, 2007.  O. Chapelle, D. Metlzer, Y. Zhang, and P. Grinspan. Expected reciprocal rank for graded In Proceedings of the 18th ACM conference on Information and knowledge  relevance. management, pages 621-630. ACM, 2009.  St\u00b4ephan J.M. Cl\u00b4emen\u00b8con and Nicolas Vayatis. Empirical performance maximization for linear rank statistics. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Advances in Neural Information Processing Systems 21, pages 305-312. 2009. Short Title  S. Clemen\u00b8con, G. Lugosi, and N. Vayatis. Ranking and empirical minimization of U-  statistics. The Annals of Statistics, 36(2):844-874, 2008.  D. Cossock and T. Zhang. Statistical analysis of bayes optimal subset ranking. Information  Theory, IEEE Transactions on, 54(11):5140-5154, 2008.  K. Crammer and Y. Singer. Pranking with ranking. In Advances in Neural Information  Processing Systems, 2002.  Addison-Wesley, 2010.  W.B. Croft, D. Metzler, and T. Strohman. Search engines: Information retrieval in practice.  J. Duchi, L. Mackey, and M.I. Jordan. On the consistency of ranking algorithms.  In Proceedings of the 27th International Conference on Machine Learning, pages 327-334, 2010.  Y. Freund, R. Iyer, R.E. Schapire, and Y. Singer. An e\ufb03cient boosting algorithm for combining preferences. The Journal of Machine Learning Research, 4:933-969, 2003. ISSN 1532-4435.  J. H\u00b4ajek, Z. \u02c7Sid\u00b4ak, and P.K. Sen. Theory of rank tests. Academic press New York, 1967.  R. Herbrich, T. Graepel, and K. Obermayer. Large margin rank boundaries for ordinal regression. Advances in Neural Information Processing Systems, pages 115-132, 1999.  K. J\u00a8arvelin and J. Kek\u00a8al\u00a8ainen. IR evaluation methods for retrieving highly relevant doc- In Proceedings of the 23rd annual international ACM SIGIR conference on  uments. Research and development in information retrieval, pages 41-48. ACM, 2000.  K. J\u00a8arvelin and J. Kek\u00a8al\u00a8ainen. Cumulated gain-based evaluation of IR techniques. ACM  Transactions on Information Systems (TOIS), 20(4):422-446, 2002.  T. Joachims. Optimizing search engines using clickthrough data.  In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 133-142. ACM, 2002.  Evangelos Kanoulas and Javed A. Aslam. Empirical justification of the gain and discount In Proceedings of the 18th ACM conference on Information and  function for NDCG. knowledge management, pages 611-620. ACM, 2009.  M.G. Kendall. A new measure of rank correlation. Biometrika, 30(1/2):81-93, 1938.  R. Nallapati. Discriminative models for information retrieval. In Proceedings of the 27th an- nual international ACM SIGIR conference on Research and development in information retrieval, pages 64-71. ACM, 2004.  P. Ravikumar, A. Tewari, and E. Yang. On NDCG consistency of listwise ranking methods. In Proceedings of 14th International Conference on Artificial Intelligence and Statistics, AISTATS, 2011. Wang Wang Li He Chen Liu  C. Rudin. The p-norm push: A simple convex ranking algorithm that concentrates at the  top of the list. The Journal of Machine Learning Research, 10:2233-2271, 2009.  T. Sakai. Evaluating evaluation metrics based on the bootstrap. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in informa- tion retrieval, pages 525-532. ACM, 2006.  G. Sansone. Orthogonal Functions. Interscience Publishers Inc., New York, 1959.  A. Tewari and P.L. Bartlett. On the consistency of multiclass classification methods. Journal  of Machine Learning Research, 8:1007-1025, 2007.  A. Turpin and F. Scholer. User performance versus precision measures for simple search tasks. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 11-18. ACM, 2006.  H. Valizadegan, R. Jin, R. Zhang, and J. Mao. Learning to rank by optimizing NDCG  measure. Advances in Neural Information Processing Systems, 22:1883-1891, 2009.  E.M. Voorhees. Evaluation by highly relevant documents. In Proceedings of the 24th an- nual international ACM SIGIR conference on Research and development in information retrieval, pages 74-82. ACM, 2001.  F. Xia, T.Y. Liu, J. Wang, W. Zhang, and H. Li. Listwise approach to learning to rank: theory and algorithm. In Proceedings of the 25th international conference on Machine learning, pages 1192-1199. ACM, 2008.  Y. Yue, T. Finley, F. Radlinski, and T. Joachims. A support vector method for optimizing average precision. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, pages 271-278. ACM, 2007.  T. Zhang. Statistical behavior and consistency of classification methods based on convex  risk minimization. Annals of Statistics, pages 56-85, 2004a.  T. Zhang. Statistical analysis of some multi-category large margin classification methods.  The Journal of Machine Learning Research, 5:1225-1251, 2004b.  K. Zhou, H. Zha, Y. Chang, and G.R. Xue. Learning the gain values and discount factors of discounted cumulative gains. IEEE Transactions on Knowledge and Data Engineering, to appear. "}, "Excess risk bounds for multitask learning with trace norm regularization": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Excess risk bounds for multitask learning with trace norm regularization", "abstract": "Trace norm regularization is a popular method of multitask learning. We give excess risk bounds with explicit dependence on the number of tasks, the number of examples per task and properties of the data distribution. The bounds are independent of the dimension of the input space, which may be infinite as in the case of reproducing kernel Hilbert spaces. A byproduct of the proof are bounds on the expected norm of sums of random positive semidefinite matrices with subexponential moments.", "pdf_url": "http://proceedings.mlr.press/v30/Pontil13.pdf", "keywords": ["Multitask learning", "random matrices", "risk bounds", "trace norm regularization"], "reference": "R. Ahlswede and A. Winter. Strong converse for identification via quantum channels. IEEE  Transactions on Information Theory, 48(3):569-579, 2002.  Y. Amit, M. Fink, N. Srebro, S. Ullman. Uncovering shared structures in multiclass classifi- cation. Proc. 24th International Conference on Machine Learning (ICML), pages 17-24, 2007.  R. K. Ando, T. Zhang. A framework for learning predictive structures from multiple tasks  and unlabeled data. Journal of Machine Learning Research, 6:1817-1853, 2005.  A. Argyriou, T. Evgeniou, M. Pontil. Convex multi-task feature learning. Machine Learning,  F.R. Bach. Consistency of trace norm minimization. Journal of Machine Learning Research,  73(3):243-272, 2008.  9:1019-1048, 2008.  P.L. Bartlett and S. Mendelson. Rademacher and Gaussian Complexities: Risk bounds and  structural results. Journal of Machine Learning Research, 3:463-482, 2002.  J. Baxter. A model of inductive bias learning. Journal of Artificial Intelligence Research,  12:149-198, 2000.  S. Ben-David and R. Schuller. Exploiting task relatedness for multiple task learning. Proc. 16th Annual Conference on Computational Learning Theory (COLT), pages 567-580, 2003.  R. Bhatia. Matrix Analysis. Springer, 1997.  E. Cand`es and T. Tao. The power of convex relaxation: Near optimal matrix completion.  IEEE Transactions on Information Theory, 56(5):2053-2080, 2009.  R. Caruana. Multi-task learning. Machine Learning, 28(1):41-75, 1997.  G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear algorithms for online multitask  classification. Journal of Machine Learning Research, 11:2597-2630, 2010.  T. Evgeniou, C. Micchelli and M. Pontil. Learning multiple tasks with kernel methods.  Journal of Machine Learning Research, 6:615-637, 2005.  M. Fazel, H. Hindi, and S. Boyd. A rank minimization heuristic with application to minimum order system approximation. Proc. American Control Conference, Vol. 6, pages 4734- 4739, 2001.  R. Foygel, R. Salakhutdinov, O. Shamir, and N. Srebro. Learning with the weighted trace- norm under arbitrary sampling distributions. Advances in Neural Information Processing Systems, 24, pages 2133-2141, 2011.  Z. Harchaoui, M. Douze, M. Paulin, M. Dudik, J. Malick. Large-scale image classification with trace-norm regularization. IEEE Conference on Computer Vision & Pattern Recog- nition (CVPR), pages 3386-3393, 2012.  13   Excess risk bounds for multitask learning  References  R. Ahlswede and A. Winter. Strong converse for identification via quantum channels. IEEE  Transactions on Information Theory, 48(3):569-579, 2002.  Y. Amit, M. Fink, N. Srebro, S. Ullman. Uncovering shared structures in multiclass classifi- cation. Proc. 24th International Conference on Machine Learning (ICML), pages 17-24, 2007.  R. K. Ando, T. Zhang. A framework for learning predictive structures from multiple tasks  and unlabeled data. Journal of Machine Learning Research, 6:1817-1853, 2005.  A. Argyriou, T. Evgeniou, M. Pontil. Convex multi-task feature learning. Machine Learning,  F.R. Bach. Consistency of trace norm minimization. Journal of Machine Learning Research,  73(3):243-272, 2008.  9:1019-1048, 2008.  P.L. Bartlett and S. Mendelson. Rademacher and Gaussian Complexities: Risk bounds and  structural results. Journal of Machine Learning Research, 3:463-482, 2002.  J. Baxter. A model of inductive bias learning. Journal of Artificial Intelligence Research,  12:149-198, 2000.  S. Ben-David and R. Schuller. Exploiting task relatedness for multiple task learning. Proc. 16th Annual Conference on Computational Learning Theory (COLT), pages 567-580, 2003.  R. Bhatia. Matrix Analysis. Springer, 1997.  E. Cand`es and T. Tao. The power of convex relaxation: Near optimal matrix completion.  IEEE Transactions on Information Theory, 56(5):2053-2080, 2009.  R. Caruana. Multi-task learning. Machine Learning, 28(1):41-75, 1997.  G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear algorithms for online multitask  classification. Journal of Machine Learning Research, 11:2597-2630, 2010.  T. Evgeniou, C. Micchelli and M. Pontil. Learning multiple tasks with kernel methods.  Journal of Machine Learning Research, 6:615-637, 2005.  M. Fazel, H. Hindi, and S. Boyd. A rank minimization heuristic with application to minimum order system approximation. Proc. American Control Conference, Vol. 6, pages 4734- 4739, 2001.  R. Foygel, R. Salakhutdinov, O. Shamir, and N. Srebro. Learning with the weighted trace- norm under arbitrary sampling distributions. Advances in Neural Information Processing Systems, 24, pages 2133-2141, 2011.  Z. Harchaoui, M. Douze, M. Paulin, M. Dudik, J. Malick. Large-scale image classification with trace-norm regularization. IEEE Conference on Computer Vision & Pattern Recog- nition (CVPR), pages 3386-3393, 2012. Maurer Pontil  W. Hoe\ufb00ding. Probability inequalities for sums of bounded random variables. Journal of  the American Statistical Association, 58:13-30, 1963.  S. M. Kakade, S. Shalev-Shwartz, A. Tewari. Regularization techniques for learning with  matrices. Journal of Machine Learning Research 13:1865-1890, 2012.  V. Koltchinskii and D. Panchenko. Empirical margin distributions and bounding the gen-  eralization error of combined classiers. Annals of Statistics, 30(1):1-50, 2002.  M. Ledoux, M. Talagrand. Probability in Banach Spaces:  Isoperimetry and Processes.  Springer, Berlin, 1991.  K. Lounici, M. Pontil, A.B. Tsybakov and S. van de Geer. Oracle inequalities and optimal  inference under group sparsity. Annals of Statistics, 39(4):2164-2204, 2011.  A. Maurer. Bounds for linear multi-task learning. Journal of Machine Learning Research,  7:117-139, 2006.  A. Maurer. The Rademacher complexity of linear transformation classes. Proc. 19th Annual  Conference on Learning Theory (COLT), pages 65-78, 2006.  A. Maurer and M. Pontil. A uniform lower error bound for half-space learning. Proc. 19th  International Conference on Algorithmic Learning Theory, pages 70-78, 2008.  S. Mendelson and A. Pajor. On singular values of matrices with independent rows. Bernoulli  12(5):761-773, 2006.  R.I. Oliveira. Sums of random Hermitian matrices and an inequality by Rudelson, Electronic  Communications in Probability, 15:203-212, 2010.  B. Recht. A simpler approach to matrix completion. Journal of Machine Learning Research,  12:3413-3430, 2009.  O. Shamir and S. Shalev-Shwartz. Collaborative filtering with the trace norm: Learning, bounding and transducing. Proc. 24th Annual Conference on Learning Theory (COLT), pages 661-678, 2011.  N. Srebro and A. Shraibman. Rank, trace-norm and max-norm. Proc. 18th Annual Confer-  ence on Learning Theory (COLT), pages 545-560, 2005.  S. Thrun and L. Pratt. Learning to Learn. Springer, 1998.  J. Tropp. User-friendly tail bounds for sums of random matrices. Foundations of Computa-  tional Mathematics, 12:389-434, 2012. Excess risk bounds for multitask learning  "}, "Honest Compressions and Their Application to Compression Schemes": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Honest Compressions and Their Application to Compression Schemes", "abstract": "The existence of a compression scheme for every concept class with bounded VC-dimension is one of the oldest open problems in statistical learning theory. Here we demonstrate the existence of such compression schemes under stronger assumptions than finite VC-dimension. Specifically, for each concept class we associate a family of concept classes that we call the alternating concept classes. Under the assumption that these concept classes have bounded VC dimension, we prove existence of a compression scheme. This result is motivated by recent progress in the field of model theory with respect to an analogues problem. In fact, our proof can be considered as a constructive proof of these advancements. This means that we describe the reconstruction function explicitly. Not less important, the theorems and proofs we present are in purely combinatorial terms and are available to the reader who is unfamiliar with model theory. Also, using tools from model theory, we apply our results and prove existence of compression schemes in interesting cases, such as concept classes defined by hyperplanes, polynomials, exponentials, restricted analytic functions and compositions, additions and multiplications of all of the above.", "pdf_url": "http://proceedings.mlr.press/v30/Livni13.pdf", "keywords": ["Compression Conjecture", "Compression Scheme", "NIP Structures"], "reference": "Mathematical Logic, 2008.  The authors would like to thank Amir Globerson for some helpful comments and discussions, and to the first anonymous reviewer for some suggestions and simplifications in the proofs.  H. Adler. An introduction to theories without the independence property. Archive for  N. Alon and D.J. Kleitman. Piercing convex sets and the hadwiger-debrunner (p, q)-  problem. Advances in Mathematics, 96(1):103-112, 1992.  13   Honest Compressions  the trace of the concept class, then one can e\ufb03ciently reconstruct. It would be surpris- ing if such a simple compression scheme would work for every concept class. Indeed, the compactness theorem of first order logic would imply the existence of a uniform formula defining a reconstruction function for all concept classes of given VC-dimension. One could however imagine such a uniform formula with, for example, quantifiers over the domain X. The computation would then involve queries on the whole underlying concept class (X, C). Its computational complexity would then depend on the concept class.  Our results apply to a wide family of concept classes, most notably, geometric concept classes and concept classes definable in the structure (cid:104)R; +, \u00b7, \u2264, exp, 0, 1(cid:105). One important family of concept classes for which we do not know if our theorem applies is the family of maximum concept classes, first studied by Floyd and Warmuth (1995). A concept class (X, C) is called maximum if for every finite set A, the number of concepts on A equals the upper bound attained by Sauer\u2019s lemma. As discussed earlier, such concept classes always have a VC-dim compression scheme (in fact an unlabeled compression scheme).  Rubinstein and Rubinstein (2012) suggest studying compression schemes via operating on geometric representations. They study classes that correspond to Hyperbolic arrange- ments and PL hyperplanes. It is natural to ask what kind of compression schemes arise from general representations in NIP structures. If any maximal concept class can be represented in an NIP structure, this would give a positive solution to the problem of sample compres- sion (without O(d) bound however). On the other hand, a maximal concept class with VC-dim(ALT (X; C)) = \u221e cannot be embedded in an NIP structure without an increase in the VC-dimension.  Finally we wish to discuss further directions toward a complete solution to the problem. Due to our extensive use of Ramsey\u2019s theorem, it would be challenging to use our methods to obtain VC-dim bounds on compression schemes. However the methods presented in this paper might be used for the construction of compression schemes in general, in particular definable compression schemes. Theorem 20 due to Matou\u02c7sek is part of a family of Helly type theorems. An analogue theorem exists, for example, for convex sets whose VC-dimension is unbounded (see, Alon and Kleitman (1992)). Thus, our requirements from ALT (X; C) may be relaxed or altered. Other concept classes derived from the original concept class might also be exploited. Finally, it would be interesting to know if there are necessary conditions to the existence of compression schemes that relate to NIP structures. This might enable the construction of a counter example to the compression conjecture.  Acknowledgments  References  Mathematical Logic, 2008.  The authors would like to thank Amir Globerson for some helpful comments and discussions, and to the first anonymous reviewer for some suggestions and simplifications in the proofs.  H. Adler. An introduction to theories without the independence property. Archive for  N. Alon and D.J. Kleitman. Piercing convex sets and the hadwiger-debrunner (p, q)-  problem. Advances in Mathematics, 96(1):103-112, 1992. Livni Simon  S. Ben-David and A. Litman. Combinatorial variability of vapnik-chervonenkis classes with applications to sample compression schemes. Discrete Applied Mathematics, 86(1):3-25, 1998.  A. Chernikov and P. Simon. Externally definable sets and dependent pairs. Israel Journal  of Mathematics, pages 1-17, 2010.  A. Chernikov and P. Simon. Externally definable sets and dependent pairs ii. arXiv preprint  arXiv:1202.2650, 2012.  S. Floyd. Space-bounded learning and the vapnik-chervonenkis dimension. In Proceedings of the second annual workshop on Computational learning theory, pages 349-364. Morgan Kaufmann Publishers Inc., 1989.  S. Floyd and M. Warmuth. Sample compression, learnability, and the vapnik-chervonenkis  dimension. Machine Learning, 21(3):269-304, 1995.  Y. Freund. Boosting a weak learning algorithm by majority. Information and computation,  121(2):256-285, 1995.  R.L. Graham, B.L. Rothschild, and J.H. Spencer. Ramsey theory, volume 2. Wiley, 1990.  Vincent Guingona. On uniform definability of types over finite sets. Journal of Symbolic  Logic, 77(2):499-514, 2012.  H. R. Johnson and M. C. Laskowski. Compression schemes, stable definable families, and o- minimal structures. Discrete Comput. Geom., 43(4):914-926, 2010. ISSN 0179-5376. doi: 10.1007/s00454-009-9201-3. URL http://dx.doi.org/10.1007/s00454-009-9201-3.  M. Karpinski and A. Macintyre. Polynomial bounds for vc dimension of sigmoidal neural networks. In Proceedings of the twenty-seventh annual ACM symposium on Theory of computing, pages 200-208. ACM, 1995.  D. Kuzmin and M. Warmuth. Unlabeled compression schemes for maximum classes. Learn-  ing Theory, pages 801-814, 2005.  M.C Laskowski. Vapnik-chervonenkis classes of definable sets. J. London Math. Soc, 45:  377-384, 1992.  N. Littlestone and M. Warmuth. Relating data compression and learnability. Technical  report, Technical report, University of California, Santa Cruz, 1986.  A. Macintyre and E.D. Sontag. Finiteness results for sigmoidal \u201cneural\u201d networks.  In Proceedings of the twenty-fifth annual ACM symposium on Theory of computing, pages 325-334. ACM, 1993.  J. Matou\u02c7sek. Bounded vc-dimension implies a fractional helly theorem. Discrete & Com-  putational Geometry, 31(2):251-255, 2004.  B.I.P. Rubinstein and J.H. Rubinstein. A geometric approach to sample compression. The  Journal of Machine Learning Research, 98888:1221-1261, 2012. Honest Compressions  B.I.P. Rubinstein, P.L. Bartlett, and J.H. Rubinstein. Shifting: One-inclusion mistake bounds and sample compression. Journal of Computer and System Sciences, 75(1):37- 59, 2009.  S. Shelah. Stability, the f.c.p., and superstability; model theoretic properties of formulas in  first order theory. Ann. Math. Logic, 3(3):271-362, 1971. ISSN 0168-0072.  P Simon. Lecture notes on nip theories. ArXiv: 1208.3944, 2012.  P. Speissegger. Pfa\ufb03an sets and o-minimality. In Chris Miller, Jean-Philippe Rolin, and Patrick Speissegger, editors, Lecture Notes on O-Minimal Structures and Real Analytic Geometry, volume 62 of Fields Institute Communications, pages 179-218. Springer New York, 2012. ISBN 978-1-4614-4041-3. doi: 10.1007/978-1-4614-4042-0 5. URL http: //dx.doi.org/10.1007/978-1-4614-4042-0_5.  V.N. Vapnik and A.Y. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability & Its Applications, 16(2):264-280, 1971.  "}, "The price of bandit information in multiclass online classification": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "The price of bandit information in multiclass online classification", "abstract": "We consider two scenarios of multiclass online learning of a hypothesis class H\u2286Y^X. In the \\em full information scenario, the learner is exposed to instances together with their labels. In the \\em bandit scenario, the true label is not exposed, but rather an indication whether the learner\u2019s prediction is correct or not. We show that the ratio between the error rates in the two scenarios is at most 8\u22c5|Y|\u22c5\\log(|Y|) in the realizable case, and \\tildeO(\\sqrt|Y|) in the agnostic case. The results are tight up to a logarithmic factor and essentially answer an open question from (Daniely et. al. - Multiclass learnability and the erm principle).We apply these results to the class of \u03b3-margin multiclass linear classifiers in \\mathbbR^d. We show that the bandit error rate of this class is \\tilde\u0398\\left(\\frac|Y|\u03b3^2\\right) in the realizable case and \\tilde\u0398\\left(\\frac1\u03b3\\sqrt|Y|T\\right) in the agnostic case. This resolves an open question from (Kakade et. al. - Efficient bandit algorithms for onlinemulticlass prediction).", "pdf_url": "http://proceedings.mlr.press/v30/Daniely13.pdf", "keywords": ["Bandits", "Online", "Multiclass classification", "Littlestone Dimension", "Learnability", "Large Margin Halfspaces"], "reference": "P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2):235-256, 2002.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R.E. Schapire. The nonstochastic multiarmed  bandit problem. SICOMP: SIAM Journal on Computing, 32(1):48-77, 2003.  S. Ben-David, D. Pal, , and S. Shalev-Shwartz. Agnostic online learning. In COLT, 2009.  V. Dani, T. Hayes, and S.M. Kakade. The price of bandit information for online optimiza-  tion. Advances in Neural Information Processing Systems, 20:345-352, 2008.  11   The price of bandit information in multiclass online classification  4. Conclusion and future work  We have bounded the price of bandit information in the setting of hypothesis class based on-line learning and extended the results of Auer et al. (2003). We applied our results to estimate the bandit error rate of the class of large margin classifiers.  The focus of this paper is information theoretic. That is, we have ignored time com- plexity issues. It is of interest to study the computational price of bandit information - i.e. how the required runtime grows when moving from the full-info to the bandit scenario. It is instructive to consider the PAC setting. Given a learning algorithm, A, for a class H in the PAC full-info setting we can simply construct a bandit learning algorithm as follows - given a sample of unlabled instances, we guess, for each instance, a label from Y , uni- formly at random. Typically, we will be correct on about 1 k of the examples. Thus, we can generate a labeled i.i.d. sample whose size is 1 k -fraction of the original sample, and run the full-info algorithm A on this sample. Using this construction (see Daniely et al. (2011)), it easily follows that in the PAC setting, the price of bandit information, both information theoretic and computational, is O(k). Is this true in the on-line setting as well? We note that this question is open and interesting already for the class of large-margin multiclass linear separators.  There is still some room for improvements of the bounds in Theorems 2 and 3. We H (T ) = O(k \u00b7 L(H))  conjecture that the optimal bounds are that for every class H, B-Errr and B-Erra  H (T ) = O((cid:112)k \u00b7 L(H)T ).  \u221a  k).  Theorem 3 together with Theorem 1 characterize the bandit-agnostic error rate up to a factor of \u02dcO( It is of interest to find a tighter characterization. We note that Theorem 1 shows that the bandit Littlestone dimension characterizes the error rate in the bandit realizable case for deterministic algorithms. It is an open question to show that this dimension quantifies the error rate also in the agnostic case and for randomized algorithms in the realizable case.  Acknowledgements  We thank Nati Linial and Shai Shalev-Shwartz for many comments and suggestions regard- ing this work. Amit Daniely is a recipient of the Google Europe Fellowship in Learning Theory, and this research is supported in part by this Google Fellowship.  References  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2):235-256, 2002.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R.E. Schapire. The nonstochastic multiarmed  bandit problem. SICOMP: SIAM Journal on Computing, 32(1):48-77, 2003.  S. Ben-David, D. Pal, , and S. Shalev-Shwartz. Agnostic online learning. In COLT, 2009.  V. Dani, T. Hayes, and S.M. Kakade. The price of bandit information for online optimiza-  tion. Advances in Neural Information Processing Systems, 20:345-352, 2008. Daniely Halbertal  A. Daniely, S. Sabato, S. Ben-David, and S. Shalev-Shwartz. Multiclass learnability and  the erm principle. In COLT, 2011.  R. O. Duda, P. E. Hart, and D. G. Stork. Pattern Classification. Wiley, 2 edition, 2001.  S.M. Kakade, S. Shalev-Shwartz, and A. Tewari. E\ufb03cient bandit algorithms for online  multiclass prediction. In International Conference on Machine Learning, 2008.  N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold  algorithm. Machine Learning, 2:285-318, 1988.  Nick Littlestone and Manfred Warmuth. The weighted majority algorithm. In FOCS, pages  256-261, October 1989.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Random averages, combinatorial  parameters, and learnability. In NIPS, 2010.  "}, "Estimation of Extreme Values and Associated Level Sets of a Regression Function via Selective Sampling": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Estimation of Extreme Values and Associated Level Sets of a Regression Function via Selective Sampling", "abstract": "We propose a new method for estimating the locations and the value of an absolute maximum (minimum) of a function from the observations contaminated by random noise. Our goal is to solve the problem under minimal regularity and shape constraints. In particular, we do not assume differentiability of a function nor that its maximum is attained at a single point. We provide tight upper and lower bounds for the performance of proposed estimators. Our method is adaptive with respect to the unknown parameters of the problem over a large class of underlying distributions.", "pdf_url": "http://proceedings.mlr.press/v30/Minsker13.pdf", "keywords": ["Regression", "optimization", "level sets", "selective sampling", "active learning", "multiarmed bandits"], "reference": "J.-Y. Audibert and A. B. Tsybakov. Fast learning rates for plug-in classi\ufb01ers. Preprint (shorter version was published in Ann. Statist., 2007, Vol. 35(2)), 2005. Available at: http://imagine.enpc.fr/publications/papers/05preprint_AudTsy.pdf.  P. Auer, R. Ortner, and C. Szepesv\u00b4ari. Improved rates for the stochastic continuum-armed  bandit problem. In Learning Theory, pages 454\u2013468. Springer, 2007.  13   Estimation of Extreme Values and Level Sets  where we used (9) in the last inequality. This gives LM \u2286 \u02c6Ak for all 1 \u2264 k \u2264 J. On the other hand,  x \u2208 \u02c6Ak+1 =\u21d2 \u02c6\u03b7k(x) \u2265 \u02c6Mk \u2212 2\u03b4k =\u21d2 \u03b7(x) \u2265 \u02c6\u03b7k(x) \u2212 |\u03b7(x) \u2212 \u02c6\u03b7k(x)| \u2265  \u2265 M (\u03b7) \u2212 2\u03b4k \u2212 sup x\u2208 \u02c6Ak  |(\u03b7 \u2212 \u02c6\u03b7k)(x)| \u2212 |\u03b7(x) \u2212 \u02c6\u03b7k(x)| \u2265 M (\u03b7) \u2212 4\u03b4k,  (11)  hence on event E  (cid:110)  \u02c6Ak+1 \u2286  x \u2208 [0, 1]d : \u03b7(x) \u2265 M (\u03b7) \u2212 4\u03b4k  (cid:111)  ,  (12)  and (10) follows. It remains to show (9), (10). The main tools are given by Proposition 10 and Theorem 13. The proof of (9) consists of applying these results on each step of the algorithm combined with the union bound; (10) immediately follows from (9), (12) and Assumption 3. Detailed derivation is given in "}, "Bounded regret in stochastic multi-armed bandits": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Bounded regret in stochastic multi-armed bandits", "abstract": "We study the stochastic multi-armed bandit problem when one knows the value \u03bc^(\u22c6) of an optimal arm, as a well as a positive lower bound on the smallest positive gap \u2206. We propose a new randomized policy that attains a regret uniformly bounded over time in this setting. We also prove several lower bounds, which show in particular that bounded regret is not possible if one only knows \u2206, and bounded regret of order 1/\u2206is not possible if one only knows \u03bc^(\u22c6).", "pdf_url": "http://proceedings.mlr.press/v30/Bubeck13.pdf", "keywords": [], "reference": "R. Agrawal, D. Teneketzis, and V. Anantharam. Asymptotically efficient adaptive allocation schemes for controlled i.i.d. processes: finite parameter space. IEEE Trans. Automat. Control, 34(3):258-267, 1989.  J.-Y. Audibert and S. Bubeck. Minimax policies for adversarial and stochastic bandits. In Proceedings of the  22nd Annual Conference on Learning Theory (COLT), 2009.  P. Auer and R. Ortner. UCB revisited: Improved regret bounds for the stochastic multi-armed bandit problem.  Periodica Mathematica Hungarica, 61(1):55-65, 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine  Learning Journal, 47(2-3):235-256, 2002.  S. Bubeck and N. Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit prob-  lems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.  S. R. Kulkarni and G. Lugosi. Finite-time lower bounds for the two-armed bandit problem. IEEE Transactions  on Automatic Control, 45(4):711-714, 2000.  T. L. Lai and H. Robbins. Optimal sequential sampling from two populations. Proc. Natl. Acad. Sci. USA,  81:1284-1286, 1984a.  T. L. Lai and H. Robbins. Asymptotically optimal allocation of treatments in sequential experiments. In T. J. Santner and A. C. Tamhane, editors, Design of Experiments: Ranking and Selection, pages 127-142. 1984b.  T. L. Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Advances in Applied Mathemat-  ics, 6:4-22, 1985.  V. Perchet and P. Rigollet. The multi-armed bandit problem with covariates, October 2011. arXiv:1110.6084.  P. Rigollet and A. Zeevi. Nonparametric bandits with covariates. In Adam Tauman Kalai and Mehryar Mohri, editors, Proceedings of the 23rd Annual Conference on Learning Theory (COLT), pages 54-66, 2010.  11   BOUNDED REGRET IN STOCHASTIC BANDITS  where we use the fact that \u03c4  3/2  2. On the other hand one also has  \u2265  1, which implies C\u03bb \u2264 Rn(\u03bd0)  IE\u03bd0 T2(n)  \u2264  \u2265  Therefore  max  Rn(\u03bd0),  \u2206Rn(\u03bd\u2206)  sup \u2206\u2208(0,1]     min x\u2208[0,n]  ! \u2265  x +  exp(  x/2)  =  log(n/139) .  1 2  (cid:16)  \u221an 16  1 2  \u2212  (cid:17)  Theorem 6 and 8 have important consequences on the exploration-exploitation tradeoff men- tioned in the introduction. Indeed, consider the full information case where at each round, the agent observes the reward of both arms. In this case, it is not hard to see that the policy that indicates to pull the arm with the best average reward has bounded regret of order 1/\u2206. Therefore, the knowledge of \u2206 or \u00b5(\u22c6) alone does not alleviate the price for exploration. However, when both are known, it vanishes (see Theorem 1).  References  R. Agrawal, D. Teneketzis, and V. Anantharam. Asymptotically efficient adaptive allocation schemes for controlled i.i.d. processes: finite parameter space. IEEE Trans. Automat. Control, 34(3):258-267, 1989.  J.-Y. Audibert and S. Bubeck. Minimax policies for adversarial and stochastic bandits. In Proceedings of the  22nd Annual Conference on Learning Theory (COLT), 2009.  P. Auer and R. Ortner. UCB revisited: Improved regret bounds for the stochastic multi-armed bandit problem.  Periodica Mathematica Hungarica, 61(1):55-65, 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine  Learning Journal, 47(2-3):235-256, 2002.  S. Bubeck and N. Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit prob-  lems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.  S. R. Kulkarni and G. Lugosi. Finite-time lower bounds for the two-armed bandit problem. IEEE Transactions  on Automatic Control, 45(4):711-714, 2000.  T. L. Lai and H. Robbins. Optimal sequential sampling from two populations. Proc. Natl. Acad. Sci. USA,  81:1284-1286, 1984a.  T. L. Lai and H. Robbins. Asymptotically optimal allocation of treatments in sequential experiments. In T. J. Santner and A. C. Tamhane, editors, Design of Experiments: Ranking and Selection, pages 127-142. 1984b.  T. L. Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Advances in Applied Mathemat-  ics, 6:4-22, 1985.  V. Perchet and P. Rigollet. The multi-armed bandit problem with covariates, October 2011. arXiv:1110.6084.  P. Rigollet and A. Zeevi. Nonparametric bandits with covariates. In Adam Tauman Kalai and Mehryar Mohri, editors, Proceedings of the 23rd Annual Conference on Learning Theory (COLT), pages 54-66, 2010. BUBECK PERCHET RIGOLLET  H. Robbins. Some aspects of the sequential design of experiments. Bulletin of the American Mathematics  Society, 58:527-535, 1952.  A. Salomon and J.-Y. Audibert. Deviations of stochastic bandit regret. In Proceedings of the 22nd Interna-  tional Conference on Algorithmic Learning Theory (ALT), 2011.  A. B. Tsyabkov. Introduction to Nonparametric Estimation. Springer, 2009. BOUNDED REGRET IN STOCHASTIC BANDITS  "}, "Recovering the Optimal Solution by Dual Random Projection": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Recovering the Optimal Solution by Dual Random Projection", "abstract": "Random projection has been widely used in data classification. It maps high-dimensional data into a low-dimensional subspace in order to reduce the computational cost in solving the related optimization problem. While previous studies are focused on analyzing the classification performance of using random projection, in this work, we consider the recovery problem, i.e., how to accurately recover the optimal solution to the original optimization problem in the high-dimensional space based on the solution learned from the subspace spanned by random projections. We present a simple algorithm, termed Dual Random Projection, that uses the dual solution of the low-dimensional optimization problem to recover the optimal solution to the original problem. Our theoretical analysis shows that with a high probability, the proposed algorithm is able to accurately recover the optimal solution to the original problem, provided that the data matrix is of low rank or can be well approximated by a low rank matrix.", "pdf_url": "http://proceedings.mlr.press/v30/Zhang13a.pdf", "keywords": ["Random projection", "Primal solution", "Dual solution", "Low rank"], "reference": "Dimitris Achlioptas. Database-friendly random projections: Johnson-lindenstrauss with  binary coins. Journal of Computer and System Sciences, 66(4):671 - 687, 2003.  Rosa I. Arriaga and Santosh Vempala. An algorithmic theory of learning: robust concepts and random projection. In Proceedings of the 40th Annual Symposium on Foundations of Computer Science, pages 616-623, 1999.  Maria-Florina Balcan, Avrim Blum, and Santosh Vempala. Kernels as features: On kernels,  margins, and low-dimensional mappings. Machine Learning, 65(1):79-94, 2006.  Ella Bingham and Heikki Mannila. Random projection in dimensionality reduction: appli- cations to image and text data. In Proceedings of the 7th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 245-250, 2001.  Avrim Blum. Random projection, margins, kernels, and feature-selection. In Proceedings of the 2005 international conference on Subspace, Latent Structure and Feature Selection, pages 52-68, 2006.  J.M. Borwein, A.S. Lewis, J. Borwein, and AS Lewis. Convex analysis and nonlinear  optimization: theory and examples. Springer New York, 2006.  Christos Boutsidis, Anastasios Zouzias, and Petros Drineas. Random projections for k- means clustering. In Advances in Neural Information Processing Systems 23, pages 298- 306, 2010.  Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University  Press, 2004.  Vladimir Braverman, Rafail Ostrovsky, and Yuval Rabani. Rademacher chaos, ran- dom eulerian graphs and the sparse johnson-lindenstrauss transform. ArXiv e-prints, arXiv:1011.2590, 2010.  Emmanuel J. Cand`es and Michael B. Wakin. An introduction to compressive sampling.  IEEE Signal Processing Magazine, 25(2):21 -30, 2008.  Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  Sanjoy Dasgupta and Yoav Freund. Random projection trees and low dimensional manifolds. In Proceedings of the 40th annual ACM symposium on Theory of computing, pages 537- 546, 2008.  David L. Donoho. Compressed sensing.  IEEE Transaction on Information Theory, 52:  1289-1306, 2006.  Xiaoli Zhang Fern and Carla E. Brodley. Random projection for high dimensional data clus- tering: a cluster ensemble approach. In Proceedings of the 20th International Conference on Machine Learning, pages 186-193, 2003.  14   Zhang Mahdavi Jin Yang Zhu  References  Dimitris Achlioptas. Database-friendly random projections: Johnson-lindenstrauss with  binary coins. Journal of Computer and System Sciences, 66(4):671 - 687, 2003.  Rosa I. Arriaga and Santosh Vempala. An algorithmic theory of learning: robust concepts and random projection. In Proceedings of the 40th Annual Symposium on Foundations of Computer Science, pages 616-623, 1999.  Maria-Florina Balcan, Avrim Blum, and Santosh Vempala. Kernels as features: On kernels,  margins, and low-dimensional mappings. Machine Learning, 65(1):79-94, 2006.  Ella Bingham and Heikki Mannila. Random projection in dimensionality reduction: appli- cations to image and text data. In Proceedings of the 7th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 245-250, 2001.  Avrim Blum. Random projection, margins, kernels, and feature-selection. In Proceedings of the 2005 international conference on Subspace, Latent Structure and Feature Selection, pages 52-68, 2006.  J.M. Borwein, A.S. Lewis, J. Borwein, and AS Lewis. Convex analysis and nonlinear  optimization: theory and examples. Springer New York, 2006.  Christos Boutsidis, Anastasios Zouzias, and Petros Drineas. Random projections for k- means clustering. In Advances in Neural Information Processing Systems 23, pages 298- 306, 2010.  Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University  Press, 2004.  Vladimir Braverman, Rafail Ostrovsky, and Yuval Rabani. Rademacher chaos, ran- dom eulerian graphs and the sparse johnson-lindenstrauss transform. ArXiv e-prints, arXiv:1011.2590, 2010.  Emmanuel J. Cand`es and Michael B. Wakin. An introduction to compressive sampling.  IEEE Signal Processing Magazine, 25(2):21 -30, 2008.  Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  Sanjoy Dasgupta and Yoav Freund. Random projection trees and low dimensional manifolds. In Proceedings of the 40th annual ACM symposium on Theory of computing, pages 537- 546, 2008.  David L. Donoho. Compressed sensing.  IEEE Transaction on Information Theory, 52:  1289-1306, 2006.  Xiaoli Zhang Fern and Carla E. Brodley. Random projection for high dimensional data clus- tering: a cluster ensemble approach. In Proceedings of the 20th International Conference on Machine Learning, pages 186-193, 2003. Dual Random Projection  Dmitriy Fradkin and David Madigan. Experiments with random projections for machine learning. In Proceedings of the 9th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 517-522, 2003.  Yoav Freund, Sanjoy Dasgupta, Mayank Kabra, and Nakul Verma. Learning the structure of manifolds using random projections. In Advances in Neural Information Processing Systems 20, pages 473-480, 2008.  Alex Gittens and Joel A. Tropp. Tail bounds for all eigenvalues of a sum of random matrices.  ArXiv e-prints, arXiv:1104.4513, 2011.  Navin Goel, George Bebis, and Ara Nefian. Face recognition experiments with random  projection. In Proceedings of SPIE, pages 426-437, 2005.  Gene H. Golub and Charles F. Van Loan. Matrix computations, 3rd Edition. Johns Hopkins  University Press, 1996.  Xin Guo and Ding-Xuan Zhou. An empirical feature-based learning algorithm producing sparse approximations. Applied and Computational Harmonic Analysis, 32(3):389-400, 2012.  Isabelle Guyon and Andr\u00b4e Elissee\ufb00. An introduction to variable and feature selection.  Journal of Machine Learning Research, 3:1157-1182, 2003.  N. Halko, P. G. Martinsson, and J. A. Tropp. Finding structure with randomness: Prob- abilistic algorithms for constructing approximate matrix decompositions. SIAM Review, 53(2):217-288, 2011.  Per Christian Hansen. Rank-deficient and discrete ill-posed problems: numerical aspects of linear inversion. Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 1998.  Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learn-  ing. Springer Series in Statistics. Springer New York, 2009.  Elad Hazan and Satyen Kale. Beyond the regret minimization barrier: an optimal algorithm for stochastic strongly-convex optimization. In Proceedings of the 24th Annual Conference on Learning Theory (COLT), pages 421-436, 2011.  Elad Hazan, Tomer Koren, and Nati Srebro. Beating sgd: Learning svms in sublinear time.  In Advances in Neural Information Processing Systems 24, pages 1233-1241, 2011.  Ming Ji, Tianbao Yang, Binbin Lin, Rong Jin, and Jiawei Han. A simple algorithm for semi-supervised learning with improved generalization error bound. In Proceedings of the 29th International Conference on Machine Learning (ICML-12), pages 1223-1230, 2012.  Samuel Kaski. Dimensionality reduction by random mapping: fast similarity computation for clustering. In Proceedings of the 1998 IEEE International Joint Conference on Neural Networks, volume 1, pages 413-418, 1998. Zhang Mahdavi Jin Yang Zhu  Edo Liberty, Nir Ailon, and Amit Singer. Dense fast random projections and lean walsh transforms. In In Proceedings of the 12th International Workshop on Randomization and Computation (RANDOM), pages 512-522, 2008.  Oldalric-Ambrym Maillard and Remi Munos. Linear regression with random projections.  Journal of Machine Learning Research, 13:2735-2772, 2012.  Rajeev Mowani and Prabhakar Raghavan. Randomized Algorithms. Cambridge University  Press, 1995.  103(1):127-152, 2005.  Yu. Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming,  Saurabh Paul, Christos Boutsidis, Malik Magdon-Ismail, and Petros Drineas. Random  projections for support vector machines. ArXiv e-prints, arXiv:1211.6085, 2012.  Ali Rahimi and Benjamin Recht. Random features for large-scale kernel machines. Advances in Neural Information Processing Systems 20, pages 1177-1184, 2008.  In  Shai Shalev-Shwartz and Yoram Singer. Online learning meets optimization in the dual. In Proceedings of 19th Annual Conference on Learning Theory (COLT), pages 423-437, 2006.  Qinfeng Shi, Chunhua Shen, Rhys Hill, and Anton van den Hengel. Is margin preserved after random projection? In Proceedings of the 29th International Conference on Machine Learning, 2012.  Santosh S. Vempala. The Random Projection Method. American Mathematical Society,  2004.  arXiv:1212.5860, 2012.  Shenghuo Zhu. A short note on the tail bound of wishart distribution. ArXiv e-prints,  "}, "Opportunistic Strategies for Generalized No-Regret Problems": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Opportunistic Strategies for Generalized No-Regret Problems", "abstract": "No-regret algorithms has played a key role in on-line learning and prediction problems. In this paper, we focus on a generalized no-regret problem with vector-valued rewards, defined in terms of a desired reward set of the agent. For each mixed action q of the opponent, the agent has a set R(q) where the average reward should reside. In addition, the agent has a response mixed action p which brings the expected reward under these two actions, r(p, q), to R(q). If a strategy of the agent ensures that the average reward converges to R(\\barq_n), where \\barq_n is the empirical distribution of the opponent\u2019s actions, for any strategy of the opponent, we say that it is a no-regret strategy with respect to R(q). The standard no-regret problem is obtained as a special case for scalar rewards and R(q) = r \u2208R: r \u2265r(q), where r(q) = \\max_p r(p, q). For this problem, the multifunction R(q) is convex, and no-regret strategies can be devised. Our main interest in this paper is in cases where this convexity property does not hold. The best that can be guaranteed in general then is the convergence of the average reward to R^c(\\barq_n), the convex hull of R(\\barq_n). However, as the game unfolds, it may turn out that the opponent\u2019s choices of actions are limited in some way. If  these restrictions were known in advance, the agent could possibly ensure convergence of the average reward to some desired subset of R^c(\\barq_n), or even approach R(\\barq_n) itself. We formulate appropriate goals for opportunistic no-regret strategies, in the sense that they may exploit such limitations on the opponent\u2019s action sequence in an on-line manner, without knowing them beforehand. As the main technical tool, we propose a class of approachability algorithms that rely on a calibrated forecast of the opponent\u2019s actions, which are opportunistic in the above mentioned sense. As an application, we consider the online no-regret problem with average cost constraints, introduced in Mannor, Tsitsiklis, and Yu (2009), where the best-response-in-hindsight is not generally attainable, but only its convex relaxation. Our proposed algorithm applied to this problem does attain the best-response-in-hindsight if the opponent\u2019s play happens to be stationary (either in terms of its mixed actions, or the empirical frequencies of its pure actions).", "pdf_url": "http://proceedings.mlr.press/v30/Bernstein13.pdf", "keywords": ["No-regret algorithms", "Blackwell\u2019s approachability", "Calibrated play"], "reference": "J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learning are equivalent. In Proceedings of the 24th Annual Conference on Learning Theory (COLT \u201911), 2011.  A. Bernstein, S. Mannor, and N. Shimkin. Online classification with specificity constraints.  In NIPS, 2010.  A. Bernstein, S. Mannor, and N. Shimkin.  ized no-regret problems: Full version. Technical report, Technion, http://tx.technion.ac.il/\u02dcandreyb/OppNoRegretColt13Full.pdf.  Opportunistic strategies for general- Israel, 2013.  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of  Mathematicians, volume III, pages 335-338, 1954.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6:1-8, 1956.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, New York, NY, USA, 2006.  A. P. Dawid. The impossibility of inductive inference. Journal of the American Statistical  Association, 80:340-341, 1985.  E. Even-Dar, R. Kleinberg, S. Mannor, and Y. Mansour. Online learning with global cost  functions. 2009.  D. P. Foster and R. V. Vohra. Calibrated learning and correlated equilibrium. Games and  Economic Behavior, 21:40-55, 1997.  D. P. Foster, A. Rakhlin, K. Sridharan, approach to calibration with checking  and A. Tewari.  rules.  In Proceedings of  Complexity-based the 24th  13   Opportunistic No-Regret  solving a zero-sum game in every stage. Specifically, it is sometimes di\ufb03cult to compute the projection to the convex hull of a non-convex set; a step which our approach avoids.  We have applied our opportunistic framework to the problem of constrained regret min- imization, and shown that the best-reward-in-hindsight (rather than its convex relaxation) is attained when the opponent turns out to be stationary in our sense.  It should be of interest to devise alternative algorithms that are computationally e\ufb03cient and have optimal convergence rates. Specifically, we are currently considering a new class of algorithms that is based on online convex optimization methods.  This research was partially supported by the Israel Science Foundation under grant no. 920/12 and by the European Research Counsel under the European Union\u2019s Seventh Framework Program (FP7/2007-2013) / ERC Grant Agreement no. 306638.  Acknowledgments  References  J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learning are equivalent. In Proceedings of the 24th Annual Conference on Learning Theory (COLT \u201911), 2011.  A. Bernstein, S. Mannor, and N. Shimkin. Online classification with specificity constraints.  In NIPS, 2010.  A. Bernstein, S. Mannor, and N. Shimkin.  ized no-regret problems: Full version. Technical report, Technion, http://tx.technion.ac.il/\u02dcandreyb/OppNoRegretColt13Full.pdf.  Opportunistic strategies for general- Israel, 2013.  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of  Mathematicians, volume III, pages 335-338, 1954.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6:1-8, 1956.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, New York, NY, USA, 2006.  A. P. Dawid. The impossibility of inductive inference. Journal of the American Statistical  Association, 80:340-341, 1985.  E. Even-Dar, R. Kleinberg, S. Mannor, and Y. Mansour. Online learning with global cost  functions. 2009.  D. P. Foster and R. V. Vohra. Calibrated learning and correlated equilibrium. Games and  Economic Behavior, 21:40-55, 1997.  D. P. Foster, A. Rakhlin, K. Sridharan, approach to calibration with checking  and A. Tewari.  rules.  In Proceedings of  Complexity-based the 24th Bernstein Mannor Shimkin  Annual Conference on Learning Theory http://jmlr.csail.mit.edu/proceedings/papers/v19/foster11a/foster11a.pdf.  (COLT \u201911),  pages 293-314,  2011.  J. Hannan. Approximation to Bayes risk in repeated play. Contributions to the Theory of  Games, 3:97-139, 1957.  Theory, 98:26-54, 2001.  S. Hart and A. Mas-Colell. A general class of adaptive strategies. Journal of Economic  E. Hazan and S. Kakade.  (weak) Calibration is computationally hard.  CoRR,  abs/1202.4478, 2012. http://arxiv.org/abs/1202.4478.  E. Lehrer. Approachability in infinite dimensional spaces. International Journal of Game  Theory, 31:253-268, 2002.  S. Mannor and N. Shimkin. The empirical Bayes envelope and regret minimization in competitive Markov decision processes. Mathematics of Operations Research, 28(2):327- 345, 2003.  S. Mannor and N. Shimkin. Regret minimization in repeated matrix games with variable  stage duration. Games and Economic Behavior, 63(1):227-258, 2008.  S. Mannor, J. S. Shamma, and G. Arslan. Online calibrated forecasts: Memory e\ufb03ciency  versus universality for learning in games. Machine Learning, 67:77-115, 2007.  S. Mannor, J. N. Tsitsiklis, and J. Y. Yu. Online learning with sample path constraints.  Journal of Machine Learning Research, 10:569-590, 2009.  E. Milman. Approachable sets of vector payo\ufb00s in stochastic games. Games and Economic  Behavior, 56(1):135-147, July 2006.  V. Perchet. Calibration and internal no-regret with partial monitoring. In Proceedings of the 20th International Conference on Algorithmic Learning Theory (ALT \u201909), 2009.  N. Shimkin and A. Shwartz. Guaranteed performance regions in Markovian systems with competing decision makers. IEEE Transactions on Automatic Control, 38(1):84-95, 1993.  A. N. Shiryaev. Probability. Springer, 1995.  X. Spinat. A necessary and su\ufb03cient condition for approachability. Mathematics of Oper-  ations Research, 27(1):31-44, 2002. "}, "Online Learning for Time Series Prediction": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Online Learning for Time Series Prediction", "abstract": "In this paper, we address the problem of predicting a time series using the ARMA (autoregressive moving average) model, under minimal assumptions on the noise terms. Using regret minimization techniques, we develop effective online learning algorithms for the prediction problem, \\emphwithout assuming that the noise terms are Gaussian, identically distributed or even independent. Furthermore, we show that our algorithm\u2019s performances asymptotically approaches the performance of the best ARMA model in hindsight.", "pdf_url": "http://proceedings.mlr.press/v30/Anava13.pdf", "keywords": ["Time series analysis", "online learning", "regret minimization"], "reference": "Oren Anava, Elad Hazan, Shie Mannor, and Ohad Shamir. Online learning for time series  prediction. CoRR, abs/1302.6927, 2013.  G. Box, G. Jenkins, and G. Reinsel. Time Series Analysis: Forecasting and Control.  Prentice-Hall, 3 edition, 1994.  P. Brockwell and R. Davis. Time Series: Theory and Methods. Springer, 2 edition, 2009.  N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge University  Press, 2006.  E. Damsleth and A. H. El-Shaarawi. ARMA models with double-exponentially distributed  noise. Journal of the Royal Statistical Society. Series B, 51(1):61-69, 1989.  F. Ding, Y. Shi, and T. Chen. Performance analysis of estimation algorithms of nonsta- IEEE Transactions on Signal Processing, 33(3):1041-1053,  tionary ARMA processes. 2006.  R.F. Engle. Autoregressive conditional heteroscedasticity with estimates of the variance of  united kingdom in\ufb02ation. Econometrica, 50:987-1007, 1982.  J. Hamilton. Time Series Analysis. Princeton Univ. Press, 1994.  E. Hazan and C. Seshadhri. E\ufb03cient learning algorithms for changing environments. In  ICML, page 50, 2009.  E. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex opti-  mization. Machine Learning, 69(2-3):169-192, 2007.  R. Shumway and D. Sto\ufb00er. Time Series Analysis and Its Applications. Springer, 2005.  D. Thomson. Jackknifing multiple-window spectra. In ICASSP, volume 6, pages VI/73 -  VI/76, April 1994.  M. Tiku, W. K. Wong, D. Vaughan, and G. Bian. Time series models in non-normal situations: Symmetric innovations. Journal of Time Series Analysis, 21(5):571-596, 2000.  M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In  ICML, pages 928-936, 2003.  13   Online Learning for Time Series Prediction  References  Oren Anava, Elad Hazan, Shie Mannor, and Ohad Shamir. Online learning for time series  prediction. CoRR, abs/1302.6927, 2013.  G. Box, G. Jenkins, and G. Reinsel. Time Series Analysis: Forecasting and Control.  Prentice-Hall, 3 edition, 1994.  P. Brockwell and R. Davis. Time Series: Theory and Methods. Springer, 2 edition, 2009.  N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge University  Press, 2006.  E. Damsleth and A. H. El-Shaarawi. ARMA models with double-exponentially distributed  noise. Journal of the Royal Statistical Society. Series B, 51(1):61-69, 1989.  F. Ding, Y. Shi, and T. Chen. Performance analysis of estimation algorithms of nonsta- IEEE Transactions on Signal Processing, 33(3):1041-1053,  tionary ARMA processes. 2006.  R.F. Engle. Autoregressive conditional heteroscedasticity with estimates of the variance of  united kingdom in\ufb02ation. Econometrica, 50:987-1007, 1982.  J. Hamilton. Time Series Analysis. Princeton Univ. Press, 1994.  E. Hazan and C. Seshadhri. E\ufb03cient learning algorithms for changing environments. In  ICML, page 50, 2009.  E. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex opti-  mization. Machine Learning, 69(2-3):169-192, 2007.  R. Shumway and D. Sto\ufb00er. Time Series Analysis and Its Applications. Springer, 2005.  D. Thomson. Jackknifing multiple-window spectra. In ICASSP, volume 6, pages VI/73 -  VI/76, April 1994.  M. Tiku, W. K. Wong, D. Vaughan, and G. Bian. Time series models in non-normal situations: Symmetric innovations. Journal of Time Series Analysis, 21(5):571-596, 2000.  M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In  ICML, pages 928-936, 2003. "}, "Sharp analysis of low-rank  kernel matrix approximations": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Sharp analysis of low-rank  kernel matrix approximations", "abstract": "We consider supervised learning problems within the positive-definite kernel framework, such as kernel ridge regression, kernel logistic regression or the support vector machine. With  kernels leading to infinite-dimensional feature spaces, a common practical limiting difficulty is the necessity of computing the kernel matrix, which most frequently leads to algorithms with running time at least quadratic in the number of observations n, i.e., O(n^2). Low-rank approximations of the kernel matrix are often considered as they allow the reduction of  running time complexities  to O(p^2 n), where\u00a0p is the rank of the approximation. The practicality of such methods thus depends on the required rank p. In this paper, we show that for approximations based on a random subset of columns of the original kernel matrix, the rank p may be chosen to be linear in the \\emphdegrees of freedom associated with the problem, a quantity which is classically used in the statistical analysis of such methods, and is often seen as the implicit number of parameters of non-parametric estimators. This result enables simple algorithms that have sub-quadratic running time complexity, but provably exhibit the same \\emphpredictive performance than existing algorithms, for any given problem instance, and not only for worst-case situations.", "pdf_url": "http://proceedings.mlr.press/v30/Bach13.pdf", "keywords": [], "reference": "NIPS, 2009.  414, 2010.  2005.  S. Arlot and F. Bach. Data-driven calibration of linear estimators with minimal penalties. In Adv.  F. Bach. Self-concordant analysis for logistic regression. Electronic Journal of Statistics, 4:384-  F. Bach and M. I. Jordan. Predictive low-rank decomposition for kernel methods. In Proc. ICML,  G. Blanchard, P. Massart, R. Vert, and L. Zwald. Kernel projection machine: a new tool for pattern  recognition. In Adv. NIPS, 2004.  G. Blanchard, O. Bousquet, and P. Massart. Statistical performance of support vector machines.  The Annals of Statistics, 36(2):489-531, 2008.  A. Bordes, S. Ertekin, J. Weston, and L. Bottou. Fast kernel classifiers with online and active  learning. Journal of Machine Learning Research, 6:1579-1619, 2005.  C. Boutsidis, M. W. Mahoney, and P. Drineas. An improved approximation algorithm for the column  subset selection problem. In Proc. SODA, 2009.  A. Caponnetto and E. De Vito. Optimal rates for the regularized least-squares algorithm. Found.  Comput. Math., 7(3):331-368, 2007.  O. Chapelle. Training a support vector machine in the primal. Neural Computation, 19(5):1155-  1178, 2007.  BACH  22   Functions. Let f (x) = consider zi = f (xi) = f ((i P \u2212 the same reasoning as above):  \u221ei=1 2\u03bd1/2 cos 2i\u03c0x, for \u03bdi a non-negative summable sequence. We 1)/n). The component of z on the i-th eigenvector of K is (following  i  n  Xj=1  1 \u221an  e\u2212  2\u03c9i(j  1)\u03c0/nf ((j  \u2212  1)/n)  = \u221an  \u03bd1/2 i +  (cid:18)  \u221e  Xh=1  \u03bd1/2 i+hn +  \u03bd1/2 \u2212  i+hn(cid:19)  ,  \u2212  \u221e  Xh=1  and the asymptotic equivalent is (n\u03bdi)1/2.  2\u03b2 to certain Link with Sobolev spaces. The kernel k(x, y) defined above corresponds for \u00b5i = i\u2212 Sobolev spaces (Wahba, 1990; Gu, 2002). Indeed, for \u03b2 integer, the associated RKHS is the Sobolev space of periodic functions which are \u03b2-times differentiable.  Moreover, when \u03bdi = i\u2212  1/2)-times differentiable, and the minimax rate of estimation is known to be exactly O(n1/2\u03b40 ) (Speckman, 1985; Johnstone, 1994). Thus, up to logarithmic terms, the best possible rate is O(n1/2\u03b4), and is achieved if \u03b2 is large enough (Section 4.3).  2\u03b4, then for \u03b4 > \u03b40, then the corresponding function is (\u03b40 \u2212  References  NIPS, 2009.  414, 2010.  2005.  S. Arlot and F. Bach. Data-driven calibration of linear estimators with minimal penalties. In Adv.  F. Bach. Self-concordant analysis for logistic regression. Electronic Journal of Statistics, 4:384-  F. Bach and M. I. Jordan. Predictive low-rank decomposition for kernel methods. In Proc. ICML,  G. Blanchard, P. Massart, R. Vert, and L. Zwald. Kernel projection machine: a new tool for pattern  recognition. In Adv. NIPS, 2004.  G. Blanchard, O. Bousquet, and P. Massart. Statistical performance of support vector machines.  The Annals of Statistics, 36(2):489-531, 2008.  A. Bordes, S. Ertekin, J. Weston, and L. Bottou. Fast kernel classifiers with online and active  learning. Journal of Machine Learning Research, 6:1579-1619, 2005.  C. Boutsidis, M. W. Mahoney, and P. Drineas. An improved approximation algorithm for the column  subset selection problem. In Proc. SODA, 2009.  A. Caponnetto and E. De Vito. Optimal rates for the regularized least-squares algorithm. Found.  Comput. Math., 7(3):331-368, 2007.  O. Chapelle. Training a support vector machine in the primal. Neural Computation, 19(5):1155-  1178, 2007.  BACH SHARP ANALYSIS OF LOW-RANK KERNEL MATRIX APPROXIMATIONS  C. Cortes, M. Mohri, and A. Talwalkar. On the impact of kernel approximation on learning accuracy.  In Proc. AISTATS, 2010.  budget. In Adv. NIPS, 2005.  O. Dekel, S. Shalev-Shwartz, and Y. Singer. The Forgetron: A kernel-based perceptron on a fixed  P. S. Dhillon, D. P. Foster, S. M. Kakade, and L. H. Ungar. A risk comparison of ordinary least  squares vs. ridge regression. Technical Report 1105.0875, ArXiv, 2011.  P. Drineas, M. Magdon-Ismail, M. W. Mahoney, and D. P. Woodruff. Fast approximation of matrix coherence and statistical leverage. Journal of Machine Learning Research, 13:3475-3506, 2012.  S. Fine and K. Scheinberg. Efficient SVM training using low-rank kernel representations. Journal  of Machine Learning Research, 2:243-264, 2001.  A. Gittens. The spectral norm error of the naive Nystr\u00a8om extension. Arxiv preprint arXiv:1110.5305,  2011.  R. M. Gray. Toeplitz and circulant matrices: A review. Foundations and Trends in Communications  and Information Theory, 2(3):155-239, 2006.  C. Gu. Smoothing spline ANOVA models. Springer, 2002.  Z. Harchaoui, F. Bach, and E. Moulines. Testing for homogeneity with kernel Fisher discriminant  analysis. Technical Report 00270806 v1, HAL, 2008.  T. J. Hastie and R. J. Tibshirani. Generalized Additive Models. Chapman & Hall, 1990.  W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the  American Statistical Association, 58(301):13-30, 1963.  D. Hsu, S. M. Kakade, and T. Zhang. An analysis of random design linear regression. In Proc.  COLT, 2011.  D. Hsu, S. M. Kakade, and T. Zhang. Tail inequalities for sums of random matrices that depend on  the intrinsic dimension. Electronic Communications in Probability, 17(14):1-13, 2012.  R. Jin, T. Yang, M. Mahdavi, Y.-F. Li, and Z.-H. Zhou. Improved bound for the Nystr\u00a8om\u2019s method  and its application to kernel classification. Technical Report 1111.2262v2, arXiv, 2001.  T. Joachims, T. Finley, and C.-N. Yu. Cutting-plane training of structural SVMs. Machine Learning,  77(1):27-59, 2009.  I. M. Johnstone. Minimax Bayes, asymptotic minimax and sparse wavelet priors. Statistical Deci-  sion Theory and Related Topics, pages 303-326, 1994.  S. S. Keerthi, O. Chapelle, and D. DeCoste. Building support vector machines with reduced classi-  fier complexity. Journal of Machine Learning Research, 7:1493-1515, 2006.  S. Kumar, M. Mohri, and A. Talwalkar. Sampling methods for the Nystr\u00a8om method. Journal of  Machine Learning Research, 13:981-1006, 2012. BACH  N. D. Lawrence, M. Seeger, and R. Herbrich. Fast sparse Gaussian process methods: The informa-  tive vector machine. In Adv. NIPS, 2002.  M. W. Mahoney. Randomized algorithms for matrices and data. Foundations and Trends in Machine  Learning, 3(2):123-224, 2011.  M. W. Mahoney and P. Drineas. CUR matrix decompositions for improved data analysis. Proceed-  ings of the National Academy of Sciences, 106(3):697-702, 2009.  O. A. Maillard and R. Munos. Compressed least-squares regression. In Adv. NIPS, 2009.  F. Orabona, J. Keshet, and B. Caputo. The Projectron: a bounded kernel-based perceptron. In Proc.  ICML, 2008.  J. C. Platt. Fast training of support vector machines using sequential minimal optimization.  In  Advances in kernel methods, pages 185-208. MIT Press, 1999.  A. Rahimi and B. Recht. Random features for large-scale kernel machines. Adv. NIPS, 2007.  C. Rasmussen and C. Williams. Gaussian Processes for Machine Learning. MIT Press, 2006.  R. M. Rifkin and R. A. Lippert. Value regularization and Fenchel duality. Journal of Machine  Learning Research, 8:441-479, 2007.  S. Sabato, N. Srebro, and N. Tishby. Tight sample complexity of large-margin learning. In Adv.  NIPS, 2010.  B. Sch\u00a8olkopf and A. J. Smola. Learning with Kernels. MIT Press, 2002.  B. Sch\u00a8olkopf, K. Tsuda, and J.P. Vert. Kernel methods in computational biology. MIT press, 2004.  S. Shalev-Shwartz, Y. Singer, and N. Srebro. Pegasos: Primal estimated sub-gradient solver for  SVM. In Proc. ICML, 2007.  J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. Camb. U. P., 2004.  A. J. Smola and B. Sch\u00a8olkopf. Sparse greedy matrix approximation for machine learning. In Proc.  ICML, 2000.  P. Speckman. Spline smoothing and optimal rates of convergence in nonparametric regression mod-  els. The Annals of Statistics, 13(3):970-983, 1985.  I. Steinwart, D. Hush, C. Scovel, et al. Optimal rates for regularized least squares regression. In  Proc. COLT, 2009.  A. Talwalkar and A. Rostamizadeh. Matrix coherence and the nystr\u00a8om method. In Proc. UAI, 2010.  P. Tarr`es and Y. Yao. Online learning as stochastic approximation of regularization paths. Technical  Report 1103.5538, arXiv, 2011.  Data Anal., 13(1-2):115-126, 2011.  J. A. Tropp. Improved analysis of the subsampled randomized Hadamard transform. Adv. Adapt. SHARP ANALYSIS OF LOW-RANK KERNEL MATRIX APPROXIMATIONS  J. A. Tropp. User-friendly tail bounds for sums of random matrices. Foundations of Computational  Mathematics, 12(4):389-434, 2012.  G. Wahba. Spline Models for Observational Data. SIAM, 1990.  Z. Wang, K. Crammer, and S. Vucetic. Breaking the curse of kernelization: Budgeted stochastic gradient descent for large-scale SVM training. Journal of Machine Learning Research, 13:3103- 3131, 2012.  C. Williams and M. Seeger. Using the Nystr\u00a8om method to speed up kernel machines. In Adv. NIPS,  2001.  T. Yang, Y.-F. Li, M. Mahdavi, R. Jin, and Z.-H. Zhou. Nystr\u00a8om method vs. random fourier features:  A theoretical and empirical comparison. In Adv. NIPS, 2012.  J. Zhang, M. Marsza\u0142ek, S. Lazebnik, and C. Schmid. Local features and kernels for classification of texture and object categories: A comprehensive study. International Journal of Computer Vision, 73(2):213-238, 2007. "}, "Beating Bandits in Gradually Evolving Worlds": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Beating Bandits in Gradually Evolving Worlds", "abstract": "Consider the online convex optimization problem, in which a player has to choose actions iteratively and suffers corresponding losses according to some convex loss functions, and the goal is to minimize the regret. In the full-information setting, the player after choosing her action can observe the whole loss function in that round, while in the bandit setting, the only information the player can observe is the loss value of that action. Designing such bandit algorithms appears challenging, as the best regret currently achieved for general convex loss functions is much higher than that in the full-information setting, while for strongly convex loss functions, there is even a regret lower bound which is exponentially higher than that achieved in the full-information setting. To aim for smaller regrets, we adopt a relaxed two-point bandit setting in which the player can play two actions in each round and observe the loss values of those two actions. Moreover, we consider loss functions parameterized by their deviation D, which measures how fast they evolve, and we study how regrets depend on D. We show that two-point bandit algorithms can in fact achieve regrets matching those in the full-information setting in terms of D. More precisely, for convex loss functions, we achieve a regret of O(\\sqrtD), while for strongly convex loss functions, we achieve a regret of O(\\ln D), which is much smaller than the \u03a9(\\sqrtD) lower bound in the traditional bandit setting.", "pdf_url": "http://proceedings.mlr.press/v30/Chiang13.pdf", "keywords": ["Online Convex Optimization", "Regret", "Deviation", "Multi-Point Bandit"], "reference": "In COLT, 2009.  Jacob Abernethy and Alexander Rakhlin. Beating the adaptive bandit with high probability.  Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An e\ufb03cient  algorithm for bandit linear optimization. In COLT, pages 263-274, 2008.  Alekh Agarwal, Ofer Dekel, and Lin Xiao. Optimal algorithms for online convex optimiza-  tion with multi-point bandit feedback. In COLT, pages 28-40, 2010.  Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University  Press, New York, NY, USA, 2004. ISBN 0521833787.  S\u00b4ebastien Bubeck, Nicol`o Cesa-Bianchi, and Sham M. Kakade. Towards minimax policies for online linear optimization with bandit feedback. Journal of Machine Learning Research - Proceedings Track, 23:41.1-41.14, 2012.  Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin, and Shenghuo Zhu. Online optimization with gradual variations. Journal of Machine Learning Research - Proceedings Track, 23:6.1-6.20, 2012.  Thomas Cover. Universal portfolios. Mathematical Finance, 1:1-19, 1991.  Abraham Flaxman, Adam Tauman Kalai, and H. Brendan McMahan. Online convex op- timization in the bandit setting: gradient descent without a gradient. In SODA, pages 385-394, 2005.  Elad Hazan and Satyen Kale. Extracting certainty from uncertainty: Regret bounded by  variation in costs. In COLT, pages 57-68, 2008.  Elad Hazan and Satyen Kale. On stochastic and worst-case models for investing. In NIPS,  pages 709-717, 2009a.  2009b.  Elad Hazan and Satyen Kale. Better algorithms for benign bandits. In SODA, pages 38-47,  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Journal of Computer and System Sciences, 69(2-3):169-192, 2007.  Kevin G. Jamieson, Robert D. Nowak, and Benjamin Recht. Query complexity of derivative-  free optimization. In NIPS, 2012.  Ankan Saha and Ambuj Tewari.  Improved regret guarantees for online smooth convex optimization with bandit feedback. Journal of Machine Learning Research - Proceedings Track, 15:636-642, 2011.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.  In ICML, pages 928-936, 2003.  13   Beating Bandits in Gradually Evolving Worlds  References  In COLT, 2009.  Jacob Abernethy and Alexander Rakhlin. Beating the adaptive bandit with high probability.  Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An e\ufb03cient  algorithm for bandit linear optimization. In COLT, pages 263-274, 2008.  Alekh Agarwal, Ofer Dekel, and Lin Xiao. Optimal algorithms for online convex optimiza-  tion with multi-point bandit feedback. In COLT, pages 28-40, 2010.  Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University  Press, New York, NY, USA, 2004. ISBN 0521833787.  S\u00b4ebastien Bubeck, Nicol`o Cesa-Bianchi, and Sham M. Kakade. Towards minimax policies for online linear optimization with bandit feedback. Journal of Machine Learning Research - Proceedings Track, 23:41.1-41.14, 2012.  Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin, and Shenghuo Zhu. Online optimization with gradual variations. Journal of Machine Learning Research - Proceedings Track, 23:6.1-6.20, 2012.  Thomas Cover. Universal portfolios. Mathematical Finance, 1:1-19, 1991.  Abraham Flaxman, Adam Tauman Kalai, and H. Brendan McMahan. Online convex op- timization in the bandit setting: gradient descent without a gradient. In SODA, pages 385-394, 2005.  Elad Hazan and Satyen Kale. Extracting certainty from uncertainty: Regret bounded by  variation in costs. In COLT, pages 57-68, 2008.  Elad Hazan and Satyen Kale. On stochastic and worst-case models for investing. In NIPS,  pages 709-717, 2009a.  2009b.  Elad Hazan and Satyen Kale. Better algorithms for benign bandits. In SODA, pages 38-47,  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Journal of Computer and System Sciences, 69(2-3):169-192, 2007.  Kevin G. Jamieson, Robert D. Nowak, and Benjamin Recht. Query complexity of derivative-  free optimization. In NIPS, 2012.  Ankan Saha and Ambuj Tewari.  Improved regret guarantees for online smooth convex optimization with bandit feedback. Journal of Machine Learning Research - Proceedings Track, 15:636-642, 2011.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.  In ICML, pages 928-936, 2003. Chiang Lee Lu  "}, "Information Complexity in Bandit Subset Selection": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Information Complexity in Bandit Subset Selection", "abstract": "We consider the problem of efficiently exploring the arms of a stochastic bandit to identify the best subset. Under the PAC and the fixed-budget formulations, we derive improved bounds by using KL-divergence-based confidence intervals. Whereas the application of a similar idea in the regret setting has yielded bounds in terms of the KL-divergence between the arms, our bounds in the pure-exploration setting involve the Chernoff information between the arms. In addition to introducing this novel quantity to the bandits literature, we contribute a comparison between the \u201cracing\u201d and \u201csmart sampling\u201d strategies for pure-exploration problems, finding strong evidence in favor of the latter.", "pdf_url": "http://proceedings.mlr.press/v30/Kaufmann13.pdf", "keywords": ["Stochastic multi-armed bandits", "subset selection", "KL-divergence"], "reference": "J-Y. Audibert, S. Bubeck, and R. Munos. Best arm identification in multi-armed bandits.  In Conference on Learning Theory (COLT), 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine Learning, 47(2):235-256, 2002.  S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in finitely armed and continuous armed bandits. Theoretical Computer Science 412, 1832-1852, 412:1832-1852, 2011.  S. Bubeck, T. Wang, and N. Viswanathan. Multiple identifications in multi-armed bandits.  In International Conference on Machine Learning (ICML). To appear, 2013.  O. Capp\u00b4e, A. Garivier, O-A. Maillard, R. Munos, and G. Stoltz. Kullback-Leibler upper to appear in Annals of Statistics,  confidence bounds for optimal sequential allocation. 2013.  T. Cover and J. Thomas. Elements of Information Theory (2nd Edition). Wiley, 2006.  E. Even-Dar, S. Mannor, and Y. Mansour. Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. Journal of Machine Learning Research, 7:1079-1105, 2006.  V. Gabillon, M. Ghavamzadeh, and A. Lazaric. Best arm identification: A unified approach to fixed budget and fixed confidence. In Neural Information and Signal Processing (NIPS), 2012.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and  beyond. In Conference on Learning Theory (COLT), 2011.  V. Heidrich-Meisner and C. Igel. Hoe\ufb00ding and Bernstein races for selecting policies in evo- lutionary direct policy search. In International Conference on Learning Theorey (ICML), 2009.  S. Kalyanakrishnan. Learning Methods for Sequential Decision Making with Imperfect Rep- resentations. PhD thesis, Departement of Computer Science, The University of Texas at Austin, 2011.  S. Kalyanakrishnan and P. Stone. E\ufb03cient selection in multiple bandit arms: Theory and  practice. In International Conference on Machine Learning (ICML), 2010.  S. Kalyanakrishnan, A. Tewari, P. Auer, and P. Stone. PAC subset selection in stochastic multi-armed bandits. In International Conference on Machine Learning (ICML), 2012.  E. Kaufmann, N. Korda, and R. Munos. Thompson sampling : an asymptotically optimal  finite-time analysis. In Algorithmic Learning Theory (ALT), 2012.  T.L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6(1):4-22, 1985.  14   Kaufmann Kalyanakrishnan  References  J-Y. Audibert, S. Bubeck, and R. Munos. Best arm identification in multi-armed bandits.  In Conference on Learning Theory (COLT), 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine Learning, 47(2):235-256, 2002.  S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in finitely armed and continuous armed bandits. Theoretical Computer Science 412, 1832-1852, 412:1832-1852, 2011.  S. Bubeck, T. Wang, and N. Viswanathan. Multiple identifications in multi-armed bandits.  In International Conference on Machine Learning (ICML). To appear, 2013.  O. Capp\u00b4e, A. Garivier, O-A. Maillard, R. Munos, and G. Stoltz. Kullback-Leibler upper to appear in Annals of Statistics,  confidence bounds for optimal sequential allocation. 2013.  T. Cover and J. Thomas. Elements of Information Theory (2nd Edition). Wiley, 2006.  E. Even-Dar, S. Mannor, and Y. Mansour. Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. Journal of Machine Learning Research, 7:1079-1105, 2006.  V. Gabillon, M. Ghavamzadeh, and A. Lazaric. Best arm identification: A unified approach to fixed budget and fixed confidence. In Neural Information and Signal Processing (NIPS), 2012.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and  beyond. In Conference on Learning Theory (COLT), 2011.  V. Heidrich-Meisner and C. Igel. Hoe\ufb00ding and Bernstein races for selecting policies in evo- lutionary direct policy search. In International Conference on Learning Theorey (ICML), 2009.  S. Kalyanakrishnan. Learning Methods for Sequential Decision Making with Imperfect Rep- resentations. PhD thesis, Departement of Computer Science, The University of Texas at Austin, 2011.  S. Kalyanakrishnan and P. Stone. E\ufb03cient selection in multiple bandit arms: Theory and  practice. In International Conference on Machine Learning (ICML), 2010.  S. Kalyanakrishnan, A. Tewari, P. Auer, and P. Stone. PAC subset selection in stochastic multi-armed bandits. In International Conference on Machine Learning (ICML), 2012.  E. Kaufmann, N. Korda, and R. Munos. Thompson sampling : an asymptotically optimal  finite-time analysis. In Algorithmic Learning Theory (ALT), 2012.  T.L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6(1):4-22, 1985. Information Complexity in Bandit Subset Selection  O-A. Maillard, R. Munos, and G. Stoltz. A finite-time analysis of multi-armed bandits problems with Kullback-Leibler divergences. In Conference On Learning Theory (COLT), 2011.  S. Mannor and J. Tsitsiklis. The sample complexity of exploration in the multi-armed  bandit problem. Journal of Machine Learning Research, pages 623-648, 2004.  O. Maron and A. Moore. The racing algorithm: Model selection for lazy learners. Artificial  Intelligence Review, 11(1-5):113-131, 1997.  V. Mnih, C. Szepesv\u00b4ari, and J-Y. Audibert. Empirical Bernstein stopping. In International  Conference on Machine Learning (ICML), 2008.  W.R. Thompson. On the likelihood that one unknown probability exceeds another in view  of the evidence of two samples. Biometrika, 25:285-294, 1933. Kaufmann Kalyanakrishnan  "}, "Passive Learning with Target Risk": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Passive Learning with Target Risk", "abstract": "In this paper we consider learning in passive setting but with a slight modification. We assume that the target expected loss, also referred to as target risk, is provided in advance for  learner as  prior knowledge. Unlike most studies in the learning theory  that only incorporate the prior knowledge into the generalization bounds, we are able to explicitly utilize the target risk in the learning process. Our analysis reveals a surprising result on the sample complexity of learning: by exploiting the target risk in the learning algorithm,  we show that when the loss function is both strongly convex and smooth, the sample complexity reduces to \\mathcalO(\\log \\left(\\frac1\u03b5\\right)), an exponential improvement compared to the sample complexity \\mathcalO(\\frac1\u03b5) for learning with strongly convex loss functions.  Furthermore,  our proof is constructive and is based on a computationally efficient stochastic optimization algorithm  for such settings which demonstrate that the  proposed algorithm is practically useful.", "pdf_url": "http://proceedings.mlr.press/v30/Mahdavi13.pdf", "keywords": ["learning theory", "risk minimization", "stochastic optimization", "sample complexity"], "reference": "M. Anthony and P.L. Bartlett. Neural network learning: Theoretical foundations. Cam-  bridge University Press, 1999.  13   Passive Learning with Target Risk  By combining the bounds in (13) and (15), under the assumption that at least one of the two conditions in (12) and (14) is true, by setting (cid:22) = B=8, we have  L( bwk+1) (cid:0) L(w(cid:3)) (cid:20) 1 T1  (  \u221a  2(cid:24)(cid:12)  T1 +  [ (cid:24)3(cid:12)d + 2(cid:24)(cid:12)  p  ]  d  ln  )  s (cid:14)  \u22062  k +  \u03f5prior;  4 (cid:24)  implying  \u2225 bwk+1 (cid:0) w(cid:3)\u2225 (cid:20) 2 (cid:11)T1  (  \u221a  2(cid:24)(cid:12)  T1 +  [ (cid:24)3(cid:12)d + 2(cid:24)(cid:12)  p  ]  d  ln  )  s (cid:14)  \u22062  k +  \u03f5prior:  8 (cid:11)(cid:24)  We complete the proof by using Lemma 8, which states that the probability for either of the two conditions hold is no less than 1 (cid:0) (cid:14).  6. Conclusions  In this paper, we have studied the sample complexity of passive learning when the target expected risk is given to the learner as prior knowledge. The crucial fact about target risk assumption is that, it can be fully exploited by the learning algorithm and stands in contrast to most common types of prior knowledges that usually enter into the generalization bounds and are often perceived as a rather crude way to incorporate such assumptions. We showed that by explicitly employing the target risk \u03f5prior in a properly designed stochastic optimization algorithm, it is possible to attain the given target risk \u03f5prior with a logarithmic , under the assumption that the loss function is both strongly sample complexity log convex and smooth.  1 \u03f5prior  )  (  There are various directions for future research. The current study is restricted to the parametric setting where the hypothesis space is of (cid:12)nite dimension. It would be interesting to see how to achieve a logarithmic sample complexity in a non-parametric setting where hy- potheses lie in a functional space of in(cid:12)nite dimension. Evidently, it is impossible to extend the current algorithm for the non-parametric setting; therefore additional analysis tools are needed to address the challenge of in(cid:12)nite dimension arising from the non-parametric set- ting. It is also an interesting problem to relate target risk assumption we made here to the low noise margin condition which is often made in active learning for binary classi(cid:12)cation since both settings appear to share the same sample complexity. However it is currently unclear how to derive a connection between these two settings. We believe this issue is worthy of further exploration and leave it as an open problem.  Acknowledgments  The authors would like to thank the PC for insightful discussions and three anonymous reviewers for their constructive comments and helpful suggestions on the original version of this paper. This work is partially supported by O(cid:14)ce of Navy Research (ONR Award N00014-09-1-0663 and N000141210431).  References  M. Anthony and P.L. Bartlett. Neural network learning: Theoretical foundations. Cam-  bridge University Press, 1999. Mahdavi Jin  Maria-Florina Balcan, Steve Hanneke, and Jennifer Wortman Vaughan. The true sample  complexity of active learning. Machine Learning, 80(2-3):111{139, 2010.  P.L. Bartlett, O. Bousquet, and S. Mendelson. Local rademacher complexities. The Annals  of Statistics, 33(4):1497{1537, 2005.  Shai Ben-David, David Pal, and Shai Shalev-Shwartz. Agnostic online learning. In COLT,  2009.  Anselm Blumer, A. Ehrenfeucht, David Haussler, and Manfred K. Warmuth. Learnability  and the vapnik-chervonenkis dimension. J. ACM, 36(4):929{965, 1989.  Nicol(cid:18)o Cesa-Bianchi and G(cid:19)abor Lugosi. Prediction, learning, and games. Cambridge Uni-  versity Press, 2006.  Andrew Cotter, Ohad Shamir, Nati Srebro, and Karthik Sridharan. Better mini-batch  algorithms via accelerated gradient methods. In NIPS, pages 1647{1655, 2011.  John C. Duchi, Peter L. Bartlett, and Martin J. Wainwright. Randomized smoothing for  stochastic optimization. SIAM Journal on Optimization, 22(2):674{701, 2012.  A. Ehrenfeucht, D. Haussler, M. Kearns, and L. Valiant. A general lower bound on the number of examples needed for learning. Information and Computation, 82(3):247{261, 1989.  Steve Hanneke. Theoretical Foundations of Active Learning. PhD thesis, 2009.  Elad Hazan and Satyen Kale. Beyond the regret minimization barrier: an optimal algorithm  for stochastic strongly-convex optimization. COLT, 2011.  Elad Hazan and Tomer Koren. Optimal algorithms for ridge and lasso regression with  partially observed attributes. CoRR, 2011.  Elad Hazan, Adam Kalai, Satyen Kale, and Amit Agarwal. Logarithmic regret algorithms  for online convex optimization. In COLT, pages 499{513, 2006.  Anatoli  Iouditski  and Yuri Nesterov. minimizing convex ouvertes.fr/docs/00/50/89/33/PDF/Strong-hal.pdf, 2010.  Primal-dual  functions.  uniformly  available  subgradient methods  for http://hal.archives-  at  Sham M. Kakade, Karthik Sridharan, and Ambuj Tewari. On the complexity of linear prediction: Risk bounds, margin bounds, and regularization. In NIPS, pages 793{800, 2008.  Vladimir Koltchinskii. Oracle Inequalities in Empirical Risk Minimization and Sparse Re-  covery Problems. Lecture Notes in mathematics. Springer, 2011.  Wee Sun Lee, Peter L. Bartlett, and Robert C. Williamson. The importance of convexity in learning with squared loss. IEEE Transactions on Information Theory, 44(5):1974{1980, 1998. Passive Learning with Target Risk  A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approximation approach to stochastic programming. SIAM Journal on Optimization, 19(4):1574{1609, 2009.  A.S. Nemirovsky and D.B. Yudin. Problem complexity and method e(cid:14)ciency in optimiza-  tion. Wiley Interscience Series in Discrete Mathematics, 1983.  Yurii Nesterov. Introductory Lectures on Convex Optimization: A Basic Course. Kluwer  Academic Publishers, 2004.  Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning: Random  averages, combinatorial parameters, and learnability. CoRR, abs/1006.1138, 2010.  Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan. Making gradient descent optimal  for strongly convex stochastic optimization. In ICML, 2012.  Aaditya Ramdas and Aarti Singh. Optimal stochastic convex optimization through the lens  of active learning. In ICML, 2013.  S. Shalev-Shwartz, O. Shamir, K. Sridharan, and N. Srebro. Learnability and stability in  the general learning setting. COLT, 2009a.  S. Shalev-Shwartz, O. Shamir, K. Sridharan, and N. Srebro. Stochastic convex optimization.  COLT, 2009b.  Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan. Learnability, stability and uniform convergence. Journal of Machine Learning Research, 11:2635{2670, 2010.  Nathan Srebro, Karthik Sridharan, and Ambuj Tewari. Smoothness, low noise and fast  rates. In NIPS, pages 2199{2207, 2010.  Karthik Sridharan. Learning from an optimization viewpoint. PhD Thesis, 2012.  Karthik Sridharan, Shai Shalev-Shwartz, and Nathan Srebro. Fast rates for regularized  objectives. In NIPS, pages 1545{1552, 2008.  V.N. Vapnik and A.Y. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and Its Applications, 16(2):264{280, 1971. Mahdavi Jin  "}, "Blind Signal Separation in the Presence of Gaussian Noise": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Blind Signal Separation in the Presence of Gaussian Noise", "abstract": "A prototypical blind signal separation problem  is the so-called cocktail party problem, with n people talking simultaneously and n different microphones within a room. The goal is to  recover  each speech signal  from the microphone inputs. Mathematically this can be modeled by assuming that we are given samples from a n-dimensional random variable X=AS, where S is a vector whose coordinates are independent random variables corresponding to each speaker. The objective is to recover the  matrix A^-1 given random samples from X. A range of techniques  collectively known as Independent Component Analysis (ICA) have been proposed to address this problem in the signal processing and machine learning literature. Many of these techniques are based on using the kurtosis or other cumulants to recover the components. In this paper we propose a new algorithm for solving the blind signal separation problem in the presence of additive Gaussian noise, when we are given samples from X=AS+\u03b7, where \u03b7is drawn from an unknown, not necessarily spherical n-dimensional Gaussian distribution. Our approach is based on a method for decorrelating a sample with additive Gaussian noise under the assumption that the underlying distribution is a linear transformation of a distribution with independent components. Our decorrelation routine is based on the properties of cumulant tensors and can be combined with any standard cumulant-based method for ICA to get an algorithm that is provably robust in the presence of Gaussian noise. We derive polynomial bounds for sample complexity and error propagation of our method.", "pdf_url": "http://proceedings.mlr.press/v30/Belkin13.pdf", "keywords": [], "reference": "Sanjeev Arora, Rong Ge, Ankur Moitra, and Sushant Sachdeva. Provable ICA with un- known Gaussian noise, and implications for Gaussian mixtures and autoencoders. Neural Information Processing Systems, 2012. to appear.  A.J. Bell and T.J. Sejnowski. The \u201cindependent components\u201d of natural scenes are edge  filters. Vision research, 37(23):3327-3338, 1997.  J.F. Cardoso and A. Souloumiac. Blind beamforming for non-Gaussian signals. In Radar  and Signal Processing, IEE Proceedings F, volume 140, pages 362-370. IET, 1993.  Pierre Comon and Christian Jutten, editors. Handbook of Blind Source Separation. Aca-  demic Press, 2010.  13   Blind Signal Separation in the Presence of Gaussian Noise  Then with probability 1 \u2212 \u03b4,  (cid:104) \u02c6B\u22121Aei, \u02c6B\u22121Aej(cid:105) (cid:107)Ai(cid:107)2(cid:107)Aj(cid:107)2  i AT \u02c6B\u2212T \u02c6B\u22121Aej eT (cid:107)Ai(cid:107)2(cid:107)Aj(cid:107)2  =  \u2208  \u2283  \u2212  (cid:15) 2  ,  (cid:32)  D\u22121 ij (cid:107)Ai(cid:107)2(cid:107)Aj(cid:107)2 (cid:18) \u03b4ij(cid:107)Ai(cid:107)(cid:107)Aj(cid:107) (cid:107)Ai(cid:107)(cid:107)Aj(cid:107)  =  i Y \u22121ej eT (cid:107)Ai(cid:107)2(cid:107)Aj(cid:107)2 D\u22121 ij (cid:107)Ai(cid:107)2(cid:107)Aj(cid:107)2  +  (cid:33)  (cid:15) 2  (cid:19)  (cid:15) 2  \u2212  (cid:15) 2  ,  \u03b4ij(cid:107)Ai(cid:107)(cid:107)Aj(cid:107) (cid:107)Ai(cid:107)(cid:107)Aj(cid:107)  +  = \u03b4ij \u00b1  (cid:15) 2  .  Consider the case where i = j. Then,  2 (cid:107) \u02c6B\u22121Aei(cid:107) 2 \u2208  (cid:16)  1 \u00b1  (cid:17)  (cid:15) 2  (cid:107)Ai(cid:107)2 2,  which gives equation (2) Consider the case where i (cid:54)= j. Then,  (cid:104) \u02c6B\u22121Aei, \u02c6B\u22121Aej(cid:105) (cid:107)Ai(cid:107)2(cid:107)Aj(cid:107)2  \u00b7  (cid:107) \u02c6B\u22121Aei(cid:107)2(cid:107) \u02c6B\u22121Aej(cid:107)2 (cid:107) \u02c6B\u22121Aei(cid:107)2(cid:107) \u02c6B\u22121Aej(cid:107)2  \u2208 \u00b1  (cid:15) 2  (cid:104) \u02c6B\u22121Aei, \u02c6B\u22121Aej(cid:105) (cid:107) \u02c6B\u22121Aei(cid:107)2(cid:107) \u02c6B\u22121Aej(cid:107)2  \u2208 \u00b1  \u00b7  (cid:15) 2  1 1 \u00b1 (cid:15)/2  \u2282 \u00b1(cid:15)  by restricting (cid:15) < 1  2 . This gives equation (1), completing the proof.  We would like to thank Navin Goyal for useful discussions. Mikhail Belkin and James Voss were partially supported by NSF Grants IIS 0643916 and IIS 1117707 during the writing of the paper.  Acknowledgments  References  Sanjeev Arora, Rong Ge, Ankur Moitra, and Sushant Sachdeva. Provable ICA with un- known Gaussian noise, and implications for Gaussian mixtures and autoencoders. Neural Information Processing Systems, 2012. to appear.  A.J. Bell and T.J. Sejnowski. The \u201cindependent components\u201d of natural scenes are edge  filters. Vision research, 37(23):3327-3338, 1997.  J.F. Cardoso and A. Souloumiac. Blind beamforming for non-Gaussian signals. In Radar  and Signal Processing, IEE Proceedings F, volume 140, pages 362-370. IET, 1993.  Pierre Comon and Christian Jutten, editors. Handbook of Blind Source Separation. Aca-  demic Press, 2010. Belkin Rademacher Voss  N. Delfosse and P. Loubaton. Adaptive blind separation of independent sources: a de\ufb02ation  approach. Signal processing, 45(1):59-83, 1995.  Alan M. Frieze, Mark Jerrum, and Ravi Kannan. Learning linear transformations. In FOCS,  pages 359-368, 1996.  Daniel Hsu and Sham M. Kakade. Learning mixtures of spherical Gaussians: moment  methods and spectral decompositions, 2012.  A. Hyvarinen. Gaussian moments for noisy independent component analysis. Signal Pro-  cessing Letters, IEEE, 6(6):145-147, 1999.  Aapo Hyv\u00a8arinen. Fast and robust fixed-point algorithms for independent component anal-  ysis. IEEE Transactions on Neural Networks, 10(3):626-634, 1999.  Aapo Hyv\u00a8arinen and Erkki Oja. Independent component analysis: algorithms and applica-  tions. Neural Networks, 13(4-5):411-430, 2000.  T.P. Jung, S. Makeig, C. Humphries, T.W. Lee, M.J. Mckeown, V. Iragui, and T.J. Se- jnowski. Removing electroencephalographic artifacts by blind source separation. Psy- chophysiology, 37(2):163-178, 2000.  Maurice Kendall, Alan Stuart, and J. Keith Ord. Kendall\u2019s advanced theory of statistics.  Vol. 1. Halsted Press, sixth edition, 1994. Distribution theory.  S. Makino, T.W. Lee, and H. Sawada. Blind speech separation. Springer, 2007.  Peter McCullagh. Tensor methods in statistics. Monographs on Statistics and Applied  Probability. Chapman & Hall, London, 1987. ISBN 0-412-27480-9.  J. Morton and L.-H. Lim. Principal cumulant component analysis. Preprint.  Phong Q. Nguyen and Oded Regev. Learning a parallelepiped: Cryptanalysis of GGH and  NTRU signatures. J. Cryptology, 22(2):139-160, 2009.  Amnon Shashua and Tamir Hazan. Non-negative tensor factorization with applications to  statistics and computer vision. In ICML, pages 792-799, 2005.  G. W. Stewart and Ji Guang Sun. Matrix perturbation theory. Computer Science and Scientific Computing. Academic Press Inc., Boston, MA, 1990. ISBN 0-12-670230-6.  Santosh S. Vempala and Ying Xiao. Structure from local optima: Learning subspace juntas  via higher order pca. CoRR, abs/1108.3329, 2011.  Arie Yeredor. Blind source separation via the second characteristic function. Signal Pro-  cessing, 80(5):897-902, 2000. Blind Signal Separation in the Presence of Gaussian Noise  "}, "Active and passive learning of linear separators under log-concave distributions": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Active and passive learning of linear separators under log-concave distributions", "abstract": "We prove that active learning provides an exponential improvement over PAC (passive) learning of homogeneous linear separators under nearly log-concave distributions. Building on this, we provide a computationally efficient PAC algorithm with optimal (up to a constant factor) sample complexity for such problems. This resolves an open question of (Long, 1995, 2003; Bshouty et al., 2009) concerning the sample complexity of efficient PAC algorithms under the uniform distribution in the unit ball. Moreover, it provides the first bound for a polynomial-time  PAC algorithm that is tight for an interesting infinite class of hypothesis functions under a general class of data-distributions, providing significant progress towards  a long standing open question of (Ehrenfeucht et al., 1989; Blumer et al., 1989). We also provide new bounds for active and passive learning in the case that the data might not be linearly separable, both in the agnostic case and and under the Tsybakov low-noise condition. To derive our results, we provide new  structural results for (nearly) log-concave distributions, which might be of independent interest  as well.", "pdf_url": "http://proceedings.mlr.press/v30/Balcan13.pdf", "keywords": ["Active learning", "PAC learning", "ERM", "nearly log-concave distributions", "Tsybakov lownoise condition", "agnostic learning"], "reference": "1991.  K.S. Alexander. Rates of growth and sample moduli for weighted empirical processes indexed by  sets. Probability Theory and Related Fields, 1987.  N. Alon. A non-linear lower bound for planar epsilon-nets. FOCS, pages 341\u2013346, 2010.  D. Applegate and R. Kannan. Sampling and integration of near log-concave functions. In STOC,  P. Assouad. Plongements lipschitziens dans. R . Bull. Soc. Math. France, 111(4):429\u2013448, 1983.  13   ACTIVE AND PASSIVE LEARNING OF LINEAR SEPARATORS UNDER LOG-CONCAVE DISTRIBUTIONS  \u2208  [0, 1) and a  Theorem 15 Let s = O(log(1/\u01eb)). Assume that the distribution DXY satisfies the Tsybakov noise 0, and that the marginal D on Rd is isotropic log- condition for constants \u03b1 \u03b4 using concave. (1) If \u03b1 = 0, we can find a separator with excess error O(log(1/\u01eb))(d + log(s/\u03b4)) labeled examples in the active learning model, and O (cid:17) labeled examples in the passive learning model. (2) If \u03b1 > 0, we can find a separator with excess \u03b4 using O((1/\u01eb)2\u03b1 log2(1/\u01eb))(d + log(s/\u03b4)) labeled examples in the error active learning model.  \u01eb with probability 1  \u01eb with probability 1  d+log(1/\u03b4) \u01eb  \u2264  \u2212  \u2265  \u2264  \u2212  (cid:16)  In the case \u03b1 = 0 (that is more general than the Massart noise condition) our analysis leads to optimal bounds for active and passive learning of linear separators under log-concave distribu- tions, improving the dependence on d over previous best known results (Hanneke and Yang, 2012; Gin\u00b4e and Koltchinskii, 2006). Our analysis for Tsybakov noise (\u03b1 0) leads to bounds on active learning with improved dependence on d over previous known results (Hanneke and Yang, 2012) in this case as well. Proofs and further details appear in "}, "Randomized partition trees for exact nearest neighbor search": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Randomized partition trees for exact nearest neighbor search", "abstract": "The k-d tree was one of the first spatial data structures proposed for nearest neighbor search. Its efficacy is diminished in high-dimensional spaces, but several variants, with randomization and overlapping cells, have proved to be successful in practice. We analyze three such schemes. We show that the probability that they fail to find the nearest neighbor, for any data set and any query point, is directly related to a simple potential function that captures the difficulty of the point configuration. We then bound this potential function in two situations of interest: the first, when data come from a doubling measure, and the second, when the data are documents from a topic model.", "pdf_url": "http://proceedings.mlr.press/v30/Dasgupta13.pdf", "keywords": ["Nearest-neighbor search."], "reference": "N. Ailon and B. Chazelle. The fast Johnson-Lindenstrauss transform and approximate  nearest neighbors. SIAM Journal on Computing, 39:302-322, 2009.  13   Randomized trees for NN search  The overall distribution is thus a mixture \u00b5 = w1\u00b51 + a Bernoulli product distribution \u00b5j = B(p for the distribution on 0 < p  + wt\u00b5t whose jth component is (j) N ). Here B(p) is a shorthand with expected value p. It will simplify things to assume that  (j) i < 1/2; this is not a huge assumption if, say, stopwords have been removed.  0, 1 {  \u00d7 \u00b7 \u00b7 \u00b7 \u00d7  \u00b7 \u00b7 \u00b7 B(p  (j) 1 )  }  For the purposes of bounding \u03a6, we are interested in the distribution of dH (q, X), where X is chosen from \u00b5 and dH denotes Hamming distance. This is a sum of small independent quantities, and it is customary to approximate such sums by a Poisson distribution. In the current context, however, this approximation is rather poor, and we instead use counting arguments to directly bound how rapidly the distribution grows. The results stand in stark contrast to those we obtained for doubling measures, and reveal this to be a substantially more di\ufb03cult setting for nearest neighbor search. For a doubling measure, the probability mass of a ball B(q, r) doubles whenever r is multiplied by a constant. In our present setting, it doubles whenever r is increased by an additive constant:  Theorem 10 Suppose that all p of words in a document from topic j, and let L = min(L1, . . . , Lt). Pick any query q 0, 1 }  N , and draw X  denote the expected number  \u00b5. For any (cid:96)  i p  0,  \u223c  \u2208  {  (0, 1/2). Let Lj = (cid:80)  (j) i \u2208  (j) i  \u2265 Pr(dH (q, X) = (cid:96) + 1) Pr(dH (q, X) = (cid:96))  L  (cid:96)/2  \u2212 (cid:96) + 1  .  \u2265  Now, fix a particular query q  0, 1  N , and draw x1, . . . , xn from distribution \u00b5.  \u2208 {  }  Lemma 11 There is an absolute constant co for which the following holds. Pick any 0 < \u03b4 < 1 and any k v) for any m  1, and let v denote the smallest integer for which PrX\u223c\u00b5(dH (q, X)  (8/n) max(k, ln 1/\u03b4). Then with probability at least 1  \u2264 3\u03b4 over the choice of x1, . . . , xn,  n,  \u2265  \u2265  \u2212  \u2264  \u03a6k,m(q,  x1, . . . , xn  )  {  }  \u2264  coL  log2(n/m)  .  (cid:114) 4  v  \u2212  The implication of this lemma is that for any of the three tree data structures, the (cid:112) v/L. This means that the tree can only be  failure probability at a single level is roughly  (cid:112)  grown to depth O(  L/v), and thus the query time is dominated by no = n  When n is large, we expect v to be small, and thus the query time improves over L.  exhaustive search by a factor of roughly 2\u2212  \u221a  2\u2212O(\u221aL/v).  \u00b7  We thank the National Science Foundation for support under grant IIS-1162581.  Acknowledgments  References  N. Ailon and B. Chazelle. The fast Johnson-Lindenstrauss transform and approximate  nearest neighbors. SIAM Journal on Computing, 39:302-322, 2009. Dasgupta Sinha  A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor  in high dimensions. Communications of the ACM, 51(1):117-122, 2008.  S. Arya, D.M. Mount, N.S. Netanyahu, R. Silverman, and A.Y. Wu. An optimal algorithm for approximate nearest neighbor searching. Journal of the ACM, 45:891-923, 1998.  J.L. Bentley. Multidimensional binary search trees used for associative searching. Commu-  nications of the ACM, 18(9):509-517, 1975.  A. Beygelzimer, S. Kakade, and J. Langford. Cover trees for nearest neighbor.  In 23rd  International Conference on Machine Learning, 2006.  S. Dasgupta and Y. Freund. Random projection trees and low dimensional manifolds. In  ACM Symposium on Theory of Computing, pages 537-546, 2008.  D.R. Karger and M. Ruhl. Finding nearest neighbors in growth-restricted metrics. In ACM  Symposium on Theory of Computing, pages 741-750, 2002.  J. Kleinberg. Two algorithms for nearest-neighbor search in high dimensions. In 29th ACM  Symposium on Theory of Computing, 1997.  R. Krauthgamer and J.R. Lee. Navigating nets: simple algorithms for proximity search. In  ACM-SIAM Symposium on Discrete Algorithms, 2004.  T. Liu, A.W. Moore, A. Gray, and K. Yang. An investigation of practical approximate  nearest neighbor algorithms. In Neural Information Processing Systems, 2004.  S. Maneewongvatana and D.M. Mount. The analysis of a probabilistic approach to nearest neighbor searching. In Seventh International Worshop on Algorithms and Data Struc- tures, pages 276-286, 2001.  "}, "Surrogate Regret Bounds for the Area Under the ROC Curve via Strongly Proper Losses": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Surrogate Regret Bounds for the Area Under the ROC Curve via Strongly Proper Losses", "abstract": "The area under the ROC curve (AUC) is a widely used performance measure in machine learning, and has been widely studied in recent years particularly in the context of bipartite ranking. A dominant theoretical and algorithmic framework for AUC optimization/bipartite ranking has been to reduce the problem to pairwise classification; in particular, it is well known that the AUC regret can be formulated as a pairwise classification regret, which in turn can be upper bounded using usual regret bounds for binary classification. Recently, Kotlowski et al. (2011) showed AUC regret bounds in terms of the regret associated with \u2018balanced\u2019 versions of the standard (non-pairwise) logistic and exponential losses. In this paper, we obtain such (non-pairwise) surrogate regret bounds for the AUC in terms of a broad class of proper (composite) losses that we term \\emphstrongly proper. Our proof technique is considerably simpler than that of Kotlowski et al. (2011), and relies on properties of proper (composite) losses as elucidated recently by Reid and Williamson (2009, 2010, 2011) and others. Our result yields explicit surrogate bounds (with no hidden balancing terms) in terms of a variety of strongly proper losses, including for example logistic, exponential, squared and squared hinge losses. An important consequence is that standard algorithms minimizing a (non-pairwise) strongly proper loss, such as logistic regression and boosting algorithms (assuming a universal function class and appropriate regularization), are in fact AUC-consistent; moreover, our results allow us to quantify the AUC regret in terms of the corresponding surrogate regret. We also obtain tighter surrogate regret bounds under certain low-noise conditions via a recent result of Cl\u00e9men\\con and Robbiano (2011).", "pdf_url": "http://proceedings.mlr.press/v30/Agarwal13.pdf", "keywords": ["Area under ROC curve (AUC)", "bipartite ranking", "statistical consistency", "regret bounds", "proper losses", "strongly proper losses"], "reference": "Shivani Agarwal, Thore Graepel, Ralf Herbrich, Sariel Har-Peled, and Dan Roth. General- ization bounds for the area under the ROC curve. Journal of Machine Learning Research, 6:393-425, 2005.  Nir Ailon and Mehryar Mohri. An e\ufb03cient reduction of ranking to classification. In Pro-  ceedings of the 21st Annual Conference on Learning Theory, 2008.  Maria-Florina Balcan, Nikhil Bansal, Alina Beygelzimer, Don Coppersmith, John Lang- ford, and Gregory B. Sorkin. Robust reductions from ranking to classification. Machine Learning, 72:139-153, 2008.  Peter Bartlett, Michael Jordan, and Jon McAuli\ufb00e. Convexity, classification and risk  bounds. Journal of the American Statistical Association, 101(473):138-156, 2006.  David Bu\ufb00oni, Cl\u00b4ement Calauzenes, Patrick Gallinari, and Nicolas Usunier. Learning scor- ing functions with order-preserving losses and standardized supervision. In Proceedings of the 28th International Conference on Machine Learning, 2011.  Andreas Buja, Werner Stuetzle, and Yi Shen. Loss functions for binary class probability estimation: Structure and applications. Technical report, University of Pennsylvania, November 2005.  C. J. C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullen- der. Learning to rank using gradient descent. In Proceedings of the 22nd International Conference on Machine Learning, 2005.  Cl\u00b4ement Calauz`enes, Nicolas Usunier, and Patrick Gallinari. On the (non-)existence of con- vex, calibrated surrogate losses for ranking. In Advances in Neural Information Processing Systems 25, pages 197-205. 2012.  St\u00b4ephan Cl\u00b4emen\u00b8con, Gabor Lugosi, and Nicolas Vayatis. Ranking and empirical minimiza-  tion of U-statistics. Annals of Statistics, 36:844-874, 2008.  St\u00b4ephan Cl\u00b4emen\u00b8con and Sylvain Robbiano. Minimax learning rates for bipartite ranking and plug-in rules. In Proceedings of the 28th International Conference on Machine Learning, 2011.  St\u00b4ephan Cl\u00b4emen\u00b8con and Nicolas Vayatis. Ranking the best instances. Journal of Machine  Learning Research, 8:2671-2699, 2007.  13   AUC Regret Bounds via Strongly Proper Losses  Acknowledgments  Thanks to Harish G. Ramaswamy and Arun Rajkumar for helpful discussions. Thanks also to Yoonkyung Lee for inviting me to give a talk at the ASA Conference on Statistical Learning and Data Mining held in Ann Arbor, Michigan, in June 2012; part of this work was done while preparing for that talk. This research was supported in part by a Ramanujan Fellowship from the Department of Science and Technology, Government of India.  References  Shivani Agarwal, Thore Graepel, Ralf Herbrich, Sariel Har-Peled, and Dan Roth. General- ization bounds for the area under the ROC curve. Journal of Machine Learning Research, 6:393-425, 2005.  Nir Ailon and Mehryar Mohri. An e\ufb03cient reduction of ranking to classification. In Pro-  ceedings of the 21st Annual Conference on Learning Theory, 2008.  Maria-Florina Balcan, Nikhil Bansal, Alina Beygelzimer, Don Coppersmith, John Lang- ford, and Gregory B. Sorkin. Robust reductions from ranking to classification. Machine Learning, 72:139-153, 2008.  Peter Bartlett, Michael Jordan, and Jon McAuli\ufb00e. Convexity, classification and risk  bounds. Journal of the American Statistical Association, 101(473):138-156, 2006.  David Bu\ufb00oni, Cl\u00b4ement Calauzenes, Patrick Gallinari, and Nicolas Usunier. Learning scor- ing functions with order-preserving losses and standardized supervision. In Proceedings of the 28th International Conference on Machine Learning, 2011.  Andreas Buja, Werner Stuetzle, and Yi Shen. Loss functions for binary class probability estimation: Structure and applications. Technical report, University of Pennsylvania, November 2005.  C. J. C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullen- der. Learning to rank using gradient descent. In Proceedings of the 22nd International Conference on Machine Learning, 2005.  Cl\u00b4ement Calauz`enes, Nicolas Usunier, and Patrick Gallinari. On the (non-)existence of con- vex, calibrated surrogate losses for ranking. In Advances in Neural Information Processing Systems 25, pages 197-205. 2012.  St\u00b4ephan Cl\u00b4emen\u00b8con, Gabor Lugosi, and Nicolas Vayatis. Ranking and empirical minimiza-  tion of U-statistics. Annals of Statistics, 36:844-874, 2008.  St\u00b4ephan Cl\u00b4emen\u00b8con and Sylvain Robbiano. Minimax learning rates for bipartite ranking and plug-in rules. In Proceedings of the 28th International Conference on Machine Learning, 2011.  St\u00b4ephan Cl\u00b4emen\u00b8con and Nicolas Vayatis. Ranking the best instances. Journal of Machine  Learning Research, 8:2671-2699, 2007. Agarwal  Corinna Cortes and Mehryar Mohri. AUC optimization vs. error rate minimization.  In Sebastian Thrun, Lawrence Saul, and Bernhard Sch\u00a8olkopf, editors, Advances in Neural Information Processing Systems 16. MIT Press, Cambridge, MA, 2004.  David Cossock and Tong Zhang. Statistical analysis of Bayes optimal subset ranking. IEEE  Transactions on Information Theory, 54(11):5140-5154, 2008.  John Duchi, Lester Mackey, and Michael I. Jordan. On the consistency of ranking algo- rithms. In Proceedings of the 27th International Conference on Machine Learning, 2010.  Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram Singer. An e\ufb03cient boosting al- gorithm for combining preferences. Journal of Machine Learning Research, 4:933-969, 2003.  Tilmann Gneiting and Adrian E. Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477):359-378, 2007.  A. D. Hendrickson and R. J. Buehler. Proper scores for probability forecasters. The Annals  of Mathematical Statistics, 42:1916-1921, 1971.  R. Herbrich, T. Graepel, and K. Obermayer. Large margin rank boundaries for ordinal  regression. Advances in Large Margin Classifiers, pages 115-132, 2000.  T. Joachims. Optimizing search engines using clickthrough data. In Proceedings of the 8th  ACM Conference on Knowledge Discovery and Data Mining, 2002.  Wojciech Kotlowski, Krzysztof Dembczynski, and Eyke Huellermeier. Bipartite ranking through minimization of univariate loss. In Proceedings of the 28th International Confer- ence on Machine Learning, 2011.  Yanyan Lan, Jiafeng Guo, Xueqi Cheng, and Tie-Yan Liu. Statistical consistency of ranking methods in a rank-di\ufb00erentiable probability space. In Advances in Neural Information Processing Systems 25, pages 1241-1249. 2012.  A. Rakotomamonjy. Optimizing area under ROC curves with SVMs. In Proceedings of the  ECAI-2004 Workshop on ROC Analysis in AI, 2004.  Pradeep Ravikumar, Ambuj Tewari, and Eunho Yang. On NDCG consistency of listwise ranking methods. In Proceedings of the 14th International Conference on Artificial Intel- ligence and Statistics, 2010, volume 15 of JMLR Workshop and Conference Proceedings, pages 618-626, 2011.  Mark D. Reid and Robert C. Williamson. Surrogate regret bounds for proper losses. In  Proceedings of the 26th International Conference on Machine Learning, 2009.  Mark D. Reid and Robert C. Williamson. Composite binary losses. Journal of Machine  Learning Research, 11:2387-2422, 2010.  Mark D. Reid and Robert C. Williamson.  Information, divergence and risk for binary  experiments. Journal of Machine Learning Research, 12:731-817, 2011. AUC Regret Bounds via Strongly Proper Losses  Cynthia Rudin and Robert E. Schapire. Margin-based ranking and an equivalence between AdaBoost and RankBoost. Journal of Machine Learning Research, 10:2193-2232, 2009.  Leonard J. Savage. Elicitation of personal probabilities and expectations. Journal of the  American Statistical Association, 66(336):783-801, 1971.  M. J. Schervish. A general method for comparing probability assessors. The Annals of  Statistics, 17:1856-1879, 1989.  Alexandre B. Tsybakov. Optimal aggregation of classifiers in statistical learning. The  Annals of Statistics, 32(1):135-166, 2004.  Kazuki Uematsu and Yoonkyung Lee. On theoretically optimal ranking functions in bipar- tite ranking. Technical Report 863, Department of Statistics, The Ohio State University, December 2011.  Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, and Hang Li. Listwise approach to learning to rank: Theory and algorithm. In Proceedings of the 25th International Con- ference on Machine Learning, 2008.  Tong Zhang. Statistical behavior and consistency of classification methods based on convex  risk minimization. The Annals of Statistics, 32(1):56-134, 2004.  "}, "Algorithms and Hardness for Robust Subspace Recovery": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Algorithms and Hardness for Robust Subspace Recovery", "abstract": "We consider a fundamental problem in unsupervised learning called subspace recovery: given a collection of m points in R^n, if many but not necessarily all of these points are contained in a d-dimensional subspace T can we find it? The points contained in T are called  inliers and the remaining points are  outliers. This problem has received considerable attention in computer science and in statistics. Yet efficient algorithms from computer science are not robust to  adversarial outliers, and the estimators from robust statistics are hard to compute in high dimensions. This is a serious and persistent issue not just in this application, but for many other problems in unsupervised learning. Are there algorithms for subspace recovery that are both robust to outliers and efficient?  We give an algorithm that finds T when it contains more than a d/n fraction of the points.  Hence, for say d = n/2 this estimator is both easy to compute and well-behaved when there are a constant fraction of outliers. We prove that it is small set expansion hard to find T when the fraction of errors is any larger and so our estimator is an  optimal compromise between efficiency and robustness. In fact, this basic problem has a surprising number of connections to other areas including small set expansion, matroid theory and functional analysis that we make use of here.", "pdf_url": "http://proceedings.mlr.press/v30/Hardt13.pdf", "keywords": ["robust statistics", "unique games conjecture", "principal component analysis", "subspace recovery"], "reference": "335-361, 1998.  F. Barthe. On a reverse form of the Brascamp-Lieb inequality.  Invent. Math., 134(2):  H. J. Brascamp and E. H. Lieb. Best constants in Young\u2019s inequality, its converse, and its generalization to more than three functions. Advances in Math., 20(2):151-173, 1976.  E. Candes and B. Recht. Exact matrix completion via convex optimization. Foundations  of Comp. Math., pages 717-772, 2009.  E. Candes, X. Li, Y. Ma, and J. Wright. Robust principal component analysis? Journal of  the ACM, 2011.  E. Carlen and D. Cordero-Erausquin. Subadditivity of the entropy and its relation to brascamp-lieb type inequalities. Geometric and Functional Analysis, 19(2):373-405, 2009.  E. Carlen, E. H. Lieb, and M. Loss. A sharp analog of Young\u2019s inequality on SN and related  entropy inequalities. J. Geom. Anal., 14(3):487-520, 2004.  V. Chandrasekaran, S. Sanghavi, P. Parrilo, and A. Willsky. Rank-sparsity incoherence for  matrix decomposition. SIAM J. Optim., pages 572-596, 2011.  W. Cunningham. Testing membership in matroid polyhedra. J. Combin. Theory Ser. B,  pages 161-188, 1984.  A. Deshpande, M. Tulsiani, and N. Vishnoi. Algorithms and hardness for subspace approx-  imation. SODA, pages 482-496, 2011.  D. Donoho and P. Huber. The notion of breakdown point. A Festshrift for Erich L.  Lehmann, pages 157-184, 1983.  J. Dunagan and S. Vempala. Optimal outlier removal in high-dimensional spaces. J. Com-  put. Syst. Sci., pages 335-373, 2000.  H. Edelsbrunner and D. Souvaine. Computing median-of-squares regression lines and guided  topological sweep. Journal of the Amer. Stat. Assoc., pages 115-119, 1990.  J. Edmonds. Submodular functions, matroids, and certain polyhedra. In Combinatorial  Structures, pages 69-87. 1970.  M. Fischler and R. Bolles. Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM, pages 381-395, 1981.  M. Gr\u00b4otschel, L. Lov\u00b4asz, and A. Schrijver. The ellipsoid method and its consequences in  combinatorial optimization. Combinatorica, pages 169-197, 1981.  V. Guruswami and P. Raghavendra. Hardness of solving sparse overdetermined linear sys- tems: A. pages 1-20, 2009. 3-query PCP over integers. ACM Trans. Comput. Theory.  13   Subspaces with Outliers  References  335-361, 1998.  F. Barthe. On a reverse form of the Brascamp-Lieb inequality.  Invent. Math., 134(2):  H. J. Brascamp and E. H. Lieb. Best constants in Young\u2019s inequality, its converse, and its generalization to more than three functions. Advances in Math., 20(2):151-173, 1976.  E. Candes and B. Recht. Exact matrix completion via convex optimization. Foundations  of Comp. Math., pages 717-772, 2009.  E. Candes, X. Li, Y. Ma, and J. Wright. Robust principal component analysis? Journal of  the ACM, 2011.  E. Carlen and D. Cordero-Erausquin. Subadditivity of the entropy and its relation to brascamp-lieb type inequalities. Geometric and Functional Analysis, 19(2):373-405, 2009.  E. Carlen, E. H. Lieb, and M. Loss. A sharp analog of Young\u2019s inequality on SN and related  entropy inequalities. J. Geom. Anal., 14(3):487-520, 2004.  V. Chandrasekaran, S. Sanghavi, P. Parrilo, and A. Willsky. Rank-sparsity incoherence for  matrix decomposition. SIAM J. Optim., pages 572-596, 2011.  W. Cunningham. Testing membership in matroid polyhedra. J. Combin. Theory Ser. B,  pages 161-188, 1984.  A. Deshpande, M. Tulsiani, and N. Vishnoi. Algorithms and hardness for subspace approx-  imation. SODA, pages 482-496, 2011.  D. Donoho and P. Huber. The notion of breakdown point. A Festshrift for Erich L.  Lehmann, pages 157-184, 1983.  J. Dunagan and S. Vempala. Optimal outlier removal in high-dimensional spaces. J. Com-  put. Syst. Sci., pages 335-373, 2000.  H. Edelsbrunner and D. Souvaine. Computing median-of-squares regression lines and guided  topological sweep. Journal of the Amer. Stat. Assoc., pages 115-119, 1990.  J. Edmonds. Submodular functions, matroids, and certain polyhedra. In Combinatorial  Structures, pages 69-87. 1970.  M. Fischler and R. Bolles. Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM, pages 381-395, 1981.  M. Gr\u00b4otschel, L. Lov\u00b4asz, and A. Schrijver. The ellipsoid method and its consequences in  combinatorial optimization. Combinatorica, pages 169-197, 1981.  V. Guruswami and P. Raghavendra. Hardness of solving sparse overdetermined linear sys- tems: A. pages 1-20, 2009. 3-query PCP over integers. ACM Trans. Comput. Theory. Hardt Moitra  V. Guruswami, P. Raghavendra, R. Saket, and Y. Wu. Bypassing UGC for some optimal  geometric inapproximability results. SODA, pages 699-717, 2012.  P. Huber. Robust Statistics. 1981. John Wiley & Sons.  S. Iwata, L. Fleischer, and S. Fujishige. A combinatorial strongly polynomial time algorithm  for minimizing submodular functions. JACM, pages 761-777, 2001.  V. Kabanets and R. Impagliazzo. Constructive proofs of concentration bounds. APPROX-  RANDOM, pages 617-631, 2010.  L. Khachiyan. On the complexity of approximating extremal determinants in matrices.  Journal of Complexity, pages 138-153, 1995.  S. Khot and D. Moshkovitz. Hardness of approximately solving linear equations over the  reals. STOC, pages 413-420, 2011.  P. Lax. Linear algebra. 2007. Wiley Interscience.  G. Lerman, M. McCoy, J. Tropp, and T. Zhang. Robust computation of linear models, or  how to find a needle in a haystack. Arxiv, 2012. .  J. Matousek. Lectures on Discrete Geometry. 2002. Springer-Verlag New York, Inc.  A. Naor, O. Regev, and T. Vidick. E\ufb03cient rounding for the noncommutative grothendieck  inequality. STOC, 2013.  A. Nemirovski. Lectures on modern convex optimization. 2005.  http://www2.isye.gatech.edu/~nemirovs/.  P. Raghavendra and D. Steurer. Graph expansion and the unique games conjecture. STOC,  pages 755-764, 2010.  P. Raghavendra, D. Steurer, and M. Tulsiani. Reductions between expansion problems.  Electronic Colloquium on Computational Complexity (ECCC), 2010. 17:172.  B. Recht, M. Fazel, and P. Parrilo. Guaranteed minimum rank solutions of matrix equations  via nuclear norm minimization. SIAM Rev., pages 471-501, 2010.  P. Rousseeuw. Least median squares regression. Journal of the Amer. Stat. Assoc., pages  871-880, 1984.  Sons.  P. Rousseeuw and A. Leroy. Robust Regression and Outlier Detection. 1987. John Wiley &  A. Schrijver. A combinatorial algorithm for minimizing submodular functions in strongly  polynomial time. J. Combin. Theory Ser. B, pages 346-355, 2000.  M. Soltanolkotabi and E. Candes. A geometric analysis of subspace clustering with outliers.  Ann. of Stat., pages 2195-2238, 2012. Subspaces with Outliers  S. Vempala. The joy of PCA. 2010.  http://www.cc.gatech.edu/events/cse-seminar-santosh-vempala-0.  H. Xu, C. Carmanis, and S. Sanghavi. Robust PCA via outlier pursuit.  IEEE Trans.  Inform. Theory, pages 1-24, 2010.  H. Xu, C. Caramanis, and S. Mannor. Outlier-robust PCA: The high-dimensional case.  IEEE Transactions on Information Theory, 59(1):546-572, 2013.  T. Zhang and G. Lerman. A novel m-estimator for robust pca. Arxiv, 2011.  "}, "PLAL: Cluster-based active learning": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "PLAL: Cluster-based active learning", "abstract": "We investigate the label complexity of active learning under some smoothness assumptions on the data-generating process.We propose a procedure, PLAL, for \u201cactivising\u201d passive, sample-based learners. The procedure takes an unlabeledsample, queries the labels of some of its members, and outputs a full labeling of that sample. Assuming the data satisfies \u201cProbabilistic Lipschitzness\u201d, a notion of clusterability, we show that for several common learning paradigms, applying our procedure as a preprocessing leads to provable label complexity reductions (over any \u201cpassive\u201dlearning algorithm, under the same data assumptions). Our labeling procedure is simple and easy to implement. We complement our theoretical findings with experimental validations.", "pdf_url": "http://proceedings.mlr.press/v30/Urner13.pdf", "keywords": ["learning theory", "agnostic active learning", "label complexity"], "reference": "Maria-Florina Balcan, Andrei Z. Broder, and Tong Zhang. Margin based active learning.  In COLT, pages 35-50, 2007.  Maria-Florina Balcan, Steve Hanneke, and Jennifer Wortman Vaughan. The true sample  complexity of active learning. Machine Learning, 80(2-3):111-139, 2010.  Shai Ben-David, Alon Itai, and Eyal Kushilevitz. Learning by distances. In COLT, pages  232-245, 1990.  Alina Beygelzimer, Sanjoy Dasgupta, and John Langford.  Importance weighted active  learning. In ICML, page 7, 2009.  Alina Beygelzimer, Daniel Hsu, John Langford, and Tong Zhang. Agnostic active learning  without constraints. In NIPS, pages 199-207, 2010.  Avrim Blum, Alan M. Frieze, Ravi Kannan, and Santosh Vempala. A polynomial-time algorithm for learning noisy linear threshold functions. Algorithmica, 22(1/2):35-52, 1998.  Sanjoy Dasgupta. Analysis of a greedy active learning strategy. In NIPS, 2004.  Sanjoy Dasgupta. Coarse sample complexity bounds for active learning. In NIPS, 2005.  Sanjoy Dasgupta. Two faces of active learning. Theor. Comput. Sci., 412(19):1767-1781,  2011.  208-215, 2008.  Sanjoy Dasgupta and Daniel Hsu. Hierarchical sampling for active learning. In ICML, pages  Sanjoy Dasgupta, Daniel Hsu, and Claire Monteleoni. A general agnostic active learning  algorithm. In ISAIM, 2008.  Vitaly Feldman, Elena Grigorescu, Lev Reyzin, Santosh Vempala, and Ying Xiao. Statistical algorithms and a lower bound for detecting planted cliques. STOC 2013, to appear, 2013.  Alon Gonen, Sivan Sabato, and Shai Shalev-Shwartz. Active learning halfspaces under  margin assumptions. CoRR, abs/1112.1556, 2011.  Steve Hanneke. A bound on the label complexity of agnostic active learning. In ICML,  pages 353-360, 2007.  Steve Hanneke. Activized learning: Transforming passive to active with improved label complexity. Journal of Machine Learning Research (JMLR), 13(May):14691587, 2012.  Matti K\u00a8a\u00a8ari\u00a8ainen. Active learning in the non-realizable case. In ALT, pages 63-77, 2006.  Michael J. Kearns. E\ufb03cient noise-tolerant learning from statistical queries. In STOC, pages  392-401, 1993.  14   Urner Wulff Ben-David  References  Maria-Florina Balcan, Andrei Z. Broder, and Tong Zhang. Margin based active learning.  In COLT, pages 35-50, 2007.  Maria-Florina Balcan, Steve Hanneke, and Jennifer Wortman Vaughan. The true sample  complexity of active learning. Machine Learning, 80(2-3):111-139, 2010.  Shai Ben-David, Alon Itai, and Eyal Kushilevitz. Learning by distances. In COLT, pages  232-245, 1990.  Alina Beygelzimer, Sanjoy Dasgupta, and John Langford.  Importance weighted active  learning. In ICML, page 7, 2009.  Alina Beygelzimer, Daniel Hsu, John Langford, and Tong Zhang. Agnostic active learning  without constraints. In NIPS, pages 199-207, 2010.  Avrim Blum, Alan M. Frieze, Ravi Kannan, and Santosh Vempala. A polynomial-time algorithm for learning noisy linear threshold functions. Algorithmica, 22(1/2):35-52, 1998.  Sanjoy Dasgupta. Analysis of a greedy active learning strategy. In NIPS, 2004.  Sanjoy Dasgupta. Coarse sample complexity bounds for active learning. In NIPS, 2005.  Sanjoy Dasgupta. Two faces of active learning. Theor. Comput. Sci., 412(19):1767-1781,  2011.  208-215, 2008.  Sanjoy Dasgupta and Daniel Hsu. Hierarchical sampling for active learning. In ICML, pages  Sanjoy Dasgupta, Daniel Hsu, and Claire Monteleoni. A general agnostic active learning  algorithm. In ISAIM, 2008.  Vitaly Feldman, Elena Grigorescu, Lev Reyzin, Santosh Vempala, and Ying Xiao. Statistical algorithms and a lower bound for detecting planted cliques. STOC 2013, to appear, 2013.  Alon Gonen, Sivan Sabato, and Shai Shalev-Shwartz. Active learning halfspaces under  margin assumptions. CoRR, abs/1112.1556, 2011.  Steve Hanneke. A bound on the label complexity of agnostic active learning. In ICML,  pages 353-360, 2007.  Steve Hanneke. Activized learning: Transforming passive to active with improved label complexity. Journal of Machine Learning Research (JMLR), 13(May):14691587, 2012.  Matti K\u00a8a\u00a8ari\u00a8ainen. Active learning in the non-realizable case. In ALT, pages 63-77, 2006.  Michael J. Kearns. E\ufb03cient noise-tolerant learning from statistical queries. In STOC, pages  392-401, 1993. PLAL  Michael J. Kearns. E\ufb03cient noise-tolerant learning from statistical queries. J. ACM, 45(6):  983-1006, 1998.  Ingo Steinwart and Andreas Christmann. Support Vector Machines. Springer Publishing  Company, Incorporated, 1st edition, 2008. ISBN 0387772413.  Ingo Steinwart and Clint Scovel. Fast rates for support vector machines. 35(2):575-607,  2007.  Ruth Urner, Shai Ben-David, and Shai Shalev-Shwartz. Unlabeled data can speed up prediction time. Supplementay Material, 2011a. URL http://www.cs.uwaterloo.ca/ ~rurner/SupplementICML2011.pdf.  Ruth Urner, Shai Ben-David, and Shai Shalev-Shwartz. Unlabeled data can speed up  prediction time. In ICML, 2011b.  Nakul Verma, Samory Kpotufe, and Sanjoy Dasgupta. Which spatial partition trees are  adaptive to intrinsic dimension? CoRR, abs/1205.2609, 2012.  "}, "Learning Using Local Membership Queries": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Learning Using Local Membership Queries", "abstract": "We introduce a new model of membership query (MQ) learning, where the learning algorithm is restricted to query points that are close to random examples drawn from the underlying distribution. The learning model is intermediate between the PAC model (Valiant,1984) and the PAC+MQ model (where the queries are allowed to be arbitrary points). Membership query algorithms are not popular among machine learning practitioners. Apart from the obvious difficulty of adaptively querying labellers, it has also been observed that querying unnatural points leads to increased noise from human labellers (Lang and Baum, 1992). This motivates our study of learning algorithms that make queries that are close to examples generated from the data distribution. We restrict our attention to functions defined on the n-dimensional Boolean hypercube and say that a membership query is local if its Hamming distance from some example in the (random) training data is at most O(log(n)). We show the following results in this model:  \\beginenumerate \\item The class of sparse polynomials (with coefficients in R) over {0, 1}^n is polynomial time learnable under a large class of locally smooth distributions using O(log(n))-local queries. This class also includes the class of O(log(n))-depth decision trees.  \\item The class of polynomial-sized decision trees is polynomial time learnable under product distributions using O(log(n))-local queries.  \\item The class of polynomial size DNF formulas is learnable under the uniform distribution using O(log(n))-local queries in time n^O(log(log(n))).  \\item In addition we prove a number of results relating the proposed model to the traditional PAC model and the PAC+MQ model. \\endenumerate", "pdf_url": "http://proceedings.mlr.press/v30/Awasthi13.pdf", "keywords": ["PAC learning", "membership queries", "decision trees", "DNF"], "reference": "D. Aldous and U. Vazirani. A markovian extension of valiant\u2019s learning model. In Proceed-  ings of the 31st Annual Symposium on Foundations of Computer Science, 1990.  D. Angluin. Queries and concept learning. Machine Learning, 2:319-342, 1988.  Dana Angluin. Learning regular sets from queries and counterexamples. Inf. Comput., 75  (2):87-106, 1987.  values. In STOC, 2006.  Dana Angluin, James Aspnes, Jiang Chen, and Wu Yinghua. Learning a circuit by injecting  A. Blum, A. Kalai, and H. Wasserman. Noise-tolerant learning, the parity problem, and  the statistical query model. Journal of the ACM, 50(4):506-519, 2003.  Avrim Blum, Prasad Chalasani, Sally A. Goldman, and Donna K. Slonim. Learning with  unreliable boundary queries. J. Comput. Syst. Sci., 56, April 1998.  Avrim Blum, Merrick Furst, Je\ufb00rey Jackson, Michael Kearns, Yishay Mansour, and Steven Rudich. Weakly learning dnf and characterizing statistical query learning using fourier analysis. In Proceedings of the twenty-sixth annual ACM symposium on Theory of com- puting, STOC \u201994, 1994.  R. C. Bose and D. K. Ray-Chaudhuri. On a class of error correcting binary group codes.  Information and Control, 3(1):68-79, 1960.  Nader H. Bshouty. Exact learning via the monotone theory (extended abstract). In FOCS,  1993.  Nader H. Bshouty, Elchanan Mossel, Ryan O\u2019Donnell, and Rocco A. Servedio. Learning  dnf from random walks. J. Comput. Syst. Sci., 71, October 2005.  Z. Dvir, A. Rao, A. Wigderson, and A. Yehudayo\ufb00. Restriction access. In ITCS, 2012.  Dan Feldman and Leonard J. Schulman. Data reduction for weighted and outlier-resistant clustering. In Proceedings of the Twenty-Third Annual ACM-SIAM Symposium on Dis- crete Algorithms, SODA \u201912, 2012.  V. Feldman. Learning dnf expressions from fourier spectrum. In COLT, 2012.  V. Feldman, P. Gopalan, S. Khot, and A. Ponnuswami. New results for learning noisy  parities and halfspaces. In FOCS, 2006.  Vitaly Feldman. On the power of membership queries in agnostic learning. In COLT, 2008.  Vitaly Feldman. Distribution-specific agnostic boosting. In ICS, 2010.  Oded Goldreich, Shafi Goldwasser, and Silvio Micali. How to construct random functions. J. ACM, 33:792-807, 1986. ISSN 0004-5411. URL http://doi.acm.org/10.1145/6490. 6503.  13   Learning using Local Membership Queries  References  D. Aldous and U. Vazirani. A markovian extension of valiant\u2019s learning model. In Proceed-  ings of the 31st Annual Symposium on Foundations of Computer Science, 1990.  D. Angluin. Queries and concept learning. Machine Learning, 2:319-342, 1988.  Dana Angluin. Learning regular sets from queries and counterexamples. Inf. Comput., 75  (2):87-106, 1987.  values. In STOC, 2006.  Dana Angluin, James Aspnes, Jiang Chen, and Wu Yinghua. Learning a circuit by injecting  A. Blum, A. Kalai, and H. Wasserman. Noise-tolerant learning, the parity problem, and  the statistical query model. Journal of the ACM, 50(4):506-519, 2003.  Avrim Blum, Prasad Chalasani, Sally A. Goldman, and Donna K. Slonim. Learning with  unreliable boundary queries. J. Comput. Syst. Sci., 56, April 1998.  Avrim Blum, Merrick Furst, Je\ufb00rey Jackson, Michael Kearns, Yishay Mansour, and Steven Rudich. Weakly learning dnf and characterizing statistical query learning using fourier analysis. In Proceedings of the twenty-sixth annual ACM symposium on Theory of com- puting, STOC \u201994, 1994.  R. C. Bose and D. K. Ray-Chaudhuri. On a class of error correcting binary group codes.  Information and Control, 3(1):68-79, 1960.  Nader H. Bshouty. Exact learning via the monotone theory (extended abstract). In FOCS,  1993.  Nader H. Bshouty, Elchanan Mossel, Ryan O\u2019Donnell, and Rocco A. Servedio. Learning  dnf from random walks. J. Comput. Syst. Sci., 71, October 2005.  Z. Dvir, A. Rao, A. Wigderson, and A. Yehudayo\ufb00. Restriction access. In ITCS, 2012.  Dan Feldman and Leonard J. Schulman. Data reduction for weighted and outlier-resistant clustering. In Proceedings of the Twenty-Third Annual ACM-SIAM Symposium on Dis- crete Algorithms, SODA \u201912, 2012.  V. Feldman. Learning dnf expressions from fourier spectrum. In COLT, 2012.  V. Feldman, P. Gopalan, S. Khot, and A. Ponnuswami. New results for learning noisy  parities and halfspaces. In FOCS, 2006.  Vitaly Feldman. On the power of membership queries in agnostic learning. In COLT, 2008.  Vitaly Feldman. Distribution-specific agnostic boosting. In ICS, 2010.  Oded Goldreich, Shafi Goldwasser, and Silvio Micali. How to construct random functions. J. ACM, 33:792-807, 1986. ISSN 0004-5411. URL http://doi.acm.org/10.1145/6490. 6503. Awasthi Feldman Kanade  A. Hocquenghem. Codes correcteurs d\u2019erreurs (in french). Chi\ufb00res, 2:147-156, 1959.  J. Jackson. An e\ufb03cient membership-query algorithm for learning DNF with respect to the  uniform distribution. Journal of Computer and System Sciences, 55:414-440, 1997.  Je\ufb00rey C. Jackson and Karl Wimmer. New results for random walk learning. In COLT,  Adam Kalai and Varun Kanade. Potential-based agnostic boosting. In NIPS, 2009.  Adam Kalai, Varun Kanade, and Yishay Mansour. Reliable agnostic learning. In COLT,  2009.  2009a.  Adam Tauman Kalai, Alex Samorodnitsky, and Shang-Hua Teng. Learning and smoothed  analysis. In FOCS, 2009b.  Vladlen Koltun and Christos H. Papadimitriou. Approximately dominating representatives.  Theor. Comput. Sci., 371(3), February 2007.  E. Kushilevitz and Y. Mansour. Learning decision trees using the Fourier spectrum. SIAM  Journal on Computing, 22(6):1331-1348, 1993.  K. Lang and E. Baum. Query learning can work poorly when a human oracle is used. IEEE  Intl. Joint Conference on Neural Networks, 1992.  L. Levin. Randomness and non-determinism. Journal of Symbolic Logic, 58(3):1102-1103,  Y. Mansour. An o(nlog log n) learning algorithm for dnf under the uniform distribution. In  Yishay Mansour. Learning boolean functions via the fourier transform. Survey, 1994.  J. Massey. Shift-register synthesis and BCH decoding. IEEE Trans. Inform. Theory, 15:  Robert E. Schapire and Linda M. Sellie. Learning sparse multivariate polynomials over a  field with queries and counterexamples. In COLT, pages 17-26, 1996.  Rocco A. Servedio. Smooth boosting and learning with malicious noise. J. Mach. Learn. Res., 4:633-648, December 2003. ISSN 1532-4435. URL http://dx.doi.org/10.1162/ 153244304773936072.  Daniel A. Spielman and Shang-Hua Teng. Smoothed analysis of algorithms: Why the  simplex algorithm usually takes polynomial time. J. ACM, 51(3), 2004.  L. G. Valiant. A theory of the learnable. In STOC, 1984.  1993.  COLT, 1992.  122-127, 1969. Learning using Local Membership Queries  "}, "Sparse Adaptive Dirichlet-Multinomial-like Processes": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Sparse Adaptive Dirichlet-Multinomial-like Processes", "abstract": "Online estimation and modelling of i.i.d. data for shortsequences over large or complex \u201calphabets\u201d is a ubiquitous (sub)problem in machine learning, information theory, data compression, statistical language processing, and document analysis. The Dirichlet-Multinomial distribution (also called Polya urn scheme) and extensions thereof are widely applied for online i.i.d. estimation. Good a-priori choices for the parameters in this regime are difficult to obtain though. I derive an optimal adaptive choice for the main parameter via tight, data-dependent redundancy bounds for a related model. The 1-line recommendation is to set the \u2019total mass\u2019 = \u2019precision\u2019 = \u2019concentration\u2019 parameter to m/[2\\ln\\fracn+1m], where n is the (past) sample size and m the number of different symbols observed (so far). The resulting estimator is simple, online, fast,and experimental performance is superb.", "pdf_url": "http://proceedings.mlr.press/v30/Hutter13.pdf", "keywords": ["sparse coding", "adaptive parameters", "Dirichlet-Multinomial", "Polya urn", "datadependent redundancy bound", "small/large alphabet", "data compression"], "reference": "T. Bayes. An essay towards solving a problem in the doctrine of chances. Philosophi- cal Transactions of the Royal Society, 53:370\u2013418, 1763. doi: 10.1098/rstl.1763.0053. [Reprinted in Biometrika, 45, 296\u2013315, 1958].  R. Begleiter and R. El-Yaniv. Superior guarantees for sequential prediction and lossless com- pression via alphabet decomposition. Journal of Machine Learning Research, 7:379411, 2006.  J. M. Bernardo. Reference posterior distributions for Bayesian inference (with discussion).  Journal of the Royal Statistical Society, B41:113\u2013147, 1979.  C. M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006.  13   Sparse Adaptive Dirichlet-Multinomial-like Processes  8. Conclusion  I introduced and analyzed a model, closely related to the Dirichlet-multinomial distribution, which predicts an Old symbol with its past frequency scaled down by t t+\u03b2 and a new symbol with its weight, scaled down by \u03b2 t+\u03b2 . Natural weight choices are uniform and 2\u2212CodeLength. I derived exact expressions and for small m rather tight bounds for the code length and redundancy. The bounds were data-dependent rather then expected or worst-case bounds. This led to an (approximately) optimal choice of \u03b2 di\ufb00erent from traditional recommendations. The constant o\ufb04ine \u03b2\u2217 (16) depends on the total sequence length n and number of di\ufb00erent used symbols m. The variable online (cid:126)\u03b2\u2217 (21) depends on the current sequence length t and number of di\ufb00erent symbols observed so far mt.  The redundancy bounds additionally depend on the individual symbol counts ni them- selves. They show that S\u03b2\u2217 has (at most) zero redundancy for unused symbols and finite redundancy for symbols occurring only finitely often, unlike the KT estimator and compan- ions which have redundancy 1 2 lnn+O(1) per base symbol, whether it occurs or not. Indeed, my bounds are independent of the base alphabet size D, therefore also hold for denumerable and with suitable reinterpretation for continuous X .  There seems to be not much leeway in choosing a globally good \u03b2. Experimentally it seems that even slight changes in \u03b2\u2217 can significantly deteriorate performance in some (m,n,D)-regime, but can only marginally and locally improve performance in others. Empir- ically S (cid:126)\u03b2\u2217 seems superior to the other fast online estimators I compared it to. See "}, "Prediction by random-walk perturbation": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Prediction by random-walk perturbation", "abstract": "We propose a version of the follow-the-perturbed-leader online prediction algorithm in which the cumulative losses are perturbed by independent symmetric random walks. The forecaster is shown to achieve an expected regret of the optimal order O(\\sqrtn \\log N) where n is the time horizon and N is the number of experts. More importantly, it is shown that the forecaster changes its prediction at most O(\\sqrtn \\log N) times, in expectation. We also extend the analysis to online combinatorial optimization and show that even in this more general setting, the forecaster rarely switches between experts while having a regret of near-optimal order.", "pdf_url": "http://proceedings.mlr.press/v30/Devroye13.pdf", "keywords": ["Online learning", "Online combinatorial optimization", "Follow the Perturbed Leader", "Random walk"], "reference": "J. Y. Audibert, S. Bubeck, and G. Lugosi. Minimax policies for combinatorial prediction games. In Conference on Learning Theory, 2011. URL http://arxiv.org/abs/1105. 4871.  J. Y. Audibert, S. Bubeck, and G. Lugosi. Regret in online combinatorial optimization.  Manuscript, 2012. URL http://arxiv.org/abs/1204.4710.  S. Boucheron, G. Lugosi, and P. Massart. Concentration inequalities: A Nonasymptotic  Theory of Independence. Oxford University Press, 2013.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, New York, NY, USA, 2006.  N. Cesa-Bianchi and G. Lugosi. Combinatorial bandits. Journal of Computer and System  Sciences, 78:1404-1422, 2012.  E. Even-Dar, S. Kakade, and Y. Mansour. Online Markov decision processes. Mathematics of Operations Research, 34(3):726-736, 2009. ISSN 0364-765X. doi: http://dx.doi.org/ 10.1287/moor.1090.0396.  W. Feller. An Introduction to Probability Theory and its Applications, Vol. 1. John Wiley,  New York, 1968.  Y. Freund and R. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55:119-139, 1997.  C. Gentile and M. Warmuth. Linear hinge loss and average margin. In Advances in Neural  Information Processing Systems (NIPS), pages 225-231, 1998.  S. Geulen, B. Voecking, and M. Winkler. Regret minimization for online bu\ufb00ering problems using the weighted majority algorithm. In Proceedings of the Twenty-Third Conference on Computational Learning Theory, pages 132-143, 2010.  A. Grove, N. Littlestone, and D. Schuurmans. General convergence results for linear dis-  criminant updates. Machine Learning, 43:173-210, 2001.  A. Gy\u00a8orgy and G. Neu. Near-optimal rates for limited-delay universal lossy source coding. In Proceedings of the IEEE International Symposium on Information Theory (ISIT), pages 2344-2348, 2011.  J. Hannan. Approximation to Bayes risk in repeated play. Contributions to the theory of  games, 3:97-139, 1957.  E. Hazan, S. Kale, and M. Warmuth. Learning rotations with little regret. In Proceedings  of the 23rd Annual Conference on Learning Theory (COLT), pages 144-154, 2010.  D. P. Helmbold and M. Warmuth. Learning permutations with exponential weights. Journal  of Machine Learning Research, 10:1705-1736, 2009.  13   Prediction by random-walk perturbation  References  J. Y. Audibert, S. Bubeck, and G. Lugosi. Minimax policies for combinatorial prediction games. In Conference on Learning Theory, 2011. URL http://arxiv.org/abs/1105. 4871.  J. Y. Audibert, S. Bubeck, and G. Lugosi. Regret in online combinatorial optimization.  Manuscript, 2012. URL http://arxiv.org/abs/1204.4710.  S. Boucheron, G. Lugosi, and P. Massart. Concentration inequalities: A Nonasymptotic  Theory of Independence. Oxford University Press, 2013.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, New York, NY, USA, 2006.  N. Cesa-Bianchi and G. Lugosi. Combinatorial bandits. Journal of Computer and System  Sciences, 78:1404-1422, 2012.  E. Even-Dar, S. Kakade, and Y. Mansour. Online Markov decision processes. Mathematics of Operations Research, 34(3):726-736, 2009. ISSN 0364-765X. doi: http://dx.doi.org/ 10.1287/moor.1090.0396.  W. Feller. An Introduction to Probability Theory and its Applications, Vol. 1. John Wiley,  New York, 1968.  Y. Freund and R. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55:119-139, 1997.  C. Gentile and M. Warmuth. Linear hinge loss and average margin. In Advances in Neural  Information Processing Systems (NIPS), pages 225-231, 1998.  S. Geulen, B. Voecking, and M. Winkler. Regret minimization for online bu\ufb00ering problems using the weighted majority algorithm. In Proceedings of the Twenty-Third Conference on Computational Learning Theory, pages 132-143, 2010.  A. Grove, N. Littlestone, and D. Schuurmans. General convergence results for linear dis-  criminant updates. Machine Learning, 43:173-210, 2001.  A. Gy\u00a8orgy and G. Neu. Near-optimal rates for limited-delay universal lossy source coding. In Proceedings of the IEEE International Symposium on Information Theory (ISIT), pages 2344-2348, 2011.  J. Hannan. Approximation to Bayes risk in repeated play. Contributions to the theory of  games, 3:97-139, 1957.  E. Hazan, S. Kale, and M. Warmuth. Learning rotations with little regret. In Proceedings  of the 23rd Annual Conference on Learning Theory (COLT), pages 144-154, 2010.  D. P. Helmbold and M. Warmuth. Learning permutations with exponential weights. Journal  of Machine Learning Research, 10:1705-1736, 2009. Devroye Lugosi Neu  M. Hutter and J. Poland. Prediction with expert advice by following the perturbed leader for general weights. In Algorithmic Learning Theory, pages 279-293. Springer, 2004.  A. Kalai and S. Vempala. E\ufb03cient algorithms for the online decision problem.  In B. Sch\u00a8olkopf and M. Warmuth, editors, Proceedings of the 16th Annual Conference on Learning Theory and the 7th Kernel Workshop, COLT-Kernel 2003, pages 26-40, New York, USA, Aug. 2003. Springer.  A. Kalai and S. Vempala. E\ufb03cient algorithms for online decision problems. Journal of  Computer and System Sciences, 71:291-307, 2005.  J. Kivinen and M. Warmuth. Relative loss bounds for multidimensional regression problems.  Machine Learning, 45:301-329, 2001.  W. Koolen, M. Warmuth, and J. Kivinen. Hedging structured concepts. In Proceedings of  the 23rd Annual Conference on Learning Theory (COLT), pages 93-105, 2010.  N. Littlestone and M. Warmuth. The weighted majority algorithm. Information and Com-  putation, 108:212-261, 1994.  G. Neu, A. Gy\u00a8orgy, Cs. Szepesv\u00b4ari, and A. Antos. Online Markov decision processes under  bandit feedback. In Advances in Neural Information Processing Systems 23, 2010.  J. Poland. FPL analysis for adaptive bandits. In In 3rd Symposium on Stochastic Algo-  rithms, Foundations and Applications (SAGA\u201905), pages 58-69, 2005.  A. Rakhlin, O. Shamir, and K. Sridharan. Relax and randomize : From value to algorithms.  In Advances in Neural Information Processing Systems 25, pages 2150-2158, 2012.  E. Takimoto and M. Warmuth. Paths kernels and multiplicative updates. Journal of  Machine Learning Research, 4:773-818, 2003.  V. Vovk. Aggregating strategies. In Proceedings of the third annual workshop on Compu-  tational learning theory (COLT), pages 371-386, 1990.  M. Warmuth and D. Kuzmin. Randomized online pca algorithms with regret bounds that are logarithmic in the dimension. Journal of Machine Learning Research, 9:2287-2320, 2008. "}, "Approachability, fast and slow": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Approachability, fast and slow", "abstract": "Approachability has become a central tool in the analysis of repeated games and online learning. A player plays a repeated vector-valued game against Nature and her objective is to have her long-term average reward inside some target set.  The celebrated results of Blackwell provide a 1/\\sqrtn convergence rate of the expected point-to-set distance if this is achievable, i.e., if the set is approachable. In this paper we provide a  characterization for the convergence rates of approachability and show that in some cases a set can be approached with a 1/n rate. Our characterization is solely based on a combination of geometric properties of the set with properties of the repeated game, and not on additional restrictive assumptions on Nature\u2019s behavior.", "pdf_url": "http://proceedings.mlr.press/v30/Perchet13.pdf", "keywords": [], "reference": "are equivalent. (COLT\u201911), 2011.  environments. (COLT\u201911), 2011.  ics, 6:1-8, 1956a.  2006.  605-613, 1982.  J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learning In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory  Jean-Yves Audibert and Alexandre B. Tsybakov. Fast learning rates for plug-in classifiers. Ann.  Statist., 35:608-633, 2007.  R.J. Aumann and M.B. Maschler. Repeated Games with Incomplete Information. MIT Press, 1995.  G. Bart\u00b4ok, D. P\u00b4al, and C. Szepesv\u00b4ari. Minimax regret of finite partial monitoring games in stochastic In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory  D. Blackwell. An analog of the minimax theorem for vector payoffs. Pacific Journal of Mathemat-  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of Mathe-  maticians, 1954, Amsterdam, vol. III, pages 336-338, 1956b.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press,  N. Cesa-Bianchi, G. Lugosi, and G. Stoltz. Regret minimization under partial monitoring. Mathe-  matics of Operations Research, 31:562-580, 2006.  A.P. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association, 77:  D. Foster and R. Vohra. Asymptotic calibration. Biometrika, 85:379-390, 1998.  D. P. Foster. A proof of calibration via Blackwell\u2019s approachabilitytheorem. Games Econom.  Behav., 29:73-78, 1999.  D. P. Foster and A. Rakhlin. No internal regret via neighborhood watch.  In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS\u201912), 2012.  J. Hannan. Approximation to Bayes risk in repeated play. In Contributions to the Theory of Games, volume 3 of Annals of Mathematics Studies, pages 97-139. Princeton University Press, Princeton, N. J., 1957.  S. Hart and A. Mas-Colell. A general class of adaptive strategies. Journal of Economic Theory, 98:  26-54, 2001.  E. Kohlberg. Optimal strategies in repeated games with incomplete information.  International  Journal of Game Theory, 4:7-243, 1975.  G. Lugosi, S. Mannor, and G. Stoltz. Strategies for prediction under imperfect monitoring. Mathe-  matics of Operations Research, 33:513-528, 2008.  14   MANNOR PERCHET  References  are equivalent. (COLT\u201911), 2011.  environments. (COLT\u201911), 2011.  ics, 6:1-8, 1956a.  2006.  605-613, 1982.  J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learning In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory  Jean-Yves Audibert and Alexandre B. Tsybakov. Fast learning rates for plug-in classifiers. Ann.  Statist., 35:608-633, 2007.  R.J. Aumann and M.B. Maschler. Repeated Games with Incomplete Information. MIT Press, 1995.  G. Bart\u00b4ok, D. P\u00b4al, and C. Szepesv\u00b4ari. Minimax regret of finite partial monitoring games in stochastic In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory  D. Blackwell. An analog of the minimax theorem for vector payoffs. Pacific Journal of Mathemat-  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of Mathe-  maticians, 1954, Amsterdam, vol. III, pages 336-338, 1956b.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press,  N. Cesa-Bianchi, G. Lugosi, and G. Stoltz. Regret minimization under partial monitoring. Mathe-  matics of Operations Research, 31:562-580, 2006.  A.P. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association, 77:  D. Foster and R. Vohra. Asymptotic calibration. Biometrika, 85:379-390, 1998.  D. P. Foster. A proof of calibration via Blackwell\u2019s approachabilitytheorem. Games Econom.  Behav., 29:73-78, 1999.  D. P. Foster and A. Rakhlin. No internal regret via neighborhood watch.  In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS\u201912), 2012.  J. Hannan. Approximation to Bayes risk in repeated play. In Contributions to the Theory of Games, volume 3 of Annals of Mathematics Studies, pages 97-139. Princeton University Press, Princeton, N. J., 1957.  S. Hart and A. Mas-Colell. A general class of adaptive strategies. Journal of Economic Theory, 98:  26-54, 2001.  E. Kohlberg. Optimal strategies in repeated games with incomplete information.  International  Journal of Game Theory, 4:7-243, 1975.  G. Lugosi, S. Mannor, and G. Stoltz. Strategies for prediction under imperfect monitoring. Mathe-  matics of Operations Research, 33:513-528, 2008. APPROACHABILITY, FAST AND SLOW  S. Mannor and N. Shimkin. Regret minimization in repeated matrix games with variable stage  duration. Games and Economic Behavior, 63(1):227-258, 2008.  S. Mannor and G. Stoltz. A geometric proof of calibration. Mathematics of Operations Research,  35:721-727, 2010.  S. Mannor, J. Tsitsiklis, and J. Y. Yu. Online learning with sample path constraints. Journal of  Machine Learning Research, 10:569-590, 2009.  S. Mannor, V. Perchet, and G. Stoltz. Robust approachability and regret minimization in games with partial monitoring. In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory (COLT\u201911), 2011.  J.-F. Mertens, S. Sorin, and S. Zamir. Repeated games. Technical Report no. 9420, 9421, 9422,  Universit\u00b4e de Louvain-la-Neuve, 1994.  V. Perchet. Approachability of convex sets in games with partial monitoring. Journal of Optimiza-  tion Theory and Applications, 149:665-677, 2011a.  V. Perchet. Internal regret with partial monitoring calibration-based optimal algorithms. Journal of  Machine Learning Research, 2011b. In press.  V. Perchet.  Approachability,  regret and calibration,  implications and equivalences.  ArXiv.org:1301.2663, 2013.  A. Piccolboni and C. Schindelhauer. Discrete prediction games with arbitrary feedback and loss. In Proceedings of the Fourteenth Annual Conference on Computational Learning Theory (COLT\u201901), pages 208-223, 2001.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Beyond regret. In Proceedings of the Twenty-Fifth Annual Conference on Neural Information Processing Systems (NIPS\u201911), 2011a.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Stochastic and constrained adversaries. In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory (COLT\u201911), 2011b.  R. T. Rockafellar. Convex analysis. Princeton Landmarks in Mathematics. Princeton University  Press, Princeton, NJ, 1997. Reprint of the 1970 original, Princeton Paperbacks.  R. T. Rockafellar and R. J.-B. Wets. Variational analysis, volume 317 of Grundlehren der Mathe- matischen Wissenschaften [Fundamental Principles of Mathematical Sciences]. Springer-Verlag, Berlin, 1998.  X. Spinat. A necessary and sufficient condition for approachability. Math. Oper. Res., 27:31-44,  2002.  New York, 1995.  I. Steinwart and C. Scovel. Fast rates for support vector machine. In Proceedings of the eighteenth  Annual Conference on Learning Theory (COLT\u201905), 2005.  G. Ziegler. Lectures on Polytopes, volume 152 of Graduate Texts in Mathematics. Springer-Verlag, "}, "Classification with Asymmetric Label Noise: Consistency and Maximal Denoising": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Classification with Asymmetric Label Noise: Consistency and Maximal Denoising", "abstract": "In many real-world classification problems, the labels of training examples are randomly corrupted. Thus, the set of training examples for each class is contaminated by examples of the other class. Previous theoretical work on this problem assumes that the two classes are separable, that the label noise is independent of the true class label, or that the noise proportions for each class are known. We introduce a general framework for classification with label noise that eliminates these assumptions. Instead, we give assumptions ensuring identifiability and the existence of a consistent estimator of the optimal risk, with associated estimation strategies. For any arbitrary pair of contaminated distributions, there is a unique pair of non-contaminated distributions satisfying the proposed assumptions, and we argue that this solution corresponds in a certain sense to maximal denoising. In particular, we find that learning in the presence of label noise is possible even when the class-conditional distributions overlap and the label noise is not symmetric. A key to our approach is a universally consistent estimator of the maximal proportion of one distribution that is present in another, a problem we refer to as\u201cmixture proportion estimation. This work is motivated by a problem in nuclear particle classification.", "pdf_url": "http://proceedings.mlr.press/v30/Scott13.pdf", "keywords": ["Label noise", "consistency", "error estimation", "mixture proportion estimation"], "reference": "J. M. Adams and G. White. A versatile pulse shape discriminator for charged particle sepa- ration and its application to fast neutron time-of-\ufb02ight spectroscopy. Nuclear Instruments and Methods in Physics Research, 1978.  S. Ambers, M. Flaska, and S. Pozzi. A hybrid pulse shape discrimination technique with en- hanced performance at neutron energies below 500 kev. Nuclear Instruments and Methods in Physics Research A, 638:116-121, 2011.  D. Angluin and P. Laird. Learning from noisy examples. Machine Learning, 2:343-370,  1988.  (cid:15) 8 (cid:15) 8  (cid:15) 8  21   Classification with Asymmetric Label Noise  Assume that both  |R0(f ) \u2212 (cid:98)R0(f )| <  for all f \u2208 Fk  |R1(f ) \u2212 (cid:98)R1(f )| <  for all f \u2208 Fk,  which by the result just stated, occurs with probability at least 1\u2212\u03b4 for m and n su\ufb03ciently large. It follows that  (cid:15) 8  (cid:15) 8  .  max{R0( (cid:98)fk), R1( (cid:98)fk)} < max{ (cid:98)R0( (cid:98)fk), (cid:98)R1( (cid:98)fk)} +  and  max{R0(f \u2217  k ), R1(f \u2217  k )} > max{ (cid:98)R0(f \u2217  k ), (cid:98)R1(f \u2217  k )} \u2212  Using these inequalities in Equation (19) yields  R( (cid:98)fk) \u2212 R(Fk) < max{ (cid:98)R0( (cid:98)fk), (cid:98)R1( (cid:98)fk)} +  \u2212 (max{ (cid:98)R0(f \u2217  k ), (cid:98)R1(f \u2217  k )} \u2212  ) +  (cid:15) 8  (cid:15) 8  .  From our definition of (cid:98)fk in Equation (16), for m and n su\ufb03ciently large we have  max{ (cid:98)R0( (cid:98)fk), (cid:98)R1( (cid:98)fk)} \u2264 max{ (cid:98)R0(f \u2217  k ), (cid:98)R1(f \u2217  k )} +  (cid:15) 8  .  Therefore, we can conclude that  R( (cid:98)fk) \u2212 R(Fk) <  (cid:15) 2  ,  with probability at least 1 \u2212 \u03b4. Thus, we conclude that  0 \u2297 \u02dcP n \u02dcP m  1 (R( (cid:98)fk) \u2212 R\u2217 < (cid:15)) > 1 \u2212 \u03b4,  for m and n su\ufb03ciently large.  References  J. M. Adams and G. White. A versatile pulse shape discriminator for charged particle sepa- ration and its application to fast neutron time-of-\ufb02ight spectroscopy. Nuclear Instruments and Methods in Physics Research, 1978.  S. Ambers, M. Flaska, and S. Pozzi. A hybrid pulse shape discrimination technique with en- hanced performance at neutron energies below 500 kev. Nuclear Instruments and Methods in Physics Research A, 638:116-121, 2011.  D. Angluin and P. Laird. Learning from noisy examples. Machine Learning, 2:343-370,  1988.  (cid:15) 8 (cid:15) 8  (cid:15) 8 Scott Blanchard Handy  J. Aslam and S. Decatur. On the sample complexity of noise-tolerant learning. Inf. Process.  Lett., 57:189-195, 1996.  G. Blanchard, G. Lee, and C. Scott. Semi-supervised novelty detection. Journal of Machine  Learning Research, 11:2973-3009, 2010.  A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training.  In Proceedings of the 11th Annual Conference on Computational Learning Theory, pages 92-100, 1998.  C. Bouveyron and S. Girard. Robust supervised classification with mixture models: Learn- ing from data with uncertain labels. Journal of Pattern Recognition, 42:2649-2658, 2009.  C. Brodley and M. Friedl. Identifying mislabeled training data. Journal of Artifcial Intel-  ligence Research, pages 131-167, 1999.  N. H. Bshouty, S. A. Goldman, H. D. Mathias, S. Suri, and H. Tamaki. Noise-tolerant distribution-free learning of general geometric concepts. J. ACM, 45(5):863-890, 1998.  N. Cesa-Bianchi, P. Fischer, E. Shamir, and H.-U. Simon. Randomized hypotheses and In Proc. Third European  minimum disagreement hypotheses for learning with noise. Conf. on Computational Learning Theory, pages 119-133, 1997.  V. Denchev, N. Ding, S. V. N. Vishwanathan, and H. Neven. Robust classification with adiabatic quantum optimization. In J. Langford and J. Pineau, editors, Proc. 29th Int. Conf. on Machine Learning, pages 863-870, 2012.  L. Devroye, L. Gy\u00a8orfi, and G. Lugosi. A Probabilistic Theory of Pattern Recognition.  Springer, 1996.  N. Ding and S. V. N. Vishwanathan. t-logistic regression. In J. La\ufb00erty, C. K. I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23, pages 514-522. 2010.  S. Jabbari. PAC-learning with label noise. Master\u2019s thesis, University of Alberta, December  2010.  A. Kalai and R. Servedio. Boosting in the presence of noise. Symposium on Theory of  Computing, pages 196-205, 2003.  M. Kearns. E\ufb03cient noise-tolerant learning from statistical queries. Proceedings of the Twenty-Fifth Annual ACM Symposium on THeory of Computing, pages 392-401, 1993.  N. Lawrence and B. Sch\u00a8olkopf. Estimating a kernel Fisher discriminant in the presence of label noise. Proceedings of the International Conference in Machine Learning, 2001.  P. Long and R. Servido. Random classification noise defeats all convex potential boosters.  Machine Learning, 78:287-304, 2010.  N. Manwani and P. S. Sastry. Noise tolerance under risk minimization. Technical Report  arXiv:1109.5231, 2011. Classification with Asymmetric Label Noise  H. Masnadi-Shirazi and N. Vasconcelos. On the design of loss functions for classification: theory, robustness to outliers, and savageboost. In Y. Bengio D. Koller, D. Schuurmans and L. Bottou, editors, Advances in Neural Information Processing Systems 21, pages 1049-1056. 2009.  L. Mason, J. Baxter, P. Bartlett, and M. Frean. Boosting algorithms as gradient descent. In In Advances in Neural Information Processing Systems 12, pages 512-518. MIT Press, 2000.  U. Rebbapragada and C. Brodley. Class noise mitigation through instance weighting. Eu-  ropean Conference on Machine Learning, pages 708-715, 2007.  S. Sabato and N. Tishby. Multi-instance learning with any hypothesis class. J. Machine  Learning Research, 13:2999-3039, 2012.  G. Stempfel and L. Ralaivola. Learning SVMs from sloppily labeled data. In Proc. 19th  Int. Conf. on Artificial Neural Networks: Part I, pages 884-893, 2009.  L. Xu, K. Crammer, and D. Schuurmans. Robust support vector machine training via convex outlier ablation. Proceedings of the 21st National Conference on Artificial Intelligence (AAAI), 2006. "}, "General Oracle Inequalities for Gibbs Posterior with Application to Ranking": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "General Oracle Inequalities for Gibbs Posterior with Application to Ranking", "abstract": "In this paper, we summarize some recent results in Li et al. (2012), which can be used to extend an important PAC-Bayesian approach, namely the Gibbs posterior, to study the nonadditive ranking risk. The methodology is based on assumption-free risk bounds and nonasymptotic oracle inequalities, which leads to nearly optimal convergence rates and optimal model selection to balance the approximation errors and the stochastic errors.", "pdf_url": "http://proceedings.mlr.press/v30/Li13.pdf", "keywords": ["Gibbs posterior", "model selection", "oracle inequalities", "ranking", "risk minimization"], "reference": "P. Alquier and K. Lounici. PAC-Bayesian bounds for sparse regression estimation with  exponential weights. Electronic Journal of Statistics, 5:127-145, 2011.  P. Alquier and O. Wintenberger. Model selection for weakly dependent time series forecast-  ing. Bernoulli, 18:883-913, 2012.  J. Y. Audibert. Classification using gibbs estimators under complexity and margin assump-  tions. preprint, laboratoire de probabilit\u00b4es et model`es al\u00b4eatoires, http://www.proba.jussieu.fr/mathdoc/textes/pma-908.pdf. 2004.  J. Y. Audibert. PAC-Bayesian aggregation and multi-armed bandits. habilitation thesis.  universit\u00b4e paris est. 2010.  A. Belloni and V. Chernozhukov. On the computational complexity of MCMC-based esti-  mators in large samples. The Annals of Statistics, 37:2011-2055, 2009.  O. Catoni. PAC-Bayesian Supervised Classification (The Thermodynamics of Statistical  Learning), volume 37. IMS, 2007.  K. Chen, W. Jiang, and M. A. Tanner. A note on some algorithms for the Gibbs posterior.  Statistics and Probability Letters, 80:1234-1241, 2010.  V. Chernozhukov and H. Hong. An MCMC approach to classical estimation. Journal of  Econometrics, 115:293-346, 2003.  S. Cl\u00b4emencon, G. Lugosi, and N. Vayatis. Ranking and empirical minimization of u-  statistics. The Annals of Statistics, 36:844-874, 2008.  A. K. Han. Non-parametric analysis of a generalized regression model - the maximum rank  correlation estimator. Journal of Econometrics, 35:303-316, 1987.  W. Jiang and M. A. Tanner. Gibbs posterior for variable selection in high dimensional  classification and data mining. The Annals of Statistics, 36:2207-2231, 2008.  W. Jiang and M. A. Tanner. Risk minimization for time series binary choice with variable  selection. Econometric Theory, 26:1437-1452, 2010.  G Lecu\u00b4e. Suboptimality of penalized empirical risk minimization in classification. COLT\u201907 Proceedings of the 20th Annual Conference on Learning Theory, pages 142-156, 2007.  C. Li, W. Jiang, and M. A. Tanner. General inequalities for Gibbs posterior with nonadditive  empirical risk. Manuscript Submitted, 2012.  P. Massart. Concentration inequalities and model selection. Spriner, Berlin, 2003.  W. Rejchel. On ranking and generalization bounds. Journal of Machine Learning Research,  13:1373-1392, 2012.  P. Rigollet and A. Tsybakov. Exponential screening and optimal rates of sparse estimation.  The Annals of Statistics, 39:731-771, 2011.  9   General Oracle Inequalities for Gibbs Posterior  References  P. Alquier and K. Lounici. PAC-Bayesian bounds for sparse regression estimation with  exponential weights. Electronic Journal of Statistics, 5:127-145, 2011.  P. Alquier and O. Wintenberger. Model selection for weakly dependent time series forecast-  ing. Bernoulli, 18:883-913, 2012.  J. Y. Audibert. Classification using gibbs estimators under complexity and margin assump-  tions. preprint, laboratoire de probabilit\u00b4es et model`es al\u00b4eatoires, http://www.proba.jussieu.fr/mathdoc/textes/pma-908.pdf. 2004.  J. Y. Audibert. PAC-Bayesian aggregation and multi-armed bandits. habilitation thesis.  universit\u00b4e paris est. 2010.  A. Belloni and V. Chernozhukov. On the computational complexity of MCMC-based esti-  mators in large samples. The Annals of Statistics, 37:2011-2055, 2009.  O. Catoni. PAC-Bayesian Supervised Classification (The Thermodynamics of Statistical  Learning), volume 37. IMS, 2007.  K. Chen, W. Jiang, and M. A. Tanner. A note on some algorithms for the Gibbs posterior.  Statistics and Probability Letters, 80:1234-1241, 2010.  V. Chernozhukov and H. Hong. An MCMC approach to classical estimation. Journal of  Econometrics, 115:293-346, 2003.  S. Cl\u00b4emencon, G. Lugosi, and N. Vayatis. Ranking and empirical minimization of u-  statistics. The Annals of Statistics, 36:844-874, 2008.  A. K. Han. Non-parametric analysis of a generalized regression model - the maximum rank  correlation estimator. Journal of Econometrics, 35:303-316, 1987.  W. Jiang and M. A. Tanner. Gibbs posterior for variable selection in high dimensional  classification and data mining. The Annals of Statistics, 36:2207-2231, 2008.  W. Jiang and M. A. Tanner. Risk minimization for time series binary choice with variable  selection. Econometric Theory, 26:1437-1452, 2010.  G Lecu\u00b4e. Suboptimality of penalized empirical risk minimization in classification. COLT\u201907 Proceedings of the 20th Annual Conference on Learning Theory, pages 142-156, 2007.  C. Li, W. Jiang, and M. A. Tanner. General inequalities for Gibbs posterior with nonadditive  empirical risk. Manuscript Submitted, 2012.  P. Massart. Concentration inequalities and model selection. Spriner, Berlin, 2003.  W. Rejchel. On ranking and generalization bounds. Journal of Machine Learning Research,  13:1373-1392, 2012.  P. Rigollet and A. Tsybakov. Exponential screening and optimal rates of sparse estimation.  The Annals of Statistics, 39:731-771, 2011. Li Jiang Tanner  R. P. Sherman. The limiting distribution of the maximum rank correlation estimator.  Econometrica, 61:123-137, 1993.  A. W. van der Vaart and J. A. Wellner. Weak convergence and empirical process. Spriner,  New York, 1996.  T. Zhang. Theoretical analysis of a class of randomized regularization methods. COLT \u201999 Proceedings of the 12th Annual Conference on Computational Learning Theory, pages 156-163, 1999.  T. Zhang. Information theoretical upper and lower bounds for statistical estimation. IEEE  Transactions on Information Theory, 52:1307-1321, 2006. "}, "Learning Halfspaces Under Log-Concave Densities: Polynomial Approximations and Moment Matching": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Learning Halfspaces Under Log-Concave Densities: Polynomial Approximations and Moment Matching", "abstract": "We give the first polynomial-time algorithm for agnostically learning any function of a constant number of halfspaces with respect to any log-concave distribution (for any constant accuracy parameter).  This result was not known even for the case of PAC learning the intersection of two halfspaces. We give two very different proofs of this result.  The first develops a theory of polynomial approximation for log-concave measures and constructs a low-degree L_1 polynomial approximator for sufficiently smooth functions.  The second uses techniques related to the classical moment problem to obtain sandwiching polynomials.  Both approaches deviate significantly from known Fourier-based methods, where essentially all previous work required the underlying distribution to have some product structure. Additionally, we show that in the smoothed-analysis setting, the above results hold with respect to distributions that have sub-exponential tails, a property satisfied by many natural and well-studied distributions in machine learning.", "pdf_url": "http://proceedings.mlr.press/v30/Kane13.pdf", "keywords": ["Log-concave distributions", "smoothed analysis", "halfspaces", "agnostic learning", "Fourier analysis"], "reference": "N.I Akhiezer. The Classical Moment Problem and Some Related Questions in Analysis. Hanfer  Publishing Co, 1 edition, 1965.  Louay M. J. Bazzi. Polylogarithmic independence can fool DNF formulas. SIAM J. Comput, 38(6):  2220\u20132272, 2009. URL http://dx.doi.org/10.1137/070691954.  Dimitris Bertsimas and Ioana Popescu. Optimal inequalities in probability theory: A convex  optimization approach. SIAM Journal on Optimization, 15(3):780\u2013804, 2005.  Avrim Blum and John Dunagan. Smoothed analysis of the perceptron algorithm for linear program-  ming. In SODA, pages 905\u2013914, 2002.  Avrim Blum and Ravi Kannan. Learning an intersection of k halfspaces over a uniform distribution.  In FOCS, pages 312\u2013320, 1993.  V.V. Buldygin and I.U.V. Kozachenko. Metric Characterization of Random Variables and Random Processes. Translations of Mathematical Monographs. American Mathematical So- ISBN 9780821805336. URL http://books.google.com/books?id= ciety, 2000. ePDXvIhdEjoC.  Anthony Carbery and James Wright. Distributional and Lq norm inequalities for polynomials over convex bodies in Rn. Mathematical Research Letters, 8(3):233\u2013248, 2001. URL http: //www.mrlonline.org/mrl/2001-008-003/2001-008-003-001.html.  Ilias Diakonikolas, Daniel M. Kane, and Jelani Nelson. Bounded independence fools degree-2  threshold functions. In FOCS, pages 11\u201320, 2010a.  Ilias Diakonikolas, Rocco A. Servedio, Li-Yang Tan, and Andrew Wan. A regularity lemma, and low-weight approximators, for low-degree polynomial threshold functions. In IEEE Conference on Computational Complexity, pages 211\u2013222, 2010b.  William Feller. An Introduction to Probability Theory and Its Applications, Vol. 2 (Volume 2). Wiley, 2 edition, January 1971. ISBN 0471257095. URL http://www.amazon.com/exec/ obidos/redirect?tag=citeulike07-20&path=ASIN/0471257095.  Yu. R. Gabovich. Stability of the characterization of the multivariate normal distribution in the Skitovich-Darmois theorem. Journal of Mathematical Sciences, 16:1341\u20131349, 1981. ISSN 1072-3374. URL http://dx.doi.org/10.1007/BF01091625.  13   LEARNING HALFSPACES UNDER LOG-CONCAVE DENSITIES  5. Smoothed Complexity of Learning Functions of Halfspaces  We defer this section to the "}, "Subspace Embeddings and \\ell_p-Regression Using Exponential Random Variables": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Subspace Embeddings and \\ell_p-Regression Using Exponential Random Variables", "abstract": "Oblivious low-distortion subspace embeddings are a crucial building block for numerical linear algebra problems. We show for any real p, 1 \u2264p < \u221e, given a matrix M \u2208\\mathbbR^n \\times d with n \u226bd, with constant probability we can choose a matrix \\Pi with \\max(1, n^1-2/p) \\textpoly(d) rows and n columns so that simultaneously for all x \u2208\\mathbbR^d, \\|Mx\\|_p \u2264\\|\\Pi Mx\\|_\u221e \u2264\\textpoly(d) \\|Mx\\|_p. Importantly, \\Pi M can be computed in the optimal O(\\textnnz(M)) time, where \\textnnz(M) is the number of non-zero entries of M. This generalizes all previous oblivious subspace embeddings which required p \u2208[1,2] due to their use of p-stable random variables. Using our new matrices \\Pi, we also improve the best known distortion of oblivious subspace embeddings of \\ell_1 into \\ell_1 with \\tildeO(d) target dimension in O(\\textnnz(M)) time from \\tildeO(d^3) to \\tildeO(d^2), which can further be improved to \\tildeO(d^3/2) \\log^1/2 n if d = \u03a9(\\log n), answering a question of Meng and Mahoney (STOC, 2013). We apply our results to \\ell_p-regression, obtaining a (1+\u03b5)-approximation in O(\\textnnz(M)\\log n) + \\textpoly(d/\u03b5) time, improving the best known \\textpoly(d/\u03b5) factors for every p \u2208[1, \u221e) \u2216{2}. If one is just interested in a \\textpoly(d) rather than a (1+\u03b5)-approximation to \\ell_p-regression, a corollary of our results is that for all p \u2208[1, \u221e) we can solve the \\ell_p-regression problem without using general convex programming, that is, since our subspace embeds into \\ell_\u221e it suffices to solve a linear programming problem.  Finally, we give the first protocols for the distributed \\ell_p-regression problem for every p \u22651 which are nearly optimal in communication and computation.", "pdf_url": "http://proceedings.mlr.press/v30/Woodruff13.pdf", "keywords": [], "reference": "[1] Nir Ailon and Bernard Chazelle. The fast johnson\u2013lindenstrauss transform and approximate nearest  neighbors. SIAM J. Comput., 39(1):302\u2013322, 2009.  [2] Nir Ailon and Edo Liberty. Fast dimension reduction using rademacher series on dual bch codes. In  SODA, pages 1\u20139, 2008.  [3] Alexandr Andoni.  High http://web.mit.edu/andoni/www/papers/fkStable.pdf, 2012.  frequency moment  via max  stability.  Available  at  [4] Alexandr Andoni, Robert Krauthgamer, and Krzysztof Onak. Streaming algorithms via precision  sampling. In FOCS, pages 363\u2013372, 2011.  [5] H. Auerbach. On the area of convex curves with conjugate diameters. PhD thesis, PhD thesis, Univer-  sity of Lw\u00b4ow, 1930.  [6] Lakshminath Bhuvanagiri, Sumit Ganguly, Deepanjan Kesh, and Chandan Saha. Simpler algorithm  for estimating frequency moments of data streams. In SODA, pages 708\u2013713, 2006.  [7] J. Bourgain, J. Lindenstrauss, and V. Milman. Approximation of zonoids by zonotopes. Acta mathe-  matica, 162(1):73\u2013141, 1989.  abs/1011.2571, 2010.  [8] Vladimir Braverman and Rafail Ostrovsky. Recursive sketching for frequency moments. CoRR,  [9] Kenneth L. Clarkson. Subgradient and sampling algorithms for (cid:96)1 regression. In In Proceedings of the  16th Annual ACM-SIAM Symposium on Discrete Algorithms, pages 257\u2013266, 2005.  [10] Kenneth L. Clarkson and David P. Woodruff. Numerical linear algebra in the streaming model. In  STOC, pages 205\u2013214, 2009.  [11] Kenneth L. Clarkson and David P. Woodruff. Low rank approximation and regression in input sparsity  time. CoRR, abs/1207.6365, 2012. To appear in STOC, 2013.  13   Application to (cid:96)1 Subspace Approximation. Given a matrix M \u2208 Rn\u00d7d and a parameter k, the (cid:96)1- subspace approximation is to compute a matrix \u02c6M of rank k \u2208 [d \u2212 1] such that is minimized. When k = d \u2212 1, \u02c6M is a hyperplane, and the problem is called (cid:96)1 best hyperplane fitting. In [12] it is shown that this problem is equivalent to solving the regression problem minW \u2208C (cid:107)AW (cid:107)1, where the constraint set is C = {W \u2208 Rd\u00d7d : Wii = \u22121}. Therefore, our (cid:96)1-regression result directly implies an improved algorithm for (cid:96)1 best hyperplane fitting. Formally, we have  (cid:13) (cid:13)M \u2212 \u02c6M (cid:13)  (cid:13) (cid:13) (cid:13)1  Theorem 19 Given M \u2208 Rn\u00d7d, there exists an algorithm that computes a (1 + (cid:15))-approximation to the (cid:96)1 best hyperplane fitting problem with probability 0.9, using time O (cid:0)nnz(M ) log n + 1  (cid:15) )(cid:1). The poly(d) factor in our algorithm is better than those by using the regression results in [11, 12, 22].  (cid:15)2 poly(d, log d  6. Regression in the Distributed Setting  Due to space constraints, we leave this section to "}, "Consistency of Robust Kernel Density Estimators": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Consistency of Robust Kernel Density Estimators", "abstract": "The kernel density estimator (KDE) based on a radial positive-semidefinite kernel may be viewed as a sample mean in a reproducing kernel Hilbert space. This mean can be viewed as the solution of a least squares problem in that space. Replacing the squared loss with a robust loss yields a robust kernel density estimator (RKDE). Previous work has shown that RKDEs are weighted kernel density estimators which have desirable robustness properties. In this paper we establish asymptotic L^1 consistency of the RKDE for a class of losses and show that the RKDE converges with the same rate on bandwidth required for the traditional KDE. We also present a novel proof of the consistency of the traditional KDE.", "pdf_url": "http://proceedings.mlr.press/v30/Vandermeulen13.pdf", "keywords": ["Kernel Density Estimation", "Robust Estimation", "Reproducing Kernel Hilbert Space", "Consistency"], "reference": "Society, 68, 1950.  N. Aronszajn. Theory of reproducing kernels. Transactions of the American Mathematical  Frank Bauer, Sergei Pereverzev, and Lorenzo Rosasco. On regularization algorithms in learning theory. J. Complex., 23(1):52-72, February 2007. ISSN 0885-064X. doi: 10. 1016/j.jco.2006.07.001. URL http://dx.doi.org/10.1016/j.jco.2006.07.001.  Andrea Caponnetto and Ernesto De Vito. Optimal rates for the regularized least-squares  algorithm. Foundations of Computational Mathematics, 7(3):331-368, 2007.  P. Deheuvels. Uniform limit laws for kernel density estimators on possibly unbounded interval. In Recent Advances in Reliability Theory, pages 477-492. Birkh\u00a8auser, 2000.  L. Devroye and G. Lugosi. Combinatorial Methods in Density Estimation. Springer, New  York, 2001.  U. Einmahl and D. Mason. An empirical process approach to the uniform consistency of  kernel-type function estimators. J. Theoret. Probab., 13:1-37, 2000.  23   Consistency of Robust Kernel Density Estimators  Returning to the original notation, this means, for su\ufb03ciently small \u03c3  (cid:107)A(cid:107)H\u03c3  \u2264  \u03a6\u03c3 (x) d\u00b5n (x)  4 (cid:107)g \u2212 h(cid:107)H\u03c3  1 \u2212  (cid:90)  (cid:13) (cid:13) (cid:13) (cid:13)  (cid:13) (cid:13) (cid:13) (cid:13)H\u03c3  (cid:32)  (cid:33)\u22123  (cid:114) 9 10  (cid:107)\u03a6\u03c3(cid:107)\u22123 H\u03c3  .  From our proof of the consistency of the KDE we know that (cid:13) p (cid:82) \u03a6\u03c3(x)d\u00b5n(x) \u2212 \u00aff\u03c3 \u2192 0 (cid:13) and from Lemma 8 (cid:13) is bounded by some constant with probability going to one. Note that this is the only probabilistic step, which does not depend on g or h, so the result holds over the whole ball in H\u03c3. So there exists CA > 0 such that  (cid:82) \u03a6\u03c3(x)d\u00b5n(x)(cid:13) \u2264 (cid:107)f (cid:107)2 so (cid:13) (cid:13)  (cid:13) (cid:13)H\u03c3  (cid:13) (cid:13)H\u03c3  (cid:13) \u00aff\u03c3  (cid:13)H\u03c3  with probability going to one (we can omit \u201cfor su\ufb03ciently small \u03c3\u201d since \u03c3 \u2192 0 as n \u2192 \u221e). Finally we get with probability going to one as n\u03c3d \u2192 \u221e  (cid:107)A(cid:107)H\u03c3  \u2264 (cid:107)g \u2212 h(cid:107)H\u03c3  (cid:107)\u03a6\u03c3(cid:107)\u22123 H\u03c3  CA  (cid:13) (cid:13) (cid:13) (cid:13)  A B  (cid:13) (cid:13) (cid:13) (cid:13)H\u03c3  =  (cid:107)A(cid:107)H\u03c3 B  \u2264 (cid:107)g \u2212 h(cid:107)H\u03c3  = (cid:107)g \u2212 h(cid:107)H\u03c3  CA (cid:107)\u03a6\u03c3(cid:107)\u22123 H\u03c3 CB (cid:107)\u03a6\u03c3(cid:107)\u22122 H\u03c3 CR (cid:107)\u03a6\u03c3(cid:107)\u22121 H\u03c3  .  References  Society, 68, 1950.  N. Aronszajn. Theory of reproducing kernels. Transactions of the American Mathematical  Frank Bauer, Sergei Pereverzev, and Lorenzo Rosasco. On regularization algorithms in learning theory. J. Complex., 23(1):52-72, February 2007. ISSN 0885-064X. doi: 10. 1016/j.jco.2006.07.001. URL http://dx.doi.org/10.1016/j.jco.2006.07.001.  Andrea Caponnetto and Ernesto De Vito. Optimal rates for the regularized least-squares  algorithm. Foundations of Computational Mathematics, 7(3):331-368, 2007.  P. Deheuvels. Uniform limit laws for kernel density estimators on possibly unbounded interval. In Recent Advances in Reliability Theory, pages 477-492. Birkh\u00a8auser, 2000.  L. Devroye and G. Lugosi. Combinatorial Methods in Density Estimation. Springer, New  York, 2001.  U. Einmahl and D. Mason. An empirical process approach to the uniform consistency of  kernel-type function estimators. J. Theoret. Probab., 13:1-37, 2000. Vandermeulen Scott  E. Gine, V. Koltchinskii, and J. Zinn. Weighted uniform consistency of kernel density  estimators. Ann. Probab., 32:2570-2605, 2004.  Evarist Gin\u00b4e and Armelle Guillou. Rates of strong uniform consistency for multivariate ker- nel density estimators. Annales de l\u2019Institut Henri Poincare (B) Probability and Statistics, 38(6):907 - 921, 2002. ISSN 0246-0203. doi: 10.1016/S0246-0203(02)01128-7.  J. Kim and C. Scott. Robust kernel density estimation. J. Machine Learning Res., 13:  2529-2565, 2012.  Iosif Pinelis. Optimum bounds for the distributions of martingales in banach spaces. The  Annals of Probability, 22(4):pp. 1679-1706, 1994.  D. W. Scott. Multivariate Density Estimation. Wiley, New York, 1992.  Clint Scovel, Don Hush, Ingo Steinwart, and James Theiler. Radial kernels and their reproducing kernel Hilbert spaces. Journal of Complexity, 26(6):641 - 660, 2010. ISSN 0885-064X. doi: 10.1016/j.jco.2010.03.002.  B W Silverman. Weak and strong uniform consistency of the kernel estimate of a density  and its derivatives. The Annals of Statistics, 6(1), 1978.  B. W. Silverman. Density Estimation for Statistics and Data Analysis. Chapman and Hall,  London, 1986.  Steve Smale and Ding-Xuan Zhou. Learning theory estimates via integral operators and their approximations. Constructive Approximation, 26:153-172, 2007. ISSN 0176-4276. 10.1007/s00365-006-0659-y.  I. Steinwart and A. Christmann. Support Vector Machines. Springer, 2008.  W. Stute. A law of the logarithm for kernel density estimators. Ann. Probab., 10:414-422,  1982.  Papers, 53:1-21, 2012.  D. Wied and R. Weissbach. Consistency of the kernel density estimator: a survey. Statistical "}, "Divide and Conquer Kernel Ridge Regression": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Divide and Conquer Kernel Ridge Regression", "abstract": "We study a decomposition-based scalable approach to performing kernel ridge regression.  The method is simply described: it randomly partitions a dataset of size N into m subsets of equal size, computes an independent kernel ridge regression estimator for each subset, then averages the local solutions into a global predictor. This partitioning leads to a substantial reduction in computation time versus the standard approach of performing kernel ridge regression on all N samples. Our main theorem establishes that despite the computational speed-up, statistical optimality is retained: that so long as m is not too large, the partition-based estimate achieves optimal rates of convergence for the full sample size N.  As concrete examples, our theory guarantees that m may grow polynomially in N for Sobolev spaces, and nearly linearly for finite-rank kernels and Gaussian kernels. We conclude with simulations complementing our theoretical results and exhibiting the computational and statistical benefits of our approach.", "pdf_url": "http://proceedings.mlr.press/v30/Zhang13.pdf", "keywords": [], "reference": "P. Bartlett, O. Bousquet, and S. Mendelson. Local Rademacher complexities. Annals of  Statistics, 33(4):1497-1537, 2005.  A. Berlinet and C. Thomas-Agnan. Reproducing Kernel Hilbert Spaces in Probability and  Statistics. Kluwer Academic, 2004.  R. Bhatia. Matrix Analysis. Springer, 1997.  M. Birman and M. Solomjak. Piecewise-polynomial approximations of functions of the  classes W \u03b1  p . Sbornik: Mathematics, 2(3):295-317, 1967.  G. Blanchard and N. Kr\u00a8amer. Optimal learning rates for kernel conjugate gradient regres-  sion. In Advances in Neural Information Processing Systems 24, 2010.  A. Caponnetto and E. De Vito. Optimal rates for the regularized least-squares algorithm.  Foundations of Computational Mathematics, 7(3):331-368, 2007.  R. Chen, A. Gittens, and J. A. Tropp. The masked sample covariance estimator: an analysis using matrix concentration inequalities. Information and Inference, to appear, 2012.  S. Fine and K. Scheinberg. E\ufb03cient SVM training using low-rank kernel representations.  Journal of Machine Learning Research, 2:243-264, 2002.  C. Gu. Smoothing spline ANOVA models. Springer, 2002.  L. Gyorfi, M. Kohler, A. Krzyzak, and H. Walk. A Distribution-Free Theory of Nonpara-  metric Regression. Springer Series in Statistics. Springer, 2002.  T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning. Springer,  2001.  A. E. Hoerl and R. W. Kennard. Ridge regression: Biased estimation for nonorthogonal  problems. Technometrics, 12:55-67, 1970.  A. Kleiner, A. Talwalkar, P. Sarkar, and M. Jordan. Bootstrapping big data. In Proceedings  of the 29th International Conference on Machine Learning, 2012.  V. Koltchinskii. Local Rademacher complexities and oracle inequalities in risk minimization.  Annals of Statistics, 34(6):2593-2656, 2006.  M. Ledoux and M. Talagrand. Probability in Banach Spaces. Springer, 1991.  D. Luenberger. Optimization by Vector Space Methods. Wiley, 1969.  R. McDonald, K. Hall, and G. Mann. Distributed training strategies for the structured perceptron. In North American Chapter of the Association for Computational Linguistics (NAACL), 2010.  S. Mendelson. Geometric parameters of kernel machines. In Proceedings of COLT, pages  29-43, 2002.  14   Zhang Duchi Wainwright  References  P. Bartlett, O. Bousquet, and S. Mendelson. Local Rademacher complexities. Annals of  Statistics, 33(4):1497-1537, 2005.  A. Berlinet and C. Thomas-Agnan. Reproducing Kernel Hilbert Spaces in Probability and  Statistics. Kluwer Academic, 2004.  R. Bhatia. Matrix Analysis. Springer, 1997.  M. Birman and M. Solomjak. Piecewise-polynomial approximations of functions of the  classes W \u03b1  p . Sbornik: Mathematics, 2(3):295-317, 1967.  G. Blanchard and N. Kr\u00a8amer. Optimal learning rates for kernel conjugate gradient regres-  sion. In Advances in Neural Information Processing Systems 24, 2010.  A. Caponnetto and E. De Vito. Optimal rates for the regularized least-squares algorithm.  Foundations of Computational Mathematics, 7(3):331-368, 2007.  R. Chen, A. Gittens, and J. A. Tropp. The masked sample covariance estimator: an analysis using matrix concentration inequalities. Information and Inference, to appear, 2012.  S. Fine and K. Scheinberg. E\ufb03cient SVM training using low-rank kernel representations.  Journal of Machine Learning Research, 2:243-264, 2002.  C. Gu. Smoothing spline ANOVA models. Springer, 2002.  L. Gyorfi, M. Kohler, A. Krzyzak, and H. Walk. A Distribution-Free Theory of Nonpara-  metric Regression. Springer Series in Statistics. Springer, 2002.  T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning. Springer,  2001.  A. E. Hoerl and R. W. Kennard. Ridge regression: Biased estimation for nonorthogonal  problems. Technometrics, 12:55-67, 1970.  A. Kleiner, A. Talwalkar, P. Sarkar, and M. Jordan. Bootstrapping big data. In Proceedings  of the 29th International Conference on Machine Learning, 2012.  V. Koltchinskii. Local Rademacher complexities and oracle inequalities in risk minimization.  Annals of Statistics, 34(6):2593-2656, 2006.  M. Ledoux and M. Talagrand. Probability in Banach Spaces. Springer, 1991.  D. Luenberger. Optimization by Vector Space Methods. Wiley, 1969.  R. McDonald, K. Hall, and G. Mann. Distributed training strategies for the structured perceptron. In North American Chapter of the Association for Computational Linguistics (NAACL), 2010.  S. Mendelson. Geometric parameters of kernel machines. In Proceedings of COLT, pages  29-43, 2002. Divide and Conquer Kernel Ridge Regression  G. Raskutti, M. Wainwright, and B. Yu. Early stopping for non-parametric regression: An optimal data-dependent stopping rule. In 49th Annual Allerton Conference on Commu- nication, Control, and Computing, pages 1318-1325, 2011.  G. Raskutti, M. J. Wainwright, and B. Yu. Minimax-optimal rates for sparse additive models over kernel classes via convex programming. Journal of Machine Learning Research, 12: 389-427, March 2012.  C. Saunders, A. Gammerman, and V. Vovk. Ridge regression learning algorithm in dual In Proceedings of the 15th International Conference on Machine Learning,  variables. pages 515-521. Morgan Kaufmann, 1998.  B. Sch\u00a8olkopf, A. Smola, and K.-R. M\u00a8uller. Nonlinear component analysis as a kernel eigen-  value problem. IEEE Transactions on Information Theory, 10(5):1299-1319, 1998.  J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. Cambridge  University Press, 2004.  I. Steinwart, D. Hush, and C. Scovel. Optimal rates for regularized least squares regression. In Proceedings of the 22nd Annual Conference on Learning Theory, pages 79-93, 2009.  C. J. Stone. Optimal global rates of convergence for non-parametric regression. Annals of  Statistics, 10(4):1040-1053, 1982.  A. B. Tsybakov. Introduction to Nonparametric Estimation. Springer, 2009.  S. van de Geer. Empirical Processes in M-Estimation. Cambridge University Press, 2000.  G. Wahba. Spline models for observational data. CBMS-NSF Regional Conference Series  in Applied Mathematics. SIAM, Philadelphia, PN, 1990.  L. Wasserman. All of Nonparametric Statistics. Springer, 2006.  C. Williams and M. Seeger. Using the Nystr\u00a8om method to speed up kernel machines.  Advances in Neural Information Processing Systems 14, pages 682-688, 2001.  Y. Yao, L. Rosasco, and A. Caponnetto. On early stopping in gradient descent learning.  Constructive Approximation, 26(2):289-315, 2007.  T. Zhang. Learning bounds for kernel regression using e\ufb00ective data dimensionality. Neural  Computation, 17(9):2077-2098, 2005.  Y. Zhang, J. C. Duchi, and M. J. Wainwright. Communication-e\ufb03cient algorithms for statistical optimization. In Advances in Neural Information Processing Systems 26, 2012. Zhang Duchi Wainwright  h  i  f  b  \u2212  P  f \u2217  \u03bexi  \u03a3 := 1 n  = f (x)  ), so \u00b7  \u03bex, f h  f, \u03bexi  f f \u2217 b \u2206 \u03bex \u03a3  b \u03a3f = 1 n  = defined as the outer product  Empirical KRR minimizer based on n samples Optimal function generating data, where yi = f \u2217(xi) + \u03b5i Error RKHS evaluator \u03bex := K(x, Operator mapping H \u2192 H n so that \u03bexi, f i=1 h i jth orthonormal basis vector for L2(P) Basis coe\ufb03cients of \u2206 or E[\u2206 Basis coe\ufb03cients of f \u2217, i.e. f \u2217 = Integer-valued truncation point Diagonal matrix with M = diag(\u00b51, . . . , \u00b5d) Diagonal matrix with Q = Id\u00d7d + \u03bbM \u22121 n Truncation of vector v. For v = v Untruncated part of vector v, defined as v\u2191 = (vd+1, vd+1, . . .) v\u2191 j>d \u00b5j The tail sum \u03b2d \u221e j=1 1/(1 + \u03bb/\u00b5j) \u03b3(\u03bb) The sum max b(n, d, k) The maximum max  d matrix with coordinates \u03a6ij = \u03c6j(xi) j \u03bdj\u03c6j \u2208 H  \u21132(N) defined as v\u2193 = (v1, . . . , vd)  b \u03c6j \u03b4j \u03b8j d M Q \u03a6 v\u2193  \u221e j=1 \u03b8j\u03c6j  , defined as v\u2193 =  , max  P  P  P  \u00d7  \u2208  b  |  X] (depending on context), i.e. \u2206 =  P  { p  k, log(2d) } {  /n1/2\u22121/k k, log(2d) } {  }  Table 2: Notation used in proofs  n  i=1 \u03bexi \u2297  \u03bexi,  P  \u221e j=1 \u03b4j\u03c6j  P  d j=1 \u03bdj\u03c6j; for  P  "}, "Regret Minimization for Branching Experts": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Regret Minimization for Branching Experts", "abstract": "We study regret minimization bounds in which the dependence on the number of experts is replaced by measures of the realized complexity of the expert class. The measures we consider are defined in retrospect given the realized losses. We concentrate on two interesting cases. In the first, our measure of complexity is the number of different \u201cleading experts\u201d, namely, experts that were best at some point in time. We derive regret bounds that depend only on this measure, independent of the total number of experts. We also consider a case where all experts remain grouped in just a few clusters in terms of their realized cumulative losses. Here too, our regret bounds depend only on the number of clusters determined in retrospect, which serves as a measure of complexity. Our results are obtained as special cases of a more general analysis for a setting of branching experts,where the set of experts may grow over time according to a tree-like structure, determined by an adversary. For this setting of branching experts, we give algorithms and analysis that cover both the full information and the bandit scenarios.", "pdf_url": "http://proceedings.mlr.press/v30/Gofer13.pdf", "keywords": ["Regret Minimization", "Hedge Algorithm", "Structured Experts"], "reference": "Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic  multiarmed bandit problem. SIAM Journal on Computing, 32(1):48-77, 2002.  Avrim Blum and Yishay Mansour. From external to internal regret. Journal of Machine  Learning Research, 8:1307-1324, 2007.  Olivier Bousquet and Manfred Warmuth. Tracking a small set of experts by mixing past  posteriors. Journal of Machine Learning Research, 3:363-396, 2002.  S\u00b4ebastien Bubeck and Nicol`o Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.  N. Cesa-Bianchi, Y. Mansour, and G. Stoltz. Improved second-order bounds for prediction  with expert advice. Machine Learning, 66(2-3):321-352, 2007.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  In NIPS, pages 297-305, 2009.  Kamalika Chaudhuri, Yoav Freund, and Daniel Hsu. A parameter-free hedging algorithm.  13   Regret Minimization for Branching Experts  random variable denoting Exp3.C\u2019s total loss with respect to the sequence I1, . . . , IT of random draws.  R+ such that for every Theorem 12 Let \u03b71, \u03b72, . . . be a sequence of functions \u03b7t : N . . . (in what follows, we write \u03b7t = \u03b7t(Nt) k2 \u2264 k1 \u2264 \u2265 for short). If i0, . . . , iT = m(T ) are the actions on the path from the root to the best action m(T ), then  . . ., it holds that \u03b71(k1)  \u03b72(k2)  \u2192  \u2265  T  T  E RT  1 2  \u2264  Nt\u03b7t +  ln  |  1 \u03b7t  Nt  C(it, t + 1)  Nt+1  |  +  ln NT +1 \u03b7T  .  t=1 X If Exp3.C is run with \u03b7t(k) =  t=1 X ln ek tk , then  E RT  \u2264T NT ln eNT  1 +  C(it, t + 1)  ln  T t=1 |  2 ln eNT  Q  .  |  !     q  p  (2)  (3)  Acknowledgments  We wish to thank the anonymous reviewers for their helpful comments. This research was supported in part by the Google Inter-university center for Electronic Markets and Auctions, by a grant from the Israel Science Foundation, by a grant from United States- Israel Binational Science Foundation (BSF), by a grant from the Israeli Ministry of Science (MoS), and by The Israeli Centers of Research Excellence (I-CORE) program (Center No. 4/11). This work is part of Ph.D. thesis research carried out by the first author at Tel Aviv University.  References  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic  multiarmed bandit problem. SIAM Journal on Computing, 32(1):48-77, 2002.  Avrim Blum and Yishay Mansour. From external to internal regret. Journal of Machine  Learning Research, 8:1307-1324, 2007.  Olivier Bousquet and Manfred Warmuth. Tracking a small set of experts by mixing past  posteriors. Journal of Machine Learning Research, 3:363-396, 2002.  S\u00b4ebastien Bubeck and Nicol`o Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.  N. Cesa-Bianchi, Y. Mansour, and G. Stoltz. Improved second-order bounds for prediction  with expert advice. Machine Learning, 66(2-3):321-352, 2007.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  In NIPS, pages 297-305, 2009.  Kamalika Chaudhuri, Yoav Freund, and Daniel Hsu. A parameter-free hedging algorithm. Gofer Cesa-Bianchi Gentile Mansour  Alexey V. Chernov and Vladimir Vovk. Prediction with advice of unknown number of  experts. In UAI, pages 117-125, 2010.  Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin, and Shenghuo Zhu. Online optimization with gradual variations. Journal of Machine Learning Research - Proceedings Track, 23:6.1-6.20, 2012.  Peter DeMarzo, Ilan Kremer, and Yishay Mansour. Online trading algorithms and robust  option pricing. In STOC, pages 477-486, 2006.  Y. Freund, R. Schapire, Y. Singer, and M. Warmuth. Using and combining predictors that specialize. In Proceedings of the 29th Annual ACM Symposium on the Theory of Computing, pages 334-343. ACM Press, 1997.  Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. In Euro-COLT, pages 23-37. Springer-Verlag, 1995.  E. Gofer and Y. Mansour. Pricing exotic derivatives using regret minimization. In Proc. of  the 4th Symposium on Algorithmic Game Theory (SAGT), 2011.  E. Hazan and S. Kale. Extracting certainty from uncertainty: regret bounded by variation  in costs. In COLT, pages 57-68, 2008.  M. Herbster and M.K. Warmuth. Tracking the best expert. Machine Learning, 32(2):  151-178, 1998.  A. Kalai and S. Vempala. E\ufb03cient algorithms for online decision problems. Journal of  Computer and System Sciences, 71(3):291-307, 2005.  R. Kleinberg, A. Niculescu-Mizil, and Y. Sharma. Regret bounds for sleeping experts and  bandits. Machine learning, 80(2):245-272, 2010.  Wouter Koolen, Dmitry Adamskiy, and Manfred Warmuth. Putting Bayes to sleep.  In  NIPS, pages 135-143, 2012.  N. Littlestone and M.K. Warmuth. The weighted majority algorithm. Information and  Computation, 108:212-261, 1994.  Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V. Vazirani. Algorithmic Game Theory. Cambridge University Press, New York, NY, USA, 2007. ISBN 0521872820.  Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan. Relax and localize: From value  to algorithms. arXiv preprint arXiv:1204.0870, 2012.  Cosma Rohilla Shalizi, Abigail Z. Jacobs, and Aaron Clauset. Adapting to non-stationarity  with growing expert ensembles. CoRR, abs/1103.0949, 2011.  V.G. Vovk. Aggregating strategies. In Proceedings of the 3rd Annual Workshop on Com-  putational Learning Theory, pages 372-383, 1990. Regret Minimization for Branching Experts  "}, "Horizon-Independent Optimal Prediction with Log-Loss in Exponential Families": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Horizon-Independent Optimal Prediction with Log-Loss in Exponential Families", "abstract": "We study online learning under logarithmic loss with regular parametric models. Hedayati and Bartlett (2012) showed that a Bayesian prediction strategy with Jeffreys prior and sequential normalized maximum likelihood (SNML) coincide and are optimal if and only if the latter is exchangeable, which occurs if and only if the optimal strategy can be calculated without knowing the time horizon in advance. They put forward the question what families have exchangeable SNML strategies. We answer this question for one-dimensional exponential families: SNML is exchangeable only for three classes of natural exponential family distributions,namely the Gaussian, the gamma, and the Tweedie exponential family of order\u00a03/2.", "pdf_url": "http://proceedings.mlr.press/v30/Bartlett13.pdf", "keywords": ["SNML Exchangeability", "Exponential Family", "Online Learning", "Logarithmic Loss", "Bayesian Strategy", "Je\ufb00reys Prior", "Fisher Information"], "reference": "York: John Wiley, 1978.  O. Barndor\ufb00-Nielsen. Information and Exponential Families in Statistical Theory. New  12   Bartlett Gr\u00a8unwald Harremo\u00a8es Hedayati Kot(cid:32)lowski  Now we get to the second case where the variance function is given by Equation 15. If c1 = 0 we get an exponential family where the variance is constant, i.e. the family is the Gaussian translation family. Then the term k corresponds to a translation of the exponential family and we may assume that k = 0. If c1 (cid:54)= 0 we can scale up or down and obtain the equation  V (\u00b5) = 2\u00b53/2.  (16)  There exists an exponential family with this variance function, namely the Tweedie family of order 3/2 with V (\u00b5) = 2\u00b53/2. Since exponential families are uniquely determined by their variance function Morris (1982), the Tweedie family of order 3/2 is the only family satisfying (16).  4. Discussion  The present paper has focused on 1-dimensional exponential families with non-empty inte- rior parameter spaces. Any model that admits a 1-dimensional su\ufb03cient statistic can be embedded in a one dimensional exponential family. One can prove that SNML exchange- ability implies that the parameter space must have non-empty interior, thus strengthening our results further, but the limited space did not allow us to go into this problem here.  We do not have any general results for the multidimensional case, but we can make a few observations: products of models that are SNML exchangeable are also exchangeable. All multidimensional Gaussian location models can be obtained in this way by a suitable choice of coordinate system. The only other SNML exchangeable models we know of in higher dimensions are Gaussian models where the mean is unknown and the scaling of the covariance matrix is unknown. This can be seen from the fact that a sum of squared Gaussian variables has a Gamma distribution. The Tweedie family of order 3/2 does not seem to play any interesting role in higher dimensions, because it cannot be combined with the other distributions.  One of the consequences of this paper is that for 1-dimensional exponential families, NML (if it is defined without conditioning) will always be horizon dependent. We conjecture that this conclusion will hold for arbitrary models. Only conditional versions of NML allow the kind of consistency that we call SNML exchangeability, and even after conditioning, SNML exchangeability is restricted to a few but very important models.  Acknowledgements  Wojciech Kot(cid:32)lowski has been supported by the Foundation of Polish Science under the Homing Plus programme. We gratefully acknowledge the support of the NSF through grant CCF-1115788 and of the Australian Research Council through Australian Laureate Fellowship FL110100281.  References  York: John Wiley, 1978.  O. Barndor\ufb00-Nielsen. Information and Exponential Families in Statistical Theory. New Horizon-Independent Optimal Prediction with Log-Loss in Exponential Families  A. Barron, J. Rissanen, and B. Yu. The minimum description length principle in coding and modeling. IEEE Transactions on Information Theory, 44(6):2743-2760, 1998. Special Commemorative Issue: Information Theory: 1948-1998.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning and Games. Cambridge University  I. Csisz\u00b4ar and F. Mat\u00b4us. Information projections revisited. IEEE Transactions on Infor-  mation Theory, vol. 49, no. 6, pp. 1474-1490, 2003.  P. Gr\u00a8unwald. The Minimum Description Length Principle. MIT Press, Cambridge, MA,  Press, 2006.  2007.  P. Harremo\u00a8es. Extendable MDL. Accepted for presentation at International Symposium for  Information Theory (ISIT 2013), ArXiv: 1301.6465, Jan. 2013.  F. Hedayati and P. Bartlett. Exchangeability Characterizes Optimality of Sequential Nor- malized Maximum Likelihood and Bayesian Prediction with Je\ufb00reys Prior. In Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS \u201912), 2012a.  F. Hedayati and P. Bartlett. The optimality of Je\ufb00reys prior for online density estimation and the asymptotic normality of maximum likelihood estimators. In Proceedings of the Twenty Fifth Conference on Learning Theory (COLT\u2019 12), 2012b.  A. Hurwitz. \u00a8Uber die angen\u00a8aherte Darstellung der Irrationalzahlen durch rationale Br\u00a8uche (On the approximation of irrational numbers by rational numbers, in German). Mathe- matische Annalen 39 (2): 279-284, 1891.  B. J\u00f8rgensen. The Theory of Dispersion Models. Chapman & Hall, 1997.  S. Kakade, M. Seeger, and D. Foster. Worst-case bounds for Gaussian process models. In Proceedings of the 2005 Neural Information Processing Systems Conference (NIPS 2005), 2006.  W. Kot(cid:32)lowski and P. Gr\u00a8unwald. Maximum likelihood vs. sequential normalized maximum likelihood in on-line density estimation. In Proceedings of the Twenty-Fourth Conference on Learning Theory (COLT\u2019 11), 761-779, Budapest, 2011.  F. Liang and A. R. Barron. Exact minimax strategies for predictive density estimation, data compression, and model selection. IEEE Transactions on Information Theory, 50: 2708-2726, 2004.  C. Morris. Natural exponential families with quadratic variance functions. Ann. Statist.,  10:65-80, 1982.  J. Rissanen. Modeling by the shortest data description. Automatica, 14:465-471, 1978.  J. Rissanen. Fisher information and stochastic complexity. IEEE Transactions on Infor-  mation Theory, 42(1):40-47, 1996. Bartlett Gr\u00a8unwald Harremo\u00a8es Hedayati Kot(cid:32)lowski  J. Rissanen and T. Roos. Conditional NML universal models. In Information Theory and  Applications Workshop (ITA-07), 337-341, 2007.  T. Roos and J. Rissanen. On sequentially normalized maximum likelihood models.  In Workshop on Information Theoretic Methods in Science and Engineering (WITMSE-08), 2008.  Y. Shtarkov. Universal sequential coding of single messages. Problems of Information  Transmission, 23(3):175-186, 1987.  E. Takimoto and M. Warmuth. The last-step minimax algorithm. In Conference on Algo-  rithmic Learning Theory (ALT \u201900), 2000a.  E. Takimoto and M. Warmuth. The minimax strategy for Gaussian density estimation. In  Conference on Learning Theory (COLT \u201900), 100-106, 2000b.  "}, "Online Similarity Prediction of Networked Data from Known and Unknown Graphs": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Online Similarity Prediction of Networked Data from Known and Unknown Graphs", "abstract": "We consider online similarity prediction problems over networked data. We begin by relating this task to the more standard class prediction problem, showing that, given an arbitrary algorithm for class prediction, we can construct an algorithm for similarity prediction with \u201cnearly\u201d the same mistake bound, and vice versa. After noticing that this general construction is computationally infeasible, we target our study to feasible similarity prediction algorithms on networked data. We initially assume that the network structure is known to the learner. Here we observe that Matrix Winnow (Warmuth, 2007) has a near-optimal mistake guarantee, at the price of cubic prediction time per round. This motivates our effort for an efficient implementation of a Perceptron-like algorithm with a weaker mistake guarantee but with only poly-logarithmic prediction time. Our focus then turns to the challenging case of networks whose structure is initially unknown to the learner. In this novel setting, where the network structure is only incrementally revealed, we obtain a mistake-bounded algorithm with a quadratic prediction time per round.", "pdf_url": "http://proceedings.mlr.press/v30/Gentile13.pdf", "keywords": ["graph transduction", "similarity prediction", "online learning"], "reference": "N. Alon, C. Avin, M. Kouck\u00b4y, G. Kozma, Z. Lotker, and M. Tuttle. Many random walks  are faster than one. Comb. Probab. Comput., 20(4):481-502, 2011.  J. Basilico and T. Hofmann. Unifying collaborative and content-based filtering. In Proc of  the 21st ICML, ICML, 2004.  graphs. In COLT 2004, 2004.  M. Belkin, I. Matveeva, and P. Niyogi. Regularization and semi-supervised learning on large  A. Ben-Dor, R. Shamir, and Z. Yakhini. Clustering gene expression patterns. Journal of  Computational Biology, 6(3/4), 1999.  A. Broder. Generating random spanning trees. In Proceedings of the 30th Annual Symposium on Foundations of Computer Science, SFCS \u201989, pages 442-447. IEEE Computer Society, 1989.  C. Brunner, A. Fischer, K. Luig, and T. Thies. Pairwise support vector machines and their application to large scale problems. Journal of Machine Learning Research, 13:2279-2292, 2012.  E. Candes and B. Recht. Exact matrix completion via convex optimization. Foundations  of Computational Mathematics, 9(6):717-772, 2009.  E. Candes and T. Tao. The power of convex relaxation: near-optimal matrix completion.  IEEE Transactions on Information Theory, 56:2053-2080, 2010.  Q. Cao, Z. Guo, and Y. Ying. Generalization bounds for metric and similarity learning.  CoRR, abs/1207.5437, 2012.  G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear algorithms for online multitask  classification. Journal of Machine Learning Research, 11:2901-2934, 2010.  N. Cesa-Bianchi, C. Gentile, and F. Vitale. Fast and optimal prediction on a labeled tree.  In Proceedings of the 22nd Annual Conference on Learning. Omnipress, 2009.  N. Cesa-Bianchi, C Gentile, F. Vitale, and G. Zappella. Random spanning trees and the prediction of weighted graphs. In Proceedings of the 27th International Conference on Machine Learning (27th ICML), pages 175-182, 2010a.  N. Cesa-Bianchi, C. Gentile, F. Vitale, and G. Zappella. Active learning on trees and graphs. In Proceedings of the 23rd Conference on Learning Theory (23rd COLT), pages 320-332, 2010b.  T. H. Cormen, C. Stein, R. L. Rivest, and C. E. Leiserson. Introduction to Algorithms.  McGraw-Hill Higher Education, 2001. ISBN 0070131511.  A. Demiriz, K. Bennett, and M.J. Embrechts. Semi-supervised clustering using genetic algorithms. In In Artificial Neural Networks in Engineering (ANNIE-99), pages 809-814, 1999.  14   Gentile Herbster Pasteris  References  N. Alon, C. Avin, M. Kouck\u00b4y, G. Kozma, Z. Lotker, and M. Tuttle. Many random walks  are faster than one. Comb. Probab. Comput., 20(4):481-502, 2011.  J. Basilico and T. Hofmann. Unifying collaborative and content-based filtering. In Proc of  the 21st ICML, ICML, 2004.  graphs. In COLT 2004, 2004.  M. Belkin, I. Matveeva, and P. Niyogi. Regularization and semi-supervised learning on large  A. Ben-Dor, R. Shamir, and Z. Yakhini. Clustering gene expression patterns. Journal of  Computational Biology, 6(3/4), 1999.  A. Broder. Generating random spanning trees. In Proceedings of the 30th Annual Symposium on Foundations of Computer Science, SFCS \u201989, pages 442-447. IEEE Computer Society, 1989.  C. Brunner, A. Fischer, K. Luig, and T. Thies. Pairwise support vector machines and their application to large scale problems. Journal of Machine Learning Research, 13:2279-2292, 2012.  E. Candes and B. Recht. Exact matrix completion via convex optimization. Foundations  of Computational Mathematics, 9(6):717-772, 2009.  E. Candes and T. Tao. The power of convex relaxation: near-optimal matrix completion.  IEEE Transactions on Information Theory, 56:2053-2080, 2010.  Q. Cao, Z. Guo, and Y. Ying. Generalization bounds for metric and similarity learning.  CoRR, abs/1207.5437, 2012.  G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear algorithms for online multitask  classification. Journal of Machine Learning Research, 11:2901-2934, 2010.  N. Cesa-Bianchi, C. Gentile, and F. Vitale. Fast and optimal prediction on a labeled tree.  In Proceedings of the 22nd Annual Conference on Learning. Omnipress, 2009.  N. Cesa-Bianchi, C Gentile, F. Vitale, and G. Zappella. Random spanning trees and the prediction of weighted graphs. In Proceedings of the 27th International Conference on Machine Learning (27th ICML), pages 175-182, 2010a.  N. Cesa-Bianchi, C. Gentile, F. Vitale, and G. Zappella. Active learning on trees and graphs. In Proceedings of the 23rd Conference on Learning Theory (23rd COLT), pages 320-332, 2010b.  T. H. Cormen, C. Stein, R. L. Rivest, and C. E. Leiserson. Introduction to Algorithms.  McGraw-Hill Higher Education, 2001. ISBN 0070131511.  A. Demiriz, K. Bennett, and M.J. Embrechts. Semi-supervised clustering using genetic algorithms. In In Artificial Neural Networks in Engineering (ANNIE-99), pages 809-814, 1999. Similarity Prediction of Networked Data  C. Gentile. The robustness of the p-norm algorithms. Machine Learning, 53:265-299, 2003.  D. Gross. Recovering low-rank matrices from few coe\ufb03cients in any basis. IEEE Transac-  tions on Information Theory, 57/3:1548-1566, 2011.  J. L. Gross and J. Yellen. Handbook of graph theory. CRC Press, 2003. ISBN 1584880902.  A. J. Grove, N. Littlestone, and D. Schuurmans. General convergence results for linear  discriminant updates. Machine Learning, 43:173-210, 2001.  E. Hazan, S. Kale, and S. Shalev-Shwartz. Near-optimal algorithms for online matrix prediction. In Proceedings of the 25th Annual Conference on Learning Theory (COLT\u201912), 2012.  M. Hein, J.Y. Audibert, and U. von Luxburg. Graph laplacians and their convergence on random neighborhood graphs. Journal of Machine Learning Research, 8:1325-1368, 2007.  M. Herbster. Exploiting cluster-structure to predict the labeling of a graph. In Proceedings of the 19th International Conference on Algorithmic Learning Theory, pages 54-69, 2008.  M. Herbster and G. Lever. Predicting the labelling of a graph via minimum p-seminorm In Proceedings of the 22nd Annual Conference on Learning Theory  interpolation. (COLT\u201909), 2009.  M. Herbster and M. Pontil. Prediction on a graph with a perceptron. In Advances in Neural Information Processing Systems 19, pages 577-584. MIT Press, Cambridge, MA, 2007.  M. Herbster and M. K. Warmuth. Tracking the best expert. Machine Learning, 32(2):  151-178, 1998. ISSN 0885-6125.  M. Herbster, M. Pontil, and L. Wainer. Online learning over graphs. In ICML \u201905: Pro- ceedings of the 22nd international conference on Machine learning, pages 305-312, New York, NY, USA, 2005. ACM.  M. Herbster, M. Pontil, and S. R. Galeano. Fast prediction on a tree.  In Proc. of the 22nd Annual Conference on Neural Information Processing Systems, pages 657-664. MIT Press, 2008.  M. Herbster, G. Lever, and M. Pontil. Online prediction on large diameter graphs.  In Advances in Neural Information Processing Systems (NIPS 22), pages 649-656. MIT Press, 2009.  M. Jerrum and A. Sinclair. Polynomial-time approximation algorithms for the ising model.  SIAM J. Comput., 22(5):1087-1116, 1993.  S. M. Kakade, S. Shalev-Shwartz, and A. Tewari. Regularization techniques for learning  with matrices. The Journal of Machine Learning Research, pages 1865-1890, 2012.  V. Koltchinskii and P. Rangel. Low rank estimation of similarities on graphs. CoRR, 2012. Gentile Herbster Pasteris  V. Koltchinskii, K. Lounici, and A. Tsybakov. Nuclear norm penalization and optimal rates  for noisy matrix completion. Annals of Statistics, 39(5):2302-2329, 2011.  R. Kondor, N. Shervashidze, and K. M. Borgwardt. The graphlet spectrum. In ICML 2009,  2009.  Z. Li, J. Liu, and X. Tang. Pairwise constraint propagation by semidefinite programming  for semi-supervised classification. In Proc of the 25th ICML, ICML, 2008.  N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold  algorithm. Machine Learning, 2:285-318, April 1988.  N. Littlestone and M. K. Warmuth. The weighted majority algorithm. Inf. Comput., 108  (2):212-261, 1994.  R. Lyons and Y. Peres. Probability on Trees and Networks. Cambridge University Press, 2012. In preparation. Current version available at http://mypage.iu.edu/~rdlyons/.  A. Maurer. Learning similarity with operator-valued large-margin classifiers. Journal of  Machine Learning Research, 9:1049-1082, 2008.  S. Negahban and M. Wainwright. Restricted strong convexity and weighted matrix com-  pletion with noise. Preprint, 2010.  A.B. Noviko\ufb00. On convergence proofs on perceptrons. In Proceedings of the Symposium on  the Mathematical Theory of Automata, pages 615-622, 1962.  J. Pearl. Reverend Bayes on inference engines: A distributed hierarchical approach.  In  Proc. Natl. Conf. on AI, pages 133-136, 1982.  S. S. Rangapuram and M. Hein. Constrained 1-spectral clustering. In Proc. 15th Interna-  tional Conference on Artificial Intelligence and Statistics, AISTATS, 2012.  A. Rohde and A. Tsybakov. Estimation of high-dimensional low rank matrices. Annals of  Statistics, 39(2):887-930, 2011.  S. Shalev-Shwartz, Y. Singer, and A. Ng. Online and batch learning of pseudo-metrics. In Proceedings of the twenty-first international conference on Machine learning, ICML \u201904. ACM, 2004.  K. Tsuda, G. R\u00a8atsch, and M. K. Warmuth. Matrix exponentiated gradient updates for on-line learning and bregman projections. Journal of Machine Learning Research, 6: 995-1018, 2005.  F. Vitale, N. Cesa-Bianchi, C. Gentile, and G. Zappella. See the tree through the lines:  The shazoo algorithm. In NIPS, pages 1584-1592, 2011.  M. K. Warmuth. Winnowing subspaces. In Proceedings of the 24th International Conference  on Machine Learning, pages 999-1006. ACM, 2007. Similarity Prediction of Networked Data  D. B. Wilson. Generating random spanning trees more quickly than the cover time. In Proceedings of the twenty-eighth annual ACM symposium on Theory of computing, pages 296-303. ACM, 1996.  E. P. Xing, A. Y. Ng, M. I. Jordan, and J. Russell S. Distance metric learning with  application to clustering with side-information. In NIPS, pages 505-512, 2002.  J. Zhang and R. Yan. On the value of pairwise constraints in classification and consistency.  In Proc of the 24th ICML, ICML, 2007.  "}, "A near-optimal algorithm for finite partial-monitoring games against adversarial opponents": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "A near-optimal algorithm for finite partial-monitoring games against adversarial opponents", "abstract": "Partial monitoring is an online learning model where in every time step, after a learner and an opponent choose their actions, the loss and the feedback for the learner is calculated based on a loss  and a feedback function, both of which are known to the learner ahead of time. As in other online learning scenarios, the goal of the learner is to minimize his cumulative loss. In this paper we present and analyze a new algorithm for locally observable partial monitoring games. We prove that the expected regret of our algorithm is of \\tilde O(\\sqrtN\u2019T), where T is the time horizon and N\u2019 is the size of the largest point-local game. The most important improvement of this bound compared to previous results is that it does not depend directly on the number of actions, but rather on the structure of the game.", "pdf_url": "http://proceedings.mlr.press/v30/Bartok13.pdf", "keywords": ["partial monitoring", "online learning", "limited feedback", "regret analysis"], "reference": "bandits. In COLT, 2009.  Jean-Yves Audibert and S\u00b4ebastien Bubeck. Minimax policies for adversarial and stochastic  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic  multiarmed bandit problem. SIAM J. Comput., 32(1):48-77, 2002.  G\u00b4abor Bart\u00b4ok, D\u00b4avid P\u00b4al, and Csaba Szepesv\u00b4ari. Toward a classification of finite partial-  monitoring games. In ALT, pages 224-238, 2010.  G\u00b4abor Bart\u00b4ok, D\u00b4avid P\u00b4al, and Csaba Szepesv\u00b4ari. Minimax regret of finite partial-monitoring games in stochastic environments. Journal of Machine Learning Research - Proceedings Track (COLT), 19:133-154, 2011.  13   Near-optimal algorithm for partial monitoring  to the construction of point-local games, this situation is avoided and thus we have the opportunity to play a point-local game of choice without randomizing.  One may notice that our bound contains the value (cid:15)G in the denominator. This value depends on the structure of the game and can get very small in some cases. One might also think that with more actions, (cid:15)G decreases and thus N gets in the bound implicitly. However, there exist game instances with many actions and large (cid:15)G. For an example consider cell decomposition in which every corner of the probability simplex has a local game with many actions, but these local games are far away from each other.  We would also like to note that a value related to (cid:15)G naturally must appear in the regret upper bound. To understand why, consider a game where two non-neighboring actions do not satisfy the local observability condition, but their cells are very close to each other (and thus (cid:15)G is small). Imagine these cells moving towards each other. When the gap becomes zero, the actions become neighbors and the game becomes non-locally observable; thus the regret will scale with T 2/3. Hence, as (cid:15)G shrinks, the regret must go up.  The bound also shows a dependence on the number of outcomes (M ). We conjecture that this dependence can be lifted with a more sophisticated way of tracking qt. Our method of devoting some rounds to exploration seems suboptimal. Improving the bound in this aspect remains future work.  As a final remark we note a fact that we found interesting.  If we use the algorithm LocalExp3 on a bandit game (we can because it is a point-local locally observable game), the algorithm does not reduce to Exp3. This is due to the fact that the expectation of the updates are o\ufb00set by the value (cid:80)N k=1 pk(t)L(k, Jt), which is in turn the expected loss of the algorithm at time step t. This \u201ccentralized\u201d update might even improve upon the performance of Exp3 because it makes the absolute values of the updates smaller.  Acknowledgments  The author thanks the anonymous reviewers for their insightful comments and constructive suggestions. This research was supported in part by DARPA grant MSEE FA8650-11-1- 7156.  References  bandits. In COLT, 2009.  Jean-Yves Audibert and S\u00b4ebastien Bubeck. Minimax policies for adversarial and stochastic  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic  multiarmed bandit problem. SIAM J. Comput., 32(1):48-77, 2002.  G\u00b4abor Bart\u00b4ok, D\u00b4avid P\u00b4al, and Csaba Szepesv\u00b4ari. Toward a classification of finite partial-  monitoring games. In ALT, pages 224-238, 2010.  G\u00b4abor Bart\u00b4ok, D\u00b4avid P\u00b4al, and Csaba Szepesv\u00b4ari. Minimax regret of finite partial-monitoring games in stochastic environments. Journal of Machine Learning Research - Proceedings Track (COLT), 19:133-154, 2011. Bart\u00b4ok  St\u00b4ephane Boucheron, G\u00b4abor Lugosi, and Olivier Bousquet. Concentration inequalities. In  Advanced Lectures on Machine Learning, pages 208-240, 2003.  Nicol`o Cesa-Bianchi, G\u00b4abor Lugosi, and Gilles Stoltz. Regret minimization under partial  monitoring. Math. Oper. Res., 31(3):562-580, 2006.  Dean P. Foster and Alexander Rakhlin. No internal regret via neighborhood watch. Journal  of Machine Learning Research - Proceedings Track (AISTATS), 22:382-390, 2012.  Nick Littlestone and Manfred K. Warmuth. The weighted majority algorithm. Inf. Comput.,  108(2):212-261, 1994.  In NIPS, pages 684-692, 2011.  Shie Mannor and Ohad Shamir. From bandits to experts: On the value of side-observations.  Antonio Piccolboni and Christian Schindelhauer. Discrete prediction games with arbitrary  feedback and loss. In COLT/EuroCOLT, pages 208-223, 2001.  V. G. Vovk. Aggregating strategies. In COLT, pages 371-386, 1990.  "}, "Representation, Approximation and Learning of Submodular Functions Using Low-rank Decision Trees": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Representation, Approximation and Learning of Submodular Functions Using Low-rank Decision Trees", "abstract": "We study the complexity of approximate representation and learning of submodular functions over the uniform distribution on the Boolean hypercube {0,1}^n. Our main result is the following structural theorem: any submodular function is \u03b5-close in \\ell_2 to a real-valued decision tree (DT) of depth O(1/\u03b5^2). This immediately implies that any submodular function is  \u03b5-close to a function of at most 2^O(1/\u03b5^2) variables and has a spectral \\ell_1 norm of 2^O(1/\u03b5^2). It also implies the closest previous result that states that submodular functions can be approximated by polynomials of degree O(1/\u03b5^2) (Cheraghchi et al., 2012). Our result is proved by constructing an approximation of a submodular function by a DT of rank 4/\u03b5^2 and a proof that any rank-r DT can be \u03b5-approximated by a DT of depth \\frac52(r+\\log(1/\u03b5)). We show that these structural results can be exploited to give an attribute-efficient PAC learning algorithm for submodular functions running in time \\tildeO(n^2) \u22c52^O(1/\u03b5^4). The best previous algorithm for the problem requires n^O(1/\u03b5^2) time and examples (Cheraghchi et al., 2012) but works also in the agnostic setting. In addition, we give improved learning algorithms for a number of related settings. We also prove that our PAC and agnostic learning algorithms are essentially optimal via two lower bounds: (1) an information-theoretic lower bound of 2^\u03a9(1/\u03b5^2/3) on the complexity of learning monotone submodular functions  in any reasonable model (including learning with value queries); (2) computational lower bound of n^\u03a9(1/\u03b5^2/3) based on a reduction to learning of sparse parities with noise, widely-believed to be intractable. These are the first lower bounds for learning of submodular functions over the uniform distribution.", "pdf_url": "http://proceedings.mlr.press/v30/Feldman13.pdf", "keywords": ["submodular function", "decision tree", "learning", "uniform distribution"], "reference": "D. J. Lehmann B. Lehmann and N. Nisan. Combinatorial auctions with decreasing marginal utilities.  Games and Economic Behavior, 55:1884-1899, 2006.  Ashwinkumar Badanidiyuru, Shahar Dobzinski, Hu Fu, Robert Kleinberg, Noam Nisan, and Tim  Roughgarden. Sketching valuation functions. In SODA, pages 1025-1035, 2012.  M.F. Balcan and N. Harvey. Submodular functions: Learnability, structure, and optimization. CoRR,  abs/1008.2159, 2012. Earlier version in proceedings of STOC 2011.  M.F. Balcan, Florin Constantin, Satoru Iwata, and Lei Wang. Learning valuation functions. Journal  of Machine Learning Research - COLT Proceedings, 23:4.1-4.24, 2012.  Eric Blais, Krzysztof Onak, Rocco Servedio, and Grigory Yaroslavtsev. Concise representations of  discrete submodular functions, 2013. Personal communication.  A. Blum, A. Kalai, and H. Wasserman. Noise-tolerant learning, the parity problem, and the statisti-  cal query model. Journal of the ACM, 50(4):506-519, 2003.  St\u00b4ephane Boucheron, G\u00b4abor Lugosi, and Pascal Massart. A sharp concentration inequality with  applications. Random Struct. Algorithms, 16(3):277-292, 2000.  M. Cheraghchi, A. Klivans, P. Kothari, and H. Lee. Submodular functions are noise stable.  In  SODA, pages 1586-1592, 2012.  G. Cornuejols, M. Fisher, and G. Nemhauser. Location of bank accounts to optimize \ufb02oat: an analytic studyof exact and approximate algorithms. Management Science, 23:789-810, 1977.  Shahar Dobzinski, Noam Nisan, and Michael Schapira. Approximation algorithms for combinato-  rial auctions with complement-free bidders. In STOC, pages 610-618, 2005.  Shaddin Dughmi, Tim Roughgarden, and Qiqi Yan. From convex optimization to randomized mech-  anisms: toward optimal combinatorial auctions. In STOC, pages 149-158, 2011.  Jack Edmonds. Matroids, submodular functions and certain polyhedra. Combinatorial Structures  and Their Applications, pages 69-87, 1970.  13   LEARNING SUBMODULAR FUNCTIONS USING LOW-RANK DTS  {0, 1}, with probability at least 2/3, outputs a function h : {0, 1}n \u2192 [0, 1], such that (cid:107)f \u2212 h(cid:107)1 \u2264 \u2206 + (cid:15), where \u2206 = ming\u2208DT[0,1](r){(cid:107)f \u2212 g(cid:107)1}. Further, A runs in time poly(n, 2r, 1/(cid:15)) and uses poly(log n, 2r, 1/(cid:15)) value queries.  Combining Theorems 20 and 1 gives the following agnostic learning algorithm for submodular  functions (the proof is in App. A.4).  Theorem 21 Let Cs denote the class of all submodular functions from {0, 1}n to [0, 1]. There exists an algorithm A that given (cid:15) > 0 and access to value queries of any real-valued f , with probability at least 2/3, outputs a function h, such that (cid:107)f \u2212 h(cid:107)1 \u2264 \u2206 + (cid:15), where \u2206 = ming\u2208Cs{(cid:107)f \u2212 g(cid:107)1}. Further, A runs in time poly(n, 21/(cid:15)2) and using poly(log n, 21/(cid:15)2) value queries.  References  D. J. Lehmann B. Lehmann and N. Nisan. Combinatorial auctions with decreasing marginal utilities.  Games and Economic Behavior, 55:1884-1899, 2006.  Ashwinkumar Badanidiyuru, Shahar Dobzinski, Hu Fu, Robert Kleinberg, Noam Nisan, and Tim  Roughgarden. Sketching valuation functions. In SODA, pages 1025-1035, 2012.  M.F. Balcan and N. Harvey. Submodular functions: Learnability, structure, and optimization. CoRR,  abs/1008.2159, 2012. Earlier version in proceedings of STOC 2011.  M.F. Balcan, Florin Constantin, Satoru Iwata, and Lei Wang. Learning valuation functions. Journal  of Machine Learning Research - COLT Proceedings, 23:4.1-4.24, 2012.  Eric Blais, Krzysztof Onak, Rocco Servedio, and Grigory Yaroslavtsev. Concise representations of  discrete submodular functions, 2013. Personal communication.  A. Blum, A. Kalai, and H. Wasserman. Noise-tolerant learning, the parity problem, and the statisti-  cal query model. Journal of the ACM, 50(4):506-519, 2003.  St\u00b4ephane Boucheron, G\u00b4abor Lugosi, and Pascal Massart. A sharp concentration inequality with  applications. Random Struct. Algorithms, 16(3):277-292, 2000.  M. Cheraghchi, A. Klivans, P. Kothari, and H. Lee. Submodular functions are noise stable.  In  SODA, pages 1586-1592, 2012.  G. Cornuejols, M. Fisher, and G. Nemhauser. Location of bank accounts to optimize \ufb02oat: an analytic studyof exact and approximate algorithms. Management Science, 23:789-810, 1977.  Shahar Dobzinski, Noam Nisan, and Michael Schapira. Approximation algorithms for combinato-  rial auctions with complement-free bidders. In STOC, pages 610-618, 2005.  Shaddin Dughmi, Tim Roughgarden, and Qiqi Yan. From convex optimization to randomized mech-  anisms: toward optimal combinatorial auctions. In STOC, pages 149-158, 2011.  Jack Edmonds. Matroids, submodular functions and certain polyhedra. Combinatorial Structures  and Their Applications, pages 69-87, 1970. FELDMAN KOTHARI VONDR \u00b4AK  A. Ehrenfeucht and D. Haussler. Learning decision trees from random examples. Information and  Computation, 82(3):231-246, 1989.  Uriel Feige. A threshold of ln n for approximating set cover. Journal of the ACM, 45(4):634-652,  1998.  V. Feldman. Attribute efficient and non-adaptive learning of parities and DNF expressions. Journal  of Machine Learning Research, (8):1431-1460, 2007.  V. Feldman. Distribution-specific agnostic boosting. In Proceedings of Innovations in Computer  Science, pages 241-250, 2010.  V. Feldman. A complete characterization of statistical query learning with applications to evolv-  ability. Journal of Computer System Sciences, 78(5):1444-1459, 2012.  V. Feldman and P. Kothari. Learning coverage functions. CoRR, abs/1304.2079, 2013.  V. Feldman, P. Gopalan, S. Khot, and A. Ponuswami. On agnostic learning of parities, monomials  and halfspaces. SIAM Journal on Computing, 39(2):606-645, 2009.  L. Fleischer, S. Fujishige, and S. Iwata. A combinatorial, strongly polynomial-time algorithm for  minimizing submodular functions. Journal of the ACM, 48(4):761-777, 2001.  Andr\u00b4as Frank. Matroids and submodular functions. Annotated Biblographies in Combinatorial  Optimization, pages 65-80, 1997.  M. X. Goemans and D. P. Williamson.  Improved approximation algorithms for maximum cut and satisfiability problemsusing semidefinite programming. Journal of the ACM, 42:1115-1145, 1995.  Michel X. Goemans, Nicholas J. A. Harvey, Satoru Iwata, and Vahab S. Mirrokni. Approximating  submodular functions everywhere. In SODA, pages 535-544, 2009.  O. Goldreich and L. Levin. A hard-core predicate for all one-way functions. In Proceedings of  STOC, pages 25-32, 1989.  pages 527-536, 2008.  P. Gopalan, A. Kalai, and A. Klivans. Agnostically learning decision trees. In Proceedings of STOC,  Carlos Guestrin, Andreas Krause, and Ajit Paul Singh. Near-optimal sensor placements in gaussian  processes. In ICML, pages 265-272, 2005.  A. Gupta, M. Hardt, A. Roth, and J. Ullman. Privately releasing conjunctions and the statistical  query barrier. In STOC, pages 803-812, 2011.  M. Hardt, G. Rothblum, and R. Servedio. Private data release via learning thresholds. In SODA,  pages 168-187, 2012.  D. Haussler. Decision theoretic generalizations of the PAC model for neural net and other learning  applications. Information and Computation, 100(1):78-150, 1992. ISSN 0890-5401. LEARNING SUBMODULAR FUNCTIONS USING LOW-RANK DTS  A. Kalai and V. Kanade. Potential-based agnostic boosting. In Proceedings of NIPS, pages 880-888,  2009.  A. Kalai, A. Klivans, Y. Mansour, and R. Servedio. Agnostically learning halfspaces. SIAM Journal  on Computing, 37(6):1777-1805, 2008.  M. Kearns and R. Schapire. Efficient distribution-free learning of probabilistic concepts. Journal  of Computer and System Sciences, 48:464-497, 1994.  M. Kearns, R. Schapire, and L. Sellie. Toward efficient agnostic learning. Machine Learning, 17  (2-3):115-141, 1994.  Andreas Krause and Carlos Guestrin. Submodularity and its applications in optimized information  gathering. ACM TIST, 2(4):32, 2011.  Andreas Krause, Carlos Guestrin, Anupam Gupta, and Jon M. Kleinberg. Near-optimal sensor In IPSN, pages  placements: maximizing information while minimizing communication cost. 2-10, 2006.  Andreas Krause, Ajit Paul Singh, and Carlos Guestrin. Near-optimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies. Journal of Machine Learning Research, 9:235-284, 2008.  E. Kushilevitz and Y. Mansour. Learning decision trees using the Fourier spectrum. SIAM Journal  on Computing, 22(6):1331-1348, 1993.  N. Linial, Y. Mansour, and N. Nisan. Constant depth circuits, Fourier transform and learnability.  Journal of the ACM, 40(3):607-620, 1993.  L\u00b4aszl\u00b4o Lov\u00b4asz. Submodular functions and convexity. Mathematical Programmming: The State of  the Art, pages 235-257, 1983.  Ryan O\u2019Donnell and Rocco A. Servedio. Learning monotone decision trees in polynomial time.  SIAM J. Comput., 37(3):827-844, 2007.  Christos H. Papadimitriou, Michael Schapira, and Yaron Singer. On the hardness of being truthful.  In FOCS, pages 250-259, 2008.  Maurice Queyranne. A combinatorial algorithm for minimizing symmetric submodular functions.  In Proc. of 6th ACM-SIAM SODA, pages 98-101, 1995.  Sofya Raskhodnikova and Grigory Yaroslavtsev. Learning pseudo-boolean k-dnf and submodular  functions. In Proceedings of SODA, 2013.  Gregory Valiant. Finding correlations in subquadratic time, with applications to learning parities and juntas. In The 53rd Annual IEEE Symposium on the Foundations of Computer Science (FOCS), 2012.  L. G. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134-1142, 1984. FELDMAN KOTHARI VONDR \u00b4AK  Jan Vondr\u00b4ak. Optimal approximation for the submodular welfare problem in the value oracle model.  In STOC, pages 67-74, 2008.  Jan Vondr\u00b4ak. A note on concentration of submodular functions, 2010. arXiv:1005.2791v1.  "}, "A Tale of Two Metrics: Simultaneous Bounds on Competitiveness and Regret": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "A Tale of Two Metrics: Simultaneous Bounds on Competitiveness and Regret", "abstract": "We consider algorithms for \u201csmoothed online convex optimization\u201d problems, a variant of the class of online convex optimization problems that is strongly related to metrical task systems. Prior literature on these problems has focused on two performance metrics: regret and the competitive ratio. There exist known algorithms with sublinear regret and known algorithms with constant competitive ratios; however, no known algorithm achieves both simultaneously. We show that this is due to a fundamental incompatibility between these two metrics - no algorithm (deterministic or randomized) can achieve sublinear regret and a constant competitive ratio, even in the case when the objective functions are linear. However, we also exhibit an algorithm that, for the important special case of one dimensional decision spaces, provides sublinear regret while maintaining a competitive ratio that grows arbitrarily slowly.", "pdf_url": "http://proceedings.mlr.press/v30/Andrew13.pdf", "keywords": [], "reference": "Jacob Abernethy, Peter L. Bartlett, Niv Buchbinder, and Isabelle Stanton. A regularization approach to metrical task systems. In Proc. Algorithmic Learning Theory (ALT), pages 270-284, 2010.  Manjari Asawa and Demosthenis Teneketzis. Multi-armed bandits with switching penalties.  IEEE Trans. Automatic Control, 41(3):328 -348, March 1996.  Avrim Blum and Carl Burch. On-line learning and the metrical task system problem.  Machine Learning, 39(1):35-58, 2000.  Avrim Blum and Yishay Mansour. From external to internal regret. Learning Theory,  LNCS 3559:621-636, 2005.  Avrim Blum, Howard Karlo\ufb00, Yuval Rabani, and Michael Saks. A decomposition theo- rem and bounds for randomized server problems. In Proc. IEEE Symp. Foundations of Computer Science (FOCS), pages 197-207, 1992.  Avrim Blum, Carl Burch, and Adam Kalai. Finely-competitive paging. Symp. Foundations of Computer Science (FOCS), pages 450-457, 1999.  In Proc. IEEE  13   A Tale of Two Metrics:Simultaneous Bounds on Competitiveness and Regret  6. Concluding remarks  This paper studies the relationship between regret and competitive ratio when applied to the class of SOCO problems. It shows that these metrics, from the learning and algorithms communities respectively, are fundamentally incompatible, in the sense that algorithms with sublinear regret must have infinite competitive ratio, and those with constant competitive ratio have at least linear regret. Thus, the choice of performance measure significantly a\ufb00ects the style of algorithm designed. It also introduces a generic approach for balancing these competing metrics, exemplified by a specific algorithm, RBG.  There are a number of interesting directions that this work motivates. In particular, the SOCO formulation is still under-explored, and many variations of the formulation discussed here are still not understood. For example, is it possible to tradeo\ufb00 between regret and the competitive ratio in bandit versions of SOCO? More generally, the message from this paper is that regret and the competitive ratio are incompatible within the formulation of SOCO. It is quite interesting to try to understand how generally this holds. For example, does the \u201cincompatibility result\u201d proven here extend to settings where the cost functions are random instead of adversarial, e.g., variations of SOCO such as k-armed bandit problems with switching costs?  Acknowledgments  This work was supported by NSF grants CNS 0846025 and DoE grant DE-EE0002890, along with the Australian Research Council (ARC) grants FT0991594 and DP130101378. Katrina Ligett gratefully acknowledges the generous support of the Charles Lee Powell Foundation. Alan Roytman was partially supported by NSF grants IIS-1065276, CCF-1016540, CNS- 1118126, and CNS-1136174.  References  Jacob Abernethy, Peter L. Bartlett, Niv Buchbinder, and Isabelle Stanton. A regularization approach to metrical task systems. In Proc. Algorithmic Learning Theory (ALT), pages 270-284, 2010.  Manjari Asawa and Demosthenis Teneketzis. Multi-armed bandits with switching penalties.  IEEE Trans. Automatic Control, 41(3):328 -348, March 1996.  Avrim Blum and Carl Burch. On-line learning and the metrical task system problem.  Machine Learning, 39(1):35-58, 2000.  Avrim Blum and Yishay Mansour. From external to internal regret. Learning Theory,  LNCS 3559:621-636, 2005.  Avrim Blum, Howard Karlo\ufb00, Yuval Rabani, and Michael Saks. A decomposition theo- rem and bounds for randomized server problems. In Proc. IEEE Symp. Foundations of Computer Science (FOCS), pages 197-207, 1992.  Avrim Blum, Carl Burch, and Adam Kalai. Finely-competitive paging. Symp. Foundations of Computer Science (FOCS), pages 450-457, 1999.  In Proc. IEEE Andrew Barman Ligett Lin Meyerson Roytman Wierman  Avrim Blum, Suchi Chawla, and Adam Kalai. Static optimality and dynamic search- optimality in lists and trees. In Proc. ACM-SIAM Symp. Discrete Algorithms (SODA), pages 1-8, 2002.  Allan Borodin, Nathan Linial, and Michael E. Saks. An optimal on-line algorithm for  metrical task system. J. ACM, 39(4):745-763, 1992.  Niv Buchbinder, Shahar Chen, Joseph Naor, and Ohad Shamir. Unified algorithms for online learning and competitive analysis. In Proc. Conf. on Learning Theory (COLT), 2012.  Giuseppe Carlo Calafiore. Multi-period portfolio optimization with linear control policies.  Automatica, 44(10):2463-2473, 2008.  Aaron Cot\u00b4e, Adam Meyerson, and Laura Poplawski. Randomized k-server on hierarchical  binary trees. In Proc. ACM Symp. on the Theory of Computing (STOC), 2008.  Thomas M. Cover. Universal portfolios. Mathematical Finance, 1(1):1-29, 1991.  ISSN  1467-9965.  Sudipto Guha and Kamesh Munagala. Multi-armed bandits with metric switching costs. In Automata, Languages and Programming, volume 5556 of Lecture Notes in Computer Science, pages 496-507. Springer Berlin / Heidelberg, 2009.  Yonatan Gur, Omar Besbes, and Assaf Zeevi. Non-stationary online stochastic approxima-  tion. In Presented at INFORMS general meeting, 2012.  Elad Hazan and C. Seshadhri. E\ufb03cient learning algorithms for changing environments. In  Proc. International Conference on Machine Learning, pages 393-400. ACM, 2009.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online  convex optimization. Mach. Learn., 69:169-192, December 2007. ISSN 0885-6125.  Mark Herbster and Manfred K. Warmuth. Tracking the best expert. Mach. Learn., 32(2):  151-178, August 1998. ISSN 0885-6125.  Dara Kusic and Nagarajan Kandasamy. Risk-aware limited lookahead control for dynamic resource provisioning in enterprise computing systems. Cluster Computing, 10(4):395- 408, 2007.  Minghong Lin, Adam Wierman, Lachlan L. H. Andrew, and Eno Thereska. Dynamic right-  sizing for power-proportional data centers. In Proc. IEEE INFOCOM, 2011.  Minghong Lin, Zhenhua Liu, Adam Wierman, and Lachlan L. H. Andrew. Online algorithms for geographical load balancing. In International Green Computing Conference(IGCC), 2012.  Nick Littlestone and Manfred K. Warmuth. The weighted majority algorithm. Inf. Comput.,  108(2):212-261, February 1994. ISSN 0890-5401. A Tale of Two Metrics:Simultaneous Bounds on Competitiveness and Regret  Tan Lu, Minghua Chen, and Lachlan L. H. Andrew. Simple and e\ufb00ective dynamic provision- ing for power-proportional data centers. IEEE Trans. Parallel and Distributed Systems, 2012.  Mark Manasse, Lyle McGeoch, and Daniel Sleator. Competitive algorithms for on-line problems. In Proc. ACM Symp. Theory of Computing (STOC), pages 322-333, 1988.  Rahul Urgaonkar, Bhuvan Urgaonkar, Michael J. Neely, and Anand Sivasubramaniam. Op- timal power cost management using stored energy in data centers. In Proc. ACM SIG- METRICS, pages 221-232. ACM, 2011.  Jian Yang, Ke Zeng, Han Hu, and Hongsheng Xi. Dynamic cluster reconfiguration for energy conservation in computation intensive service. IEEE Trans. Computers, 61(10): 1401-1416, 2012.  Qi Zhang, Mohamed Faten Zhani, Shuo Zhang, Quanyan Zhu, Raouf Boutaba, and Joseph L. Hellerstein. Dynamic energy-aware capacity provisioning for cloud computing environments. In Proc. IEEE/ACM Int. Conf. Autonomic Computing (ICAC), Septem- ber 2012.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In T. Fawcett and N. Mishra, editors, Proc. Int. Conf. Machine Learning (ICML), pages 928-936. AAAI Press, 2003.  "}, "Optimal Probability Estimation  with Applications to Prediction and Classification": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Optimal Probability Estimation  with Applications to Prediction and Classification", "abstract": "Via a unified viewpoint of probability estimation, classification,and prediction, we derive a uniformly-optimal combined-probability estimator, construct a classifier that uniformly approaches the error of the best possible label-invariant classifier, and improve existing results on pattern prediction and compression.", "pdf_url": "http://proceedings.mlr.press/v30/Acharya13.pdf", "keywords": ["Good-Turing estimators", "convergence rates", "linear estimators", "competitive classification"], "reference": "J. Acharya, H. Das, H. Mohimani, A. Orlitsky, and Shengjun Pan. Exact calculation of  pattern probabilities. In ISIT, pages 1498 -1502, June 2010.  J. Acharya, H. Das, A. Jafarpour, A. Orlitsky, and S. Pan. Competitive closeness testing.  JMLR - Proceedings Track, 19:47-68, 2011.  J. Acharya, H. Das, A. Jafarpour, A. Orlitsky, S. Pan, and A.T. Suresh. Competitive classification and closeness testing. JMLR - Proceedings Track, 23:22.1-22.18, 2012a.  J. Acharya, H. Das, and A. Orlitsky. Tight bounds on profile redundancy and distinguisha-  bility. In NIPS, 2012b.  T. Batu. Testing properties of distributions. PhD thesis, Cornell University, 2001.  T. Batu, L. Fortnow, R. Rubinfeld, W. D. Smith, and P. White. Testing that distributions  are close. In FOCS, pages 259-269, 2000.  S. Boucheron, O. Bousquet, and G. Lugosi. Theory of classification : A survey of some  recent advances. ESAIM: Probability and Statistics, 9:323-375, 2005.  Ulisses Braga-Neto. Classification and error estimation for discrete data. Pattern Recogni-  tion, 10(7):446-462, 2009.  13   Optimal Probability Estimation with Applications to Prediction and Classification  5.7. Lower bounds on estimation  We now lower bound the rate of convergence. We construct an explicit distribution such that with probability \u2265 1 \u2212 n\u22121 the total variation distance is (cid:101)\u2126(n\u22121/4). By Pinsker\u2019s inequality, this implies that the KL divergence is (cid:101)\u2126(n\u22121/2). Note that since distance is (cid:101)\u2126(n\u22121/4) with probability close to 1, the expected distance is also (cid:101)\u2126(n\u22121/4). def= (cid:112) \u03c0 2 i log1.5 n symbols with probability pi  def= (cid:98)i2 log3 n(cid:99) Let p be a distribution with ni , and ni symbols with probability pi + i . c1 and c2 are constants such that the sum of probabilities is 1. We sketch the proof and leave the details to the full version of the paper. Proof [sketch of Theorem 3] The distribution p has the following properties.  n1/4 log9/8 n  n1/4 log9/8 n  n , for c1  \u2264 i \u2264 c2  n  \u2022 Let R = \u222ai{npi, npi + 1 . . . npi + i} for c1  n1/4 log9/8 n  \u2264 i \u2264 c2  n1/4 log9/8 n  . For every \u00b5 \u2208 R,  Pr(\u03a6\u00b5 = 1) \u2265 1/3.  \u2022 If \u03a6\u00b5 = 1, then the symbol that has appeared \u00b5 times has probability pi or pi + i n  with almost equal probability.  \u2022 Label-invariant estimators cannot distinguish between the two cases, and hence incur  an error of (cid:101)\u2126(i/n) = (cid:101)\u2126(n\u22123/4) for a constant fraction of multiplicities \u00b5 \u2208 R.  The total number of multiplicities in R is n1/4 \u00b7 n1/4 = n1/2. Multiplying by the error for each multiplicity yields the bound (cid:101)\u2126(n\u22121/4).  References  J. Acharya, H. Das, H. Mohimani, A. Orlitsky, and Shengjun Pan. Exact calculation of  pattern probabilities. In ISIT, pages 1498 -1502, June 2010.  J. Acharya, H. Das, A. Jafarpour, A. Orlitsky, and S. Pan. Competitive closeness testing.  JMLR - Proceedings Track, 19:47-68, 2011.  J. Acharya, H. Das, A. Jafarpour, A. Orlitsky, S. Pan, and A.T. Suresh. Competitive classification and closeness testing. JMLR - Proceedings Track, 23:22.1-22.18, 2012a.  J. Acharya, H. Das, and A. Orlitsky. Tight bounds on profile redundancy and distinguisha-  bility. In NIPS, 2012b.  T. Batu. Testing properties of distributions. PhD thesis, Cornell University, 2001.  T. Batu, L. Fortnow, R. Rubinfeld, W. D. Smith, and P. White. Testing that distributions  are close. In FOCS, pages 259-269, 2000.  S. Boucheron, O. Bousquet, and G. Lugosi. Theory of classification : A survey of some  recent advances. ESAIM: Probability and Statistics, 9:323-375, 2005.  Ulisses Braga-Neto. Classification and error estimation for discrete data. Pattern Recogni-  tion, 10(7):446-462, 2009. Acharya Jafarpour Orlitsky Suresh  N. Cesa-Bianchi and G. Lugosi. Minimax regret under log loss for general classes of experts.  COLT, pages 12-18, New York, NY, USA, 1999. ACM.  S. F. Chen and J. Goodman. An empirical study of smoothing techniques for language modeling. In Proceedings of the 34th annual meeting on Association for Computational Linguistics, ACL \u201996, pages 310-318. Association for Computational Linguistics, 1996.  H. Das. Competitive Tests and Estimators for Properties of Distributions. PhD thesis,  E. Drukh and Y. Mansour. Concentration bounds for unigrams language model. In COLT,  UCSD, 2012.  2004.  W. A. Gale and G. Sampson. Good-turing frequency estimation without tears. Journal of  Quantitative Linguistics, 2(3):217-237, 1995.  I. J. Good. The population frequencies of species and the estimation of population param-  eters. 40(3-4):237-264, 1953.  P. D. Gr\u00a8unwald. The Minimum Description Length Principle. The MIT Press, 2007.  R. Krichevsky and V. Trofimov. The performance of universal encoding.  Information  Theory, IEEE Transactions on, 27(2):199 - 207, March 1981.  L. LeCam. Asymptotic methods in statistical decision theory. Springer series in statistics.  Springer, New York, 1986.  G.G. Lorentz. Bernstein polynomials. Chelsea Publishing Company, Incorporated, 1986.  D. A. McAllester and R. E. Schapire. On the convergence rate of good-turing estimators.  In COLT, 2000.  C. McDiarmid. On the method of bounded di\ufb00erences. In Surveys in Combinatorics, London  Mathematical Society Lecture Note Series. Cambridge University Press, 1989.  N. Merhav and M. Feder. Universal prediction. IEEE Transactions on Information Theory,  44(6):2124-2147, 1998.  M. Mitzenmacher and E. Upfal. Probability and computing: Randomized algorithms and  probabilistic analysis. Cambridge University Press, 2005.  M. I. Ohannessian and M A. Dahleh. Rare probability estimation under regularly varying  heavy tails. JMLR- Proceedings Track, 23:21.1-21.24, 2012.  A. Orlitsky, N. P. Santhanam, and J. Zhang. Always good turing: Asymptotically optimal  probability estimation. In FOCS, 2003.  A. Orlitsky, N.P. Santhanam, and J. Zhang. Universal compression of memoryless sources over unknown alphabets. IEEE Transactions on Information Theory, 50(7):1469- 1481, July 2004. Optimal Probability Estimation with Applications to Prediction and Classification  A. Orlitsky, N. Santhanam, K. Viswanathan, and J. Zhang. Convergence of profile based  estimators. In ISIT 2005, pages 1843 -1847, September 2005.  L. Paninski. Variational minimax estimation of discrete distributions under kl loss.  In  NIPS, 2004.  L. Paninski. A coincidence-based test for uniformity given very sparsely sampled discrete  data. IEEE Transactions on Information Theory, 54(10), 2008.  J. Rissanen. Universal coding, information, prediction, and estimation. IEEE Transactions  on Information Theory, 30(4):629-636, July 1984.  G. Shamir. A new upper bound on the redundancy of unknown alphabets. In Proceedings of The Annual Conference on Information Sciences and Systems, Princeton, New-Jersey, 2004.  G. Valiant and P. Valiant. Estimating the unseen: an n/log(n)-sample estimator for entropy  and support size, shown optimal via new clts. STOC. ACM, 2011.  V. G. Vovk. A game of prediction with expert advice. COLT, pages 51-60, New York, NY,  A. B. Wagner, P. Viswanath, and S. R. Kulkarni. Strong consistency of the good-turing  USA, 1995. ACM.  estimator. In ISIT, 2006.  "}, "Polynomial Time Optimal Query Algorithms for Finding Graphs with Arbitrary Real Weights": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Polynomial Time Optimal Query Algorithms for Finding Graphs with Arbitrary Real Weights", "abstract": "We consider the problem of finding the edges of a hidden weighted graph and their weights by using a certain type of queries as few times as possible, with focusing on two types of queries with additive property. For a set of vertices, the additive query asks the sum of weights of the edges with both ends in the set. For a pair of disjoint sets of vertices, the cross-additive query asks the sum of weights of the edges crossing between the two sets. These queries were motivated by DNA sequencing, population genetics, and artificial intelligence, and have been paid considerable attention to in computational learning. In this paper, we achieve an ultimate goal of recent years for graph finding with the two types of queries, by constructing the first polynomial time algorithms with optimal query complexity for the general class of graphs with n vertices and at most m edges in which the weights of edges are arbitrary real numbers. The algorithms are randomized and their query complexities are O(\\fracm \\log n\\log m). These bounds improve the best known by a factor of \\log m, and settle the open problem posed in some papers including [Choi and Kim, Optimal query complexity bounds for finding graphs, STOC 2008].  To build key components for graph finding, we consider the coin weighing problem with a spring scale. The problem itself has been paid much attention to in a long history of combinatorial search. We construct the first polynomial time algorithm with optimal query complexity for the general case in which the weight differences between counterfeit and authentic coins are arbitrary real numbers. We also construct the first polynomial time optimal query algorithm for finding the Fourier coefficients of a certain class of pseudo-Boolean functions.", "pdf_url": "http://proceedings.mlr.press/v30/Choi13.pdf", "keywords": ["Graph finding", "coin weighing", "Fourier coe\ufb03cients", "pseudo-Boolean functions", "query complexity"], "reference": "18(4):697-712, 2005.  N. Alon and V. Asodi. Learning a hidden subgraph. SIAM Journal on Discrete Mathematics,  N. Alon, R. Beigel, S. Kasif, S. Rudich, and B. Sudakov. Learning a hidden matching.  SIAM Journal on Computing, 33(2):487-501, 2004.  D. Angluin and J. Chen. Learning a hidden graph using O(log n) queries per edge.  In Proceedings of the 17th Annual Conference on Learning Theory (COLT 2004), pages 210-223, Ban\ufb00, Canada, 2004.  D. Angluin and J. Chen. Learning a hidden hypergraph. Journal of Machine Learning  Research, 7:2215-2236, 2006.  R. Beigel, N. Alon, M. S. Apaydin, L. Fortnow, and S. Kasif. An optimal procedure for gap closing in whole genome shotgun sequencing. In Proceedings of the Fifth Annual International Conference on Computational Molecular Biology (RECOMB 2001), pages 22-30, 2001.  R. Berinde, A. C. Gilbert, P. Indyk, H. J. Karlo\ufb00, and M. J. Strauss. Combining geometry  and combinatorics: A unified approach to sparse signal recovery. Allerton, 2008.  N. H. Bshouty. Optimal algorithms for the coin weighing problem with a spring scale. In Proceedings of the 22nd Annual Conference on Learning Theory (COLT 2009), Montreal, Canada, 2009.  N. H. Bshouty and H. Mazzawi. Toward a deterministic polynomial time algorithm with optimal additive query complexity. In Proceedings of the 35th International Symposium on Mathematical Foundations of Computer Science (MFCS 2010), pages 221-232, Brno, Czech Republic, 2010a.  N. H. Bshouty and H. Mazzawi. Optimal query complexity for reconstructing hypergraphs. In Proceedings of the 27th International Symposium on Theoretical Aspects of Computer Science (STACS 2010), pages 143-154, Nancy, France, 2010b.  N. H. Bshouty and H. Mazzawi. On parity check (0, 1)-matrix over Zp. In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms (SODA 2011), pages 1383-1394, San Francisco, USA, 2011a.  N. H. Bshouty and H. Mazzawi. Reconstructing weighted graphs with minimal query com-  plexity. Theoretical Computer Science, 412(19):1782-1790, 2011b.  D. G. Cantor. Determining a set from the cardinalities of its intersections with other sets.  Canadian Journal of Mathematics, 16:94-97, 1964.  D. G. Cantor and W. H. Mills. Determination of a subset from certain combinatorial  properties. Canadian Journal of Mathematics, 18:42-48, 1966.  J. Capetanakis. Tree algorithms for packet broadcast channels.  IEEE Transactions on  Information Theory, 25(5):505-515, 1979a.  14   Choi  References  18(4):697-712, 2005.  N. Alon and V. Asodi. Learning a hidden subgraph. SIAM Journal on Discrete Mathematics,  N. Alon, R. Beigel, S. Kasif, S. Rudich, and B. Sudakov. Learning a hidden matching.  SIAM Journal on Computing, 33(2):487-501, 2004.  D. Angluin and J. Chen. Learning a hidden graph using O(log n) queries per edge.  In Proceedings of the 17th Annual Conference on Learning Theory (COLT 2004), pages 210-223, Ban\ufb00, Canada, 2004.  D. Angluin and J. Chen. Learning a hidden hypergraph. Journal of Machine Learning  Research, 7:2215-2236, 2006.  R. Beigel, N. Alon, M. S. Apaydin, L. Fortnow, and S. Kasif. An optimal procedure for gap closing in whole genome shotgun sequencing. In Proceedings of the Fifth Annual International Conference on Computational Molecular Biology (RECOMB 2001), pages 22-30, 2001.  R. Berinde, A. C. Gilbert, P. Indyk, H. J. Karlo\ufb00, and M. J. Strauss. Combining geometry  and combinatorics: A unified approach to sparse signal recovery. Allerton, 2008.  N. H. Bshouty. Optimal algorithms for the coin weighing problem with a spring scale. In Proceedings of the 22nd Annual Conference on Learning Theory (COLT 2009), Montreal, Canada, 2009.  N. H. Bshouty and H. Mazzawi. Toward a deterministic polynomial time algorithm with optimal additive query complexity. In Proceedings of the 35th International Symposium on Mathematical Foundations of Computer Science (MFCS 2010), pages 221-232, Brno, Czech Republic, 2010a.  N. H. Bshouty and H. Mazzawi. Optimal query complexity for reconstructing hypergraphs. In Proceedings of the 27th International Symposium on Theoretical Aspects of Computer Science (STACS 2010), pages 143-154, Nancy, France, 2010b.  N. H. Bshouty and H. Mazzawi. On parity check (0, 1)-matrix over Zp. In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms (SODA 2011), pages 1383-1394, San Francisco, USA, 2011a.  N. H. Bshouty and H. Mazzawi. Reconstructing weighted graphs with minimal query com-  plexity. Theoretical Computer Science, 412(19):1782-1790, 2011b.  D. G. Cantor. Determining a set from the cardinalities of its intersections with other sets.  Canadian Journal of Mathematics, 16:94-97, 1964.  D. G. Cantor and W. H. Mills. Determination of a subset from certain combinatorial  properties. Canadian Journal of Mathematics, 18:42-48, 1966.  J. Capetanakis. Tree algorithms for packet broadcast channels.  IEEE Transactions on  Information Theory, 25(5):505-515, 1979a. Polynomial Time Optimal Query Algorithms for Finding Graphs  J. Capetanakis. Generalized TDMA: The multi-accessing tree protocol. IEEE Transactions  on Communications, 27(10):1476-1484, 1979b.  S. S. Choi and J. H. Kim. Optimal query complexity bounds for finding graphs. In Proceed- ings of the 40th ACM Symposium on Theory of Computing (STOC 2008), pages 749-758, Victoria, Canada, 2008.  S. S. Choi and J. H. Kim. Optimal query complexity bounds for finding graphs. Artificial  Intelligence, 174(9-10):551-569, 2010.  S. S. Choi, K. Jung, and J. H. Kim. Almost tight upper bound for finding Fourier coe\ufb03cients of k-bounded pseudo-Boolean functions. In Proceedings of the 21st Annual Conference on Learning Theory (COLT 2008), pages 123-134, Helsinki, Finland, 2008.  S. S. Choi, K. Jung, and B. R. Moon. Lower and upper bounds for linkage discovery. IEEE  Trans. on Evolutionary Computation, 13(2):201-216, 2009.  S. S. Choi, K. Jung, and J. H. Kim. Almost tight upper bound for finding Fourier coe\ufb03cients of k-bounded pseudo-Boolean functions. Journal of Computer and System Sciences, 77 (6):1039-1053, 2011a.  S. S. Choi, J. H. Kim, and J. Oh. Randomized polynomial time algorithms for finding  weighted graphs with optimal additive query complexity. Manuscript, 2011b.  D. Du and F. K. Hwang. Combinatorial group testing and its application. In V. 3 of Series  on applied mathematics, chapter 10. World Science, 1993.  P. Erd\u02ddos and A. R\u00b4enyi. On two problems of information theory. Publications of the Math-  ematical Institute of the Hungarian Academy of Sciences, 8:241-254, 1963.  A. Gilbert and P. Indyk. Sparse recovery using sparse matrices. Proceedings of the IEEE,  98(6):937-947, 2010.  V. Grebinski. On the power of additive combinatorial search model.  In Proceedings of the 4th Annual International Conference on Computing and Combinatorics (COCOON 1998), pages 194-203, Taipei, Taiwan, 1998.  V. Grebinski and G. Kucherov. Reconstructing a Hamiltonian cycle by querying the graph: Application to DNA physical mapping. Discrete Applied Mathematics, 88:147-165, 1998.  V. Grebinski and G. Kucherov. Optimal reconstruction of graphs under the additive model.  Algorithmica, 28:104-124, 2000.  R. B. Heckendorn and A. H. Wright. E\ufb03cient linkage discovery by limited probing. Evolu-  tionary Computation, 12(4):517-545, 2004.  J. J. Hein. An optimal algorithm to reconstruct trees from additive distance data. Bulletin  of Mathematical Biology, 51(5):597-603, 1989. Choi  P. Indyk and M. Ruzic. Near-optimal sparse recovery in the L1 norm. In Proceedings of the 49th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2008), pages 199-207, 2008.  H. Kargupta and B. Park. Gene expression and fast construction of distributed evolutionary  representation. Evolutionary Computation, 9(1):1-32, 2001.  J. H. Kim. Finding weighted graphs by combinatorial search. arXiv:1201.3793, 2012.  V. King, L. Zhang, and Y. Zhou. On the complexity of distance-based evolutionary tree reconstruction. In Proceedings of the 14th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2003), pages 444-453, 2003.  B. Lindstr\u00a8om. On a combinatory detection problem I. Publications of the Mathematical  Institute of the Hungarian Academy of Sciences, 9:195-207, 1964.  B. Lindstr\u00a8om. On a combinatorial problem in number theory. Canadian Mathematical  Bulletin, 8(4):477-490, 1965.  B. Lindstr\u00a8om. On M\u00a8obius functions and a problem in combinatorial number theory. Cana-  dian Mathematical Bulletin, 14(4):513-516, 1971.  B. Lindstr\u00a8om. Determining subsets by unramified experiments. In J. N. Srivastava, editor, A Survey of Statistical Designs and Linear Models, pages 407-418. North Holland, 1975.  J. L. Massey. Collision-resolution algorithms and random-access communications.  In G. Longo, editor, Multi-user communications systems, CISM Courses and Lecture Notes No. 265, pages 73-137. Springer, Wien and New York, 1981.  H. Mazzawi. Optimally reconstructing weighted graphs using queries. In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms (SODA 2010), pages 608-615, Austin, USA, 2010.  C. McDiarmid. On the method of bounded di\ufb00erences. In J. Siemons, editor, Surveys in Combinatorics, London Mathematical Society Lecture Note Series 141, pages 148-188. Cambridge University Press, 1989.  L. Moser. The second moment method in combinatorial analysis. In Combinatorial Struc- tures and Their Applications. Proceedings of the Calgary International Conference on Combinatorial Structures and Their Applications held at the University of Calgary. June 1969, pages 283-384. Gordon and Breach, New York, 1970.  N. Pippenger. Bounds on the performance of protocols for a multiple-access broadcast  channel. IEEE Trans. on Information Theory, 27(2):145-151, 1981.  L. Reyzin and N. Srivastava. Learning and verifying graphs using queries with a focus on edge counting. In Proceedings of the 18th International Conference on Algorithmic Learning Theory (ALT 2007), pages 285-297, Sendai, Japan, 2007a.  L. Reyzin and N. Srivastava. On the longest path algorithm for reconstructing trees from  distance matrices. Information Processing Letters, 101(3):98-100, 2007b. Polynomial Time Optimal Query Algorithms for Finding Graphs  M. Ruszink\u00b4o and P. Vanroose. How an Erd\u00a8os-R\u00b4enyi-type search approach gives an explicit code construction of rate 1 for random access with multiplicity feedback. IEEE Trans. on Information Theory, 43(1):368-373, 1997.  S. S\u00a8oderberg and H. S. Shapiro. A combinatory detection problem. American Mathematical  Monthly, 70:1066-1070, 1963.  B. Tsybakov and V. Mikhailov. Free synchronous packet access in a broadcast channel with  feedback. Problemy Peredachi Informassi, 14(4):259-280, 1978.  R. Uehara, K. Tsuchida, and I. Wegener. Identification of partial disjunction, parity, and  threshold functions. Theoretical Computer Science, 210(1-2):131-147, 2000.  "}, "Differentially Private Feature Selection via Stability Arguments, and the Robustness of the Lasso": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Differentially Private Feature Selection via Stability Arguments, and the Robustness of the Lasso", "abstract": "We design differentially private algorithms for statistical model selection. Given a data set and a large, discrete collection of  \u201cmodels\u201d, each of which is a family of probability distributions, the goal is to determine the model that best \u201cfits\u201d the data. This is a basic problem in many areas of statistics and machine learning. We consider settings in which there is a well-defined answer, in  the following sense: Suppose that there is a \\emphnonprivate model  selection procedure f, which is the reference to which we compare our performance. Our differentially private algorithms output the correct value  f(D) whenever f is \\emphstable on the input data set D. We work with two notions, \\emphperturbation stability and \\emphsub-sampling stability. We give two classes of results: generic ones, that apply to any function with discrete output set; and specific algorithms for the problem of sparse linear regression. The algorithms we describe are efficient and in some cases match the optimal \\emphnon-private asymptotic sample complexity. Our algorithms for sparse linear regression require analyzing the stability properties of the popular LASSO estimator. We give sufficient conditions for the LASSO estimator to be robust to small changes in the data set, and show that these conditions hold with high probability under essentially the same stochastic assumptions that are used in the literature to analyze convergence of the LASSO.", "pdf_url": "http://proceedings.mlr.press/v30/Guha13.pdf", "keywords": [], "reference": "Francis R. Bach. Bolasso: model consistent lasso estimation through the bootstrap. In ICML, 2008.  Olivier Bousquet and Andr\u00b4e Elisseeff. Stability and generalization. Journal of Machine Learning  Research, 2:499 - 526, 2002.  Gerda Claeskens and Nils Lid Hjort. Model selection and model averaging. Cambridge University  Press, 2008.  dimensionality, 2000.  David L. Donoho. Aide-memoire. high-dimensional data analysis: The curses and blessings of  Cynthia Dwork. Differential privacy. In ICALP, 2006.  Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In STOC, 2009.  Cynthia Dwork, Krishnaram Kenthapadi, Frank Mcsherry, Ilya Mironov, and Moni Naor. Our data,  ourselves: Privacy via distributed noise generation. In EUROCRYPT, 2006a.  Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity  in private data analysis. In TCC, 2006b.  Srivatsava Ranjit Ganta, Shiva Prasad Kasiviswanathan, and Adam Smith. Composition attacks and  auxiliary information in data privacy. In KDD, 2008.  Eitan Greenshtein and Ya\u2019acov Ritov. Persistence in high-dimensional linear predictor selection and  the virtue of overparametrization. Bernoulli, 2004.  Peter Huber. Robust Statistics. Wiley, 1981.  Anatoli Juditsky and Arkadii Nemirovski. Functional aggregation for nonparametric regression.  The Annals of Statistics, 2000.  graph structure. PVLDB, 2011.  Vishesh Karwa, Sofya Raskhodnikova, Adam Smith, and Grigory Yaroslavtsev. Private analysis of  Shiva Prasad Kasiviswanathan and Adam Smith. A note on differential privacy: Defining resistance  to arbitrary side information. CoRR, arXiv:0803.39461 [cs.CR], 2008.  Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization  and high-dimensional regression. In COLT, 2012.  Yongdai Kim, Sunghoon Kwon, and Hosik Choi. Consistent model selection criteria on high di-  mensions. Journal of Machine Learning Research, 2012.  Y. Lee, S. N. MacEachern, and Y. Jung. Regularization of case-specific parameters for robustness  and efficiency. Technical report, Statistics Department, Ohio State University, April 2011.  Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In FOCS, 2007.  M. Meil\u02d8a. The uniqueness of a good optimum for k-means. In ICML, 2006.  14   SMITH THAKURTA  References  Francis R. Bach. Bolasso: model consistent lasso estimation through the bootstrap. In ICML, 2008.  Olivier Bousquet and Andr\u00b4e Elisseeff. Stability and generalization. Journal of Machine Learning  Research, 2:499 - 526, 2002.  Gerda Claeskens and Nils Lid Hjort. Model selection and model averaging. Cambridge University  Press, 2008.  dimensionality, 2000.  David L. Donoho. Aide-memoire. high-dimensional data analysis: The curses and blessings of  Cynthia Dwork. Differential privacy. In ICALP, 2006.  Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In STOC, 2009.  Cynthia Dwork, Krishnaram Kenthapadi, Frank Mcsherry, Ilya Mironov, and Moni Naor. Our data,  ourselves: Privacy via distributed noise generation. In EUROCRYPT, 2006a.  Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity  in private data analysis. In TCC, 2006b.  Srivatsava Ranjit Ganta, Shiva Prasad Kasiviswanathan, and Adam Smith. Composition attacks and  auxiliary information in data privacy. In KDD, 2008.  Eitan Greenshtein and Ya\u2019acov Ritov. Persistence in high-dimensional linear predictor selection and  the virtue of overparametrization. Bernoulli, 2004.  Peter Huber. Robust Statistics. Wiley, 1981.  Anatoli Juditsky and Arkadii Nemirovski. Functional aggregation for nonparametric regression.  The Annals of Statistics, 2000.  graph structure. PVLDB, 2011.  Vishesh Karwa, Sofya Raskhodnikova, Adam Smith, and Grigory Yaroslavtsev. Private analysis of  Shiva Prasad Kasiviswanathan and Adam Smith. A note on differential privacy: Defining resistance  to arbitrary side information. CoRR, arXiv:0803.39461 [cs.CR], 2008.  Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization  and high-dimensional regression. In COLT, 2012.  Yongdai Kim, Sunghoon Kwon, and Hosik Choi. Consistent model selection criteria on high di-  mensions. Journal of Machine Learning Research, 2012.  Y. Lee, S. N. MacEachern, and Y. Jung. Regularization of case-specific parameters for robustness  and efficiency. Technical report, Statistics Department, Ohio State University, April 2011.  Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In FOCS, 2007.  M. Meil\u02d8a. The uniqueness of a good optimum for k-means. In ICML, 2006. PRIVATE FEATURE SELECTION AND STABILITY OF LASSO  Nicolai Meinshausen and Peter Buehlmann. Stability selection. Journal of the Royal Statistical  Society: Series B (Statistical Methodology), 2010.  Sahand Negahban, Pradeep Ravikumar, Martin J. Wainwright, and Bin Yu. A unified framework for high-dimensional analysis of $m$-estimators with decomposable regularizers. In NIPS, 2009.  Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private  data analysis. In STOC, 2007.  Garvesh Raskutti, Martin J. Wainwright, and Bin Yu. Minimax rates of estimation for high-  dimensional linear regression over (cid:96)q-balls. 2011.  WH Rogers and TJ Wagner. A finite sample distribution-free performance bound for local discrim-  ination rules. The Annals of Statistics, pages 506-514, 1978.  S. Shalev-Shwartz, O. Shamir, N. Srebro, and K. Sridharan. Learnability, stability and uniform  convergence. The Journal of Machine Learning Research, 2010.  Jun Shao. Bootstrap model selection. Journal of the American Statistical Association, 1996.  Adam Smith. Privacy-preserving statistical estimation with optimal convergence rates. In STOC,  2011.  tion Theory, 2010.  2007.  ISIT, 2009.  Martin J. Wainwright. Sharp thresholds for high-dimensional and noisy recovery of sparsity using  (cid:96)1-constrained quadratic programs. In IEEE Transactions on Information Theory, 2006.  H. Xu, C. Caramanis, and S. Mannor. Robust regression and lasso. IEEE Transactions on Informa-  P. Zhao and B. Yu. On model selection consistency of lasso. Journal of Machine Learning Research,  Shuheng Zhou, Katrina Ligett, and Larry Wasserman. Differential privacy with compression. In SMITH THAKURTA  "}, "Learning a set of directions": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Learning a set of directions", "abstract": "Assume our data consists of unit vectors (directions) and we are to find a small orthogonal set of the \u201cthe most important directions\u201d summarizing the data. We develop online algorithms for this type of problem. The techniques used are similar to Principal Component Analysis which finds the most important small rank subspace of the data.The new problem is significantly more complex since the online algorithm maintains uncertainty over the most relevant subspace as well as directional information.", "pdf_url": "http://proceedings.mlr.press/v30/Koolen13.pdf", "keywords": [], "reference": "Dennis S. Bernstein. Matrix Mathematics: Theory, Facts, and Formulas (Second Edition).  Princeton reference. Princeton University Press, 2011. ISBN 9780691140391.  Elad Hazan, Satyen Kale, and Manfred K. Warmuth. On-line variance minimization in  O(n2) per trial? In COLT, pages 314-315, 2010.  Elad Hazan, Satyen Kale, and Manfred K. Warmuth. Learning rotations with little regret.  Unpublished journal submission, February 2011.  David P. Helmbold and Manfred K. Warmuth. Learning permutations with exponential  weights. Journal of Machine Learning Research, 10:1705-1736, July 2009.  Mark Herbster and Manfred K. Warmuth. Tracking the best linear predictor. Journal of  Machine Learning Research, 1:281-309, 2001.  Jyrki Kivinen and Manfred K. Warmuth. Exponentiated gradient versus gradient descent  for linear predictors. Inf. Comput., 132(1):1-63, 1997.  Wouter M. Koolen. Combining Strategies E\ufb03ciently: High-quality Decisions from Con\ufb02ict- ing Advice. PhD thesis, Institute of Logic, Language and Computation (ILLC), University of Amsterdam, January 2011.  Wouter M. Koolen, Manfred K. Warmuth, and Jyrki Kivinen. Hedging structured concepts. In Proceedings of the 23rd Annual Conference on Learning Theory (COLT), pages 93-105, June 2010.  Wojciech Kot(cid:32)lowski and Manfred K. Warmuth. Minimax algorithm for learning rotations.  Journal of Machine Learning Research - Proceedings Track, 19:821-824, 2011.  Dima Kuzmin and Manfred K. Warmuth. Online Kernel PCA with entropic matrix updates. In Proceedings of the 24rd international conference on Machine learning (ICML \u201907), pages 465-471. ACM International Conference Proceedings Series, June 2007.  Brendan McMahon. Minimax optimal algorithms for unconstrained linear optimization.  Unpublished manuscript arXiv:1302.2176v1, February 2013.  Jiazhong Nie, Wojciech Kot(cid:32)lowski, and Manfred K. Warmuth. On-line PCA with optimal  regrets. Submitted, 2013.  Koji Tsuda, Gunnar R\u00a8atsch, and Manfred K. Warmuth. Matrix Exponentiated Gradient updates for on-line learning and Bregman projections. Journal of Machine Learning Research, 6:995-1018, June 2005.  Manfred K. Warmuth and Dima Kuzmin. Randomized online PCA algorithms with regret bounds that are logarithmic in the dimension. Journal of Machine Learning Research, 9: 2287-2320, October 2008.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.  In ICML, pages 928-936, 2003.  14   Koolen Nie Warmuth  References  Dennis S. Bernstein. Matrix Mathematics: Theory, Facts, and Formulas (Second Edition).  Princeton reference. Princeton University Press, 2011. ISBN 9780691140391.  Elad Hazan, Satyen Kale, and Manfred K. Warmuth. On-line variance minimization in  O(n2) per trial? In COLT, pages 314-315, 2010.  Elad Hazan, Satyen Kale, and Manfred K. Warmuth. Learning rotations with little regret.  Unpublished journal submission, February 2011.  David P. Helmbold and Manfred K. Warmuth. Learning permutations with exponential  weights. Journal of Machine Learning Research, 10:1705-1736, July 2009.  Mark Herbster and Manfred K. Warmuth. Tracking the best linear predictor. Journal of  Machine Learning Research, 1:281-309, 2001.  Jyrki Kivinen and Manfred K. Warmuth. Exponentiated gradient versus gradient descent  for linear predictors. Inf. Comput., 132(1):1-63, 1997.  Wouter M. Koolen. Combining Strategies E\ufb03ciently: High-quality Decisions from Con\ufb02ict- ing Advice. PhD thesis, Institute of Logic, Language and Computation (ILLC), University of Amsterdam, January 2011.  Wouter M. Koolen, Manfred K. Warmuth, and Jyrki Kivinen. Hedging structured concepts. In Proceedings of the 23rd Annual Conference on Learning Theory (COLT), pages 93-105, June 2010.  Wojciech Kot(cid:32)lowski and Manfred K. Warmuth. Minimax algorithm for learning rotations.  Journal of Machine Learning Research - Proceedings Track, 19:821-824, 2011.  Dima Kuzmin and Manfred K. Warmuth. Online Kernel PCA with entropic matrix updates. In Proceedings of the 24rd international conference on Machine learning (ICML \u201907), pages 465-471. ACM International Conference Proceedings Series, June 2007.  Brendan McMahon. Minimax optimal algorithms for unconstrained linear optimization.  Unpublished manuscript arXiv:1302.2176v1, February 2013.  Jiazhong Nie, Wojciech Kot(cid:32)lowski, and Manfred K. Warmuth. On-line PCA with optimal  regrets. Submitted, 2013.  Koji Tsuda, Gunnar R\u00a8atsch, and Manfred K. Warmuth. Matrix Exponentiated Gradient updates for on-line learning and Bregman projections. Journal of Machine Learning Research, 6:995-1018, June 2005.  Manfred K. Warmuth and Dima Kuzmin. Randomized online PCA algorithms with regret bounds that are logarithmic in the dimension. Journal of Machine Learning Research, 9: 2287-2320, October 2008.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.  In ICML, pages 928-936, 2003. Learning directions  "}, "A Tensor Spectral Approach to Learning Mixed Membership Community Models": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "A Tensor Spectral Approach to Learning Mixed Membership Community Models", "abstract": "Modeling community formation and detecting hidden communities in networks is a well studied problem. However, theoretical analysis of  community detection has been mostly limited to models with non-overlapping communities such as the stochastic block model. In this paper, we remove this restriction, and consider a family of probabilistic network models with overlapping communities, termed as the mixed membership Dirichlet model, first introduced   in Aioroldi et. al (2008). This model allows for nodes to have fractional memberships in multiple communities and assumes that the community memberships are drawn from a Dirichlet distribution. We propose a unified  approach to learning these models via a   tensor spectral decomposition method. Our estimator is based on  low-order  moment tensor of the observed network, consisting of  3-star counts. Our learning method is fast and is based on   simple linear algebra operations, e.g. singular value decomposition and tensor power iterations. We provide guaranteed recovery of community memberships and model parameters and present a careful finite sample analysis of our learning method. Additionally, our results  match the best known scaling requirements in the special case of the stochastic block model.", "pdf_url": "http://proceedings.mlr.press/v30/Anandkumar13.pdf", "keywords": ["estimation", "mixed membership models"], "reference": "Edoardo M. Airoldi, David M. Blei, Stephen E. Fienberg, and Eric P. Xing. Mixed member- ship stochastic blockmodels. Journal of Machine Learning Research, 9:1981-2014, June 2008.  A. Anandkumar, D. P. Foster, D. Hsu, S. M. Kakade, and Y. Liu. Two svds su\ufb03ce: Spectral decompositions for probabilistic topic modeling and latent dirichlet allocation, 2012a. arXiv:1204.6703.  A. Anandkumar, R. Ge, D. Hsu, S. M. Kakade, and M. Telgarsky. Tensor decompositions  for latent variable models, 2012b.  A. Anandkumar, D. Hsu, and S.M. Kakade. A Method of Moments for Mixture Models  and Hidden Markov Models. In Proc. of Conf. on Learning Theory, June 2012c.  A. Anandkumar, R. Ge, D. Hsu, and S. M. Kakade. A Tensor Spectral Approach to Learning  Mixed Membership Community Models. ArXiv 1302.2684, Feb. 2013.  Sanjeev Arora, Rong Ge, Sushant Sachdeva, and Grant Schoenebeck. Finding overlapping communities in social networks: toward a rigorous approach. In Proceedings of the 13th ACM Conference on Electronic Commerce, 2012.  Maria-Florina Balcan, Christian Borgs, Mark Braverman, Jennifer T. Chayes, and Shang- Hua Teng. I like her more than you: Self-determined communities. CoRR, abs/1201.4899, 2012.  Kamalika Chaudhuri, Fan Chung, and Alexander Tsiatas. Spectral clustering of graphs with general degrees in the extended planted partition model. Journal of Machine Learning Research, pages 1-23, 2012.  S.E. Fienberg, M.M. Meyer, and S.S. Wasserman. Statistical analysis of multiple sociometric  relations. Journal of the american Statistical association, 80(389):51-67, 1985.  P. Gopalan, D. Mimno, S. Gerrish, M. Freedman, and D. Blei. Scalable inference of over- lapping communities. In Advances in Neural Information Processing Systems 25, pages 2258-2266, 2012.  C. Hillar and L.-H. Lim. Most tensor problems are NP hard, 2012.  P.W. Holland, K.B. Laskey, and S. Leinhardt. Stochastic blockmodels: first steps. Social  networks, 5(2):109-137, 1983.  T. G. Kolda and B. W. Bader. Tensor decompositions and applications. SIAM review, 51  (3):455, 2009.  F. McSherry. Spectral partitioning of random graphs. In FOCS, 2001.  G. Palla, I. Der\u00b4enyi, I. Farkas, and T. Vicsek. Uncovering the overlapping community structure of complex networks in nature and society. Nature, 435(7043):814-818, 2005.  14   Anandkumar Ge Hsu Kakade  References  Edoardo M. Airoldi, David M. Blei, Stephen E. Fienberg, and Eric P. Xing. Mixed member- ship stochastic blockmodels. Journal of Machine Learning Research, 9:1981-2014, June 2008.  A. Anandkumar, D. P. Foster, D. Hsu, S. M. Kakade, and Y. Liu. Two svds su\ufb03ce: Spectral decompositions for probabilistic topic modeling and latent dirichlet allocation, 2012a. arXiv:1204.6703.  A. Anandkumar, R. Ge, D. Hsu, S. M. Kakade, and M. Telgarsky. Tensor decompositions  for latent variable models, 2012b.  A. Anandkumar, D. Hsu, and S.M. Kakade. A Method of Moments for Mixture Models  and Hidden Markov Models. In Proc. of Conf. on Learning Theory, June 2012c.  A. Anandkumar, R. Ge, D. Hsu, and S. M. Kakade. A Tensor Spectral Approach to Learning  Mixed Membership Community Models. ArXiv 1302.2684, Feb. 2013.  Sanjeev Arora, Rong Ge, Sushant Sachdeva, and Grant Schoenebeck. Finding overlapping communities in social networks: toward a rigorous approach. In Proceedings of the 13th ACM Conference on Electronic Commerce, 2012.  Maria-Florina Balcan, Christian Borgs, Mark Braverman, Jennifer T. Chayes, and Shang- Hua Teng. I like her more than you: Self-determined communities. CoRR, abs/1201.4899, 2012.  Kamalika Chaudhuri, Fan Chung, and Alexander Tsiatas. Spectral clustering of graphs with general degrees in the extended planted partition model. Journal of Machine Learning Research, pages 1-23, 2012.  S.E. Fienberg, M.M. Meyer, and S.S. Wasserman. Statistical analysis of multiple sociometric  relations. Journal of the american Statistical association, 80(389):51-67, 1985.  P. Gopalan, D. Mimno, S. Gerrish, M. Freedman, and D. Blei. Scalable inference of over- lapping communities. In Advances in Neural Information Processing Systems 25, pages 2258-2266, 2012.  C. Hillar and L.-H. Lim. Most tensor problems are NP hard, 2012.  P.W. Holland, K.B. Laskey, and S. Leinhardt. Stochastic blockmodels: first steps. Social  networks, 5(2):109-137, 1983.  T. G. Kolda and B. W. Bader. Tensor decompositions and applications. SIAM review, 51  (3):455, 2009.  F. McSherry. Spectral partitioning of random graphs. In FOCS, 2001.  G. Palla, I. Der\u00b4enyi, I. Farkas, and T. Vicsek. Uncovering the overlapping community structure of complex networks in nature and society. Nature, 435(7043):814-818, 2005. A Tensor Spectral Approach to Learning Mixed Membership Community Models  T.A.B. Snijders and K. Nowicki. Estimation and prediction for stochastic blockmodels for  graphs with latent block structure. Journal of Classification, 14(1):75-100, 1997.  J.A. Tropp. User-friendly tail bounds for sums of random matrices. Foundations of Com-  putational Mathematics, 12(4):389-434, 2012.  Y.J. Wang and G.Y. Wong. Stochastic blockmodels for directed graphs. Journal of the  American Statistical Association, 82(397):8-19, 1987.  H.C. White, S.A. Boorman, and R.L. Breiger. Social structure from multiple networks. i. blockmodels of roles and positions. American journal of sociology, pages 730-780, 1976.  E.P. Xing, W. Fu, and L. Song. A state-space mixed membership blockmodel for dynamic  network tomography. The Annals of Applied Statistics, 4(2):535-566, 2010.  Chen Yudong, Sujay Sanghavi, and Huan Xu. Clustering sparse graphs. In Advances in  Neural Information Processing Systems 25, 2012. "}, "Adaptive Crowdsourcing Algorithms for the Bandit Survey Problem": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Adaptive Crowdsourcing Algorithms for the Bandit Survey Problem", "abstract": "Very recently crowdsourcing has become the de facto platform for distributing and collecting human computation for a wide range of tasks and applications such as information retrieval, natural language processing and machine learning. Current crowdsourcing platforms have some limitations in the area of quality control. Most of the effort to ensure good quality has to be done by the experimenter who has to manage the number of workers needed to reach good results.We propose a simple model for adaptive quality control in crowdsourced multiple-choice tasks which we call the \u201cbandit survey problem\u201d. This model is related to, but technically different from the well-known multi-armed bandit problem. We present several algorithms for this problem, and support them with analysis and simulations.Our approach is based in our experience conducting relevance evaluation for a large commercial search engine.", "pdf_url": "http://proceedings.mlr.press/v30/Abraham13.pdf", "keywords": [], "reference": "Shipra Agrawal and Navin Goyal. Analysis of Thompson Sampling for the multi-armed bandit  problem. In 25nd Conf. on Learning Theory (COLT), 2012.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2-3):235-256, 2002a. Preliminary version in 15th ICML, 1998.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multi- armed bandit problem. SIAM J. Comput., 32(1):48-77, 2002b. Preliminary version in 36th IEEE FOCS, 1995.  Moshe Babaioff, Shaddin Dughmi, Robert Kleinberg, and Aleksandrs Slivkins. Dynamic pricing  with limited supply. In 13th ACM Conf. on Electronic Commerce (EC), 2012.  R. E. Bechhofer and D. Goldsman. Truncation of the bechhofer-kiefer-sobel sequential procedure for selecting the multinomial event which has the largest probability. Communications in Statis- tics Simulation and Computation, B14:283315, 1985.  13   THE BANDIT SURVEY PROBLEM  6. Open questions  The bandit survey problem. The main open questions concern crowd-selection algorithms for the randomized benchmark. First, we do not know how to handle non-uniform costs. Second, we conjecture that our algorithm for uniform costs can be significantly improved. Moreover, it is desirable to combine guarantees against the randomized benchmark with (better) guarantees against the deterministic benchmark.  Our results prompt several other open questions. First, while we obtain strong provable guaran- tees for VirtUCB, it is desirable to extend these or similar guarantees to VirtThompson, since this algorithm performs best in the experiments. Second, is it possible to significantly improve over the composite stopping rules? Third, is it advantageous to forego our \u201dindependent design\u201d approach and design the crowd-selection algorithms jointly with the stopping rules? Extended models. It is tempting to extend our model in several directions listed below. First, while in our model the gap of each crowd does not change over time, it is natural to study settings with bounded or \u201cadversarial\u201d change; one could hope to take advantage of the tools developed for the corresponding versions of MAB. Second, as discussed in the introduction, an alternative model worth studying is to assign a monetary penalty to a mistake, and optimize the overall cost (i.e., cost of labor minus penalty). Third, one can combine the bandit survey problem with learning across multiple related microtasks.  Acknowledgments  We thank Ashwinkumar Badanidiyuru, Sebastien Bubeck, Chien-Ju Ho, Robert Kleinberg and Jen- nifer Wortman Vaughan for stimulating discussions on our problem and related research. Also, we thank Rajesh Patel, Steven Shelford and Hai Wu from Microsoft Bing for insights into the practical aspects of crowdsourcing. Finally, we are indebted to the anonymous referees for sharp comments which have substantially improved presentation. In particular, we thank anonymous reviewers for pointing out that our index-based algorithm can be interpreted via virtual rewards.  References  Shipra Agrawal and Navin Goyal. Analysis of Thompson Sampling for the multi-armed bandit  problem. In 25nd Conf. on Learning Theory (COLT), 2012.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47(2-3):235-256, 2002a. Preliminary version in 15th ICML, 1998.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multi- armed bandit problem. SIAM J. Comput., 32(1):48-77, 2002b. Preliminary version in 36th IEEE FOCS, 1995.  Moshe Babaioff, Shaddin Dughmi, Robert Kleinberg, and Aleksandrs Slivkins. Dynamic pricing  with limited supply. In 13th ACM Conf. on Electronic Commerce (EC), 2012.  R. E. Bechhofer and D. Goldsman. Truncation of the bechhofer-kiefer-sobel sequential procedure for selecting the multinomial event which has the largest probability. Communications in Statis- tics Simulation and Computation, B14:283315, 1985. ABRAHAM ALONSO KANDYLAS SLIVKINS  R. E. Bechhofer, S. Elmaghraby, and N. Morse. A single-sample multiple decision procedure for selecting the multinomial event which has the highest probability. Annals of Mathematical Statis- tics, 30:102119, 1959.  S\u00b4ebastien Bubeck, R\u00b4emi Munos, and Gilles Stoltz. Pure Exploration in Multi-Armed Bandit Prob- lems. Theoretical Computer Science, 412(19):1832-1852, 2011. Preliminary version published in ALT 2009.  Chris Callison-Burch. Fast, cheap, and creative: Evaluating translation quality using amazon\u2019s mechanical turk. In ACL SIGDAT Conf. on Empirical Methods in Natural Language Processing (EMNLP), pages 286-295, 2009.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, learning, and games. Cambridge Univ. Press,  2006.  Olivier Chapelle and Lihong Li. An Empirical Evaluation of Thompson Sampling. In 25th Advances  in Neural Information Processing Systems (NIPS), 2011.  Xi Chen, Qihang Lin, and Dengyong Zhou. Optimistic knowledge gradient for optimal budget  allocation in crowdsourcing. In 30th Intl. Conf. on Machine Learning (ICML), 2013.  Paul Dagum, Richard M. Karp, Michael Luby, and Sheldon M. Ross. An optimal algorithm for  monte carlo estimation. SIAM J. on Computing, 29(5):1484-1496, 2000.  Ofer Dekel and Ohad Shamir. Vox populi: Collecting high-quality labels from a crowd. In 22nd  Conf. on Learning Theory (COLT), 2009.  Michael J. Franklin, Donald Kossmann, Tim Kraska, Sukriti Ramesh, and Reynold Xin. Crowddb: answering queries with crowdsourcing. In ACM SIGMOD Intl. Conf. on Management of Data (SIGMOD), pages 61-72, 2011.  Thore Graepel, Joaquin Quinonero Candela, Thomas Borchert, and Ralf Herbrich. Web-scale Bayesian click-through rate prediction for sponsored search advertising in Microsofts Bing search engine. In 27th Intl. Conf. on Machine Learning (ICML), pages 13-20, 2010.  Chien-Ju Ho and Jennifer Wortman Vaughan. Online task assignment in crowdsourcing markets. In  26th Conference on Artificial Intelligence (AAAI), 2012.  Chien-Ju Ho, Shahin Jabbari, and Jennifer Wortman Vaughan. Adaptive task assignment for crowd-  sourced classification. In 30th Intl. Conf. on Machine Learning (ICML), 2013.  J. T. Ramey Jr. and K. Alam. A sequential procedure for selecting the most probable multinomial  event. Biometrica, 66:171-173, 1979.  Ece Kamar, Severin Hacker, and Eric Horvitz. Combining human and machine intelligence in large-scale crowdsourcing. In 11th Intl. Conf. on Autonomous Agents and Multiagent Systems (AAMAS), 2012.  Haim Kaplan, Eyal Kushilevitz, and Yishay Mansour. Learning with attribute costs. In 37th ACM  Symp. on Theory of Computing (STOC), pages 356-365, 2005. THE BANDIT SURVEY PROBLEM  David R. Karger, Sewoong Oh, and Devavrat Shah. Iterative learning for reliable crowdsourcing systems. In 25th Advances in Neural Information Processing Systems (NIPS), pages 1953-1961, 2011.  Robert Kleinberg. Nearly tight bounds for the continuum-armed bandit problem. In 18th Advances  in Neural Information Processing Systems (NIPS), 2004.  Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal. Multi-Armed Bandits in Metric Spaces. In  40th ACM Symp. on Theory of Computing (STOC), pages 681-690, 2008.  Tze Leung Lai and Herbert Robbins. Asymptotically efficient Adaptive Allocation Rules. Advances  in Applied Mathematics, 6:4-22, 1985.  Edith Law and Luis von Ahn. Human Computation. Morgan & Claypool Publishers, 2011.  Daniel J. Lizotte, Omid Madani, and Russell Greiner. Budgeted learning of naive-bayes classifiers.  In 19th Conf. on Uncertainty in Artificial Intelligence (UAI), pages 378-385, 2003.  Steven L.Scott. A modern bayesian look at the multi-armed bandit. Applied Stochastic Models in  Business and Industry, 26:639658, 2010.  Omid Madani, Daniel J. Lizotte, and Russell Greiner. Active model selection. In 20th Conf. on  Uncertainty in Artificial Intelligence (UAI), pages 357-365, 2004.  Shie Mannor and John N. Tsitsiklis. The sample complexity of exploration in the multi-armed bandit problem. J. of Machine Learning Research (JMLR), 5:623-648, 2004. Preliminary version in COLT, 2003.  Volodymyr Mnih, Csaba Szepesv\u00b4ari, and Jean-Yves Audibert. Empirical bernstein stopping. In  25th Intl. Conf. on Machine Learning (ICML), pages 672-679, 2008.  Victor S. Sheng, Foster J. Provost, and Panagiotis G. Ipeirotis. Get another label? improving data In 14th ACM SIGKDD Intl. Conf. on  quality and data mining using multiple, noisy labelers. Knowledge Discovery and Data Mining (KDD), pages 614-622, 2008.  Rion Snow, Brendan O\u2019Connor, Daniel Jurafsky, and Andrew Y. Ng. Cheap and fast - but is it good? evaluating non-expert annotations for natural language tasks. In ACL SIGDAT Conf. on Empirical Methods in Natural Language Processing (EMNLP), pages 254-263, 2008.  William R. Thompson. On the likelihood that one unknown probability exceeds another in view of  the evidence of two samples. Biometrika, 25(3-4):285294, 1933.  Long Tran-Thanh, Matteo Venanzi, Alex Rogers, and Nicholas R. Jennings. Efficient budget al- location with accuracy guarantees for crowdsourcing classification tasks. In 12th Intl. Conf. on Autonomous Agents and Multiagent Systems (AAMAS), 2013. ABRAHAM ALONSO KANDYLAS SLIVKINS  "}, "Boosting with the Logistic Loss is Consistent": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Boosting with the Logistic Loss is Consistent", "abstract": "This manuscript provides optimization guarantees, generalization bounds, and statistical consistency results for AdaBoost variants which replace the exponential loss with the logistic and similar losses (specifically, twice differentiable convex losses which are Lipschitz and tend to zero on one side).The heart of the analysis is to show that, in lieu of explicit regularization and constraints, the structure of the problem is fairly rigidly controlled by the source distribution itself. The first control of this type is in the separable case, where a distribution-dependent relaxed weak learning rate induces speedy convergence with high probability over any sample. Otherwise, in the nonseparable case, the convex surrogate risk itself exhibits distribution-dependent levels of curvature, and consequently the algorithm\u2019s output has small norm with high probability.", "pdf_url": "http://proceedings.mlr.press/v30/Telgarsky13.pdf"}, "Competing With Strategies": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Competing With Strategies", "abstract": "We study the problem of online learning with a notion of regret defined with respect to a set of strategies. We develop tools for analyzing the minimax rates and for deriving regret-minimization algorithms in this scenario. While the standard methods for minimizing the usual notion of regret fail, through our analysis we demonstrate existence of regret-minimization methods that compete with such sets of strategies as: autoregressive algorithms, strategies based on statistical models, regularized least squares, and follow the regularized leader strategies. In several cases we also derive efficient learning algorithms.", "pdf_url": "http://proceedings.mlr.press/v30/Han13.pdf", "keywords": [], "reference": "J. Abernethy, A. Agarwal, P. L. Bartlett, and A. Rakhlin. A stochastic view of optimal  regret through minimax duality. In COLT, 2009.  S. Ben-David, D. Pal, and S. Shalev-Shwartz. Agnostic online learning. In Proceedings of  the 22th Annual Conference on Learning Theory, 2009.  N. Cesa-Bianchi and G. Lugosi. On prediction of individual sequences. The Annals of  Statistics, 27(6):pp. 1865-1895, 1999.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  D.Z. Chen, O. Daescu, Y. Dai, N. Katoh, X. Wu, and J. Xu. E\ufb03cient algorithms and implementations for optimizing the sum of linear fractional functions, with applications. Journal of Combinatorial Optimization, 9(1):69-90, 2005.  M. Feder, N. Merhav, and M. Gutman. Universal prediction of individual sequences. In-  formation Theory, IEEE Transactions on, 38(4):1258-1270, 1992.  D. P. Foster, A. Rakhlin, K. Sridharan, and A. Tewari. Complexity-based approach to calibration with checking rules. Journal of Machine Learning Research - Proceedings Track, 19:293-314, 2011.  I. Karatzas and S. E. Shreve. Brownian Motion and Stochastic Calculus. Springer-Verlag,  Berlin, 2nd edition, 1991.  44:2124-2147, 1998.  N. Merhav and M. Feder. Universal prediction. IEEE Transactions on Information Theory,  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Random averages, combinatorial In Advances in Neural Information Processing Systems,  parameters, and learnability. 2010.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Stochastic, constrained, and  smoothed adversaries. In NIPS, pages 1764-1772, 2011.  A. Rakhlin, O. Shamir, and K. Sridharan. Relax and randomize : From value to algorithms.  In Advances in Neural Information Processing Systems, 2012.  N. Srebro, K. Sridharan, and A. Tewari. On the universality of online mirror descent. In  NIPS, pages 2645-2653, 2011.  V. Vovk. Competitive on-line linear regression.  In NIPS \u201997: Proceedings of the 1997 conference on Advances in neural information processing systems 10, pages 364-370, Cambridge, MA, USA, 1998. MIT Press.  13   Competing With Strategies  We gratefully acknowledge the support of NSF under grants CAREER DMS-0954737 and CCF-1116928, as well as Dean\u2019s Research Fund.  Acknowledgements  References  J. Abernethy, A. Agarwal, P. L. Bartlett, and A. Rakhlin. A stochastic view of optimal  regret through minimax duality. In COLT, 2009.  S. Ben-David, D. Pal, and S. Shalev-Shwartz. Agnostic online learning. In Proceedings of  the 22th Annual Conference on Learning Theory, 2009.  N. Cesa-Bianchi and G. Lugosi. On prediction of individual sequences. The Annals of  Statistics, 27(6):pp. 1865-1895, 1999.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  D.Z. Chen, O. Daescu, Y. Dai, N. Katoh, X. Wu, and J. Xu. E\ufb03cient algorithms and implementations for optimizing the sum of linear fractional functions, with applications. Journal of Combinatorial Optimization, 9(1):69-90, 2005.  M. Feder, N. Merhav, and M. Gutman. Universal prediction of individual sequences. In-  formation Theory, IEEE Transactions on, 38(4):1258-1270, 1992.  D. P. Foster, A. Rakhlin, K. Sridharan, and A. Tewari. Complexity-based approach to calibration with checking rules. Journal of Machine Learning Research - Proceedings Track, 19:293-314, 2011.  I. Karatzas and S. E. Shreve. Brownian Motion and Stochastic Calculus. Springer-Verlag,  Berlin, 2nd edition, 1991.  44:2124-2147, 1998.  N. Merhav and M. Feder. Universal prediction. IEEE Transactions on Information Theory,  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Random averages, combinatorial In Advances in Neural Information Processing Systems,  parameters, and learnability. 2010.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Stochastic, constrained, and  smoothed adversaries. In NIPS, pages 1764-1772, 2011.  A. Rakhlin, O. Shamir, and K. Sridharan. Relax and randomize : From value to algorithms.  In Advances in Neural Information Processing Systems, 2012.  N. Srebro, K. Sridharan, and A. Tewari. On the universality of online mirror descent. In  NIPS, pages 2645-2653, 2011.  V. Vovk. Competitive on-line linear regression.  In NIPS \u201997: Proceedings of the 1997 conference on Advances in neural information processing systems 10, pages 364-370, Cambridge, MA, USA, 1998. MIT Press. Han Rakhlin Sridharan  "}, "Online Learning with Predictable Sequences": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Online Learning with Predictable Sequences", "abstract": "We present methods for online linear optimization that take advantage of benign (as opposed to worst-case) sequences. Specifically if the sequence encountered by the learner is described well by a known \u201cpredictable process\u201d, the algorithms presented enjoy tighter bounds as compared to the typical worst case bounds. Additionally, the methods achieve the usual worst-case regret bounds if the sequence is not benign. Our approach can be seen as a way of adding \\emphprior knowledge about the sequence within the paradigm of online learning. The setting is shown to encompass partial and side information. Variance and path-length bounds can be seen as particular examples of online learning with simple predictable sequences.We further extend our methods to include competing with a set of possible predictable processes (models), that is \u201clearning\u201d the predictable process itself concurrently with using it to obtain better regret guarantees. We show that such model selection is possible under various assumptions on the available feedback.", "pdf_url": "http://proceedings.mlr.press/v30/Rakhlin13.pdf", "keywords": [""], "reference": "J. Abernethy and A. Rakhlin. Beating the adaptive bandit with high probability. Technical Report UCB/EECS-2009-10, EECS Department, University of California, Berkeley, Jan 2009.  J. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An e\ufb03cient algorithm for bandit linear optimization. In Proceedings of the 21st Annual Conference on Learning Theory (COLT), volume 3, page 3, 2008.  J.D. Abernethy, E. Hazan, and A. Rakhlin. Interior-point methods for full-information and Information Theory, IEEE Transactions on, 58(7):4164-4175,  bandit online learning. 2012.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed  bandit problem. SIAM J. Comput., 32(1):48-77, 2003.  P.L. Bartlett, E. Hazan, and A. Rakhlin. Adaptive online gradient descent. Advances in  Neural Information Processing Systems, 20:65-72, 2007.  A. Beck and M. Teboulle. Mirror descent and nonlinear projected subgradient methods for  convex optimization. Operations Research Letters, 31(3):167-175, 2003.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  N. Cesa-Bianchi, Y. Mansour, and G. Stoltz. Improved second-order bounds for prediction  with expert advice. Machine Learning, 66(2):321-352, 2007.  C.-K. Chiang, T. Yang, C.-J. Lee, M. Mahdavi, C.-J. Lu, R. Jin, and S. Zhu. Online  optimization with gradual variations. In COLT, 2012.  E. Hazan and S. Kale. Better algorithms for benign bandits. In Proceedings of the twen- tieth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 38-47. Society for Industrial and Applied Mathematics, 2009.  E. Hazan and S. Kale. Extracting certainty from uncertainty: Regret bounded by variation  in costs. Machine learning, 80(2):165-188, 2010.  A.S. Nemirovski and M.J. Todd. Interior-point methods for optimization. Acta Numerica,  17(1):191-234, 2008.  A. Rakhlin. Lecture notes on online learning, 2008. Available at http://www-stat.wharton.  upenn.edu/~rakhlin/papers/online_learning.pdf.  13   Online Learning with Predictable Sequences  We gratefully acknowledge the support of NSF under grants CAREER DMS-0954737 and CCF-1116928, as well as Dean\u2019s Research Fund.  Acknowledgements  References  J. Abernethy and A. Rakhlin. Beating the adaptive bandit with high probability. Technical Report UCB/EECS-2009-10, EECS Department, University of California, Berkeley, Jan 2009.  J. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An e\ufb03cient algorithm for bandit linear optimization. In Proceedings of the 21st Annual Conference on Learning Theory (COLT), volume 3, page 3, 2008.  J.D. Abernethy, E. Hazan, and A. Rakhlin. Interior-point methods for full-information and Information Theory, IEEE Transactions on, 58(7):4164-4175,  bandit online learning. 2012.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed  bandit problem. SIAM J. Comput., 32(1):48-77, 2003.  P.L. Bartlett, E. Hazan, and A. Rakhlin. Adaptive online gradient descent. Advances in  Neural Information Processing Systems, 20:65-72, 2007.  A. Beck and M. Teboulle. Mirror descent and nonlinear projected subgradient methods for  convex optimization. Operations Research Letters, 31(3):167-175, 2003.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006.  N. Cesa-Bianchi, Y. Mansour, and G. Stoltz. Improved second-order bounds for prediction  with expert advice. Machine Learning, 66(2):321-352, 2007.  C.-K. Chiang, T. Yang, C.-J. Lee, M. Mahdavi, C.-J. Lu, R. Jin, and S. Zhu. Online  optimization with gradual variations. In COLT, 2012.  E. Hazan and S. Kale. Better algorithms for benign bandits. In Proceedings of the twen- tieth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 38-47. Society for Industrial and Applied Mathematics, 2009.  E. Hazan and S. Kale. Extracting certainty from uncertainty: Regret bounded by variation  in costs. Machine learning, 80(2):165-188, 2010.  A.S. Nemirovski and M.J. Todd. Interior-point methods for optimization. Acta Numerica,  17(1):191-234, 2008.  A. Rakhlin. Lecture notes on online learning, 2008. Available at http://www-stat.wharton.  upenn.edu/~rakhlin/papers/online_learning.pdf. Rakhlin Sridharan  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Random averages, combinatorial parameters, and learnability. In NIPS, 2010. Available at http://arxiv.org/abs/1006.1138.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Stochastic, constrained, and smoothed adversaries. In NIPS, 2011. Available at http://arxiv.org/abs/1104.5070.  A. Rakhlin, O. Shamir, and K. Sridharan. Relax and localize: From value to algorithms.  CoRR, abs/1204.0870, 2012. Submitted. Online Learning with Predictable Sequences  "}, "Efficient Learning of Simplices": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Efficient Learning of Simplices", "abstract": "We show an efficient algorithm for the following problem: Given uniformly random points from an arbitrary n-dimensional simplex, estimate the simplex. The size of the sample and the number of arithmetic operations of our algorithm are polynomial in n. This answers a question of Frieze, Jerrum and Kannan Frieze et al. (1996). Our result can also be interpreted as efficiently learning the intersection of n + 1 half-spaces in R^n in the model where the intersection is bounded and we are given polynomially many uniform samples from it. Our proof uses the local search technique from Independent Component Analysis (ICA), also used by Frieze et al. (1996). Unlike these previous algorithms, which were based on analyzing the fourth moment, ours is based on the third moment.  We also show a direct connection between the problem of learning a simplex and ICA: a simple randomized reduction to ICA from the problem of learning a simplex. The connection is based on a known representation of the uniform measure on a simplex. Similar representations lead to a reduction from the problem of learning an affine transformation of an n-dimensional l_p ball to ICA.", "pdf_url": "http://proceedings.mlr.press/v30/Anderson13.pdf", "keywords": ["bodies", "method of moments"], "reference": "Rados(cid:32)law Adamczak, Alexander E. Litvak, Alain Pajor, and Nicole Tomczak-Jaegermann. Quantitative estimates of the convergence of the empirical covariance matrix in ISSN 0894- log-concave ensembles. 0347. 10.1090/S0894-0347-09-00650-X. URL http://dx.doi.org/10.1090/ S0894-0347-09-00650-X.  J. Amer. Math. Soc., 23(2):535-561, 2010.  doi:  Anima Anandkumar, Rong Ge, Daniel Hsu, Sham M. Kakade, and Matus Telgarsky. Tensor  decompositions for learning latent variable models. CoRR, abs/1210.7559, 2012a.  13   Efficient Learning of Simplices  7. Conclusion  We showed, in two di\ufb00erent ways, that the problem of learning simplices can be solved e\ufb03ciently using techniques for ICA. We also showed that when the sample is one that may not satisfy the requirement of independent components, we can e\ufb03ciently obtain from it a sample that guarantees this property and from which the original distribution can be estimated. Many questions remain: Can we do this for other polytopes? Can we do this when the points come from the Gaussian distribution with labels instead of the uniform distribution in the polytope? In particular, does any one of the two techniques that we used in this paper for learning simplices extend to learning polytopes or to latent variable models?  It is not clear how to extend our method to learn intersections of more than n + 1 half-spaces. The main hurdle seems to be that the nice symmetric form of the moment polynomial that we get for the simplex is no longer there, and it\u2019s not clear how the polyno- mial is related to the features of the polytope. We don\u2019t even know whether or not there is a one-to-one correspondence between polytopes and the moment polynomials (of low constant degree). Interestingly, it is also not clear how to learn intersections of n (or fewer, but not much fewer) half-spaces, for similar reasons: First note that we cannot consider uniform distributions over such sets because they are unbounded. As mentioned before, there is considerable literature when one considers other distributions, such as the Gaussian distri- bution. However, our moment-based method runs into the same di\ufb03culty as before, namely the relation between the moment polynomial and the half-spaces defining the polyhedron is not clear.  As pointed out by a COLT referee, our second method for learning simplices, namely direct reduction to ICA, can possibly be used to learn the more general Dirichlet distribution on the simplex when combined with the results of Barthe et al. (2010). This is an interesting direction for future work.  Acknowledgments  We thank Santosh Vempala for telling us about the polytope learning problem, the approach of using higher-order moments and for helpful discussions. We also thank Keith Ball, Alexander Barvinok, Franck Barthe, Mikhail Belkin, Adam Kalai, Assaf Naor, Aaditya Ramdas, Roman Vershynin and James Voss for helpful discussions. We thank anonymous COLT referees for useful remarks and pointers to the literature.  References  Rados(cid:32)law Adamczak, Alexander E. Litvak, Alain Pajor, and Nicole Tomczak-Jaegermann. Quantitative estimates of the convergence of the empirical covariance matrix in ISSN 0894- log-concave ensembles. 0347. 10.1090/S0894-0347-09-00650-X. URL http://dx.doi.org/10.1090/ S0894-0347-09-00650-X.  J. Amer. Math. Soc., 23(2):535-561, 2010.  doi:  Anima Anandkumar, Rong Ge, Daniel Hsu, Sham M. Kakade, and Matus Telgarsky. Tensor  decompositions for learning latent variable models. CoRR, abs/1210.7559, 2012a. Anderson Goyal Rademacher  Animashree Anandkumar, Daniel Hsu, and Sham M. Kakade.  moments http://arxiv.org/abs/1203.0683.  for mixture models and hidden markov models.  A method of In COLT, 2012b.  Sanjeev Arora, Rong Ge, Ankur Moitra, and Sushant Sachdeva. Provable ICA with un- known Gaussian noise, and implications for Gaussian mixtures and autoencoders. In NIPS, 2012. arXiv:1206.5349.  F. Barthe, O. Gu\u00b4edon, S. Mendelson, and A. Naor. A probabilistic approach to the geometry  of the (cid:96)n  p -ball. The Annals of Probability, 33(2):480-513, 2005.  F. Barthe, F. Gamboa, L. Lozada-Chang, and A. Rouault. Generalized Dirichlet distribu- tions on the ball and moments. ALEA Lat. Am. J. Probab. Math. Stat., 7:319-340, 2010. ISSN 1980-0436.  Patrick Billingsley. Probability and measure. Wiley Series in Probability and Mathematical Statistics. John Wiley & Sons Inc., New York, third edition, 1995. ISBN 0-471-00710-2. A Wiley-Interscience Publication.  P. Comon.  Independent component analysis, a new concept? Signal processing, 36(3):  287-314, 1994.  demic Press, 2010.  pages 359-368, 1996.  Pierre Comon and Christian Jutten, editors. Handbook of Blind Source Separation. Aca-  Alan M. Frieze, Mark Jerrum, and Ravi Kannan. Learning linear transformations. In FOCS,  Navin Goyal and Luis Rademacher. Learning convex bodies is hard. In COLT, 2009.  Nick Gravin, Jean Lasserre, Dmitrii V. Pasechnik, and Sinai Robins. The inverse moment problem for convex polytopes. Discrete & Computational Geometry, 48(3):596-621, 2012.  A. Grundmann and H. M. Moeller.  Invariant integration formulas for the n-simplex by  combinatorial methods. SIAM J. Numer. Anal., 15:282-290, 1978.  A. K. Gupta and D. Song. Lp-norm spherical distribution. J. Statist. Plann. Inference, 60 (2):241-260, 1997. ISSN 0378-3758. doi: 10.1016/S0378-3758(96)00129-2. URL http: //dx.doi.org/10.1016/S0378-3758(96)00129-2.  Aapo Hyv\u00a8arinen. Fast and robust fixed-point algorithms for independent component anal-  ysis. IEEE Transactions on Neural Networks, 10(3):626-634, 1999.  Aapo Hyv\u00a8arinen, Juha Karhunen, and Erkki Oja. Independent Component Analysis. Wiley,  2001.  Adam R. Klivans and Alexander A. Sherstov. A lower bound for agnostically learning  disjunctions. In COLT, pages 409-423, 2007.  Adam R. Klivans and Alexander A. Sherstov. Cryptographic hardness for learning inter-  sections of halfspaces. J. Comput. Syst. Sci., 75(1):2-12, 2009. Efficient Learning of Simplices  Adam R. Klivans, Ryan O\u2019Donnell, and Rocco A. Servedio. Learning geometric concepts  via Gaussian surface area. In FOCS, pages 541-550, 2008.  Stephen Kwek and Leonard Pitt. PAC learning intersections of halfspaces with membership  queries. Algorithmica, 22(1/2):53-75, 1998.  Jean B. Lasserre and Konstantin E. Avrachenkov. The multi-dimensional version of  (cid:82) abxpdx. American Math. Month., 108(2):151-154, 2001.  David G. Luenberger and Yinyu Ye. Linear and nonlinear programming.  International Series in Operations Research & Management Science, 116. Springer, New York, third edition, 2008. ISBN 978-0-387-74502-2.  Phong Q. Nguyen and Oded Regev. Learning a parallelepiped: Cryptanalysis of GGH and  NTRU signatures. J. Cryptology, 22(2):139-160, 2009.  Asa Packer. NP-hardness of largest contained and smallest containing simplices for V- and  H-polytopes. Discrete & Computational Geometry, 28(3):349-377, 2002.  S.T. Rachev and L. Ruschendorf. Approximate independence of distributions on spheres  and their stability properties. The Annals of Probability, 19(3):1311-1337, 1991.  G. Schechtman and J. Zinn. On the volume of the intersection of two ln  p balls. In Proc.  Amer. Math. Soc, volume 110, pages 217-224, 1990.  Bernhard Sch\u00a8olkopf, John C. Platt, John Shawe-Taylor, Alex J. Smola, and Robert C. Williamson. Estimating the support of a high-dimensional distribution. Neural Compu- tation, 13(7):1443-1471, 2001.  Fabian Sinz and Matthias Bethge. Lp-nested symmetric distributions. J. Mach. Learn.  Res., 11:3409-3451, 2010. ISSN 1532-4435.  Fabian H. Sinz and Matthias Bethge. The conjoint e\ufb00ect of divisive normalization and  orientation selectivity on redundancy reduction. In NIPS, pages 1521-1528, 2008.  D. Song and A. K. Gupta. Lp-norm uniform distribution. Proc. Amer. Math. Soc., 125 (2):595-601, 1997. ISSN 0002-9939. doi: 10.1090/S0002-9939-97-03900-2. URL http: //dx.doi.org/10.1090/S0002-9939-97-03900-2.  Nikhil Srivastava and Roman Vershynin. Covariance estimation for distributions with 2 + (cid:15)  moments, 2011.  paces. J. ACM, 57(6):32, 2010a.  FOCS, pages 124-130, 2010b.  Santosh Vempala. A random-sampling-based algorithm for learning intersections of halfs-  Santosh Vempala. Learning convex concepts from Gaussian distributions with PCA. In  Santosh S. Vempala and Ying Xiao. Structure from local optima: Learning subspace juntas  via higher order PCA. CoRR, abs/1108.3329, 2011. Anderson Goyal Rademacher  "}, "Complexity Theoretic Lower Bounds for Sparse Principal Component Detection": {"volumn": "v30", "url": "http://proceedings.mlr.press/v30/", "header": "Complexity Theoretic Lower Bounds for Sparse Principal Component Detection", "abstract": "In the context of sparse principal component detection, we bring evidence towards the existence of a statistical price to pay for computational efficiency. We measure the performance of a test by the smallest signal strength that it can detect and we propose a computationally efficient method based on semidefinite programming. We also prove that the statistical performance of this test cannot be strictly improved by any computationally efficient method. Our results can be viewed as complexity theoretic lower bounds conditionally on the assumptions that some instances of the planted clique problem cannot be solved in randomized polynomial time.", "pdf_url": "http://proceedings.mlr.press/v30/Berthet13.pdf", "keywords": ["Sparse principal component analysis", "Polynomial-time reduction", "Planted clique"], "reference": "Louigi Addario-Berry, Nicolas Broutin, Luc Devroye, and G\u00b4abor Lugosi. On combinatorial  testing problems. Annals of Statistics, 38(5):3063-3092, 08 2010.  Noga Alon, Michael Krivelevich, and Benny Sudakov. Finding a large hidden clique in a random graph. In Proceedings of the ninth annual ACM-SIAM symposium on Discrete algorithms, SODA \u201998, pages 594-598, Philadelphia, PA, USA, 1998. Society for Industrial and Applied Mathematics.  Noga Alon, Alexandr Andoni, Tali Kaufman, Kevin Matulef, Ronitt Rubinfeld, and Ning Xie. Testing k-wise and almost k-wise independence. In STOC\u201907\u2014Proceedings of the 39th Annual ACM Symposium on Theory of Computing, pages 496-505. ACM, New York, 2007.  Noga Alon, Sanjeev Arora, Rajsekar Manokaran, Dana Moshkovitz, and Omri Weinstein. On the inapproximability of the densest \u03ba-subgraph problem. Unpublished, April 2011.  Brendan P.W. Ames and Stephen A. Vavasis. Nuclear norm minimization for the planted  clique and biclique problems. Mathematical Programming, 129:69-89, 2011.  Arash A. Amini and Martin J. Wainwright. High-dimensional analysis of semidefinite re- laxations for sparse principal components. Annals of Statistics, 37(5B):2877-2921, 03 2009.  E. Arias-Castro, S. Bubeck, and G. Lugosi. Detecting positive correlations in a multivariate  sample. Arxiv Preprint, 2013. arXiv:1202.5536.  Ery Arias-Castro and Nicolas Verzelen. Community detection in random networks. Arxiv  Preprint, 02 2013. URL http://arxiv.org/abs/1302.7099.  Ery Arias-Castro, Emmanuel J. Cand`es, and Arnaud Durand. Detection of an anomalous  cluster in a network. Annals of Statistics, 39, 01 2011a.  Ery Arias-Castro, Emmanuel J. Cand`es, and Yaniv Plan.  Global testing under sparse alternatives: ANOVA, multiple comparisons and the higher criticism. Ann. Statist., 39(5):2533-2556, 2011b. ISSN 0090-5364. doi: 10.1214/11-AOS910. URL http://dx.doi.org/10.1214/11-AOS910.  Ery Arias-Castro, S\u00b4ebastien Bubeck, and G\u00b4abor Lugosi. Detection of correlations. Ann.  Statist., 40(1):412-435, 2012.  13   Complexity Theoretic Lower Bounds  Philippe Rigollet is partially supported by the National Science Foundation grants DMS- 0906424 and DMS-1053987. Quentin Berthet is partially supported by a Gordon S. Wu fellowship.  Acknowledgments  References  Louigi Addario-Berry, Nicolas Broutin, Luc Devroye, and G\u00b4abor Lugosi. On combinatorial  testing problems. Annals of Statistics, 38(5):3063-3092, 08 2010.  Noga Alon, Michael Krivelevich, and Benny Sudakov. Finding a large hidden clique in a random graph. In Proceedings of the ninth annual ACM-SIAM symposium on Discrete algorithms, SODA \u201998, pages 594-598, Philadelphia, PA, USA, 1998. Society for Industrial and Applied Mathematics.  Noga Alon, Alexandr Andoni, Tali Kaufman, Kevin Matulef, Ronitt Rubinfeld, and Ning Xie. Testing k-wise and almost k-wise independence. In STOC\u201907\u2014Proceedings of the 39th Annual ACM Symposium on Theory of Computing, pages 496-505. ACM, New York, 2007.  Noga Alon, Sanjeev Arora, Rajsekar Manokaran, Dana Moshkovitz, and Omri Weinstein. On the inapproximability of the densest \u03ba-subgraph problem. Unpublished, April 2011.  Brendan P.W. Ames and Stephen A. Vavasis. Nuclear norm minimization for the planted  clique and biclique problems. Mathematical Programming, 129:69-89, 2011.  Arash A. Amini and Martin J. Wainwright. High-dimensional analysis of semidefinite re- laxations for sparse principal components. Annals of Statistics, 37(5B):2877-2921, 03 2009.  E. Arias-Castro, S. Bubeck, and G. Lugosi. Detecting positive correlations in a multivariate  sample. Arxiv Preprint, 2013. arXiv:1202.5536.  Ery Arias-Castro and Nicolas Verzelen. Community detection in random networks. Arxiv  Preprint, 02 2013. URL http://arxiv.org/abs/1302.7099.  Ery Arias-Castro, Emmanuel J. Cand`es, and Arnaud Durand. Detection of an anomalous  cluster in a network. Annals of Statistics, 39, 01 2011a.  Ery Arias-Castro, Emmanuel J. Cand`es, and Yaniv Plan.  Global testing under sparse alternatives: ANOVA, multiple comparisons and the higher criticism. Ann. Statist., 39(5):2533-2556, 2011b. ISSN 0090-5364. doi: 10.1214/11-AOS910. URL http://dx.doi.org/10.1214/11-AOS910.  Ery Arias-Castro, S\u00b4ebastien Bubeck, and G\u00b4abor Lugosi. Detection of correlations. Ann.  Statist., 40(1):412-435, 2012. Berthet Rigollet  Francis Bach,  Selin Damla Ahipasaoglu,  relaxations  vex for http://arxiv.org/abs/1006.3601v1.  subset  selection.  and Alexandre d\u2019Aspremont. 2010.  Arxiv Preprint,Con- URL  Sivaraman Balakrishnan, Mladen Kolar, Alessandro Rinaldo, Aarti Singh, and Larry Wasserman. Statistical and computational tradeo\ufb00s in biclustering. NIPS 2011 Workshop on Computational Trade-o\ufb00s in Statistical Learning, 2011.  Quentin Berthet and Philippe Rigollet. Optimal detection of sparse principal components in high dimension. ArXiv:1202.5070, 02 2012. URL http://arxiv.org/abs/1202.5070.  Ravi B. Boppana. Eigenvalues and graph bisection: An average-case analysis. In Foun- dations of Computer Science, 1987., 28th Annual Symposium on, pages 280 -285, oct. 1987.  Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge University Press,  Cambridge, 2004.  Cristina Butucea and Yuri I. Ingster. Detection of a sparse submatrix of a high-dimensional  noisy matrix. Bernoulli (to appear), 2013.  T. Tony Cai, Zongming Ma, and Yihong Wu. Sparse PCA: Optimal rates and adaptive  estimation. Arxiv Preprint, 11 2012. URL http://arxiv.org/abs/1211.1309.  Venkat Chandrasekaran and Michael I. Jordan. Computational and statistical tradeo\ufb00s via  convex relaxation. Proceedings of the National Academy of Sciences, 2013.  Alexandre d\u2019Aspremont, Laurent El Ghaoui, Michael I. Jordan, and Gert R. G. Lanckriet. A direct formulation for sparse PCA using semidefinite programming. SIAM Review, 49 (3):434-448, July 2007.  Alexandre d\u2019Aspremont, Francis Bach, and Laurent El Ghaoui. Approximation bounds URL  sparse principal component analysis.  ArXiv:1205.0121, May 2012.  for http://arxiv.org/abs/1205.0121.  Yael Dekel, Ori Gurel-Gurevich, and Yuval Peres. Finding hidden cliques in linear time with high probability. Arxiv Preprint, 2010. URL http://arxiv.org/abs/1010.2997v1.  Persi Diaconis and David Freedman. Finite exchangeable sequences. Ann. Probab., 8(4):  745-764, 1980.  Richard Dudley. Uniform Central Limit Theorems. Cambridge University Press, 1999.  Uriel Feige and Robert Krauthgamer. Finding and certifying a large hidden clique in a  semirandom graph. Random Structures Algorithms, 16(2):195-208, 2000.  Uriel Feige and Robert Krauthgamer. The probable value of the Lov\u00b4asz-Schrijver relaxations  for maximum independent set. SIAM J. Comput., 32(2):345-370 (electronic), 2003. Complexity Theoretic Lower Bounds  Uriel Feige and Dorit Ron. Finding hidden cliques in linear time.  In 21st International Meeting on Probabilistic, Combinatorial, and Asymptotic Methods in the Analysis of Al- gorithms (AofA\u201910), Discrete Math. Theor. Comput. Sci. Proc., AM, pages 189-203. Assoc. Discrete Math. Theor. Comput. Sci., Nancy, 2010.  Vitaly Feldman, Elena Grigorescu, Lev Reyzin, Santosh Vempala, and Ying Xiao. Statistical In Proceedings of the Fourty-Fifth  algorithms and a lower bound for planted clique. Annual ACM Symposium on Theory of Computing, STOC 2013, 2013.  Johan H\u02daastad. Clique is hard to approximate within n1  \u01eb. In 37th Annual Symposium on Foundations of Computer Science (Burlington, VT, 1996), pages 627-636. IEEE Comput. Soc. Press, Los Alamitos, CA, 1996.  \u2212  Johan H\u02daastad. Clique is hard to approximate within n1  \u01eb. Acta Math., 182(1):105-142,  \u2212  1999.  Elad Hazan and Robert Krauthgamer. How hard is it to approximate the best nash equi-  librium? SIAM J. Comput., 40(1):79-91, 2011.  Mark Jerrum. Large cliques elude the Metropolis process. Random Structures Algorithms,  3(4):347-359, 1992.  Iain M. Johnstone and Arthur Yu Lu. On consistency and sparsity for principal components  analysis in high dimensions. J. Amer. Statist. Assoc., 104(486):682-693, 2009.  Ari Juels and Marcus Peinado. Hiding cliques for cryptographic security. Des. Codes  Cryptogr., 20(3):269-280, 2000.  M. Kolar, S. Balakrishnan, A. Rinaldo, and A. Singh. Minimax localization of structural information in large noisy matrices. Advances in Neural Information Processing Systems, 2011.  Michael Krivelevich and Van H. Vu. Approximating the independence number and the chromatic number in expected polynomial time. J. Comb. Optim., 6(2):143-155, 2002.  Lud\u02c7ek Ku\u02c7cera. Expected complexity of graph partitioning problems. Discrete Appl. Math.,  57(2-3):193-212, 1995. Combinatorial optimization 1992 (CO92) (Oxford).  Zongming Ma. Sparse principal component analysis and iterative thresholding. Ann. Statist.  (to appear), 2013.  Pascal Massart. Concentration inequalities and model selection, volume 1896 of Lecture Notes in Mathematics. Springer, Berlin, 2007. Lectures from the 33rd Summer School on Probability Theory held in Saint-Flour, July 6-23, 2003, With a foreword by Jean Picard.  Frank McSherry. Spectral partitioning of random graphs. In 42nd IEEE Symposium on Foundations of Computer Science (Las Vegas, NV, 2001), pages 529-537. IEEE Com- puter Soc., Los Alamitos, CA, 2001. Berthet Rigollet  Benjamin Rossman. Average-Case Complexity of Detecting Cliques. ProQuest LLC, Ann  Arbor, MI, 2010. Thesis (Ph.D.)-Massachusetts Institute of Technology.  Shai Shalev-Shwartz, Ohad Shamir, and Eran Tomer. Using more data to speed-up training time. In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics April 21-23, 2012 La Palma, Canary Islands., volume 22 of JMLR W&CP, pages 1019-1027, 2012.  Joel Spencer. Ten lectures on the probabilistic method, volume 64 of CBMS-NSF Regional Conference Series in Applied Mathematics. Society for Industrial and Applied Mathe- matics (SIAM), Philadelphia, PA, second edition, 1994.  Xing Sun and Andrew B. Nobel. On the maximal size of large-average and ANOVA-fit  submatrices in a Gaussian random matrix. Bernoulli, 19(1):275-294, 2013.  Alexandre B. Tsybakov.  Introduction to nonparametric estimation. Springer Series in Statistics. Springer, New York, 2009. Revised and extended from the 2004 French original, Translated by Vladimir Zaiats.  Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices. Arxiv  Preprint, 11 2010. URL http://arxiv.org/abs/1011.3027v7.  Vincent Vu and Jing Lei. Minimax rates of estimation for sparse pca in high dimensions. In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics April 21-23, 2012 La Palma, Canary Islands., volume 22 of JMLR W&CP, pages 1278-1286, 2012.  David Zuckerman. Linear degree extractors and the inapproximability of max clique and chromatic number. In Proceedings of the thirty-eighth annual ACM symposium on Theory of computing, STOC \u201906, pages 681-690, New York, NY, USA, 2006. ACM. Complexity Theoretic Lower Bounds  "}}