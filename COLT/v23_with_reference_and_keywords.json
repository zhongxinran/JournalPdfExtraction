{"Preface": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Preface", "abstract": "Preface to the Proceedings of the 25th Annual Conference on Learning Theory June 25-27, 2012, Edinburgh, Scotland.", "pdf_url": "http://proceedings.mlr.press/v23/mannor12/mannor12.pdf"}, "Unsupervised SVMs: On the Complexity of the Furthest Hyperplane Problem": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Unsupervised SVMs: On the Complexity of the Furthest Hyperplane Problem", "abstract": "This paper introduces the Furthest Hyperplane Problem (FHP), which is an unsupervised counterpart of Support Vector Machines. Given a set of n points in R^d, the objective is to produce the hyperplane (passing through the origin) which maximizes the separation margin, that is, the minimal distance between the hyperplane and any input point. To the best of our knowledge, this is the first paper achieving provable results regarding FHP. We provide both lower and upper bounds to this NP-hard problem. First, we give a simple randomized algorithm whose running time is n^O(1/\u03b8^2) where \u03b8is the optimal separation margin. We show that its exponential dependency on 1/\u03b8^2 is tight, up to sub-polynomial factors, assuming SAT cannot be solved in sub-exponential time. Next, we give an efficient approximation algorithm. For any \u03b1\u2208[0, 1], the algorithm produces a hyperplane whose distance from at least 1 - 3\u03b1fraction of the points is at least \u03b1times the optimal separation margin. Finally, we show that FHP does not admit a PTAS by presenting a gap preserving reduction from a particular version of the PCP theorem.", "pdf_url": "http://proceedings.mlr.press/v23/karnin12/karnin12.pdf", "keywords": [], "reference": "Noga Alon and V. D. Milman. lambda1, isoperimetric inequalities for graphs, and superconcentra-  tors. Journal of Combinatorial Theory, 38:73-88, 1985.  Sanjeev Arora. Probabilistic checking of proofs and hardness of approximation problems. Revised version of a dissertation submitted at CS Division, U C Berkeley, CS-TR-476-94, August 1994.  Rosa I. Arriaga and Santosh Vempala. An algorithmic theory of learning: Robust concepts and random projection. In IEEE Symposium on Foundations of Computer Science, pages 616-623, 1999.  Kristin P. Bennett and Ayhan Demiriz. Semi-supervised support vector machines. In Advances in  Neural Information Processing Systems, pages 368-374. MIT Press, 1998.  Tijl De Bie and Nello Cristianini. Convex methods for transduction. In Advances in Neural Infor-  mation Processing Systems 16, pages 73-80. MIT Press, 2003.  Christopher J. C. Burges. A tutorial on support vector machines for pattern recognition. Data  Mining and Knowledge Discovery, 2:121-167, 1998.  Maria \ufb02orina Balcan, Avrim Blum, and Santosh Vempala. On kernels, margins, and low-  dimensional mappings. In Algorithmic Learning Theory, pages 194-205, 2004.  Sariel Har-peled, Dan Roth, and Dav Zimak. Maximum margin coresets for active and noise tolerant learning. In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI, 2006.  Thorsten Joachims. Transductive inference for text classification using support vector machines. In Proceedings of the Sixteenth International Conference on Machine Learning, ICML \u201999, pages 200-209, San Francisco, CA, USA, 1999. Morgan Kaufmann Publishers Inc. ISBN 1-55860- 612-2. URL http://portal.acm.org/citation.cfm?id=645528.657646.  Peter Jonsson, Andrei A. Krokhin, and Fredrik Kuivinen. Hard constraint satisfaction problems  have hard gaps at location 1. Theor. Comput. Sci., 410(38-40):3856-3874, 2009.  Adam R. Klivans and Rocco A. Servedio. Learning intersections of halfspaces with a margin. In in  proceedings of the 17th annual conference on learning theory, pages 348-362, 2004.  M. K. Kozlov, S. P. Tarasov, and L. G. Khachiyan. Polynomial solvability of convex quadratic  programming. Doklady Akademiia Nauk SSSR, 248, 1979.  Rafal Latala. Some estimates of norms of random matrices. Proceedings of the American Mathe-  matical Society, 133(5):1273-1282, May 2005.  G.G. Lorentz, M. Golitschek, and Y. Makovoz. Constructive approximation: advanced problems. Grundlehren der mathematischen Wissenschaften. Springer, 1996. ISBN 9783540570288. URL http://books.google.com/books?id=pl0_AQAAIAAJ.  Alexander Lubotzky, R. Phillips, and P. Sarnak. Ramanujan graphs. Combinatorica, 8(3):261-277,  1988.  2.13   FURTHEST HYPERPLANE PROBLEM  References  Noga Alon and V. D. Milman. lambda1, isoperimetric inequalities for graphs, and superconcentra-  tors. Journal of Combinatorial Theory, 38:73-88, 1985.  Sanjeev Arora. Probabilistic checking of proofs and hardness of approximation problems. Revised version of a dissertation submitted at CS Division, U C Berkeley, CS-TR-476-94, August 1994.  Rosa I. Arriaga and Santosh Vempala. An algorithmic theory of learning: Robust concepts and random projection. In IEEE Symposium on Foundations of Computer Science, pages 616-623, 1999.  Kristin P. Bennett and Ayhan Demiriz. Semi-supervised support vector machines. In Advances in  Neural Information Processing Systems, pages 368-374. MIT Press, 1998.  Tijl De Bie and Nello Cristianini. Convex methods for transduction. In Advances in Neural Infor-  mation Processing Systems 16, pages 73-80. MIT Press, 2003.  Christopher J. C. Burges. A tutorial on support vector machines for pattern recognition. Data  Mining and Knowledge Discovery, 2:121-167, 1998.  Maria \ufb02orina Balcan, Avrim Blum, and Santosh Vempala. On kernels, margins, and low-  dimensional mappings. In Algorithmic Learning Theory, pages 194-205, 2004.  Sariel Har-peled, Dan Roth, and Dav Zimak. Maximum margin coresets for active and noise tolerant learning. In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI, 2006.  Thorsten Joachims. Transductive inference for text classification using support vector machines. In Proceedings of the Sixteenth International Conference on Machine Learning, ICML \u201999, pages 200-209, San Francisco, CA, USA, 1999. Morgan Kaufmann Publishers Inc. ISBN 1-55860- 612-2. URL http://portal.acm.org/citation.cfm?id=645528.657646.  Peter Jonsson, Andrei A. Krokhin, and Fredrik Kuivinen. Hard constraint satisfaction problems  have hard gaps at location 1. Theor. Comput. Sci., 410(38-40):3856-3874, 2009.  Adam R. Klivans and Rocco A. Servedio. Learning intersections of halfspaces with a margin. In in  proceedings of the 17th annual conference on learning theory, pages 348-362, 2004.  M. K. Kozlov, S. P. Tarasov, and L. G. Khachiyan. Polynomial solvability of convex quadratic  programming. Doklady Akademiia Nauk SSSR, 248, 1979.  Rafal Latala. Some estimates of norms of random matrices. Proceedings of the American Mathe-  matical Society, 133(5):1273-1282, May 2005.  G.G. Lorentz, M. Golitschek, and Y. Makovoz. Constructive approximation: advanced problems. Grundlehren der mathematischen Wissenschaften. Springer, 1996. ISBN 9783540570288. URL http://books.google.com/books?id=pl0_AQAAIAAJ.  Alexander Lubotzky, R. Phillips, and P. Sarnak. Ramanujan graphs. Combinatorica, 8(3):261-277,  1988.  2.13   KARNIN LIBERTY LOVETT SCHWARTZ WEINSTEIN  O. L. Mangasarian. Linear and nonlinear separation of patterns by linear programming. Oper. Res.,  13:444-452, 1965.  Jiming Peng, Jiming Peng, Lopamudra Mukherjee, Vikas Singh, Dale Schuurmans, and Linli Xu. An efficient algorithm for maximal margin clustering. To appear in Journal of Global Optimiza- tion, 2011.  N. Sauer. On the density of families of sets. Journal of Combinatorial Theory, Series A, 13(1): 145 - 147, 1972. ISSN 0097-3165. doi: DOI:10.1016/0097-3165(72)90019-2. URL http: //www.sciencedirect.com/science/article/pii/0097316572900192.  V. Vapnik and A. Lerner. Pattern recognition using generalized portrait method. Autom. Remote  Control, 24:774-780, 1963.  Linli Xu, James Neufeld, Bryce Larson, and Dale Schuurmans. Maximum margin clustering. In Advances in Neural Information Processing Systems 17, pages 1537-1544. MIT Press, 2005.  2.14   FURTHEST HYPERPLANE PROBLEM  "}, "(weak) Calibration is Computationally Hard": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "(weak) Calibration is Computationally Hard", "abstract": "We show that the existence of a computationally efficient calibration algorithm, with a low weak calibration rate, would imply the existence of an efficient algorithm for computing approximate Nash equilibria \u2013 thus implying the unlikely conclusion that every problem in \\emphPPAD is solvable in polynomial time.", "pdf_url": "http://proceedings.mlr.press/v23/hazan12a/hazan12a.pdf", "keywords": [], "reference": "Jacob Abernethy and Shie Mannor. Does an efficient calibrated forecasting strategy exist? Journal  of Machine Learning Research - Proceedings Track, 19:809-812, 2011.  3.9   (WEAK) CALIBRATION IS COMPUTATIONALLY HARD  5. Proof (of Theorem 3))  Three observations are helpful for intuition in the proof:  \u2022 By construction in Algorithm 1, in expectation, the outcomes Xt are just BR\u03b4(pt). Precisely,  E[Xt|X1, . . . Xt\u22121] = BR\u03b4(pt).  \u2022 Suppose \u03c9p(pt) is nonzero (so (cid:107)p \u2212 pt(cid:107) \u2264 \u03b5 ). Then, by Lemma 5, the larger \u03b4 is the closer  BR\u03b4(pt) and BR\u03b4(p) will be to each other.  \u2022 The smaller \u03b4 is, the more accurate an approximate NE we have for an approximate fixed  point of BR\u03b4 (by Lemma 6).  The proof of Theorem 3 is a consequence from the following lemma.  Lemma 7 Let p and X1:T be the random variables defined in Algorithm 1. For 2 < d < 1 have that:  \u03b4 , we  E (cid:107)p \u2212 BR\u03b4(p)(cid:107) \u2264 E[CT (X1:T , A, W \u03b5)] + \u03b5 +  For proof of Lemma 7 see Hazan and Kakade (2012). The proof of our Main result now follows:  Proof [Theorem 3] By Markov\u2019s inequality, we have that with probability greater than 1/2  (cid:107)p \u2212 BR\u03b4(p)(cid:107) \u2264 2 E[CT (X1:T , A, W \u03b5)] + 2\u03b5 +  \u2264 2F (d2, W \u03b5, T ) + 10\u03b51/3  using the definition of F (on a d2 sized outcome space) and \u03b4 = \u03b51/3. By applying Lemma 6, we have a (4F (d2, W \u03b5, T ) + 20\u03b51/3 + 2d\u03b51/3)-NE, which completes the proof.  4\u03b5 \u03b42  8\u03b5 \u03b42  6. Discussion and Open Problems  This work provides a computational lower bound for weak calibration, suggesting that the hardness of the problem may be fundamentally related to the problem of finding a fixed point. The following questions remain open:  \u2022 Is it possible to obtain an efficient algorithm for strong calibration? (One which gives a low  calibration error in time polynomial in the relevant parameters.)  \u2022 What is the statistical complexity of (weak or strong) calibration? Here, the statistical com- plexity is the number of rounds required to calibrate at some desired level of accuracy, without computational considerations.  References  Jacob Abernethy and Shie Mannor. Does an efficient calibrated forecasting strategy exist? Journal  of Machine Learning Research - Proceedings Track, 19:809-812, 2011.  3.9   HAZAN KAKADE  Jacob Abernethy, Peter L. Bartlett, and Elad Hazan. Blackwell approachability and no-regret learn- ing are equivalent. Journal of Machine Learning Research - Proceedings Track, 19:27-46, 2011.  Gail Blattenberger and Frank Lad. Separating the brier score into calibration and refinement com-  ponents: A graphical exposition. The American Statistician, 39:26-32, 1985.  Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge University  Press, 2006. ISBN 0521841089, 9780521841085.  X. Chen, X. Deng, and S.-H. Teng. Settling the complexity of computing two-player nash equilibria.  J. ACM, 56(3):1-57, 2009. ISSN 0004-5411.  Constantinos Daskalakis. Nash equilibria: Complexity, symmetries, and approximation. Computer  Science Review, 3(2):87-100, 2009.  A. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association, 77:  605-613, 1982.  Behavior, 29(1-2):7378, 1999.  D. P Foster. A proof of calibration via blackwell\u2019s approachability theorem. Games and Economic  D. P Foster and R. V Vohra. Asymptotic calibration. Biometrika, 85(2):379, 1998.  Drew Fudenberg and David K. Levine. An easier way to calibrate. Games and Economic Behavior,  29(1-2):131-137, October 1999.  Elad Hazan and Sham Kakade.  (weak) calibration is computationally hard.  arXiv,  http://arxiv.org/abs/1202.4478, 2012.  Sham M. Kakade and Dean P. Foster. Deterministic calibration and nash equilibrium. J. Comput.  Syst. Sci., 74(1):115-130, 2008.  S. Mannor, J.S. Shamma, and G. Arslan. Online calibrated forecasts: Memory efficiency versus universality for learning in games. Machine Learning, 67(1):77-115, 2007. ISSN 0885-6125.  Shie Mannor and Gilles Stoltz. A geometric proof of calibration. Math. Oper. Res., 35(4):721-727,  2010.  Christos H. Papadimitriou. On the complexity of the parity argument and other inefficient proofs of  existence. J. Comput. Syst. Sci., 48:498-532, June 1994. ISSN 0022-0000.  V. Perchet. Calibration and internal no-regret with random signals.  In Proceedings of the 20th international conference on Algorithmic learning theory, pages 68-82. Springer-Verlag, 2009. ISBN 3642044131.  Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning: Beyond regret. Journal  of Machine Learning Research - Proceedings Track, 19:559-594, 2011.  3.10   "}, "Learning Valuation Functions": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Learning Valuation Functions", "abstract": "A core element of microeconomics and game theory is that consumers have valuation functions over bundles of goods and that these valuations functions drive their purchases. A common assumption is that these functions are subadditive meaning that the value given to a bundle is at most the sum of values on the individual items. In this paper, we provide nearly tight guarantees on the efficient learnability of subadditive valuations. We also provide nearly tight bounds for the subclass of XOS (fractionally subadditive) valuations, also widely used in the literature. We additionally leverage the structure of valuations in a number of interesting subclasses and obtain algorithms with stronger learning guarantees.", "pdf_url": "http://proceedings.mlr.press/v23/balcan12b/balcan12b.pdf", "keywords": ["learning", "valuations", "no complementarities", "algorithmic game theory", "economics"], "reference": "versity Press, 1999.  M. Anthony and P. Bartlett. Neural Network Learning: Theoretical Foundations. Cambridge Uni-  M. Babaioff, N. Immorlica, and R. Kleinberg. Matroids, secretary problems, and online mecha- nisms. In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms, 2007.  M. Babaioff, M. Dinitz, A. Gupta, N. Immorlica, and K. Talwar. Secretary problems: weights and discounts. In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms, 2009.  A. Badanidiyuru, S. Dobzinski, H. Fu, R. D. Kleinberg, N. Nisan, and T. Roughgarden. Sketching In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algo-  valuation functions. rithms, 2012.  M. F. Balcan and N. Harvey. Learning submodular functions. In Proceedings of 43rd ACM Sympo-  sium on Theory of Computing, 2011.  K. Bhawalkar and T. Roughgarden. Welfare guarantees for combinatorial auctions with item bid-  ding. In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms, 2011.  A. Blum, M. Zinkevich, and T. Sandholm. On polynomial-time preference elicitation with value  queries. In ACM Conference on Electronic Commerce, 2003.  D. Buchfuhrer, S. Dughmi, H. Fu, R. Kleinberg, E. Mossel, C. H. Papadimitriou, M. Schapira, Y. Singer, and C. Umans. Inapproximability for vcg-based combinatorial auctions. In Proceed- ings of the Annual ACM-SIAM Symposium on Discrete Algorithms, 2010a.  D. Buchfuhrer, M. Schapira, and Y. Singer. Computation and incentives in combinatorial public  projects. In Proc. of the ACM conference on Electronic commerce, pages 33-42, 2010b.  R. Day and S. Raghavan. Assignment preferences and combinatorial auctions. Working paper,  University of Connecticut, April 2006.  S. Dobzinski. Two randomized mechanisms for combinatorial auctions. In APPROX, 2007.  S. Dobzinski, N. Nisan, and M. Schapira. Approximation algorithms for combinatorial auctions  with complement-free bidders. STOC \u201905, pages 610-618, 2005.  S. Dobzinski, N. Nisan, and M. Schapira. Truthful randomized mechanisms for combinatorial  auctions. STOC \u201906, pages 644-652, 2006.  U. Feige. On maximizing welfare when utility functions are subadditive. In STOC \u201906: Proceedings  of the thirty-eighth annual ACM symposium on Theory of computing, pages 41-50, 2006.  G. Goel, C. Karande, P. Tripathi, and L. Wang. Approximability of combinatorial problems with multi-agent submodular cost functions. In Proceedings of the 50th Annual Symposium on Foun- dations of Computer Science, 2009.  M. Goemans, N. Harvey, S. Iwata, and V. Mirrokni. Approximating submodular functions every-  where. In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, 2009.  4.13   LEARNING VALUATION FUNCTIONS  References  versity Press, 1999.  M. Anthony and P. Bartlett. Neural Network Learning: Theoretical Foundations. Cambridge Uni-  M. Babaioff, N. Immorlica, and R. Kleinberg. Matroids, secretary problems, and online mecha- nisms. In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms, 2007.  M. Babaioff, M. Dinitz, A. Gupta, N. Immorlica, and K. Talwar. Secretary problems: weights and discounts. In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms, 2009.  A. Badanidiyuru, S. Dobzinski, H. Fu, R. D. Kleinberg, N. Nisan, and T. Roughgarden. Sketching In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algo-  valuation functions. rithms, 2012.  M. F. Balcan and N. Harvey. Learning submodular functions. In Proceedings of 43rd ACM Sympo-  sium on Theory of Computing, 2011.  K. Bhawalkar and T. Roughgarden. Welfare guarantees for combinatorial auctions with item bid-  ding. In Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms, 2011.  A. Blum, M. Zinkevich, and T. Sandholm. On polynomial-time preference elicitation with value  queries. In ACM Conference on Electronic Commerce, 2003.  D. Buchfuhrer, S. Dughmi, H. Fu, R. Kleinberg, E. Mossel, C. H. Papadimitriou, M. Schapira, Y. Singer, and C. Umans. Inapproximability for vcg-based combinatorial auctions. In Proceed- ings of the Annual ACM-SIAM Symposium on Discrete Algorithms, 2010a.  D. Buchfuhrer, M. Schapira, and Y. Singer. Computation and incentives in combinatorial public  projects. In Proc. of the ACM conference on Electronic commerce, pages 33-42, 2010b.  R. Day and S. Raghavan. Assignment preferences and combinatorial auctions. Working paper,  University of Connecticut, April 2006.  S. Dobzinski. Two randomized mechanisms for combinatorial auctions. In APPROX, 2007.  S. Dobzinski, N. Nisan, and M. Schapira. Approximation algorithms for combinatorial auctions  with complement-free bidders. STOC \u201905, pages 610-618, 2005.  S. Dobzinski, N. Nisan, and M. Schapira. Truthful randomized mechanisms for combinatorial  auctions. STOC \u201906, pages 644-652, 2006.  U. Feige. On maximizing welfare when utility functions are subadditive. In STOC \u201906: Proceedings  of the thirty-eighth annual ACM symposium on Theory of computing, pages 41-50, 2006.  G. Goel, C. Karande, P. Tripathi, and L. Wang. Approximability of combinatorial problems with multi-agent submodular cost functions. In Proceedings of the 50th Annual Symposium on Foun- dations of Computer Science, 2009.  M. Goemans, N. Harvey, S. Iwata, and V. Mirrokni. Approximating submodular functions every-  where. In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, 2009.  4.13   BALCAN CONSTANTIN IWATA WANG  S. Iwata and K. Nagano. Submodular function minimization under covering constraints. In Pro-  ceedings of the 50th Annual Symposium on Foundations of Computer Science, 2009.  F. John. Extremum problems with inequalities as subsidiary conditions. presented to R. Courant on his 60th Birthday, January 8, 1948, 1948.  In Studies and Essays,  M. Kearns and U. Vazirani. An Introduction to Computational Learning Theory. MIT Press, 1994.  S. Lahaie and D. C. Parkes. Applying learning algorithms to preference elicitation. In ACM Con-  ference on Electronic Commerce, pages 180-188, 2004.  S. Lahaie, F. Constantin, and D. Parkes. More on the power of demand queries in combinatorial auctions: learning atomic languages and handling incentives. In Proceedings of the 19th interna- tional joint conference on Artificial intelligence, pages 959-964, 2005.  B. Lehmann, D. Lehmann, and N. Nisan. Combinatorial auctions with decreasing marginal utilities.  In ACM Conference on Electronic Commerce, pages 18-28, 2001.  K. Murota. Discrete Convex Analysis. SIAM, 2003.  N. Nisan. Chapter 9: Bidding Languages for Combinatorial Auctions . In P. Cramton, Y. Shoham,  and R. Steinberg, editors, Combinatorial Auctions. MIT Press, 2006.  N. Nisan, T. Roughgarden, E. Tardos, and V. Vazirani, editors. Algorithmic Game Theory. Cam-  bridge, 2007.  T. Sandholm. Algorithm for optimal winner determination in combinatorial auctions. Artificial  Intelligence, pages 542-547, 2001.  Y. Singer. Budget feasible mechanisms. FOCS \u201910, pages 765-774, 2010.  Z. Svitkina and L. Fleischer. Submodular approximation: Sampling-based algorithms and lower bounds. In Proceedings of the 49th Annual IEEE Symposium onFoundations of Computer Sci- ence, 2008.  D. Vainsencher, O. Dekel, and S. Mannor. Bundle selling by online estimation of valuation func-  tions. In ICML, 2011.  L.G. Valiant. A theory of the learnable. Commun. ACM, 27(11):1134-1142, 1984.  V. N. Vapnik. Statistical Learning Theory. Wiley and Sons, 1998.  "}, "Unified Algorithms for Online Learning and Competitive Analysis": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Unified Algorithms for Online Learning and Competitive Analysis", "abstract": "Online learning and competitive analysis are two widely studied frameworks for online decisionmaking settings. Despite the frequent similarity of the problems they study, there are significant differences in their assumptions, goals and techniques, hindering a unified analysis and richer interplay between the two. In this paper, we provide several contributions in this direction. We provide a single unified algorithm which by parameter tuning, interpolates between optimal regret for learning from experts (in online learning) and optimal competitive ratio for the metrical task systems problem (MTS) (in competitive analysis), improving on the results of Blum and Burch (1997). The algorithm also allows us to obtain new regret bounds against \u201cdrifting\u201d experts, which might be of independent interest. Moreover, our approach allows us to go beyond experts/MTS, obtaining similar unifying results for structured action sets and \u201ccombinatorial experts\", whenever the setting has a certain matroid structure.", "pdf_url": "http://proceedings.mlr.press/v23/buchbinder12/buchbinder12.pdf", "keywords": ["Online Learning", "Competitive Analysis", "Experts", "MTS", "Matroids"], "reference": "task systems. In ALT, 2010.  J. Abernethy, P. L. Bartlett, N. Buchbinder, and I. Stanton. A regularization approach to metrical  Nikhil Bansal, Niv Buchbinder, and Joseph Naor. Towards the randomized k-server conjecture: A  primal-dual approach. In SODA, pages 40-55, 2010.  5.12   BUCHBINDER CHEN NAOR SHAMIR  Note that,  0 =  (wi,T \u2212 wi,0) =  \u03b7(\u03b1\u2212bi,1\u2212  ci,t+  at)  T (cid:80) t=1  T (cid:80) t=1  e\u03b7\u03b1 \u2212 1  \u2212 1  \u2212  e\u03b7(\u03b1\u2212bi,1) \u2212 1 e\u03b7\u03b1 \u2212 1  \uf8f6  \uf8f7 \uf8f7 \uf8f8  n (cid:88)  i=1  n (cid:88)  (cid:18)  i=1  n (cid:88)  (cid:18)  i=1 (cid:18) 1 n  =  \u2265  = \u03b7  \uf8eb  \uf8ec \uf8ec \uf8ed  e  n (cid:88)  i=1  (cid:19)  \uf8eb  \uf8ec \uf8ede  wi,0 +  1 e\u03b7\u03b1 \u2212 1  (cid:32) T (cid:80) t=1  \u03b7  at\u2212  ci,t  T (cid:80) t=1  (cid:33)  \uf8f6  \uf8f7 \uf8f8  \u2212 1  wi,0 +  1 e\u03b7\u03b1 \u2212 1  (cid:32) T  (cid:88)  (cid:19)  \u03b7  t=1  at \u2212  ci,t  T (cid:88)  t=1  (cid:33)  +  1 e\u03b7\u03b1 \u2212 1  (cid:19) (cid:32) T (cid:88)  n (cid:88)  T (cid:88)  n (cid:88)  (cid:33)  ci,t  ,  at \u2212  t=1  i=1  t=1  i=1  where Inequality (11) follows since ex \u2212 1 \u2265 x for any x. This implies,  T (cid:88)  n (cid:88)  T (cid:88)  n (cid:88)  at \u2264  ci,t.  t=1  i=1  t=1  i=1  We can now bound the service cost:  (cid:104)wt, ct(cid:105) \u2264  T (cid:88)  n (cid:88)  (cid:18)  ci,t  wi,t +  T (cid:88)  t=1  (cid:19)  1 e\u03b7\u03b1 \u2212 1  \u2212  1 e\u03b7\u03b1 \u2212 1  T (cid:88)  n (cid:88)  t=1  i=1  at  T (cid:88)  atwi,t =  at  \u2264  t=1 T (cid:88)  i=1 n (cid:88)  t=1  i=1 (cid:32)  = D +  \u03b1 \u2212  t=1 ln( e\u03b7\u03b1+n\u22121 n \u03b7  (cid:33)  )  \u2264 D +  ln(n) \u03b7  ,  (11)  (12)  (13)  (14)  where Inequality (13) follows by Inequality (12), Inequality (14) follows by Inequality (10).  Acknowledgments  Niv Buchbinder was supported in part by ISF grant 954/11 and BSF grant 2010426. Seffi Naor was supported in part by the Google Inter-university center for Electronic Markets and Auctions, by ISF grant 954/11, and by BSF grant 2010426.  References  task systems. In ALT, 2010.  J. Abernethy, P. L. Bartlett, N. Buchbinder, and I. Stanton. A regularization approach to metrical  Nikhil Bansal, Niv Buchbinder, and Joseph Naor. Towards the randomized k-server conjecture: A  primal-dual approach. In SODA, pages 40-55, 2010.  5.12   UNIFIED ALGORITHMS FOR ONLINE LEARNING AND COMPETITIVE ANALYSIS  A. Blum and C. Burch. On-line learning and the metrical task system problem. In COLT, 1997.  A. Blum, H. J. Karloff, Y. Rabani, and M. E. Saks. A decomposition theorem and bounds for  randomized server problems. In FOCS, 1992.  A. Blum, C. Burch, and A. Kalai. Finely-competitive paging. In FOCS, 1999.  A. Blum, S. Chawla, and A. Kalai. Static optimality and dynamic search-optimality in lists and  trees. Algorithmica, 36(3):249-260, 2003.  A. Borodin and R. El-Yaniv. Online computation and competitive analysis. Cambridge University  Press, 1998.  ACM, 39(4):745-763, 1992.  A. Borodin, N. Linial, and M. E. Saks. An optimal on-line algorithm for metrical task system. J.  N. Buchbinder and J. Naor. The design of competitive online algorithms via a primal-dual approach.  Foundations and Trends in Theoretical Computer Science, 3(2-3):93-263, 2009.  N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge University Press,  2006.  2009.  1998.  2003.  Chandra Chekuri and Jan Vondrak. Randomized pipage rounding for matroid polytopes and appli-  cations. CoRR, abs/0909.4348, 2009.  K. Crammer, Y. Mansour, E. Even-Dar, and J. Wortman Vaughan. Regret minimization with concept  E. Even-Dar, R. Kleinberg, S. Mannor, and Y. Mansour. Online learning for global cost functions.  drift. In COLT, 2010.  In COLT, 2009.  Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an appli-  cation to boosting. J. Comput. Syst. Sci., 55(1):119-139, 1997.  E. Hazan and C. Seshadhri. Efficient learning algorithms for changing environments. In ICML,  M. Herbster and M. K. Warmuth. Tracking the best expert. Machine Learning, 32(2):151-178,  A. T. Kalai and S. Vempala. Efficient algorithms for online decision problems. J. Comput. Syst.  Sci., 71(3):291-307, 2005.  W. M. Koolen, M. K. Warmuth, and J. Kivinen. Hedging structured concepts. In COLT, 2010.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Beyond regret. In COLT, 2011.  A. Schrijver. Combinatorial Optimization: polyhedra and efficientcy. Springer, 2003.  Mohit Singh.  Iterative Methods in Combinatorial Optimization. PhD thesis, Tepper School of  Business, Carnegie Mellon University, 2008.  M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In ICML,  5.13   BUCHBINDER CHEN NAOR SHAMIR  (P)  min  ce,t \u00b7 we,t + \u03b1 \u00b7  ze,t  (D)  max  T (cid:80) t=1  (cid:80) e\u2208E  T (cid:80) t=1  (cid:80) e\u2208E  (cid:18)  T (cid:80) t=0  r(E)at \u2212 (cid:80)  r(S)aS,t  S\u2282E  (cid:19)  \u2200t \u2265 0  we,t \u2264 r (S)  \u2200t \u2265 0 and S \u2282 E (cid:80) e\u2208S (cid:80) e\u2208E ze,t \u2265 we,t \u2212 we,t\u22121 ze,t, we,t \u2265 0  \u2200t \u2265 1 and e \u2208 E \u2200t and e \u2208 E  we,t = r (E)  \u2200e \u2208 E  \u2200t \u2265 1 and e \u2208 E  aS,0 + be,1 \u2264 0  a0 \u2212 (cid:80) be,t+1 \u2264 be,t + ce,t \u2212 at + (cid:80)  S|e\u2208S  aS,t  S|e\u2208S  \u2200t \u2265 1 and e \u2208 E \u2200t, e \u2208 E, S \u2282 E  be,t \u2264 \u03b1 be,t, aS,t \u2265 0  Figure 2: The primal and dual LP formulations for the Matroid problem.  "}, "Online Optimization with Gradual Variations": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Online Optimization with Gradual Variations", "abstract": "We study the online convex optimization problem, in which an online algorithm has to make repeated decisions with convex loss functions and hopes to achieve a small regret. We consider a natural restriction of this problem in which the loss functions have a small deviation, measured by the sum of the distances between every two consecutive loss functions, according to some distance metrics. We show that for the linear and general smooth convex loss functions, an online algorithm modified from the gradient descend algorithm can achieve a regret which only scales as the square root of the deviation. For the closely related problem of prediction with expert advice, we show that an online algorithm modified  from the multiplicative update algorithm can also achieve a similar regret bound for a different measure of deviation. Finally, for loss functions which are strictly convex, we show that an online algorithm modified from the online Newton step algorithm can achieve a regret which is only logarithmic in terms of the deviation, and as an application, we can also have such a logarithmic regret for the portfolio management problem.", "pdf_url": "http://proceedings.mlr.press/v23/chiang12/chiang12.pdf", "keywords": ["Online Learning", "Regret", "Convex Optimization", "Deviation"], "reference": "Jacob Abernethy, Peter L. Bartlett, Alexander Rakhlin, and Ambuj Tewari. Optimal strate- gies and minimax lower bounds for online convex games. In COLT, pages 415-424, 2008.  Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods  for convex optimization. Operations Research Letters, 31(3):167-175, 2003.  Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University  Press, New York, NY, USA, 2004. ISBN 0521833787.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, Learning, and Games. Cambridge  Univerity Press, New York, 2006.  Thomas Cover. Universal portfolios. Mathematical Finance, 1:1-19, 1991.  Yoav Freund and Robert E. Schapire. A decision theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119-139, 1997.  Elad Hazan and Satyen Kale. Extracting certainty from uncertainty: regret bounded by  variation in costs. In COLT, pages 57-68, 2008.  Elad Hazan and Satyen Kale. On stochastic and worst-case models for investing. In NIPS,  pages 709-717, 2009.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Journal of Computer and System Sciences, 69(2-3):169-192, 2007.  Nick Littlestone and Manfred K. Warmuth. The weighted majority algorithm. Information  and Computation, 108(2):212-261, 1994.  A. Nemirovski and D. Yudin. Problem Complexity and Method E\ufb03ciency in Optimization.  Nauka Publishers, Moscow, 1978.  Yurii Nesterov. Introductory Lectures on Convex Optimization: A Basic Course (Applied  Optimization). Springer Netherlands, 1 edition, 2004.  Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning: stochastic,  constrained, and smoothed adversaries. In NIPS, pages 1764-1772, 2011.  Nati Srebro, Karthik Sridharan, and Ambuj Tewari. On the universality of online mirror  descent. In NIPS, pages 2645-2653, 2011.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.  In ICML, pages 928-936, 2003.  6.13   Online Optimization with Gradual Variations  References  Jacob Abernethy, Peter L. Bartlett, Alexander Rakhlin, and Ambuj Tewari. Optimal strate- gies and minimax lower bounds for online convex games. In COLT, pages 415-424, 2008.  Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods  for convex optimization. Operations Research Letters, 31(3):167-175, 2003.  Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University  Press, New York, NY, USA, 2004. ISBN 0521833787.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, Learning, and Games. Cambridge  Univerity Press, New York, 2006.  Thomas Cover. Universal portfolios. Mathematical Finance, 1:1-19, 1991.  Yoav Freund and Robert E. Schapire. A decision theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119-139, 1997.  Elad Hazan and Satyen Kale. Extracting certainty from uncertainty: regret bounded by  variation in costs. In COLT, pages 57-68, 2008.  Elad Hazan and Satyen Kale. On stochastic and worst-case models for investing. In NIPS,  pages 709-717, 2009.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Journal of Computer and System Sciences, 69(2-3):169-192, 2007.  Nick Littlestone and Manfred K. Warmuth. The weighted majority algorithm. Information  and Computation, 108(2):212-261, 1994.  A. Nemirovski and D. Yudin. Problem Complexity and Method E\ufb03ciency in Optimization.  Nauka Publishers, Moscow, 1978.  Yurii Nesterov. Introductory Lectures on Convex Optimization: A Basic Course (Applied  Optimization). Springer Netherlands, 1 edition, 2004.  Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning: stochastic,  constrained, and smoothed adversaries. In NIPS, pages 1764-1772, 2011.  Nati Srebro, Karthik Sridharan, and Ambuj Tewari. On the universality of online mirror  descent. In NIPS, pages 2645-2653, 2011.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.  In ICML, pages 928-936, 2003.  6.13   Chiang Yang Lee Mahdavi Lu Jin Zhu  "}, "The Optimality of Jeffreys Prior for Online Density Estimation and the Asymptotic Normality of Maximum Likelihood Estimators": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "The Optimality of Jeffreys Prior for Online Density Estimation and the Asymptotic Normality of Maximum Likelihood Estimators", "abstract": "We study online learning under logarithmic loss with regular parametric models. We show that a Bayesian strategy predicts optimally only if it uses Jeffreys prior. This result was known for canonical exponential families; we extend it to parametric models for which the maximum likelihood estimator is asymptotically normal. The optimal prediction strategy, normalized maximum likelihood, depends on the number \\emphn of rounds of the game, in general. However, when a Bayesian strategy is optimal, normalized maximum likelihood becomes independent of \\emphn. Our proof uses this to exploit the asymptotics of normalized maximum likelihood. The asymptotic normality of the maximum likelihood estimator is responsible for the necessity of Jeffreys prior.", "pdf_url": "http://proceedings.mlr.press/v23/hedayati12/hedayati12.pdf", "keywords": ["Online Learning", "Logarithmic Loss", "Bayesian Strategy", "Jeffreys Prior", "Asymptotic Normality of Maximum Likelihood Estimator"], "reference": "New York, NY, USA, 2006.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press,  P. D. Grunwald. The minimum description length principle. Cambridge, Mass. : MIT Press, 2007.  F. Hedayati and P. Bartlett. Exchangeability Characterizes Optimality of Sequential Normalized Maximum Likelihood and Bayesian Prediction with Jeffreys Prior. JMLR Workshop Conference Proceedings, 22: AISTATS 2012:504-510, 2012.  H. Jeffreys. An invariant form for the prior probability in estimation problems. Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences, 186(1007):453-461, 1946.  W. Kotlowski and P. Grunwald. Maximum Likelihood vs. Sequential Normalized Maximum Like-  lihood in On-line Density Estimation. to appear in COLT 2011, 2011.  W. K. Newey and D. McFadden. Chapter 35: Large sample estimation and hypothesis testing. In R. Engle and D. McFadden, editors, Handbook of Econometrics, volume 4, pages 2111-2245. Elsevier Science, 1994. ISBN 0-444-88766-0.  E. W. Weisstein. Fatou\u2019s lemma., February 2012a. URL http://mathworld.wolfram.com/  FatousLemma.html.  E. W. Weisstein. Lebesgue\u2019s dominated convergence theorem., February 2012b. URL http:// mathworld.wolfram.com/LebesguesDominatedConvergenceTheorem.html.  D. Zhu and J. Galbraith. A generalized asymmetric student-t distribution with application to financial econometrics. CIRANO Working Papers 2009s-13, CIRANO, Apr. 2009. URL http://ideas.repec.org/p/cir/cirwor/2009s-13.html.  7.13   OPTIMALITY OF JEFFREYS PRIOR FOR ONLINE DENSITY ESTIMATION  Also, we have  lim n\u2192\u221e  (cid:90)  \u0398  p\u03b8(xm\u22121)kn  xm\u22121(\u03b8)d\u03b8 =  lim n\u2192\u221e  p\u03b8(xm\u22121)kn  xm\u22121(\u03b8)d\u03b8  =  p\u03b8(xm\u22121)(cid:112)| I(\u03b8) | d\u03b8,  (cid:90)  \u0398  (cid:90)  \u0398  because otherwise psnml(xt | xm\u22121) = limn\u2192\u221e gn(xt, xm\u22121) = limn\u2192\u221e be a distribution. Hence we get:  (cid:82)  \u00afhn xt(\u03b8)d \u03b8 would not  \u0398  lim n\u2192\u221e  lim \u2206\u03b8\u21920  gn(xt, xm\u22121, \u2206\u03b8) =  \u0398 p\u03b8(xt)(cid:112)I(\u03b8)d\u03b8 (cid:82) \u0398 p\u03b8(xm\u22121)(cid:112)I(\u03b8)d\u03b8  (cid:82)  .  Notice that the proof does not use any properties of the Fisher information matrix. Thus, if the MLE is asymptotically normal with covariance V (\u03b8), then an optimal Bayesian strategy has prior proportional to (cid:112)|V (\u03b8)|.  References  New York, NY, USA, 2006.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press,  P. D. Grunwald. The minimum description length principle. Cambridge, Mass. : MIT Press, 2007.  F. Hedayati and P. Bartlett. Exchangeability Characterizes Optimality of Sequential Normalized Maximum Likelihood and Bayesian Prediction with Jeffreys Prior. JMLR Workshop Conference Proceedings, 22: AISTATS 2012:504-510, 2012.  H. Jeffreys. An invariant form for the prior probability in estimation problems. Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences, 186(1007):453-461, 1946.  W. Kotlowski and P. Grunwald. Maximum Likelihood vs. Sequential Normalized Maximum Like-  lihood in On-line Density Estimation. to appear in COLT 2011, 2011.  W. K. Newey and D. McFadden. Chapter 35: Large sample estimation and hypothesis testing. In R. Engle and D. McFadden, editors, Handbook of Econometrics, volume 4, pages 2111-2245. Elsevier Science, 1994. ISBN 0-444-88766-0.  E. W. Weisstein. Fatou\u2019s lemma., February 2012a. URL http://mathworld.wolfram.com/  FatousLemma.html.  E. W. Weisstein. Lebesgue\u2019s dominated convergence theorem., February 2012b. URL http:// mathworld.wolfram.com/LebesguesDominatedConvergenceTheorem.html.  D. Zhu and J. Galbraith. A generalized asymmetric student-t distribution with application to financial econometrics. CIRANO Working Papers 2009s-13, CIRANO, Apr. 2009. URL http://ideas.repec.org/p/cir/cirwor/2009s-13.html.  7.13   "}, "PAC-Bayesian Bound for Gaussian Process Regression and Multiple Kernel Additive Model": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "PAC-Bayesian Bound for Gaussian Process Regression and Multiple Kernel Additive Model", "abstract": "We develop a PAC-Bayesian bound for the convergence rate of a Bayesian variant of Multiple Kernel Learning (MKL) that is an estimation method for the sparse additive model. Standard analyses for MKL require a strong condition on the design analogous to the restricted eigenvalue condition for the analysis of Lasso and Dantzig selector. In this paper, we apply PAC-Bayesian technique to show that the Bayesian variant of MKL achieves the optimal convergence rate without such strong conditions on the design. Basically our approach is a combination of PAC-Bayes and recently developed theories of non-parametric Gaussian process regressions. Our bound is developed in a fixed design situation. Our analysis includes the existing result of Gaussian process as a special case and the proof is much simpler by virtue of PAC-Bayesian technique. We also give the convergence rate of the Bayesian variant of Group Lasso as a finite dimensional special case.", "pdf_url": "http://proceedings.mlr.press/v23/suzuki12/suzuki12.pdf", "keywords": ["PAC-Bayes", "Multiple Kernel Learning", "Group Lasso", "Gaussian Process", "Sparse Learning", "Additive Model"], "reference": "R. A. Adams and J. J. Fournier. Sobolev Spaces. Academic Press, New York, 2003. second edition.  P. Alquier and G. Biau. Sparse single-index model. Technical report, 2011. arXiv:1101.3229.  P. Alquier and K. Lounici. PAC-Bayesian bounds for sparse regression estimation with exponential  weights. Electronic Journal of Statistics, 5:127-145, 2011.  C. Archambeau and F. Bach. Multiple Gaussian process models. In NIPS 2010 Workshop on New  Directions in Multiple Kernel Learning, Whistler, 2010.  F. R. Bach, G. Lanckriet, and M. Jordan. Multiple kernel learning, conic duality, and the SMO  algorithm. In the 21st International Conference on Machine Learning, pages 41-48, 2004.  C. Bennett and R. Sharpley. Interpolation of Operators. Academic Press, Boston, 1988.  P. J. Bickel, Y. Ritov, and A. B. Tsybakov. Simultaneous analysis of Lasso and Dantzig selector.  The Annals of Statistics, 37(4):1705-1732, 2009.  8.12   SUZUKI  5. Conclusion and Discussion  In this paper, we developed a PAC-Bayesian bound for Gaussian process model and generalized it to sparse additive model. Important notion was that the optimal rate is achieved without any conditions on the design. Interpolations of spaces gave a nice characterization of the convergence rate on the misspecified situation. We have observed that Gaussian processes with scale mixture adaptively achieve the minimax optimal rate on both correctly-specified and misspecified situations.  We bounded the empirical L2-norm (cid:107)\u00b7(cid:107)n in this paper. However, the evaluation of the population L2(PX ) = (cid:82) f (X)2dPX , between the estimator and the true function is also of interest L2-norm, (cid:107)f (cid:107)2 from the view point of generalization error. For the analysis of the population L2-norm, the L\u221e- norm in the metric entropy condition (6) and the definition (4) of \u03c6(m) could be replaced with the f \u2217 m population L2-morm (cid:107)\u00b7(cid:107)L2(PX ). To bound the population L2-norm, we would need to impose some smoothness condition on the prior (see Theorem 2 and the following discussions in van der Vaart and van Zanten (2011)). Our future work includes developing a PAC-Bayesian bound that is also applicable to the population L2-norm.  Another interesting topic is to compare Bayesian-MKL with a model selection type method that minimizes a penalized risk like the BIC estimator. Rigollet and Tsybakov (2011a) discussed benefits of a model averaging type estimator comparing to a BIC type estimator in a finite dimensional linear model. It is interesting to argue an analogous thing also in a nonparametric regression situation.  We would like to thank Alexandre B. Tsybakov and Pierre Alquier for their suggestive advices. TS was partially supported by MEXT Kakenhi 22700289, Global COE Program \u201cThe Research and Training Center for New Development in Mathematics,\u201d and the Aihara Project, the FIRST program from JSPS, initiated by CSTP.  Acknowledgments  References  R. A. Adams and J. J. Fournier. Sobolev Spaces. Academic Press, New York, 2003. second edition.  P. Alquier and G. Biau. Sparse single-index model. Technical report, 2011. arXiv:1101.3229.  P. Alquier and K. Lounici. PAC-Bayesian bounds for sparse regression estimation with exponential  weights. Electronic Journal of Statistics, 5:127-145, 2011.  C. Archambeau and F. Bach. Multiple Gaussian process models. In NIPS 2010 Workshop on New  Directions in Multiple Kernel Learning, Whistler, 2010.  F. R. Bach, G. Lanckriet, and M. Jordan. Multiple kernel learning, conic duality, and the SMO  algorithm. In the 21st International Conference on Machine Learning, pages 41-48, 2004.  C. Bennett and R. Sharpley. Interpolation of Operators. Academic Press, Boston, 1988.  P. J. Bickel, Y. Ritov, and A. B. Tsybakov. Simultaneous analysis of Lasso and Dantzig selector.  The Annals of Statistics, 37(4):1705-1732, 2009.  8.12   PAC-BAYESIAN MKL  H. J. Brascamp and E. H. Lieb. On extensions of the brunn-minkowski and pr\u00b4ekopa-leindler the- orem, including inequalities for log concave functions, and with an application to the diffusion equation. Journal of Functional Analysis, 22(4):366-389, 1976.  I. Castillo. Lower bounds for posterior rates with Gaussian process priors. Electronic Journal of  Statistics, 2:1281-1299, 2008.  O. Catoni. Statistical Learning Theory and Stochastic Optimization. Lecture Notes in Mathematics.  Springer, 2004. Saint-Flour Summer School on Probability Theory 2001.  A. Dalalyan and A. B. Tsybakov. Aggregation by exponential weighting sharp PAC-Bayesian  bounds and sparsity. Machine Learning, 72:39-61, 2008.  A. Dalalyan and A. B. Tsybakov. Sparse regression learning by aggregation and Langevin Monte-  Carlo. Journal of Computer and System Sciences, in press, 2011.  D. E. Edmunds and H. Triebel. Function Spaces, Entropy Numbers, Differential Operators. Cam-  bridge University Press, Cambridge, 1996.  M. N. Gibbs. Bayesian Gaussian Processes for Regression and Classification. PhD thesis, Univer-  sity of Cambridge, 1997.  1995.  P. J. Green. Reversible jump markov chain monte carlo computation. Biometrika, 82(4):711-732,  L. Gross. Measurable functions on Hilbert space. Transactions of the American Mathematical  Society, 105(3):372-390, 1962.  G. Harg\u00b4e. A particular case of correlation inequality for the gaussian measure. The Annals of  Probability, 27(4):1939-1951, 1999.  G. Harg\u00b4e. A convex/log-concave correlation inequality for gaussian measure and an application to  abstract wiener spaces. Probability Theory and Related Fields, 130(3):415-440, 2004.  T. Hastie and R. Tibshirani. Generalized additive models. Chapman & Hall Ltd, 1999.  V. Koltchinskii and M. Yuan. Sparsity in multiple kernel learning. The Annals of Statistics, 38(6):  3660-3695, 2010.  J. Kuelbs and W. V. Li. Metric entropy and the small ball problem for gaussian measures. Journal  of Functional Analysis, 116(1):133-157, 1993.  G. Lanckriet, N. Cristianini, L. E. Ghaoui, P. Bartlett, and M. Jordan. Learning the kernel matrix  with semi-definite programming. Journal of Machine Learning Research, 5:27-72, 2004.  W. V. Li and Q.-M. Shao. Gaussian processes: inequalities, small ball probabilities and applications.  Stochastic Processes: Theory and Methods, 19:533-597, 2001.  J.-M. Marin and C. Robert. Bayesian Core: A Practical Approach to Computational Bayesian  Statistics. Springer, 2007.  8.13   SUZUKI  D. McAllester. Some PAC-Bayesian theorems. In the Anual Conference on Computational Learning  Theory, pages 230-234, 1998.  ing Theory, pages 164-170, 1999.  D. McAllester. PAC-Bayesian model averaging. In the Anual Conference on Computational Learn-  L. Meier, S. van de Geer, and P. B\u00a8uhlmann. High-dimensional additive modeling. The Annals of  Statistics, 37(6B):3779-3821, 2009.  G. Raskutti, M. J. Wainwright, and B. Yu. Minimax-optimal rates for sparse additive models over kernel classes via convex programming. Journal of Machine Learning Research, 13:389-427, 2012.  C. E. Rasmussen and C. Williams. Gaussian Processes for Machine Learning. MIT Press, 2006.  P. Ravikumar, J. Lafferty, H. Liu, and L. Wasserman. Sparse additive models. Journal of the Royal  Statistical Society: Series B, 71(5):1009-1030, 2009.  P. Rigollet and A. B. Tsybakov. Exponential screening and optimal rates of sparse estimation. The  Annals of Statistics, 39(2):731-771, 2011a.  P. Rigollet and A. B. Tsybakov. Sparse estimation by exponential weighting. Technical report,  2011b. arXiv:1108.5116.  (2), 2004.  M. Seeger. Gaussian processes for machine learning. International Journal of Neural Systems, 14  I. Steinwart. Support Vector Machines. Springer, 2008.  I. Steinwart, D. Hush, and C. Scovel. Optimal rates for regularized least squares regression. In  Proceedings of the Annual Conference on Learning Theory, pages 79-93, 2009.  T. Suzuki and M. Sugiyama. Fast learning rate of multiple kernel learning: Trade-off between sparsity and smoothness. In JMLR Workshop and Conference Proceedings 22, pages 1152-1183, 2012. Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS2012).  R. Tomioka and T. Suzuki. Regularization strategies and empirical bayesian learning for mkl. In  NIPS 2010 Workshop: New Directions in Multiple Kernel Learning, Whistler, 2010.  A. W. van der Vaart and J. H. van Zanten. Rates of contraction of posterior distributions based on  Gaussian process priors. The Annals of Statistics, 36(3):1435-1463, 2008a.  A. W. van der Vaart and J. H. van Zanten. Reproducing kernel Hilbert spaces of Gaussian priors. Pushing the Limits of Contemporary Statistics: Contributions in Honor of Jayanta K. Ghosh, 3: 200-222, 2008b. IMS Collections.  A. W. van der Vaart and J. H. van Zanten. Adaptive Bayesian estimation using a Gaussian random  field with inverse Gamma bandwidth. The Annals of Statistics, 37(5B):2655-2675, 2009.  A. W. van der Vaart and J. H. van Zanten.  Information rates of nonparametric gaussian process  methods. Journal of Machine Learning Research, 12:2095-2119, 2011.  8.14   PAC-BAYESIAN MKL  A. W. van der Vaart and J. A. Wellner. Weak Convergence and Empirical Processes: With Applica-  tions to Statistics. Springer, New York, 1996.  M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal  of The Royal Statistical Society Series B, 68(1):49-67, 2006.  "}, "Random Design Analysis of Ridge Regression": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Random Design Analysis of Ridge Regression", "abstract": "This work gives a simultaneous analysis of both the ordinary least squares estimator and the ridge regression estimator in the random design setting under mild assumptions on the covariate/response distributions. In particular, the analysis provides sharp results on the \u201cout-of-sample\u201d prediction error, as opposed to the \u201cin-sample\u201d (fixed design) error. The analysis also reveals the effect of errors in the estimated covariance structure, as well as the effect of modeling errors; neither of which effects are present in the fixed design setting. The proof of the main results are based on a simple decomposition lemma combined with concentration inequalities for random vectors and matrices.", "pdf_url": "http://proceedings.mlr.press/v23/hsu12/hsu12.pdf", "keywords": [], "reference": "arXiv:1010.0072.  J.-Y. Audibert and O. Catoni. Robust linear least squares regression, 2010a. arXiv:1010.0074.  J.-Y. Audibert and O. Catoni. Robust linear regression through PAC-Bayesian truncation, 2010b.  A. Caponnetto and E. De Vito. Optimal rates for the regularized least-squares algorithm. Founda-  tions of Computational Mathematics, 7(3):331-368, 2007.  O. Catoni. Statistical Learning Theory and Stochastic Optimization, Lectures on Probability and Statistics, Ecole d\u2019Et\u00b4e de Probabiliti\u00b4es de Saint-Flour XXXI - 2001, volume 1851 of Lecture Notes in Mathematics. Springer, 2004.  L. Gy\u00a8orfi, M. Kohler, A. Kry\u02d9zak, and H. Walk. A Distribution-Free Theory of Nonparametric  Regression. Springer, 2004.  58:54-59, 1962.  A. E. Hoerl. Application of ridge analysis to regression problems. Chemical Engineering Progress,  R. Horn and C. R. Johnson. Matrix Analysis. Cambridge University Press, 1985.  D. Hsu, S. M. Kakade, and T. Zhang. A tail inequality for quadratic forms of subgaussian random  vectors, 2011. arXiv:1110.2842.  D. Hsu, S. M. Kakade, and T. Zhang. Tail inequalities for sums of random matrices that depend on  the intrinsic dimension. Electronic Communications in Probability, 17(14):1-13, 2012.  V. Koltchinskii. Local Rademacher complexities and oracle inequalities in risk minimization. The  Annals of Statistics, 34(6):2593-2656, 2006.  B. Laurent and P. Massart. Adaptive estimation of a quadratic functional by model selection. The  Annals of Statistics, 28(5):1302-1338, 2000.  S. Smale and D.-X. Zhou. Learning theory estimates via integral operators and their approximations.  Constructive Approximations, 26:153-172, 2007.  I. Steinwart, D. Hush, and C. Scovel. Optimal rates for regularized least squares regression. In  Proceedings of the 22nd Annual Conference on Learning Theory, pages 79-93, 2009.  G. W. Stewart and J.-G. Sun. Matrix Perturbation Theory. Academic Press, 1990.  C. J. Stone. Optimal global rates of convergence for nonparametric regression. Annals of Statistics,  10:1040-1053, 1982.  putation, 17:2077-2098, 2005.  T. Zhang. Learning bounds for kernel regression using effective data dimensionality. Neural Com-  9.13   RANDOM DESIGN ANALYSIS OF RIDGE REGRESSION  References  arXiv:1010.0072.  J.-Y. Audibert and O. Catoni. Robust linear least squares regression, 2010a. arXiv:1010.0074.  J.-Y. Audibert and O. Catoni. Robust linear regression through PAC-Bayesian truncation, 2010b.  A. Caponnetto and E. De Vito. Optimal rates for the regularized least-squares algorithm. Founda-  tions of Computational Mathematics, 7(3):331-368, 2007.  O. Catoni. Statistical Learning Theory and Stochastic Optimization, Lectures on Probability and Statistics, Ecole d\u2019Et\u00b4e de Probabiliti\u00b4es de Saint-Flour XXXI - 2001, volume 1851 of Lecture Notes in Mathematics. Springer, 2004.  L. Gy\u00a8orfi, M. Kohler, A. Kry\u02d9zak, and H. Walk. A Distribution-Free Theory of Nonparametric  Regression. Springer, 2004.  58:54-59, 1962.  A. E. Hoerl. Application of ridge analysis to regression problems. Chemical Engineering Progress,  R. Horn and C. R. Johnson. Matrix Analysis. Cambridge University Press, 1985.  D. Hsu, S. M. Kakade, and T. Zhang. A tail inequality for quadratic forms of subgaussian random  vectors, 2011. arXiv:1110.2842.  D. Hsu, S. M. Kakade, and T. Zhang. Tail inequalities for sums of random matrices that depend on  the intrinsic dimension. Electronic Communications in Probability, 17(14):1-13, 2012.  V. Koltchinskii. Local Rademacher complexities and oracle inequalities in risk minimization. The  Annals of Statistics, 34(6):2593-2656, 2006.  B. Laurent and P. Massart. Adaptive estimation of a quadratic functional by model selection. The  Annals of Statistics, 28(5):1302-1338, 2000.  S. Smale and D.-X. Zhou. Learning theory estimates via integral operators and their approximations.  Constructive Approximations, 26:153-172, 2007.  I. Steinwart, D. Hush, and C. Scovel. Optimal rates for regularized least squares regression. In  Proceedings of the 22nd Annual Conference on Learning Theory, pages 79-93, 2009.  G. W. Stewart and J.-G. Sun. Matrix Perturbation Theory. Academic Press, 1990.  C. J. Stone. Optimal global rates of convergence for nonparametric regression. Annals of Statistics,  10:1040-1053, 1982.  putation, 17:2077-2098, 2005.  T. Zhang. Learning bounds for kernel regression using effective data dimensionality. Neural Com-  9.13   HSU KAKADE ZHANG  "}, "Reconstruction from Anisotropic Random Measurements": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Reconstruction from Anisotropic Random Measurements", "abstract": "Random matrices are widely used in sparse recovery problems, and the relevant properties of matrices with i.i.d. entries are well understood. The current paper discusses the recently introduced Restricted Eigenvalue (RE) condition, which is among the most general assumptions on the matrix, guaranteeing recovery. We prove a reduction principle showing that the RE condition can be guaranteed by checking the restricted isometry on a certain family of low-dimensional subspaces. This principle allows us to establish the RE condition for several broad classes of random matrices with dependent entries, including random matrices with subgaussian rows and non-trivial covariance structure, as well as matrices with independent rows, and uniformly bounded entries.", "pdf_url": "http://proceedings.mlr.press/v23/rudelson12/rudelson12.pdf", "keywords": ["(cid:96)1 minimization", "Sparsity", "Restricted Eigenvalue conditions", "Subgaussian random matrices", "Design matrices with uniformly bounded entries"], "reference": "R. Adamczak, A. E. Litvak, , A. Pajor, and N. Tomczak-Jaegermann. Restricted isometry property of matrices with independent columns and neighborly polytopes by random sampling, 2009. 0904.4723v1.  R. Adamczak, R. Latala, A. E. Litvak, , A. Pajor, and N. Tomczak-Jaegermann. Geometry of log- concave ensembles of random matrices and approximate reconstruction, 2011. 1103.0401v1.  R. G. Baraniuk, M. Davenport, R. A. DeVore, and M. B. Wakin. A simple proof of the restricted isometry property for random matrices. Constructive Approximation, 28(3):253-263, 2008.  P. Bickel, Y. Ritov, and A. Tsybakov. Simultaneous analysis of Lasso and Dantzig selector. The  Annals of Statistics, 37(4):1705-1732, 2009.  E. Cand`es and T. Tao. Decoding by Linear Programming. IEEE Trans. Info. Theory, 51:4203-4215,  2005.  E. Cand`es and T. Tao. Near optimal signal recovery from random projections: Universal encoding  strategies? IEEE Trans. Info. Theory, 52(12):5406-5425, December 2006.  E. Cand`es and T. Tao. The Dantzig selector: statistical estimation when p is much larger than n.  Annals of Statistics, 35(6):2313-2351, 2007.  E. Cand`es, J. Romberg, and T. Tao. Stable signal recovery from incomplete and inaccurate mea- surements. Communications in Pure and Applied Mathematics, 59(8):1207-1223, August 2006.  S. Chen, D. Donoho, and M. Saunders. Atomic decomposition by basis pursuit. SIAM Journal on  Scientific and Statistical Computing, 20:33-61, 1998.  D. Donoho. For most large underdetermined systems of equations, the minimal (cid:96)1-norm solution is also the sparsest solution. Communications in Pure and Applied Mathematics, 59(6):797-829, 2006a.  D. Donoho. Compressed sensing. IEEE Trans. Info. Theory, 52(4):1289-1306, April 2006b.  G. Duncan and R. Pearson. Enhancing access to microdata while protecting confidentiality:  Prospects for the future. Statistical Science, 6(3):219-232, August 1991.  Y. Gordon. Some inequalities for gaussian processes and applications. Israel Journal of Mathemat-  ics, 50(4):265-289, 1985.  M. Ledoux. The concentration of measure phenomenon. Mathematical Surveys and Monographs,  89. American Mathematical Society, 2001.  M. Ledoux and M. Talagrand. Probability in Banach Spaces: Isoperimetry and processes. Springer,  1991.  S. Mendelson, A. Pajor, and N. Tomczak-Jaegermann. Reconstruction and subgaussian operators in asymptotic geometric analysis. Geometric and Functional Analysis, 17(4):1248-1282, 2007.  10.13   ANISOTROPIC RANDOM MEASUREMENTS  References  R. Adamczak, A. E. Litvak, , A. Pajor, and N. Tomczak-Jaegermann. Restricted isometry property of matrices with independent columns and neighborly polytopes by random sampling, 2009. 0904.4723v1.  R. Adamczak, R. Latala, A. E. Litvak, , A. Pajor, and N. Tomczak-Jaegermann. Geometry of log- concave ensembles of random matrices and approximate reconstruction, 2011. 1103.0401v1.  R. G. Baraniuk, M. Davenport, R. A. DeVore, and M. B. Wakin. A simple proof of the restricted isometry property for random matrices. Constructive Approximation, 28(3):253-263, 2008.  P. Bickel, Y. Ritov, and A. Tsybakov. Simultaneous analysis of Lasso and Dantzig selector. The  Annals of Statistics, 37(4):1705-1732, 2009.  E. Cand`es and T. Tao. Decoding by Linear Programming. IEEE Trans. Info. Theory, 51:4203-4215,  2005.  E. Cand`es and T. Tao. Near optimal signal recovery from random projections: Universal encoding  strategies? IEEE Trans. Info. Theory, 52(12):5406-5425, December 2006.  E. Cand`es and T. Tao. The Dantzig selector: statistical estimation when p is much larger than n.  Annals of Statistics, 35(6):2313-2351, 2007.  E. Cand`es, J. Romberg, and T. Tao. Stable signal recovery from incomplete and inaccurate mea- surements. Communications in Pure and Applied Mathematics, 59(8):1207-1223, August 2006.  S. Chen, D. Donoho, and M. Saunders. Atomic decomposition by basis pursuit. SIAM Journal on  Scientific and Statistical Computing, 20:33-61, 1998.  D. Donoho. For most large underdetermined systems of equations, the minimal (cid:96)1-norm solution is also the sparsest solution. Communications in Pure and Applied Mathematics, 59(6):797-829, 2006a.  D. Donoho. Compressed sensing. IEEE Trans. Info. Theory, 52(4):1289-1306, April 2006b.  G. Duncan and R. Pearson. Enhancing access to microdata while protecting confidentiality:  Prospects for the future. Statistical Science, 6(3):219-232, August 1991.  Y. Gordon. Some inequalities for gaussian processes and applications. Israel Journal of Mathemat-  ics, 50(4):265-289, 1985.  M. Ledoux. The concentration of measure phenomenon. Mathematical Surveys and Monographs,  89. American Mathematical Society, 2001.  M. Ledoux and M. Talagrand. Probability in Banach Spaces: Isoperimetry and processes. Springer,  1991.  S. Mendelson, A. Pajor, and N. Tomczak-Jaegermann. Reconstruction and subgaussian operators in asymptotic geometric analysis. Geometric and Functional Analysis, 17(4):1248-1282, 2007.  10.13   RUDELSON ZHOU  S. Mendelson, A. Pajor, and N. Tomczak-Jaegermann. Uniform uncertainty principle for bernoulli  and subgaussian ensembles. Constructive Approximation, 28(3):277-289, 2008.  V. D. Milman and G. Schechtman. Asymptotic Theory of Finite Dimensional Normed Spaces. Lec-  ture Notes in Mathematics 1200. Springer, 1986.  G. Pisier. Remarques sur un r\u00b4esultat non publi\u00b4e de b. Maurey. Seminar on Functional Analysis,  \u00b4Ecole Polytech., Palaiseau, 5, 1981.  G. Raskutti, Martin Wainwright, and Bin Yu. Restricted nullspace and eigenvalue properties for  correlated gaussian designs. Journal of Machine Learning Research, 11:2241-2259, 2010.  M. Rudelson and R. Vershynin. Geometric approach to error correcting codes and reconstruction of  signals. International Mathematical Research Notices, 64:4019-4041, 2005.  M. Rudelson and R. Vershynin. Sparse reconstruction by convex relaxation: Fourier and gaussian measurements. In 40th Annual Conference on Information Sciences and Systems (CISS 2006), pages 207-212, March 2006.  M. Rudelson and R. Vershynin. On sparse reconstruction from fourier and gaussian measurements.  Communications on Pure and Applied Mathematics, 61:1025-1045, 2008.  M. Talagrand. New concentration inequalities in product spaces. Invent. Math., 126:505-563, 1996.  M. Talagrand. The Generic Chaining: Upper and Lower Bounds of Stochastic Processes. Springer,  R. Tibshirani. Regression shrinkage and selection via the Lasso. J. Roy. Statist. Soc. Ser. B, 58(1):  2000.  267-288, 1996.  S. van de Geer and P. Buhlmann. On the conditions used to prove oracle results for the lasso.  Electronic Journal of Statistics, 3:1360-1392, 2009.  R. Vershynin. Approximating the moments of marginals of high dimensional distributions. Annals  of Probability, 39:1591-1606, 2011a.  R. Vershynin. How close is the sample covariance matrix to the actual covariance matrix? Journal  of Theoretical Probability, to appear, 2011b.  S. Zhou. Restricted eigenvalue conditions on subgaussian random matrices, 2009. Unpublished  Manuscript. Available at http://arxiv.org/pdf/0912.4045v2.pdf.  S. Zhou, J. Lafferty, and L. Wasserman. Compressed and privacy sensitive sparse regression. IEEE  Transactions on Information Theory, 55(2):846-866, 2009a.  S. Zhou, S. van de Geer, and P. B\u00a8uhlmann. Adaptive Lasso for high dimensional regression and  gaussian graphical modeling, 2009b. arXiv:0903.2515.  S. Zhou, P. R\u00a8utimann, M. Xu, and P. B\u00a8uhlmann. High-dimensional covariance estimation based on  Gaussian graphical models. Journal of Machine Learning Research, 12:2975-3026, 2011.  10.14   ANISOTROPIC RANDOM MEASUREMENTS  "}, "Toward a Noncommutative Arithmetic-geometric Mean Inequality: Conjectures, Case-studies, and Consequences": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Toward a Noncommutative Arithmetic-geometric Mean Inequality: Conjectures, Case-studies, and Consequences", "abstract": "Randomized algorithms that base iteration-level decisions on samples from some pool are ubiquitous in machine learning and optimization. Examples include stochastic gradient descent and randomized coordinate descent. This paper makes progress at theoretically evaluating the difference in performance between sampling with- and without-replacement in such algorithms. Focusing on least means squares optimization, we formulate a noncommutative arithmetic-geometric mean inequality that would prove that the expected convergence rate of without-replacement sampling is faster than that of with-replacement sampling. We demonstrate that this inequality holds for many classes of random matrices and for some pathological examples as well. We provide a deterministic worst-case bound on the gap between the discrepancy between the two sampling models, and explore some of the impediments to proving this inequality in full generality. We detail the consequences of this inequality for stochastic gradient descent and the randomized Kaczmarz algorithm for solving linear systems.", "pdf_url": "http://proceedings.mlr.press/v23/recht12/recht12.pdf"}, "L1 Covering Numbers for Uniformly Bounded Convex Functions": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "L1 Covering Numbers for Uniformly Bounded Convex Functions", "abstract": "In this paper we study the covering numbers of the space of convex and uniformly bounded functions in multi-dimension. We find optimal upper and lower bounds for the \u03b5-covering number \\emphM(\\emphC([\\empha, b]^\\emphd, \\emphB), \u03b5, \\emphL_1) in terms of the relevant constants, where \\emphd > 1, \\empha < \\emphb \u2208 \\emphR, \\emphB > 0, and \\emphC([\\empha, b]^\\emphd, \\emphB) denotes the set of all convex functions on [\\empha, b]^\\emphd that are uniformly bounded by \\emphB. We summarize previously known results on covering numbers for convex functions and also provide alternate proofs of some known results. Our results have direct implications in the study of rates of convergence of empirical minimization procedures as well as optimal convergence rates in the numerous convexity constrained function estimation problems.", "pdf_url": "http://proceedings.mlr.press/v23/guntuboyina12/guntuboyina12.pdf", "keywords": ["convexity constrained function estimation", "empirical risk minimization", "Hausdorff distance", "Kolmogorov entropy", "L1 metric", "metric entropy", "packing numbers"], "reference": "L. Birg\u00b4e. Approximation dans les espaces metriques et theorie de l\u2019estimation. Zeitschrift f\u00a8ur  Wahrscheinlichkeitstheorie und Verwandte Gebiete, 65:181\u2013237, 1983.  L. Birg\u00b4e and P. Massart. Rates of convergence for minimum contrast estimators. Probability Theory  and Related Fields, 97:113\u2013150, 1993.  E. M. Bronshtein. (cid:15)-entropy of convex sets and functions. Siberian Mathematical Journal, 17:  393\u2013398, 1976.  12.10   GUNTUBOYINA SEN  Remark 6 The explicit packing subset constructed in the above proof consists of functions that can be viewed as perturbations of the quadratic function f0. Previous lower bounds on the covering numbers of convex functions in (Bronshtein, 1976, Proof of Theorem 6) and (Dryanov, 2009, Section 2) (for d = 1) are based on perturbations of a function whose graph is a subset of a sphere; a more complicated convex function than f0. The perturbations of f0 in the above proof can also be used to simplify the lower bound arguments in those papers.  Remark 7 For functions defined on [0, 1]d, the Lp metric, p > 1, is larger than L1. Thus, when a = 0, b = 1, the conclusion of Theorem 5 also holds for the Lp metric with p > 1. The scaling identity (2) then gives the following inequality for arbitrary a < b: There exist positive constants c and (cid:15)0, depending only on the dimension d, such that for every p \u2265 1, B > 0 and b > a, we have  (cid:16)  log M  C([a, b]d, B), (cid:15); Lp  \u2265 c  (cid:17)  (cid:18)  (cid:15) B(b \u2212 a)d/p  (cid:19)\u2212d/2  ,  for (cid:15) \u2264 (cid:15)0B(b \u2212 a)d/p.  4. Concluding remarks  In this paper we have studied the covering numbers of C([a, b]d, B), the class of all uniformly bounded convex functions, defined on the hypercube [a, b]d, under the L1 metric, 1 \u2264 p \u2264 \u221e. Our main result shows that we can forgo the assumption of a uniform Lipschitz norm for the underlying class of convex functions (as was assumed in Bronshtein (1976)) and still show that the logarithm of the (cid:15)-covering number grows at the same order (cid:15)\u2212d/2, under the L1 metric. Specifically, we prove that the logarithm of the (cid:15)-covering number under the L1 metric is bounded from both above and below by a constant multiple of (cid:15)\u2212d/2. Our proof of the upper bound in Theorem 2 is based on Lemma 3 which bounds the L1 distance between two convex functions by a constant multiple of the Hausdorff distance between their epigraphs. Our proof of the lower bound in Theorem 5 is based on an explicit construction of a finite packing subset of the space of uniformly bounded convex functions. In the "}, "Generalization Bounds for Online Learning Algorithms with Pairwise Loss Functions": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Generalization Bounds for Online Learning Algorithms with Pairwise Loss Functions", "abstract": "Efficient online learning with pairwise loss functions is a crucial component in building largescale learning system that maximizes the area under the Receiver Operator Characteristic (ROC) curve. In this paper we investigate the generalization performance of online learning algorithms with pairwise loss functions. We show that the existing proof techniques for generalization bounds of online algorithms with a pointwise loss can not be directly applied to pairwise losses. Using the Hoeffding-Azuma inequality and various proof techniques for the risk bounds in the batch learning, we derive data-dependent bounds for the average risk of the sequence of hypotheses generated by an arbitrary online learner in terms of an easily computable statistic, and show how to extract a low risk hypothesis from the sequence. In addition, we analyze a natural extension of the perceptron algorithm for the bipartite ranking problem providing a bound on the empirical pairwise loss. Combining these results we get a complete risk analysis of the proposed algorithm.", "pdf_url": "http://proceedings.mlr.press/v23/wang12/wang12.pdf", "keywords": ["Generalization bounds", "Pairwise loss functions", "Online learning", "Loss bounds"], "reference": "S. Agarwal and P. Niyogi. Stability and generalization of bipartite ranking algorithms.  In 18th  Annual Conference on Learning Theory, 2005.  S. Agarwal and P. Niyogi. Generalization bounds for ranking algorithms via algorithmic stability.  Journal of Machine Learning Research, 10:441-474, 2009.  13.12   WANG KHARDON PECHYONY JONES  \u03b3 \u2212 yt(cid:104)u, xt(cid:105), which implies yt(cid:104)u, xt(cid:105) (cid:62) \u03b3 \u2212 (cid:96)t.. We therefore have the lower bound  (cid:104)wt+1, u(cid:105) = (cid:104)wt, u(cid:105) + yt(cid:104)xt, u(cid:105)mt (cid:62) (cid:104)wt, u(cid:105) + (\u03b3 \u2212 (cid:96)t)mt  = (cid:104)wt, u(cid:105) + \u03b3mt \u2212 (cid:96)tmt (cid:62) (cid:104)wt, u(cid:105) + \u03b3mt \u2212 (cid:96)t  (\u2235 mt (cid:54) 1)  \u21d2 (cid:104)wn, u(cid:105) (cid:62)  \u03b3mt \u2212  (cid:96)t = \u03b3M \u2212 D1.  n (cid:88)  t=1  n (cid:88)  t=1  (21)  Combing the upper bound R2M with (21), we get (\u03b3M \u2212 D1)2 (cid:54) R2M. Solving the quadratic equation, we obtain the desired bound.  6. Conclusion and Future work  In this paper, we provide generalization bounds for online learners using pairwise loss functions and apply these to analyze the risk of an online Bipartite ranking algorithm. There are several directions for possible future work. From an empirical perspective, although the random Online AUC Maximization (OAM) is simple and easy to implement, it seems that it does not maintain buffers in an optimal way. Intuitively, one might want to store \u201csupport ranking vectors\u201d that help to build the correct ranker instead of using a random buffer. We are currently exploring ideas on building a smart buffer to improve its performance.  From the theoretical point of view, one direction is to improve the current bounds to achieve faster convergence rates. Alternatively, one can analyze Algorithm 5 from a totally different point of view. Under the batch setting, Clemenc\u00b8on et al. (2008) already provide fast convergence rates for the empirical risk minimizer. Since Algorithm 5 is in fact a stochastic gradient descent algo- rithm to minimize the U -statistic, using online convex programming techniques (Zinkevich, 2003; Shalev-Shwartz, 2007), one can show that the regret is small. Combining this with the batch results automatically yields risk bounds for the algorithm. It is interesting to compare this approach to the one proposed in this paper in terms of the risk bounds that can be obtained. However, it is important to note that the approach in this paper is more general in two ways. First we only assume that the loss function is Lipschitz instead of convex. Second, the ensemble of hypotheses can be produced by an arbitrary online learning algorithm, not just stochastic gradient descent.  We would like to thank anonymous reviewers for their constructive comments. YW and DP also thank Nicol`o Cesa-Bianchi for early discussion. YW and RK were partly supported by NSF grant IIS-0803409. Part of this research was done when YW was an intern at Akamai Technologies in 2011.  Acknowledgments  References  S. Agarwal and P. Niyogi. Stability and generalization of bipartite ranking algorithms.  In 18th  Annual Conference on Learning Theory, 2005.  S. Agarwal and P. Niyogi. Generalization bounds for ranking algorithms via algorithmic stability.  Journal of Machine Learning Research, 10:441-474, 2009.  13.12   ONLINE LEARNING WITH PAIRWISE LOSS FUNCTIONS  S. Agarwal, T. Graepel, R. Herbrich, S. Har-Peled, and D. Roth. Generalization bounds for the area  under the ROC curve. Journal of Machine Learning Research, 6:393-425, 2005.  U. Brefeld and T. Scheffer. AUC maximizing support vector learning. In ICML 2005 Workshop on  ROC Analysis in Machine Learning, 2005.  N. Cesa-Bianchi and C. Gentile. Improved risk tail bounds for on-line algorithms. IEEE Transac-  tions on Information Theory, 54(1):386-390, 2008.  N. Cesa-Bianchi, A. Conconi, and C. Gentile. On the generalization ability of on-line learning  algorithms. IEEE Transactions on Information Theory, 50(9):2050-2057, 2004.  S. Clemenc\u00b8on, G. Lugosi, and N. Vayatis. Ranking and empirical minimization of u-statistics.  Annals of Statistics, 36(2):844-874, 2008.  F. Cucker and S. Smale. On the mathematical foundations of learning. Bull. Am. Math. Soc., 39(1):  1-49, 2002.  Press, 2007.  Verlag, 1996.  F. Cucker and D. Zhou. Learning theory: an approximation theory viewpoint. Cambridge University  L. Devroye, L. Gy\u00a8orfi, and G. Lugosi. A probabilistic theory of pattern recognition. Springer  Y. Freund and R. Schapire. Large margin classification using the perceptron algorithm. Machine  Learning, 37:277-296, 1999.  Y. Freund, R. Iyer, R. Schapire, and Y. Singer. An efficient boosting algorithm for combining  preferences. Journal of Machine Learning Research, 4:933-969, 2003.  C. Gentile. The robustness of the p-norm algorithms. Machine Learning, 53(3):265-299, 2003.  T. Joachims. Optimizing search engines using clickthrough data. In Eighth ACM SIGKDD interna-  tional conference on Knowledge discovery and data mining, pages 133-142. ACM, 2002.  S. Kakade and A. Tewari. On the generalization ability of online strongly convex programming  algorithms. Advances in Neural Information Processing Systems, 2009.  M. Kearns, M. Li, L. Pitt, and L. G. Valiant. Recent results on boolean concept learning.  In Proceedings of the Fourth International Workshop on Machine Learning, pages 337-352, 1987.  N. Littlestone. Mistake bounds and logarithmic linear-threshold learning algorithms. PhD thesis,  University of California at Santa Cruz, 1990.  T. Peel, S. Anthoine, L. Ralaivola, et al. Empirical Bernstein inequalities for u-statistics. In Neural  Information Processing Systems (NIPS), 2010.  C. Rudin. The p-norm push: A simple convex ranking algorithm that concentrates at the top of the  list. Journal of Machine Learning Research, 10:2233-2271, 2009.  C. Rudin, C. Cortes, M. Mohri, and R. Schapire. Margin-based ranking meets boosting in the  middle. 18th Annual Conference on Learning Theory, 2005.  13.13   WANG KHARDON PECHYONY JONES  S. Shalev-Shwartz. Online learning: Theory, algorithms, and applications. PhD thesis, Hebrew  University, 2007.  S. Shalev-Shwartz and Y. Singer. A new perspective on an old perceptron algorithm. 18th Anual  Conference on Learning Theory, 2005.  T. Zhang. Data dependent concentration bounds for sequential prediction algorithms. In 18th Annual  Conference on Learning Theory, 2005.  P. Zhao, S. Hoi, R. Jin, and T. Yang. Online AUC Maximization. In 28th international conference  on Machine learning, 2011.  M. Zinkevich. Online Convex Programming and Generalized Infinitesimal Gradient Ascent. In 20th  international conference on Machine learning, 2003.  13.14   ONLINE LEARNING WITH PAIRWISE LOSS FUNCTIONS  "}, "Attribute-Efficient Learning andWeight-Degree Tradeoffs for Polynomial Threshold Functions": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Attribute-Efficient Learning andWeight-Degree Tradeoffs for Polynomial Threshold Functions", "abstract": "We study the challenging problem of learning decision lists attribute-efficiently, giving both positive and negative results. Our main positive result is a new tradeoff between the running time and mistake bound for learning length-\\emphk decision lists over \\emphn Boolean variables. When the allowed running time is relatively high, our new mistake bound improves significantly on the mistake bound of the best previous algorithm of Klivans and Servedio (Klivans and Servedio, 2006). Our main negative result is a new lower bound on the \\emphweight of any degree-\\emphd polynomial threshold function (PTF) that computes a particular decision list over \\emphk variables (the \u201cODD-MAX-BIT\u201d function). The main result of Beigel (Beigel, 1994) is a weight lower bound of 2^\u03a9(\\emphk/\\emphd^2), which was shown to be essentially optimal for \\emphd \u2264 \\emphk^1/3 by Klivans and Servedio. Here we prove a 2^\u03a9(\u221a\\emphk/d)  lower bound, which improves on Beigel\u2019s lower bound for \\emphd > \\emphk^1/3. This lower bound establishes strong limitations on the effectiveness of the Klivans and Servedio approach and suggests that it may be difficult to improve on our positive result. The main tool used in our lower bound is a new variant of Markov\u2019s classical inequality which may be of independent interest; it provides a bound on the derivative of a univariate polynomial in terms of both its degree \\emphand the size of its coefficients.", "pdf_url": "http://proceedings.mlr.press/v23/servedio12/servedio12.pdf", "keywords": ["attribute-efficient learning", "polynomial threshold functions", "decision lists", "Markov\u2019s inequality"], "reference": "339-349, 1994.  Richard Beigel. Perceptrons, PP, and the Polynomial Hierarchy. Computational Complexity, 4:  Avrim Blum. Learning boolean functions in an infinite atribute space (extended abstract). In STOC,  pages 64-72. ACM, 1990.  Avrim Blum and Pat Langley. Selection of relevant features and examples in machine learning.  Artif. Intell., 97(1-2):245-271, 1997.  Avrim Blum, Lisa Hellerstein, and Nick Littlestone. Learning in the presence of finitely or infinitely  many irrelevant attributes. J. Comput. Syst. Sci., 50(1):32-40, 1995.  Peter Borwein and Tam\u00b4as Erd\u00b4elyi. Markov-Bernstein type inequalities under Littlewood-type coef- ficient constraints. Indagationes Mathematicae, 11(2):159 - 172, 2000. ISSN 0019-3577. doi: 10.1016/S0019-3577(00)89074-6.  Harry Buhrman, Nikolai K. Vereshchagin, and Ronald de Wolf. On computation and communi- cation with small bias. In IEEE Conference on Computational Complexity, pages 24-32. IEEE Computer Society, 2007.  Adam R. Klivans and Rocco A. Servedio. Toward attribute efficient learning of decision lists and  parities. Journal of Machine Learning Research, 7:587-602, 2006.  Adam R. Klivans and Alexander A. Sherstov. Lower bounds for agnostic learning via approximate  rank. Computational Complexity, 19(4):581-604, 2010.  Matthias Krause and Pavel Pudl\u00b4ak. On computing boolean functions by sparse real polynomials. In  FOCS, pages 682-691. IEEE Computer Society, 1995.  Matthias Krause and Pavel Pudl\u00b4ak. Computing boolean functions by polynomials and threshold  circuits. Computational Complexity, 7(4):346-370, 1998.  N. Littlestone. From online to batch learning. In Proceedings of the Second Annual Workshop on  Computational Learning Theory, pages 269-284, 1989.  Nick Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algo-  rithm. Machine Learning, 2(4):285-318, 1987.  P. Long and R. Servedio. Attribute-efficient learning of decision lists and linear threshold functions In Proc. 20th Annual Conference on Neural Information  under unconcentrated distributions. Processing Systems (NIPS), 2006.  Ziv Nevo and Ran El-Yaniv. On online learning of decision lists. Journal of Machine Learning  Research, 3:271-301, 2002.  Noam Nisan and Mario Szegedy. On the degree of boolean functions as real polynomials. Compu-  tational Complexity, 4:301-313, 1994.  Alexander A. Sherstov. Halfspace matrices. Computational Complexity, 17(2):149-178, 2008.  14.12   SERVEDIO TAN THALER  References  339-349, 1994.  Richard Beigel. Perceptrons, PP, and the Polynomial Hierarchy. Computational Complexity, 4:  Avrim Blum. Learning boolean functions in an infinite atribute space (extended abstract). In STOC,  pages 64-72. ACM, 1990.  Avrim Blum and Pat Langley. Selection of relevant features and examples in machine learning.  Artif. Intell., 97(1-2):245-271, 1997.  Avrim Blum, Lisa Hellerstein, and Nick Littlestone. Learning in the presence of finitely or infinitely  many irrelevant attributes. J. Comput. Syst. Sci., 50(1):32-40, 1995.  Peter Borwein and Tam\u00b4as Erd\u00b4elyi. Markov-Bernstein type inequalities under Littlewood-type coef- ficient constraints. Indagationes Mathematicae, 11(2):159 - 172, 2000. ISSN 0019-3577. doi: 10.1016/S0019-3577(00)89074-6.  Harry Buhrman, Nikolai K. Vereshchagin, and Ronald de Wolf. On computation and communi- cation with small bias. In IEEE Conference on Computational Complexity, pages 24-32. IEEE Computer Society, 2007.  Adam R. Klivans and Rocco A. Servedio. Toward attribute efficient learning of decision lists and  parities. Journal of Machine Learning Research, 7:587-602, 2006.  Adam R. Klivans and Alexander A. Sherstov. Lower bounds for agnostic learning via approximate  rank. Computational Complexity, 19(4):581-604, 2010.  Matthias Krause and Pavel Pudl\u00b4ak. On computing boolean functions by sparse real polynomials. In  FOCS, pages 682-691. IEEE Computer Society, 1995.  Matthias Krause and Pavel Pudl\u00b4ak. Computing boolean functions by polynomials and threshold  circuits. Computational Complexity, 7(4):346-370, 1998.  N. Littlestone. From online to batch learning. In Proceedings of the Second Annual Workshop on  Computational Learning Theory, pages 269-284, 1989.  Nick Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algo-  rithm. Machine Learning, 2(4):285-318, 1987.  P. Long and R. Servedio. Attribute-efficient learning of decision lists and linear threshold functions In Proc. 20th Annual Conference on Neural Information  under unconcentrated distributions. Processing Systems (NIPS), 2006.  Ziv Nevo and Ran El-Yaniv. On online learning of decision lists. Journal of Machine Learning  Research, 3:271-301, 2002.  Noam Nisan and Mario Szegedy. On the degree of boolean functions as real polynomials. Compu-  tational Complexity, 4:301-313, 1994.  Alexander A. Sherstov. Halfspace matrices. Computational Complexity, 17(2):149-178, 2008.  14.12   ATTRIBUTE-EFFICIENT LEARNING AND WEIGHT-DEGREE TRADEOFFS FOR POLYNOMIAL THRESHOLD FUNCTIONS  Alexander A. Sherstov. Separating ac0 from depth-2 majority circuits. SIAM J. Comput., 38(6):  2113-2129, 2009.  Alexander A. Sherstov. The pattern matrix method. SIAM J. Comput., 40(6):1969-2000, 2011.  Leslie G. Valiant. Projection learning. Machine Learning, 37(2):115-130, 1999.  "}, "Learning Functions of Halfspaces Using Prefix Covers": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Learning Functions of Halfspaces Using Prefix Covers", "abstract": "We present a simple query-algorithm for learning arbitrary functions of k halfspaces under any product distribution on the Boolean hypercube. Our algorithms learn any function of k halfspaces to within accuracy \u03b5 in time \\emphO((nk/\u03b5)^k+1) under any product distribution on 0, 1^\\emphn using read-once branching programs as a hypothesis. This gives the first \\emphpoly(n, 1/\u03b5) algorithm for learning even the intersection of 2 halfspaces under the uniform distribution on 0, 1^\\emphn previously known algorithms had an exponential dependence either on the accuracy parameter \u03b5 or the dimension \\emphn. To prove this result, we identify a new structural property of Boolean functions that yields learnability with queries: that of having a small prefix cover.", "pdf_url": "http://proceedings.mlr.press/v23/gopalan12/gopalan12.pdf", "keywords": ["Boolean functions", "Halfspaces", "Membership queries", "Branching programs"], "reference": "tation, 75(2):87-106, 1987.  D. Angluin. Learning Regular Sets from Queries and Counterexamples. Information and Compu-  D. Barrington. Bounded-width polynomial-size branching programs recognize exactly those lan-  guages in nc1. Journal of Computer and System Sciences, 38(1):150-164, 1989.  E. Baum. On learning a union of halfspaces. Journal of Complexity, 6(1):67-101, 1990.  Amos Beimel, Francesco Bergadano, Nader H. Bshouty, Eyal Kushilevitz, and Stefano Varricchio.  Learning functions represented as multiplicity automata. J. ACM, 47(3):506-530, 2000.  A. Blum and R. Kannan. Learning an intersection of a constant number of halfspaces over a uniform  distribution. J. Comput. Syst. Sci. (JCSS), 54(2):371-380, 1997.  N. Bshouty, C. Tamon, and D. Wilson. On learning width two branching programs. Information  Processing Letters, 65:217-222, 1998.  F. Erg\u00a8un, R. Kumar, and R. Rubinfeld. On learning bounded-width branching programs. In COLT,  pages 361-368, 1995.  P. Gopalan, A. Klivans, and R. Meka. Polynomial-time approximation schemes for knapsack and re- lated counting problems using branching programs. In Electronic Colloquium on Computational Complexity (ECCC), 2011a.  P. Gopalan, A. Klivans, R. Meka, D. Stefankovic, S. Vempala, and E. Vigoda. An FPTAS for  knapsack and related counting problems. In FOCS, pages 817-826, 2011b.  15.9   LEARNING USING PREFIX COVERS  4. Conclusions  Our algorithm for learning functions of halfspaces exploits the connection between halfspaces and ROBPs. It would be interesting if this connection could lead to improved algorithms for agnosti- cally learning halfspaces. In particular, the problem of agnostically learning poly(n)-ROBPs with membership queries is open. A (query) algorithm for this problem will give a (query) algorithm for agnostically learning halfspaces.  The best known algorithm for agnostically learning a halfspace under the uniform distribution on {0, 1}n due to Kalai et al. (2008) runs in time O(n1/\u03b52). Their paper also shows that a poly(n, 1/\u03b5) algorithm for agnostically learning halfspaces from random examples alone will result in a poly(n) time algorithm for the notorious noisy parity problem. This seems to suggest that such an algo- rithm is perhaps unlikely, but it leaves open the possibility of a poly(n, 1/\u03b5) algorithm that uses membership queries. ROBP-based algorithms seem to be the only tool we currently have to exploit membership queries in the context of halfspace learning.  Adam Klivans is supported by an NSF CAREER Award and NSF CCF 0728536.  5. Acknowledgments  References  tation, 75(2):87-106, 1987.  D. Angluin. Learning Regular Sets from Queries and Counterexamples. Information and Compu-  D. Barrington. Bounded-width polynomial-size branching programs recognize exactly those lan-  guages in nc1. Journal of Computer and System Sciences, 38(1):150-164, 1989.  E. Baum. On learning a union of halfspaces. Journal of Complexity, 6(1):67-101, 1990.  Amos Beimel, Francesco Bergadano, Nader H. Bshouty, Eyal Kushilevitz, and Stefano Varricchio.  Learning functions represented as multiplicity automata. J. ACM, 47(3):506-530, 2000.  A. Blum and R. Kannan. Learning an intersection of a constant number of halfspaces over a uniform  distribution. J. Comput. Syst. Sci. (JCSS), 54(2):371-380, 1997.  N. Bshouty, C. Tamon, and D. Wilson. On learning width two branching programs. Information  Processing Letters, 65:217-222, 1998.  F. Erg\u00a8un, R. Kumar, and R. Rubinfeld. On learning bounded-width branching programs. In COLT,  pages 361-368, 1995.  P. Gopalan, A. Klivans, and R. Meka. Polynomial-time approximation schemes for knapsack and re- lated counting problems using branching programs. In Electronic Colloquium on Computational Complexity (ECCC), 2011a.  P. Gopalan, A. Klivans, R. Meka, D. Stefankovic, S. Vempala, and E. Vigoda. An FPTAS for  knapsack and related counting problems. In FOCS, pages 817-826, 2011b.  15.9   GOPALAN KLIVANS MEKA  P. Harsha, A. Klivans, and R. Meka. An invariance principle for polytopes. In STOC, pages 543-  552, 2010.  A. Kalai, A. Klivans, Y. Mansour, and R. Servedio. Agnostically learning halfspaces. SIAM Journal  on Computing, 37(6):1777-1805, 2008.  J. Kamp, A. Rao, S. P. Vadhan, and D. Zuckerman. Deterministic extractors for small-space sources.  In STOC, pages 691-700, 2006.  M. Kearns and L. Valiant. Cryptographic limitations on learning Boolean formulae and finite au-  tomata. Journal of the ACM, 41(1):67-95, 1994.  A. Klivans, R. O\u2019Donnell, and R. Servedio. Learning intersections and thresholds of halfspaces.  Journal of Computer & System Sciences, 68(4):808-840, 2004.  A. Klivans, P. M. Long, and A. Tang. Baum\u2019s algorithm learns intersections of halfspaces with  respect to log-concave distributions. In APPROX-RANDOM, pages 588-600, 2009.  A. R. Klivans, R. O\u2019Donnell, and R. Servedio. Learning geometric concepts via Gaussian surface  area. In FOCS, pages 541-550, 2008.  N. Linial, Y. Mansour, and N. Nisan. Constant depth circuits, Fourier transform and learnability.  Journal of the ACM, 40(3):607-620, 1993.  R. Meka and D. Zuckerman. Pseudorandom generators for polynomial threshold functions.  In  STOC, pages 427-436, 2010.  R. O\u2019Donnell. Noise sensitivity of intersections of halfspaces, Open problem collection (Simons  Symposium). http://analysisofbooelanfunctions.org, 2012.  S. Vempala. A random sampling based algorithm for learning the intersection of halfspaces. In  FOCS, pages 508-513, 1997.  S. Vempala. Learning convex concepts from gaussian distributions with PCA.  In FOCS, pages  S. Vempala. A random-sampling-based algorithm for learning intersections of halfspaces. J. ACM,  124-130, 2010a.  57(6):32, 2010b.  15.10   "}, "Computational Bounds on Statistical Query Learning": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Computational Bounds on Statistical Query Learning", "abstract": "We study the complexity of learning in Kearns\u2019 well-known \\emphstatistical query (SQ) learning model (Kearns, 1993). A number of previous works have addressed the definition and estimation of the information-theoretic bounds on the SQ learning complexity, in other words, bounds on the query complexity. Here we give the first strictly computational upper and lower bounds on the complexity of several types of learning in the SQ model. As it was already observed, the known characterization of distribution-specific SQ learning (Blum, et al. 1994) implies that for weak learning over a fixed distribution, the query complexity and computational complexity are essentially the same. In contrast, we show that for both distribution-specific and distribution-independent (strong) learning there exists a concept class of polynomial query complexity that is not efficiently learnable unless RP = NP. We then prove that our distribution-specific lower bound is essentially tight by showing that for every concept class \\emphC of polynomial query complexity there exists a polynomial time algorithm that given access to random points from any distribution \\emphD and an NP oracle, can SQ learn \\emphC over \\emphD. We also consider a restriction of the SQ model, the correlational statistical query (CSQ) model (Bshouty and Feldman, 2001; Feldman, 2008) of learning which is closely-related to Valiant\u2019s model of evolvability (Valiant, 2007). We show a similar separation result for distribution-independent CSQ learning under a stronger assumption: there exists a concept class of polynomial CSQ query complexity which is not efficiently learnable unless every problem in W[P] has a randomized fixed parameter tractable algorithm.", "pdf_url": "http://proceedings.mlr.press/v23/feldman12a/feldman12a.pdf", "keywords": ["statistical query learning", "computational lower bounds", "evolvability"], "reference": "M. Alekhnovich, M. Braverman, V. Feldman, A. Klivans, and T. Pitassi. The complexity of properly  learning simple classes. Journal of Computer and System Sciences, 74(1):16-34, 2008.  D. Angluin. Queries and concept learning. Machine Learning, 2:319-342, 1988.  J. Aslam and S. Decatur. General bounds on statistical query learning and pac learning with noise  via hypothesis boosting. Information and Computation, 141(2):85-118, 1998.  J. Balc\u00b4azar, J. Castro, D. Guijarro, J. K\u00a8obler, and W. Lindner. A general dimension for query  learning. Journal of Computer and System Sciences, 73(6):924-940, 2007.  N. Bansal, A. Blum, and S. Chawla. Correlation clustering. In Proceedings of FOCS, pages 238-  S. Ben-David, A. Itai, and E. Kushilevitz. Learning by distances. In Proceedings of COLT, pages  247, 2002.  232-245, 1990.  A. Blum, M. Furst, J. Jackson, M. Kearns, Y. Mansour, and S. Rudich. Weakly learning DNF and characterizing statistical query learning using Fourier analysis. In Proceedings of STOC, pages 253-262, 1994.  A. Blum, A. Frieze, R. Kannan, and S. Vempala. A polynomial time algorithm for learning noisy  linear threshold functions. Algorithmica, 22(1/2):35-52, 1997.  A. Blum, A. Kalai, and H. Wasserman. Noise-tolerant learning, the parity problem, and the statisti-  cal query model. Journal of the ACM, 50(4):506-519, 2003.  A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical privacy: the SuLQ framework.  In  Proceedings of PODS, pages 128-138, 2005.  N. Bshouty and V. Feldman. On using extended statistical queries to avoid membership queries.  Journal of Machine Learning Research, 2:359-395, 2002. ISSN 1533-7928.  N. Bshouty, R. Cleve, R. Gavald`a, S. Kannan, and C. Tamon. Oracles and queries that are sufficient  for exact learning. J. Comput. Syst. Sci., 52(3):421-433, 1996.  16.12   FELDMAN KANADE  a string of the form (\u03c6, \u03b6(\u03c6)), it is not possible to verify that \u03b6(\u03c6) is indeed the lexicographically first satisfying assignment to \u03c6 unless P = NP. We note however that even then these classes can be learned with access to an NP-oracle because C1, C2, C3 \u2208 PNP, i.e. with access to an NP-oracle, the lexicographically first satisfying assignments can be constructed (one bit at a time).  Remark 11 Under stronger cryptographic assumptions, we can construct classes C(cid:48) 3 \u2208 P that are also not efficiently learnable in the respective statistical query models. The functions constructed can be of the form (s(z), z), where s(z) is easy to find information and s is a one-way permutation (that is cannot be inverted efficiently). An additional implication of such constructions is average-case computational hardness: learning is hard for most functions in C(cid:48)  2, C(cid:48)  1, C(cid:48)  1/C(cid:48)  2/C(cid:48) 3.  References  M. Alekhnovich, M. Braverman, V. Feldman, A. Klivans, and T. Pitassi. The complexity of properly  learning simple classes. Journal of Computer and System Sciences, 74(1):16-34, 2008.  D. Angluin. Queries and concept learning. Machine Learning, 2:319-342, 1988.  J. Aslam and S. Decatur. General bounds on statistical query learning and pac learning with noise  via hypothesis boosting. Information and Computation, 141(2):85-118, 1998.  J. Balc\u00b4azar, J. Castro, D. Guijarro, J. K\u00a8obler, and W. Lindner. A general dimension for query  learning. Journal of Computer and System Sciences, 73(6):924-940, 2007.  N. Bansal, A. Blum, and S. Chawla. Correlation clustering. In Proceedings of FOCS, pages 238-  S. Ben-David, A. Itai, and E. Kushilevitz. Learning by distances. In Proceedings of COLT, pages  247, 2002.  232-245, 1990.  A. Blum, M. Furst, J. Jackson, M. Kearns, Y. Mansour, and S. Rudich. Weakly learning DNF and characterizing statistical query learning using Fourier analysis. In Proceedings of STOC, pages 253-262, 1994.  A. Blum, A. Frieze, R. Kannan, and S. Vempala. A polynomial time algorithm for learning noisy  linear threshold functions. Algorithmica, 22(1/2):35-52, 1997.  A. Blum, A. Kalai, and H. Wasserman. Noise-tolerant learning, the parity problem, and the statisti-  cal query model. Journal of the ACM, 50(4):506-519, 2003.  A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical privacy: the SuLQ framework.  In  Proceedings of PODS, pages 128-138, 2005.  N. Bshouty and V. Feldman. On using extended statistical queries to avoid membership queries.  Journal of Machine Learning Research, 2:359-395, 2002. ISSN 1533-7928.  N. Bshouty, R. Cleve, R. Gavald`a, S. Kannan, and C. Tamon. Oracles and queries that are sufficient  for exact learning. J. Comput. Syst. Sci., 52(3):421-433, 1996.  16.12   COMPUTATIONAL BOUNDS ON STATISTICAL QUERY LEARNING  T. Bylander. Learning linear threshold functions in the presence of classification noise. In Proceed-  ings of COLT, pages 340-347, 1994.  C. Chu, S. Kim, Y. Lin, Y. Yu, G. Bradski, A. Ng, and K. Olukotun. Map-reduce for machine  learning on multicore. In Proceedings of NIPS, pages 281-288, 2006.  S. Decatur. Statistical queries and faulty pac oracles.  In Proceedings of the Sixth Workshop on  Computational Learning Theory, pages 262-268, 1993.  Rod G. Downey and Michael R. Fellows. Fixed-parameter tractability and completeness i: Basic  results. SIAM J. Comput., 24:873-921, August 1995. ISSN 0097-5397.  J. Dunagan and S. Vempala. A simple polynomial-time rescaling algorithm for solving linear pro-  grams. In Proceedings of STOC, pages 315-320, 2004.  V. Feldman. Evolvability from learning algorithms. In Proceedings of STOC, pages 619-628, 2008.  V. Feldman. Robustness of evolvability. In Proceedings of COLT, pages 277-292, 2009a.  V. Feldman. A complete characterization of statistical query learning with applications to evolv-  ability. In Proceedings of FOCS, pages 375-384, 2009b.  V. Feldman. Distribution-independent evolvability of linear threshold functions. Journal of Machine  Learning Research - COLT Proceedings, 19:253-272, 2011.  V. Feldman, H. Lee, and R. Servedio. Lower bounds and hardness amplification for learning shallow monotone formulas. Journal of Machine Learning Research - COLT Proceedings, 19:273-292, 2011.  A. Gupta, M. Hardt, A. Roth, and J. Ullman. Privately releasing conjunctions and the statistical  query barrier. In STOC, pages 803-812, 2011.  J. Jackson, E. Shamir, and C. Shwartzman. Learning with queries corrupted by classification noise. In Proceedings of the Fifth Israel Symposium on the Theory of Computing Systems, pages 45-53, 1997.  M. Kallweit and H. Simon. A close look to margin complexity and related parameters. Journal of  Machine Learning Research - COLT Proceedings, 19:437-456, 2011.  S. Kasiviswanathan, H. Lee, K. Nissim, S. Raskhodnikova, and A. Smith. What can we learn  privately? In Proceedings of FOCS, pages 531-540, 2008.  M. Kearns and L. Valiant. Cryptographic limitations on learning boolean formulae and finite au-  tomata. Journal of the ACM, 41(1):67-95, 1994.  M. Kearns and U. Vazirani. An introduction to computational learning theory. MIT Press, Cam-  Michael Kearns. Efficient noise-tolerant learning from statistical queries. Journal of the ACM, 45  bridge, MA, 1994.  (6):983-1006, 1998.  16.13   FELDMAN KANADE  M. Kharitonov. Cryptographic lower bounds for learnability of boolean functions on the uniform  distribution. Journal of Computer and System Sciences, 50:600-610, 1995.  A. Klivans and A. Sherstov. Unconditional lower bounds for learning intersections of halfspaces.  Machine Learning, 69(2-3):97-114, 2007.  E. Kushilevitz and Y. Mansour. Learning decision trees using the Fourier spectrum. SIAM Journal  on Computing, 22(6):1331-1348, 1993.  Y. Mansour. Learning boolean functions via the fourier transform. In V. P. Roychodhury, K. Y. Siu, and A. Orlitsky, editors, Theoretical Advances in Neural Computation and Learning, pages 391-424. Kluwer, 1994.  R. O\u2019Donnell. Computational Applications of Noise Sensitivity. PhD thesis, MIT, 2003. URL  citeseer.ist.psu.edu/630676.html.  R. Servedio. Computational sample complexity and attribute-efficient learning. Journal of Com-  puter and System Sciences, 60(1):161-178, 2000.  A. A. Sherstov. Halfspace matrices. In Proceedings of Conference on Computational Complexity,  pages 83-95, 2007.  H. Simon. Spectral norm in learning theory: Some selected topics. In Proceedings of Algorithmic  Learning Theory, pages 13-27, 2006.  H. Simon. A characterization of strong learnability in the statistical query model. In Proceedings  of Symposium on Theoretical Aspects of Computer Science, pages 393-404, 2007.  B. Sz\u00a8or\u00b4enyi. Characterizing statistical query learning:simplified notions and proofs. In Proceedings  of ALT, pages 186-200, 2009.  L. G. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134-1142, 1984.  L. G. Valiant. Evolvability. Journal of the ACM, 56(1):3.1-3.21, 2009. Earlier version in ECCC,  2006.  ences, 70(4):485-509, 2005.  Ke Yang. New lower bounds for statistical query learning. Journal of Computer and System Sci-  16.14   COMPUTATIONAL BOUNDS ON STATISTICAL QUERY LEARNING  "}, "Learning DNF Expressions from Fourier Spectrum": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Learning DNF Expressions from Fourier Spectrum", "abstract": "Since its introduction by Valiant in 1984, PAC learning of DNF expressions remains one of the central problems in learning theory. We consider this problem in the setting where the underlying distribution is uniform, or more generally, a product distribution. Kalai, Samorodnitsky, and Teng (2009b) showed that in this setting a DNF expression can be efficiently approximated from its \u201cheavy\u201d low-degree Fourier coefficients alone. This is in contrast to previous approaches where boosting was used and thus Fourier coefficients of the target function modified by various distributions were needed. This property is crucial for learning of DNF expressions over smoothed product distributions, a learning model introduced by Kalai et al. (2009b) and inspired by the seminal smoothed analysis model of Spielman and Teng (2004). We introduce a new approach to learning (or approximating) a polynomial threshold functions which is based on creating a function with range [-1, 1] that approximately agrees with the unknown function on low-degree Fourier coefficients. We then describe conditions under which this is sufficient for learning polynomial threshold functions. Our approach yields a new, simple algorithm for approximating any polynomial-size DNF expression from its \u201cheavy\u201d low-degree Fourier coefficients alone. This algorithm greatly simplifies the proof of learnability of DNF expressions over smoothed product distributions and is simpler than all previous algorithm for PAC learning of DNF expression using membership queries. We also describe an application of our algorithm to learning monotone DNF expressions over product distributions. Building on the work of Servedio (2004), we give an algorithm that runs in time poly((\\emphs\u22c5 log (\\emphs/\u03b5))^log (\\emphs/\u03b5), \\emphn), where \\emphs is the size of the DNF expression and \u03b5 is the accuracy. This improves on poly((\\emphs\u22c5 log (\\emphns/\u03b5))^log (\\emphs/\u03b5)\u22c5 log(1/\u03b5), \\emphn) bound of Servedio (2004).", "pdf_url": "http://proceedings.mlr.press/v23/feldman12b/feldman12b.pdf", "keywords": ["PAC learning", "polynomial threshold function", "smoothed analysis", "monotone DNF"], "reference": "ing, 19(3):183\u2013208, 1995.  H. Aizenstein and L. Pitt. On the learnability of disjunctive normal form formulas. Machine Learn-  M. Bellare. The spectral norm of \ufb01nite functions. Technical Report TR-495, MIT, 1991.  A. Birkendorf, E. Dichterman, J. Jackson, N. Klasner, and H.-U. Simon. On restricted-focus-of-  attention learnability of boolean functions. Machine Learning, 30(1):89\u2013123, 1998.  A. Blum, M. Furst, J. Jackson, M. Kearns, Y. Mansour, and S. Rudich. Weakly learning DNF and characterizing statistical query learning using Fourier analysis. In Proceedings of STOC, pages 253\u2013262, 1994.  N. Bshouty and V. Feldman. On using extended statistical queries to avoid membership queries.  Journal of Machine Learning Research, 2, 2002.  N. Bshouty and C. Tamon. On the Fourier spectrum of monotone functions. Journal of the ACM,  43(4):747\u2013770, 1996.  N. Bshouty, J. Jackson, and C. Tamon. More ef\ufb01cient PAC-learning of DNF with membership queries under the uniform distribution. Journal of Computer and System Sciences, 68(1):205\u2013 234, 2004.  N. Bshouty, E. Mossel, R. O\u2019Donnell, and R. Servedio. Learning DNF from random walks. Journal  of Computer and System Sciences, 71(3):250\u2013265, 2005.  A. De, I. Diakonikolas, V. Feldman, and R. Servedio. Nearly optimal solutions for the Chow Pa- rameters Problem and low-weight approximation of halfspaces. Manuscript, to appear in STOC 2012, 2012.  17.12   FELDMAN  5. Applications  In "}, "Consistency of Nearest Neighbor Classification under Selective Sampling": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Consistency of Nearest Neighbor Classification under Selective Sampling", "abstract": "This paper studies nearest neighbor classification in a model where unlabeled data points arrive in a stream, and the learner decides, for each one, whether to ask for its label. Are there generic ways to augment or modify any selective sampling strategy so as to ensure the consistency of the resulting nearest neighbor classifier?", "pdf_url": "http://proceedings.mlr.press/v23/dasgupta12/dasgupta12.pdf", "keywords": [], "reference": "Learning, 80(2-3):111-139, 2010.  Theory, 54(5):2339-2353, 2008.  Theory, 13:21-27, 1967.  2011.  S. Dasgupta. Two faces of active learning. Theoretical Computer Science, 412(19):1767-1781,  L. Devroye. On the inequality of Cover and Hart in nearest neighbor discrimination. IEEE Trans-  actions on Pattern Analysis and Machine Intelligence, 3(1):75-78, 1981.  L. Devroye, L. Gyorfi, A. Krzyzak, and G. Lugosi. On the strong universal consistency of nearest  neighbor regression function estimates. Annals of Statistics, 22:1371-1385, 1994.  18.12   DASGUPTA  where the last step follows from the Cauchy-Schwarz inequality.  What this implies is that, after No, the error rate of Tn drops below (cid:15) after about O(k/(cid:15)) unla-  beled points are seen, and during this time, O(k log(1/(cid:15))) type-I queries are made.  How long is the initial discovery period No? It depends on the lengths of the intervals Ii, and  on the constant c in the sampling strategy: taking c < 1 reduces it substantially.  Lemma 15 Let \u2206 = mini  Ii  . Then for any n,  |  |  Pr(No  n)  \u2265  \u2264  (cid:26) k exp( k exp(  \u2212 \u2212  \u2206 ln n) \u2206n1\u2212c)  if c = 1 if 0 < c < 1  Proof Pick any interval Ii. The probability that at time m n, a point falls in this interval and is queried is at least \u2206/mc. Thus the probability that Ii is not yet discovered at time n is at most (cid:81)n m=1 m\u2212c). The lemma then follows by lower-bounding the sum-  \u2206/mc)  \u2206 (cid:80)n  m=1(1  exp(  \u2264  mation in the two regimes of interest, and taking a union bound over all Ii.  \u2212  \u2264  \u2212  Finally, how many queries are made before time No? A quick calculation shows that in the first m time steps, the expected number of type-I queries is O(k log(m/k)), because of the shrinkage rate, while the expected number of type-II queries, because they are infrequent, is O(log m) if c = 1 and O(m1\u2212c) if c < 1.  Acknowledgments  The author is grateful for the support of the National Science Foundation, under grants IIS-0713540 and CNS-0932403, and the National Institutes of Health, under grant U54HL10846.  M.-F. Balcan, S. Hanneke, and J. Wortman. The true sample complexity of active learning. Machine  R. Castro and R. Nowak. Minimax bounds for active learning. IEEE Transactions on Information  T. Cover and P.E. Hart. Nearest neighbor pattern classification. IEEE Transactions on Information  References  Learning, 80(2-3):111-139, 2010.  Theory, 54(5):2339-2353, 2008.  Theory, 13:21-27, 1967.  2011.  S. Dasgupta. Two faces of active learning. Theoretical Computer Science, 412(19):1767-1781,  L. Devroye. On the inequality of Cover and Hart in nearest neighbor discrimination. IEEE Trans-  actions on Pattern Analysis and Machine Intelligence, 3(1):75-78, 1981.  L. Devroye, L. Gyorfi, A. Krzyzak, and G. Lugosi. On the strong universal consistency of nearest  neighbor regression function estimates. Annals of Statistics, 22:1371-1385, 1994.  18.12   SELECTIVE SAMPLING FOR NEAREST NEIGHBOR  Figure 1: xL and xR are the nearest queried neighbors to the left and right of x at time t  1. The next point, Xt, is an arrival. In this figure, it is shown to the left of x, which occurs with probability 1/2.  \u2212  E. Fix and J. Hodges. Discriminatory analysis, nonparametric discrimination. USAF School of Aviation Medicine, Randolph Field, Texas, Project 21-49-004, Report 4, Contract AD41(128)- 31, 1951.  S. Hanneke. Rates of convergence in active learning. Annals of Statistics, 39(1):333-361, 2011.  S. Hanneke. Activized learning: transforming passive to active with improved label complexity. To  appear, Journal of Machine Learning Research, 2012.  S. Kulkarni and S. Posner. Rates of convergence of nearest neighbor estimation under arbitrary  sampling. IEEE Transactions on Information Theory, 41(4):1028-1039, 1995.  C. Stone. Consistent nonparametric regression. Annals of Statistics, 5:595-645, 1977.  D. Williams. Probability with Martingales. Cambridge University Press, 1991.  "}, "Active Learning Using Smooth Relative Regret Approximations with Applications": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Active Learning Using Smooth Relative Regret Approximations with Applications", "abstract": "The disagreement coefficient of Hanneke has become a central concept in proving active learning rates. It has been shown in various ways that a concept class with low complexity together with a bound on the disagreement coefficient at an optimal solution allows active learning rates that are superior to passive learning ones. We present a different tool for pool based active learning which follows from the existence of a certain uniform version of low disagreement coefficient, but is not equivalent to it. In fact, we present two fundamental active learning problems of significant interest for which our approach allows nontrivial active learning bounds. However, any general purpose method relying on the disagreement coefficient bounds only fails to guarantee any useful bounds for these problems. The tool we use is based on the learner\u2019s ability to compute an estimator of the difference between the loss of any hypotheses and some fixed \u201cpivotal\u201d hypothesis to within an absolute error of at most \u03b5 times the \\emphl_1 distance (the disagreement measure) between the two hypotheses. We prove that such an estimator implies the existence of a learning algorithm which, at each iteration, reduces its excess risk to within a constant factor. Each iteration replaces the current pivotal hypothesis with the minimizer of the estimated loss difference function with respect to the previous pivotal hypothesis. The label complexity essentially becomes that of computing this estimator. The two applications of interest are: learning to rank from pairwise preferences, and clustering with side information (a.k.a. semi-supervised clustering). They are both fundamental, and have started receiving more attention from active learning theoreticians and practitioners. Keywords: active learning, learning to rank from pairwise preferences, semi-supervised clustering, clustering with side information, disagreement coefficient, smooth relative regret approximation.", "pdf_url": "http://proceedings.mlr.press/v23/ailon12/ailon12.pdf", "keywords": ["active learning", "learning to rank from pairwise preferences", "semi-supervised clustering", "clustering with side information", "disagreement coefficient", "smooth relative regret approximation"], "reference": "N. Ailon. An active learning algorithm for ranking from pairwise preferences with an almost optimal  query complexity. Journal of Machine Learning Research, 13:137-164, 2012.  N. Ailon, B. Chazelle, S. Comandur, and D. Liu. Estimating the distance to a monotone function.  Random Struct. Algorithms, 31(3):371-383, 2007.  N. Ailon, M. Charikar, and A. Newman. Aggregating inconsistent information: Ranking and clus-  tering. Journal of the ACM, 55(5):23:1-23:27, Oct. 2008.  N. Ailon, R. Begleiter, and E. Ezra. Active learning using smooth relative regret approximations  with applications (full version). In arXiv:1110.2136, 2012.  N. Alon. Ranking tournaments. SIAM Journal on Discrete Mathematics, 20, 2006.  F. R. Bach. Active learning for misspecified generalized linear models. In B. Sch\u00a8olkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, pages 65-72. MIT Press, Cambridge, MA, 2007.  M.-F. Balcan, A. Beygelzimer, and J. Langford. Agnostic active learning. In ICML, pages 65-72,  M.-F. Balcan, A. Z. Broder, and T. Zhang. Margin based active learning. In COLT, pages 35-50,  2006.  2007.  M.-F. Balcan, S. Hanneke, and J. Wortman. The true sample complexity of active learning.  In  COLT, pages 45-56, 2008.  N. Bansal, A. Blum, and S. Chawla. Correlation clustering. Machine Learning, 56:89-113, 2004.  S. Basu. Semi-supervised Clustering: Probabilistic Models, Algorithms and Experiments. PhD  thesis, Department of Computer Sciences, University of Texas at Austin, 2005.  A. Ben-Dor, R. Shamir, and Z. Yakhini. Clustering gene expression patterns. Journal of Computa-  tional Biology, 6(3/4):281-297, 1999.  19.13   ACTIVE LEARNING USING SRRA  work of Eriksson et al. (2011) indicates that incorporating geometric information into our analysis is a fruitful direction to pursue.  Our work made no assumptions on the noise, except maybe for its magnitude. Another promis- ing future research direction would be to incorporate various standard noise assumptions known to improve active learning rates (especially the model of Mammen and Tsybakov, 1999; Tsybakov, 2004) within our setting.  We thank Alekh Agarwal, Miroslav Dudik, Ran El-Yaniv, Sariel Har-Peled, John Langford, Rob Schapire, Masashi Sugiyama, and Yair Weiner for helpful discussions.  Acknowledgments  References  N. Ailon. An active learning algorithm for ranking from pairwise preferences with an almost optimal  query complexity. Journal of Machine Learning Research, 13:137-164, 2012.  N. Ailon, B. Chazelle, S. Comandur, and D. Liu. Estimating the distance to a monotone function.  Random Struct. Algorithms, 31(3):371-383, 2007.  N. Ailon, M. Charikar, and A. Newman. Aggregating inconsistent information: Ranking and clus-  tering. Journal of the ACM, 55(5):23:1-23:27, Oct. 2008.  N. Ailon, R. Begleiter, and E. Ezra. Active learning using smooth relative regret approximations  with applications (full version). In arXiv:1110.2136, 2012.  N. Alon. Ranking tournaments. SIAM Journal on Discrete Mathematics, 20, 2006.  F. R. Bach. Active learning for misspecified generalized linear models. In B. Sch\u00a8olkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, pages 65-72. MIT Press, Cambridge, MA, 2007.  M.-F. Balcan, A. Beygelzimer, and J. Langford. Agnostic active learning. In ICML, pages 65-72,  M.-F. Balcan, A. Z. Broder, and T. Zhang. Margin based active learning. In COLT, pages 35-50,  2006.  2007.  M.-F. Balcan, S. Hanneke, and J. Wortman. The true sample complexity of active learning.  In  COLT, pages 45-56, 2008.  N. Bansal, A. Blum, and S. Chawla. Correlation clustering. Machine Learning, 56:89-113, 2004.  S. Basu. Semi-supervised Clustering: Probabilistic Models, Algorithms and Experiments. PhD  thesis, Department of Computer Sciences, University of Texas at Austin, 2005.  A. Ben-Dor, R. Shamir, and Z. Yakhini. Clustering gene expression patterns. Journal of Computa-  tional Biology, 6(3/4):281-297, 1999.  19.13   AILON BEGLEITER EZRA  A. Beygelzimer, S. Dasgupta, and J. Langford.  Importance weighted active learning.  In ICML,  2009.  In NIPS, 2010.  A. Beygelzimer, D. Hsu, J. Langford, and T. Zhang. Agnostic active learning without constraints.  M. Braverman and E. Mossel. Noisy sorting without resampling. In SODA, pages 268-276, 2008.  R. Castro, R. Willett, and R. Nowak. Faster rates in regression via active learning. In NIPS, 2005.  R. M. Castro and R. D. Nowak. Minimax bounds for active learning. IEEE Transactions on Infor-  mation Theory, 54(5):2339-2353, 2008.  G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear classification and selective sampling under  low noise conditions. In NIPS, pages 249-256, 2008.  G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Learning noisy linear classifiers via adaptive and  selective sampling. Machine Learning, 83(1):71-102, 2011.  N. Cesa-Bianchi, C. Gentile, F. Vitale, and G. Zappella. Active learning on trees and graphs. In  COLT, pages 320-332, 2010.  M. Charikar and A. Wirth. Maximizing quadratic programs: Extending grothendieck\u2019s inequality.  In FOCS, pages 54-60. IEEE Computer Society, 2004.  D. Cohn, R. Caruana, and A. Mccallum. Semi-supervised clustering with user feedback. un- published manuscript, 2000. URL http://www.cs.umass.edu/\u02dcmccallum/papers/ semisup-aaai2000s.ps.  D. Coppersmith, L. K. Fleischer, and A. Rurda. Ordering by weighted number of wins gives a good  ranking for weighted tournaments. ACM Trans. Algorithms, 6:55:1-55:13, July 2010.  S. Dasgupta. Coarse sample complexity bounds for active learning. In NIPS, 2005.  S. Dasgupta and D. Hsu. Hierarchical sampling for active learning. In ICML, pages 208-215, 2008.  S. Dasgupta, D. Hsu, and C. Monteleoni. A general agnostic active learning algorithm. In NIPS,  2007.  M. de Berg, O. Cheong, M. van Kreveld, and M. Overmars. Computational geometry: Algorithms  and applications. Springer-Verlag, Berlin, 3rd edition, 2008.  A. Demiriz, K. Bennett, and M. J. Embrechts. Semi-supervised clustering using genetic algorithms. In In Artificial Neural Networks in Engineering (ANNIE-99, pages 809-814. ASME Press, 1999.  R. El-Yaniv and Y. Wiener. On the foundations of noise-free selective classification. Journal of  Machine Learning Research, 11:1605-1641, 2010.  B. Eriksson, G. Dasarathy, A. Singh, and R. D. Nowak. Active clustering: Robust and efficient hier- archical clustering using adaptively selected similarities. Journal of Machine Learning Research - Proceedings Track, 15:260-268, 2011.  19.14   ACTIVE LEARNING USING SRRA  Y. Freund, S. H. Seung, E. Shamir, and N. Tishby. Selective sampling using the query by committee  algorithm. Machine Learning, 28:133-168, September 1997.  I. Giotis and V. Guruswami. Correlation clustering with a fixed number of clusters. Theory of  Computing, 2(1):249-266, 2006.  S. Halevy and E. Kushilevitz. Distribution-free property-testing. SIAM J. Comput., 37(4):1107-  1138, 2007.  S. Hanneke. A bound on the label complexity of agnostic active learning. In ICML, 2007.  S. Hanneke. Adaptive rates of convergence in active learning. In COLT, 2009.  S. Hanneke. Rates of convergence in active learning. Annals of Statistics, 39(1):333-361, 2011.  S. Hanneke and L. Yang. Negative results for active learning with convex losses. Journal of Machine  Learning Research - Proceedings Track, 9:321-325, 2010.  D. Haussler. Decision theoretic generalizations of the PAC model for neural net and other learning  applications. Information and Control, 100(1):78-150, Sept. 1992.  K. G. Jamieson and R. Nowak. Active ranking using pairwise comparisons. In NIPS 24, pages  2240-2248, 2011.  M. K\u00a8a\u00a8ari\u00a8ainen. Active learning in the non-realizable case. In ALT, pages 63-77, 2006.  C. Kenyon-Mathieu and W. Schudy. How to rank with few errors. In Proceedings of the thirty-ninth  annual ACM symposium on Theory of computing, STOC \u201907, pages 95-103, 2007.  D. Klein, S. D. Kamvar, and C. D. Manning. From instance-level constraints to space-level con- straints: Making the most of prior knowledge in data clustering. In ICML, pages 307-314, 2002.  V. Koltchinskii. Rademacher complexities and bounding the excess risk in active learning. Journal  of Machine Learning Research, 11:2457-2485, 2010.  Y. Li, P. M. Long, and A. Srinivasan.  Improved bounds on the sample complexity of learning.  Journal of Computer and System Sciences, 62:2001, 2000.  E. Mammen and A. B. Tsybakov. Smooth discrimination analysis. Annals of Statistics, 27:1808-  S. Minsker. Plug-in approach to active learning. Journal of Machine Learning Research, 13:67-90,  F. Orabona and N. Cesa-Bianchi. Better algorithms for selective sampling. In ICML, pages 433-  1829, 1999.  2012.  440, 2011.  K. Radinsky and N. Ailon. Ranking from pairs and triplets: information quality, evaluation methods  and query complexity. In WSDM, pages 105-114, 2011.  B. Settles. Active learning literature survey. Technical Report 1648, University of Wisconsin-  Madison, 2009.  19.15   AILON BEGLEITER EZRA  O. Shamir and N. Tishby. Spectral clustering on a budget. Journal of Machine Learning Research  - Proceedings Track, 15:661-669, 2011.  R. Shamir, R. Sharan, and D. Tsur. Cluster graph modification problems. Discrete Applied Math,  144:173-182, nov 2004.  M. Sugiyama. Active learning in approximately linear regression based on conditional expectation  of generalization error. Journal of Machine Learning Research, 7:141-166, 2006.  A. B. Tsybakov. Optimal aggregation of classifiers in statistical learning. Annals of Statistics, 32:  135-166, 2004.  K. Voevodski, M.-F. Balcan, H. R\u00a8oglin, S.-H. Teng, and Y. Xia. Active clustering of biological  sequences. Journal of Machine Learning Research, 13:203-225, 2012.  L. Wang. Smoothness, disagreement coefficient, and the label complexity of agnostic active learn-  ing. Journal of Machine Learning Research, 12:2269-2292, 2011.  E. P. Xing, A. Y. Ng, M. I. Jordan, and S. Russell. Distance metric learning, with application to In Advances in Neural Information Processing Systems 15,  clustering with side-information. pages 505-512. MIT Press, 2002.  L. Yang, S. Hanneke, and J. G. Carbonell. Bayesian active learning using arbitrary binary valued  queries. In ALT, pages 50-58, 2010.  L. Yang, S. Hanneke, and J. G. Carbonell. The sample complexity of self-verifying bayesian active  learning. Journal of Machine Learning Research - Proceedings Track, 15:816-822, 2011.  "}, "Robust Interactive Learning": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Robust Interactive Learning", "abstract": "In this paper we propose and study a generalization of the standard active-learning model where a more general type of queries including class conditional queries and mistake queries are allowed. Such queries have been quite useful in applications, but have been lacking theoretical understanding. In this work, we characterize the power of such queries under several well-known noise models. We give nearly tight upper and lower bounds on the number of queries needed to learn both for the general agnostic setting and for the bounded noise model. We further show that our methods can be made adaptive to the (unknown) noise rate, with only negligible loss in query complexity.", "pdf_url": "http://proceedings.mlr.press/v23/balcan12c/balcan12c.pdf", "keywords": ["Statistical Learning Theory", "Interactive Learning", "Query Complexity", "Active Learning"], "reference": "151-163, 2007.  D. Angluin. Queries and concept learning. Machine Learning, 2:319-342, 1998.  P. Auer and R. Ortner. A new PAC bound for intersection-closed concept classes. Machine Learning, 66:  M. F. Balcan, A. Beygelzimer, and J. Langford. Agnostic active learning. In ICML, 2006.  M.-F. Balcan, A. Broder, and T. Zhang. Margin based active learning. In COLT, 2007.  M.-F. Balcan, S. Hanneke, and J. Wortman. The true sample complexity of active learning. In COLT, 2008.  J. L. Balc\u00b4azar, J. Castro, and D. Guijarro. A general dimension for exact learning. In Proceedings of the 14th  Conference on Learning Theory, 2001.  J. L. Balc\u00b4azar, J. Castro, and D. Guijarro. A new abstract combinatorial dimension for exact learning via  queries. Journal of Computer and System Sciences, 64:2-21, 2002.  S. Ben-David, N. Cesa-Bianchi, D. Haussler, and P. M. Long. Characterizations of Learnability for Classes  of {0, ..., n}-Valued Functions. J. Comput. Syst. Sci., 1995.  A. Beygelzimer, S. Dasgupta, and J. Langford. Importance weighted active learning. In Proceedings of the  26th International Conference on Machine Learning (ICML), 2009.  A. Beygelzimer, D. Hsu, J. Langford, and T. Zhang. Agnostic active learning without constraints. In NIPS,  2010.  R. Castro and R. Nowak. Minimax bounds for active learning. In Proceedings of the 20th Annual Conference  on Computational Learning Theory (COLT), 2007.  E. Chang, S. Tong, K. Goh, and C.-W. Chang. Support vector machine concept-dependent active learning for  image retrieval. IEEE Transactions on Multimedia, 2005.  S. Dasgupta. Coarse sample complexity bounds for active learning. In NIPS, volume 18, 2005.  S. Dasgupta, A. Kalai, and C. Monteleoni. Analysis of perceptron-based active learning. In COLT, 2005.  S. Dasgupta, D.J. Hsu, and C. Monteleoni. A general agnostic active learning algorithm. Advances in Neural  Information Processing Systems, 20, 2007.  S. Doyle, J. Monaco, M. Feldman, J. Tomaszewski, and A. Madabhushi. A class balanced active learning scheme that accounts for minority class problems: Applications to histopathology. In MICCAI Workshop on Optical Tissue Image Analysis in Microsopy, Histopathology and Endoscopy, 2009.  Y. Freund, H.S. Seung, E. Shamir, and N. Tishby. Selective sampling using the query by committee algorithm.  Machine Learning, 28(2-3):133-168, 1997.  E. Gine and V. Koltchinskii. Concentration inequalities and asymptotic results for ratio type empirical pro-  cesses. The Annals of Probability, 34(3):1143-1216, 2006.  S. Hanneke. A bound on the label complexity of agnostic active learning. In ICML, 2007a.  S. Hanneke. Teaching dimension and the complexity of active learning. In Proceedings of the 20th Annual  Conference on Computational Learning Theory (COLT), 2007b.  20.13   ROBUST INTERACTIVE LEARNING  References  151-163, 2007.  D. Angluin. Queries and concept learning. Machine Learning, 2:319-342, 1998.  P. Auer and R. Ortner. A new PAC bound for intersection-closed concept classes. Machine Learning, 66:  M. F. Balcan, A. Beygelzimer, and J. Langford. Agnostic active learning. In ICML, 2006.  M.-F. Balcan, A. Broder, and T. Zhang. Margin based active learning. In COLT, 2007.  M.-F. Balcan, S. Hanneke, and J. Wortman. The true sample complexity of active learning. In COLT, 2008.  J. L. Balc\u00b4azar, J. Castro, and D. Guijarro. A general dimension for exact learning. In Proceedings of the 14th  Conference on Learning Theory, 2001.  J. L. Balc\u00b4azar, J. Castro, and D. Guijarro. A new abstract combinatorial dimension for exact learning via  queries. Journal of Computer and System Sciences, 64:2-21, 2002.  S. Ben-David, N. Cesa-Bianchi, D. Haussler, and P. M. Long. Characterizations of Learnability for Classes  of {0, ..., n}-Valued Functions. J. Comput. Syst. Sci., 1995.  A. Beygelzimer, S. Dasgupta, and J. Langford. Importance weighted active learning. In Proceedings of the  26th International Conference on Machine Learning (ICML), 2009.  A. Beygelzimer, D. Hsu, J. Langford, and T. Zhang. Agnostic active learning without constraints. In NIPS,  2010.  R. Castro and R. Nowak. Minimax bounds for active learning. In Proceedings of the 20th Annual Conference  on Computational Learning Theory (COLT), 2007.  E. Chang, S. Tong, K. Goh, and C.-W. Chang. Support vector machine concept-dependent active learning for  image retrieval. IEEE Transactions on Multimedia, 2005.  S. Dasgupta. Coarse sample complexity bounds for active learning. In NIPS, volume 18, 2005.  S. Dasgupta, A. Kalai, and C. Monteleoni. Analysis of perceptron-based active learning. In COLT, 2005.  S. Dasgupta, D.J. Hsu, and C. Monteleoni. A general agnostic active learning algorithm. Advances in Neural  Information Processing Systems, 20, 2007.  S. Doyle, J. Monaco, M. Feldman, J. Tomaszewski, and A. Madabhushi. A class balanced active learning scheme that accounts for minority class problems: Applications to histopathology. In MICCAI Workshop on Optical Tissue Image Analysis in Microsopy, Histopathology and Endoscopy, 2009.  Y. Freund, H.S. Seung, E. Shamir, and N. Tishby. Selective sampling using the query by committee algorithm.  Machine Learning, 28(2-3):133-168, 1997.  E. Gine and V. Koltchinskii. Concentration inequalities and asymptotic results for ratio type empirical pro-  cesses. The Annals of Probability, 34(3):1143-1216, 2006.  S. Hanneke. A bound on the label complexity of agnostic active learning. In ICML, 2007a.  S. Hanneke. Teaching dimension and the complexity of active learning. In Proceedings of the 20th Annual  Conference on Computational Learning Theory (COLT), 2007b.  20.13   BALCAN HANNEKE  S. Hanneke. Theoretical Foundations of Active Learning. PhD thesis, Machine Learning Department, School  of Computer Science, Carnegie Mellon University, 2009.  S. Hanneke. Rates of convergence in active learning. The Annals of Statistics, 39(1):333-361, 2011.  D. Haussler and P. M. Long. A generalization of sauer\u2019s lemma. Journal of Combinatorial Theory, Series A,  71:219-240, 1995.  T. Heged\u00a8us. Generalized teaching dimension and the query complexity of learning.  In The 8th Annual  Conference on Computational Learning Theory, 1995.  D. Helmbold, R. Sloan, and M. Warmuth. Learning nested differences of intersection-closed concept classes.  Machine Learning, 5:165-196, 1990.  chine Learning, 11:2457-2485, 2010.  chine Learning, 1988.  2006.  V. Koltchinskii. Rademacher complexities and bounding the excess risk in active learning. Journal of Ma-  N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. Ma-  P. Massart and E. Nedelec. Risk bounds for statistical learning. The Annals of Statistics, 34(5):2326-2366,  A. McCallum and K. Nigam. Employing EM in pool-based active learning for text classification. In Pro-  ceedings of the 15th International Conference on Machine Learning (ICML), pages 350-358, 1998.  B. K. Natarajan. On learning sets and functions. Machine Learning, 4:67-97, 1989.  H. Simon. PAC-learning in the presence of one-sided classification noise. In International Symposium on  Artificial Intelligence and Mathematics, 2012.  S. Tong and D. Koller. Support vector machine active learning with applications to text classification. Journal  of Machine Learning Research, 4:45-66, 2001.  A. W. van der Vaart and J. A. Wellner. Weak Convergence and Empirical Processes. Springer, 1996.  V. N. Vapnik. Statistical Learning Theory. John Wiley and Sons, 1998.  L. Wang. Sufficient conditions for agnostic active learnable. In NIPS, 2009.  "}, "Rare Probability Estimation under Regularly Varying Heavy Tails": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Rare Probability Estimation under Regularly Varying Heavy Tails", "abstract": "This paper studies the problem of estimating the probability of symbols that have occurred very rarely, in samples drawn independently from an unknown, possibly infinite, discrete distribution. In particular, we study the multiplicative consistency of estimators, defined as the ratio of the estimate to the true quantity converging to one. We first show that the classical Good-Turing estimator is not universally consistent in this sense, despite enjoying favorable additive properties. We then use Karamata\u2019s theory of regular variation to prove that regularly varying heavy tails are sufficient for consistency. At the core of this result is a multiplicative concentration that we establish both by extending the McAllester-Ortiz additive concentration for the missing mass to all rare probabilities and by exploiting regular variation. We also derive a family of estimators which, in addition to being consistent, address some of the shortcomings of the Good-Turing estimator. For example, they perform smoothing implicitly and have the absolute discounting structure of many heuristic algorithms. This also establishes a discrete parallel to extreme value theory, and many of the techniques therein can be adapted to the framework that we set forth.", "pdf_url": "http://proceedings.mlr.press/v23/ohannessian12/ohannessian12.pdf", "keywords": ["Rare events", "probability estimation", "Good-Turing", "consistency", "concentration"], "reference": "Wiley, 2004.  Cambridge, 1987.  This work was supported in part by NSF grant 6922470 and ONR grant 6918937.  J. Beirlant, Y. Goegebeur, J. Segers, and J. Teugels. Statistics of extremes: theory and applications.  N. H. Bingham, C. M. Goldie, and J. L. Teugels. Regular variation. Cambridge University Press,  S. F. Chen and J. Goodman. An empirical study of smoothing techniques for language modeling. Technical report, Center for Research in Computing Technology, Harvard University, Cambridge, Massachusetts, August 1998. TR-10-98.  H. Chernoff. A measure of the asymptotic efficiency of tests of a hypothesis based on the sum of  observations. Annals of Mathematical Statistics, 23:493-507, 1952.  21.12   OHANNESSIAN DAHLEH  quantity converges to one. We first showed that consistency is not to be taken for granted. In partic- ular, even in well-behaved distributions such as the geometric, the Good-Turing estimator may not be consistent. We then focused our attention to heavy-tailed distributions. To characterize these, we used Karamata\u2019s theory of regular variation Karamata (1933), following closely the early develop- ment of Karlin (1967) in the context of infinite urn schemes. We then used the McAllester and Ortiz (2003) method to extend their additive concentration results to all rare probabilities. Moreover, in the setting of regularly varying heavy-tailed distributions, we showed that one has multiplicative concentration.  We then used the multiplicative concentration to establish strong laws. These allowed us to show that regularly varying heavy tails are sufficient for the consistency of the Good-Turing estima- tor. We used the newly established strong laws, in addition to those established for the occupancy numbers by Karlin, to construct two new families of consistent rare probability estimators. These new estimators address some of the shortcomings of the Good-Turing estimator. In particular, they have built-in smoothing, and their structure follows closely the \u201cabsolute discounting\u201d form used extensively in computational language modeling heuristics, such as in the algorithm proposed by Kneser and Ney (1995) and extended by Chen and Goodman (1998) and others. As such, in addition to a systematic and principled estimation method, our results provide a justification to these algo- rithms and an interpretation of the discount as the regular variation index. Since our estimators can be split into two parts, first index estimation and then probability estimation, they are closely related to tail estimation techniques in extreme value theory (Beirlant et al. (2004)). This correspondence opens the door for modern semiparametric methods to be applied in the present framework.  Heavy tails are a very good model for natural language, as observed early on by Zipf (1949). As such, it is satisfying that we have shown here that this is a property that is sufficient for consis- tently estimating rare probabilities. The core multiplicative concentrations have room to generalize to heavy tails that are potentially not regularly varying, as long as the mean and variance growths balance out to yield a proper unbounded exponent. Naturally, to completely describe when rare probability estimation is possible in a meaningful manner, one ought to establish necessary condi- tions as well.  Acknowledgments  References  Wiley, 2004.  Cambridge, 1987.  This work was supported in part by NSF grant 6922470 and ONR grant 6918937.  J. Beirlant, Y. Goegebeur, J. Segers, and J. Teugels. Statistics of extremes: theory and applications.  N. H. Bingham, C. M. Goldie, and J. L. Teugels. Regular variation. Cambridge University Press,  S. F. Chen and J. Goodman. An empirical study of smoothing techniques for language modeling. Technical report, Center for Research in Computing Technology, Harvard University, Cambridge, Massachusetts, August 1998. TR-10-98.  H. Chernoff. A measure of the asymptotic efficiency of tests of a hypothesis based on the sum of  observations. Annals of Mathematical Statistics, 23:493-507, 1952.  21.12   RARE PROBABILITY ESTIMATION  A. Cohen and H. B. Sackrowitz. Admissibility of estimators of the probability of unobserved out-  comes. Annals of the Institute of Statistical Mathematics, 42(4):623-636, 1990.  D. Dubhasi and D. Ranjan. Balls and bins: A study in negative dependence. Random Structures  and Algorithms, 13(2):99-124, 1998.  W. W. Esty. A normal limit law for a nonparametric estimator of the coverage of a random sample.  The Annals of Statistics, 11(3):905-912, 1983.  W. A. Gale and G. Sampson. Good-Turing frequency estimation without tears. Journal of Quanti-  tative Linguistics, 2(3):217-237, 1995.  A. Gandolfi and C. C. A. Sastri. Nonparametric estimations about species not observed in a random  sample. Milan Journal of Mathematics, 72(1):81-105, 2004.  A. Gnedin, B. Hansen, and J. Pitman. Notes on the occupancy problem with infinitely many boxes:  general asymptotics and power laws. Probability Surveys, 4:146-171, 2007.  I. J. Good. The population frequencies of species and the estimation of population parameters.  Biometrika, 40(16):237-264, 1953.  J. Karamata. Sur un mode de croissance r\u00b4eguli`ere. Th\u00b4eor`emes fondamenteaux. Bulletin de la Soci\u00b4et\u00b4e  Math\u00b4ematique de France, 61:55-62, 1933.  S. Karlin. Central limit theorems for certain infinite urn schemes. Journal of Mathematics and  Mechanics, 17(4):373-401, 1967.  R. Kneser and H. Ney.  Improved smoothing for m-gram language modeling.  In International  Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 679-682, 1995.  D. MacKay and L. Peto. A hierarchical Dirichlet language model. Natural Language Engineering,  1(3):289-307, 1995.  D. McAllester and L. Ortiz. Concentration inequalities for the missing mass and for histogram rule  error. Journal of Machine Learning Research, 4:895-911, 2003.  D. McAllester and R .E. Schapire. On the convergence rate of Good-Turing estimators. In 13th  Annual Conference on Computational Learning Theory, 2000.  A. Orlitsky, N. P. Santhanam, and J. Zhang. Universal compression of memoryless sources over  unknown alphabets. IEEE Trans. on Information Theory, 50(7):1469-1481, 2004.  J. Pitman and M. Yor. The two-parameter Poisson-Dirichlet distribution derived from a stable sub-  ordinator. Annals of Probability, 25:855-900, 1997.  Y. W. Teh. A hierarchical Bayesian language model based on Pitman-Yor processes. In 21st Interna- tional Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics (ACL), pages 985-992, 2006.  G. Zipf. Human behavior and the principle of least effort: An introduction to human ecology.  Hafner, New York, 1949.  21.13   OHANNESSIAN DAHLEH  "}, "Competitive Classification and Closeness Testing": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Competitive Classification and Closeness Testing", "abstract": "We study the problems of \\emphclassification and \\emphcloseness testing. A \\emphclassifier associates a test sequence with the one of two training sequences that was generated by the same distribution. A \\emphcloseness test determines whether two sequences were generated by the same or by different distributions. For both problems all natural algorithms are \\emphsymmetric \u2013 they make the same decision under all symbol relabelings. With no assumptions on the distributions\u2019 support size or relative distance, we construct a classifier and closeness test that require at most O(n^3/2) samples to attain the n-sample accuracy of the best symmetric classifier or closeness test designed with knowledge of the underlying distributions. Both algorithms run in time linear in the number of samples. Conversely we also show that for any classifier or closeness test, there are distributions that require \u03a9(n^7/6) samples to achieve the n-sample accuracy of the best symmetric algorithm that knows the underlying distributions.", "pdf_url": "http://proceedings.mlr.press/v23/acharya12/acharya12.pdf", "keywords": ["Classification", "closeness testing", "competitiveness"], "reference": "probabilities. 2010a.  J. Acharya, H. Das, H. Mohimani, A. Orlitsky, and Shengjun Pan. Exact calculation of pattern In Proceedings of IEEE Symposium on Information Theory, pages 1498 \u20131502,  J. Acharya, H. Das, A. Orlitsky, S. Pan, and N. P. Santhanam. Classi\ufb01cation using pattern probability  estimators. In ISIT, pages 1493\u20131497, 2010b.  J. Acharya, H. Das, A. Jafarpour, A. Orlitsky, and S. Pan. Competitive closeness testing. Journal of  Machine Learning Research - Proceedings Track, 19:47\u201368, 2011.  T. Batu, L. Fortnow, R. Rubinfeld, W. D. Smith, and P. White. Testing that distributions are close.  In Annual IEEE Symposium on Foundations of Computer Science, page 259, 2000.  T. Batu, L. Fortnow, E. Fischer, R. Kumar, R. Rubinfeld, and P. White. Testing random variables for independence and identity. Annual IEEE Symposium on Foundations of Computer Science, page 442, 2001.  22.12   ACHARYA DAS JAFARPOUR ORLITSKY PAN SURESH  Similarly, for the closeness test T we provide additional information about labellings and further restrict that the first sequence is from P and the second sequence is either from P or Q, the error probability of such a closeness test is also lower bounded by the above equation. Hence, the error probability is lower bounded by,  Pe \u2265  1 2  min A1  max P \u2208P  Q(A1) + P (Ac 1)  (a) =  min A1  max \u00b5  Q(A1) +  \u00b5P P (Ac 1)  (cid:32)  (b) \u2265  1 2  max \u00b5  min A1  Q(A1) +  \u00b5P P (Ac 1)  (cid:33) (c) \u2265  (cid:88)  P \u2208P  max \u00b5  (cid:88)  z  (cid:32)  min  Q(z),  \u00b5P P (z)  ,  (cid:88)  P \u2208P  (cid:88)  P \u2208P  (cid:32)  1 2  1 2  (cid:33)  (cid:33)  where \u00b5 is any measure over P. (a) follows from the fact that maximum of a linear optimization problem occurs at the boundary. Min-max is bigger than max-min, hence (b). (c) follows from the error probability of the optimal hypothesis test with known prior.  Since the inequality is true for any measure we choose \u00b5 to be uniformly over the set P. Apply-  ing Lemma 13 to R(Z) and (cid:80)  P \u00b5P P (Z)  Pe \u22654E\u00b5pP (Z)  \u00b5pP (Z) Q(Z)  (cid:32)  exp  \u2212(n(cid:48))2 (cid:88)  \u03b44 i  (a) \u2265  1 4  (cid:18) 1 q2 2i\u22121  +  1 q2 2i  (cid:19)(cid:33)  ,  i  (3)  where \u03b4i = i log n  tn . Proof of (a) is given in "}, "Kernels Based Tests with Non-asymptotic Bootstrap Approaches for Two-sample Problems": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Kernels Based Tests with Non-asymptotic Bootstrap Approaches for Two-sample Problems", "abstract": "Considering either two independent i.i.d. samples, or two independent samples generated from a heteroscedastic regression model, or two independent Poisson processes, we address the question of testing equality of their respective distributions. We first propose single testing procedures based on a general symmetric kernel. The corresponding critical values are chosen from a wild or permutation bootstrap approach, and the obtained tests are exactly (and not just asymptotically) of level. We then introduce an aggregation method, which enables to overcome the difficulty of choosing a kernel and/or the parameters of the kernel. We derive non-asymptotic properties for the aggregated tests, proving that they may be optimal in a classical statistical sense.", "pdf_url": "http://proceedings.mlr.press/v23/fromont12/fromont12.pdf", "keywords": ["Two-sample problem", "kernel methods", "density model", "regression model", "Poisson process", "wild bootstrap", "permutation test", "adaptive tests", "aggregation methods"], "reference": "1992.  2002.  M. A. Arcones and E. Gin\u00b4e. On the bootstrap of U and V statistics. Ann. Statist., 20(2):655-674,  Y. Baraud. Non-asymptotic minimax rates of testing in signal detection. Bernoulli, 8(5):577-606,  Y. Baraud, S. Huet, and B. Laurent. Adaptive tests of linear hypotheses by model selection. Ann.  Statist., 31(1):225-251, 2003.  Math. Statist., 40:1-23, 1968.  P. J. Bickel. A distribution free version of the Smirnov two sample test in the p-variate case. Ann.  J. M. Bovett and J. G. Saw. On comparing two Poisson intensity functions. Comm. Statist. A\u2014  Theory Methods, 9(9):943-948, 1980.  D. J. Daley and D. Vere-Jones. An introduction to the theory of point processes. Vol. II. Probability and its Applications (New York). Springer, New York, second edition, 2008. General theory and structure.  V. H. de la Pe\u02dcna and E. Gin\u00b4e. Decoupling. Probability and its Applications (New York). Springer- Verlag, New York, 1999. From dependence to independence, Randomly stopped processes. U - statistics and processes. Martingales and beyond.  J. V. Deshpande, M. Mukhopadhyay, and U. V. Naik-Nimbalkar. Testing of two sample proportional intensity assumption for non-homogeneous Poisson processes. J. Statist. Plann. Inference, 81(2): 237-251, 1999.  J. Franke and S. Halim. Wild bootstrap tests. Signal proc. mag., IEEE, 24(4):31-37, 2007.  M. Fromont, B. Laurent, and P. Reynaud-Bouret. Adaptive tests of homogeneity for a Poisson  process. Ann. Inst. Henri Poincar\u00b4e Probab. Stat., 47(1):176-213, 2011.  23.12   FROMONT LAURENT LERASLE REYNAUD-BOURET  test is of the same order as the smallest uniform separation rate in the collection of single tests, up to the factor wm. By choosing a collection of kernels based on nested or more complicated linear subspaces generated by subsets of the Haar basis of L2(Z, d\u03bd), when Z = [0, 1] and \u03bd is the Lebesgue measure on [0, 1], as in the paper by Fromont et al. (2011), this can be used to prove that our test is adaptive in the minimax sense over classes of alternatives (s1, s2) such that (s1 \u2212 s2) belongs to Besov or weak Besov bodies with various parameters (see Fromont et al. (2011) for more details).  Acknowledgments  The authors acknowledge the support of the French Agence Nationale de la Recherche (ANR), under grant ATLAS (JCJC06-137446) \u201dFrom Applications to Theory in Learning and Adaptive Statistics\u201d and under grant Calibration (ANR-2011-BS01-010-02).  References  1992.  2002.  M. A. Arcones and E. Gin\u00b4e. On the bootstrap of U and V statistics. Ann. Statist., 20(2):655-674,  Y. Baraud. Non-asymptotic minimax rates of testing in signal detection. Bernoulli, 8(5):577-606,  Y. Baraud, S. Huet, and B. Laurent. Adaptive tests of linear hypotheses by model selection. Ann.  Statist., 31(1):225-251, 2003.  Math. Statist., 40:1-23, 1968.  P. J. Bickel. A distribution free version of the Smirnov two sample test in the p-variate case. Ann.  J. M. Bovett and J. G. Saw. On comparing two Poisson intensity functions. Comm. Statist. A\u2014  Theory Methods, 9(9):943-948, 1980.  D. J. Daley and D. Vere-Jones. An introduction to the theory of point processes. Vol. II. Probability and its Applications (New York). Springer, New York, second edition, 2008. General theory and structure.  V. H. de la Pe\u02dcna and E. Gin\u00b4e. Decoupling. Probability and its Applications (New York). Springer- Verlag, New York, 1999. From dependence to independence, Randomly stopped processes. U - statistics and processes. Martingales and beyond.  J. V. Deshpande, M. Mukhopadhyay, and U. V. Naik-Nimbalkar. Testing of two sample proportional intensity assumption for non-homogeneous Poisson processes. J. Statist. Plann. Inference, 81(2): 237-251, 1999.  J. Franke and S. Halim. Wild bootstrap tests. Signal proc. mag., IEEE, 24(4):31-37, 2007.  M. Fromont, B. Laurent, and P. Reynaud-Bouret. Adaptive tests of homogeneity for a Poisson  process. Ann. Inst. Henri Poincar\u00b4e Probab. Stat., 47(1):176-213, 2011.  23.12   KERNELS BASED TESTS  K. Fukumizu, B. Sriperumbudur, A. Gretton, and B. Sch\u00a8olkopf. Characteristic kernels on groups and semigroups. Advances in Neural Information Processing Systems 21, (NIPS 2008), pages 473-480, 2009.  A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Sch\u00a8olkopf, and A. Smola. A kernel method for the  two-sample problem. J. Mach. Learn. Res., 1:1-10, 2008.  A. Gretton, K. Fukumizu, Z. Harchaoui, and B. K. Sriperumbudur. A fast, consistent kernel two- In Advances in Neural Information Processing Systems 22, (NIPS 2009), pages  sample test. 673-681, 2010.  P. Hall and J. D. Hart. Bootstrap test for difference between means in nonparametric regression. J.  Amer. Statist. Assoc., 85(412):1039-1049, 1990.  E. King, J. D. Hart, and T. E. Wehrly. Testing the equality of two regression curves using linear  smoothers. Statist. Probab. Lett., 12(3):239-247, 1991.  Q. Li. Nonparametric testing the similarity of two unknown density functions: local power and  bootstrap analysis. J. Nonparametr. Statist., 11(1-3):189-213, 1999.  E. Mammen. Bootstrap, wild bootstrap, and asymptotic normality. Probab. Theory Related Fields,  93(4):439-455, 1992.  B. Sch\u00a8olkopf and A. J. Smola. Learning with kernels. Cambridge (Mass.) : MIT Press, 2002.  A. B. Tsybakov. Introduction to nonparametric estimation. Springer Series in Statistics. Springer, New York, 2009. Revised and extended from the 2004 French original, Translated by Vladimir Zaiats.  "}, "Differentially Private Online Learning": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Differentially Private Online Learning", "abstract": "In this paper, we consider the problem of preserving privacy in the context of online learning. Online learning involves learning from data in real-time, due to which the learned model as well as its predictions are continuously changing. This makes preserving privacy of each data point significantly more challenging as its effect on the learned model can be easily tracked by observing changes in the subsequent predictions. Furthermore, with more and more online systems (e.g. search engines like Bing, Google etc.) trying to learn their customers\u2019 behavior by leveraging their access to sensitive customer data (through cookies etc.), the problem of privacy preserving online learning has become critical. We study the problem in the framework of online convex programming (OCP) \u2013 a popular online learning setting with several theoretical and practical implications \u2013 while using differential privacy as the formal measure of privacy. For this problem, we provide a generic framework that can be used to convert any given OCP algorithm into a private OCP algorithm with provable privacy as well as regret guarantees (utility), provided that the given OCP algorithm satisfies the following two criteria: 1) linearly decreasing sensitivity, i.e., the effect of the new data points on the learned model decreases linearly, 2) sub-linear regret. We then illustrate our approach by converting two popular OCP algorithms into corresponding differentially private algorithms while guaranteeing \\emph\u00d5(\u221aT)  regret for strongly convex functions. Next, we consider the practically important class of online linear regression problems, for which we generalize the approach by Dwork et al. (2010a) to provide a differentially private algorithm with just poly-log regret. Finally, we show that our online learning framework can be used to provide differentially private algorithms for the offline learning problem as well. For the offline learning problem, our approach guarantees \\emphbetter error bounds and is more practical than the existing state-of-the-art methods (Chaudhuri et al., 2011; Rubinstein et al., 2009).", "pdf_url": "http://proceedings.mlr.press/v23/jain12/jain12.pdf", "keywords": [], "reference": "Avrim Blum, Katrina Ligett, and Aaron Roth. A learning theory approach to non-interactive  database privacy. In STOC, 2008.  Kamalika Chaudhuri and Daniel Hsu. Sample complexity bounds for differentially private learning.  JMLR, 19, 2011.  risk minimization. JMLR, 2011.  Kamalika Chaudhuri, Claire Monteleoni, and Anand D. Sarwate. Differentially private empirical  Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. Online  passive-aggressive algorithms. JMLR, 2006.  Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In STOC, 2009.  Cynthia Dwork, Krishnaram Kenthapadi, Frank Mcsherry, Ilya Mironov, and Moni Naor. Our data,  ourselves: Privacy via distributed noise generation. In EUROCRYPT, 2006a.  Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity  in private data analysis. In TCC, 2006b.  Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N. Rothblum. Differential privacy under  continual observation. In STOC, 2010a.  Cynthia Dwork, Guy N. Rothblum, and Salil P. Vadhan. Boosting and differential privacy. In FOCS,  A. Frank and A. Asuncion. UCI machine learning repository, 2010. URL http://archive.  Anupam Gupta, Aaron Roth, and Jonathan Ullman. Iterative constructions and private data release.  Moritz Hardt and Guy N. Rothblum. A multiplicative weights mechanism for privacy-preserving  2010b.  ics.uci.edu/ml.  CoRR, abs/1107.3731, 2011.  data analysis. In FOCS, 2010.  Moritz Hardt, Katrina Ligett, and Frank McSherry. A simple and practical algorithm for differen-  tially private data release. CoRR, abs/1012.4763, 2010.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex  optimization. Machine Learning, 69, 2007.  Sham Kakade and Shai Shalev-Shwartz. Mind the duality gap: Logarithmic regret algorithms for  online optimization. In NIPS, 2008.  Sham M. Kakade and Ambuj Tewari. On the generalization ability of online strongly convex pro-  gramming algorithms. In NIPS, 2008.  Adam Kalai and Santosh Vempala. Efficient algorithms for online decision problems. Journal of  Computer System and Science, 71, 2005.  24.13   DIFFERENTIALLY PRIVATE ONLINE LEARNING  References  Avrim Blum, Katrina Ligett, and Aaron Roth. A learning theory approach to non-interactive  database privacy. In STOC, 2008.  Kamalika Chaudhuri and Daniel Hsu. Sample complexity bounds for differentially private learning.  JMLR, 19, 2011.  risk minimization. JMLR, 2011.  Kamalika Chaudhuri, Claire Monteleoni, and Anand D. Sarwate. Differentially private empirical  Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. Online  passive-aggressive algorithms. JMLR, 2006.  Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In STOC, 2009.  Cynthia Dwork, Krishnaram Kenthapadi, Frank Mcsherry, Ilya Mironov, and Moni Naor. Our data,  ourselves: Privacy via distributed noise generation. In EUROCRYPT, 2006a.  Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity  in private data analysis. In TCC, 2006b.  Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N. Rothblum. Differential privacy under  continual observation. In STOC, 2010a.  Cynthia Dwork, Guy N. Rothblum, and Salil P. Vadhan. Boosting and differential privacy. In FOCS,  A. Frank and A. Asuncion. UCI machine learning repository, 2010. URL http://archive.  Anupam Gupta, Aaron Roth, and Jonathan Ullman. Iterative constructions and private data release.  Moritz Hardt and Guy N. Rothblum. A multiplicative weights mechanism for privacy-preserving  2010b.  ics.uci.edu/ml.  CoRR, abs/1107.3731, 2011.  data analysis. In FOCS, 2010.  Moritz Hardt, Katrina Ligett, and Frank McSherry. A simple and practical algorithm for differen-  tially private data release. CoRR, abs/1012.4763, 2010.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex  optimization. Machine Learning, 69, 2007.  Sham Kakade and Shai Shalev-Shwartz. Mind the duality gap: Logarithmic regret algorithms for  online optimization. In NIPS, 2008.  Sham M. Kakade and Ambuj Tewari. On the generalization ability of online strongly convex pro-  gramming algorithms. In NIPS, 2008.  Adam Kalai and Santosh Vempala. Efficient algorithms for online decision problems. Journal of  Computer System and Science, 71, 2005.  24.13   JAIN KOTHARI THAKURTA  Jyrki Kivinen and Manfred K. Warmuth. Exponentiated gradient versus gradient descent for linear  predictors. Information and Computation, 132, 1995.  Brian Kulis and Peter L. Bartlett. Implicit online learning. In ICML, 2010.  Shantanu Rane Manas Pathak and Bhiksha Raj. Multiparty differential privacy via aggregation of  locally trained classifiers. In NIPS, 2010.  Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In FOCS, 2007.  Arvind Narayanan and Vitaly Shmatikov. Robust de-anonymization of large sparse datasets.  In  IEEE Symposium on Security and Privacy (ISSP), 2008.  Tomaso Poggio, Stephen Voinea, and Lorenzo Rosasco. Online learning, stability, and stochastic  gradient descent. CoRR, abs/1105.4701, 2011.  St\u00b4ephane Ross and J. Andrew Bagnell.  Stability conditions for online learnability. CoRR,  abs/1108.3154, 2011.  Benjamin I. P. Rubinstein, Peter L. Bartlett, Ling Huang, and Nina Taft. Learning in a large function  space: Privacy-preserving mechanisms for SVM learning. CoRR, abs/0911.5708, 2009.  Oliver Williams and Frank McSherry. Probabilistic inference and differential privacy.  In NIPS,  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In  2010.  ICML, 2003.  24.14   DIFFERENTIALLY PRIVATE ONLINE LEARNING  "}, "Private Convex Empirical Risk Minimization and High-dimensional Regression": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Private Convex Empirical Risk Minimization and High-dimensional Regression", "abstract": "We consider \\emphdifferentially private algorithms for convex empirical risk minimization (ERM). Differential privacy (Dwork et al., 2006b) is a recently introduced notion of privacy which guarantees that an algorithm\u2019s output does not depend on the data of any individual in the dataset. This is crucial in fields that handle sensitive data, such as genomics, collaborative filtering, and economics. Our motivation is the design of private algorithms for sparse learning problems, in which one aims to find solutions (e.g., regression parameters) with few non-zero coefficients. To this end: (a) We significantly extend the analysis of the \u201cobjective perturbation\u201d algorithm of Chaudhuri et al. (2011) for convex ERM problems. We show that their method can be modified to use less noise (be more accurate), and to apply to problems with hard constraints and non-differentiable regularizers. We also give a tighter, data-dependent analysis of the additional error introduced by their method. A key tool in our analysis is a new nontrivial limit theorem for differential privacy which is of independent interest: if a sequence of differentially private algorithms converges, in a \\emphweak sense, then the limit algorithm is also differentially private. In particular, our methods give the best known algorithms for differentially private linear regression. These methods work in settings where the number of parameters p is less than the number of samples n. (b) We give the first two private algorithms for \\emphsparse regression problems in high-dimensional settings, where p is much larger than n. We analyze their performance for linear regression: under standard assumptions on the data, our algorithms have vanishing empirical risk for n = poly(s, \\log p) when there exists a good regression vector with s nonzero coefficients. Our algorithms demonstrate that randomized algorithms for sparse regression problems can be both stable and accurate - a combination which is impossible for deterministic algorithms.", "pdf_url": "http://proceedings.mlr.press/v23/kifer12/kifer12.pdf", "keywords": [], "reference": "Raghav Bhaskar, Srivatsan Laxman, Adam Smith, and Abhradeep Thakurta. Discovering frequent  patterns in sensitive data. In KDD, 2010.  Patrick Billingsley. Probability and Measure. John Wiley and Sons, New York, NY, USA, 1995.  ISBN 9780471007104.  Kamalika Chaudhuri, Claire Monteleoni, and Anand D. Sarwate. Differentially private empirical  risk minimization. JMLR, 12:1069-1109, 2011.  Sanjoy Dasgupta and Leonard Schulman. A probabilistic analysis of em for mixtures of separated,  spherical gaussians. J. Mach. Learn. Res., 8:203-226, December 2007.  Cynthia Dwork. Differential privacy. In ICALP, 2006.  Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In STOC, 2009.  Cynthia Dwork and Moni Naor. On the difficulties of disclosure prevention, or the case for differ-  ential privacy. Journal of Privacy and Confidentiality, 2(1), 2010.  Cynthia Dwork, Krishnaram Kenthapadi, Frank Mcsherry, Ilya Mironov, and Moni Naor. Our data,  ourselves: Privacy via distributed noise generation. In EUROCRYPT, 2006a.  Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity  in private data analysis. In TCC, 2006b.  Cynthia Dwork, Parikshit Gopalan, Huijia Lin, Toniann Pitassi, Guy Rothblum, Adam Smith, and Sergey Yekhanin. An analysis of the Chaudhuri and Monteleoni algorithm. Innovations in Com- puter Science (poster), 2009. Available as Dwork et al. (2012).  Cynthia Dwork, Parikshit Gopalan, Huijia Lin, Toniann Pitassi, Guy Rothblum, Adam Smith, and Sergey Yekhanin. An analysis of the Chaudhuri and Monteleoni algorithm. Technical Re- port NAS-TR-0156-2012, Network and Security Research Center, Pennsylvania State University, USA, February 2012.  Srivatsava Ranjit Ganta, Shiva Prasad Kasiviswanathan, and Adam Smith. Composition attacks and  auxiliary information in data privacy. In KDD, 2008.  Daniel Kifer and Ashwin Machanavajjhala. No free lunch in data privacy. In SIGMOD, 2011.  Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In FOCS, 2007.  Sahand Negahban, Pradeep Ravikumar, Martin J. Wainwright, and Bin Yu. A unified frame- work for high-dimensional analysis of $m$-estimators with decomposable regularizers. CoRR, abs/1010.2731, 2010.  Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private  data analysis. In STOC, 2007.  Jorge Nocedal and Stephen J. Wright. Numerical Optimization. Springer, 2000. ISBN 0387987932.  25.13   PRIVATE CONVEX ERM AND HIGH-DIMENSIONAL REGRESSION  References  Raghav Bhaskar, Srivatsan Laxman, Adam Smith, and Abhradeep Thakurta. Discovering frequent  patterns in sensitive data. In KDD, 2010.  Patrick Billingsley. Probability and Measure. John Wiley and Sons, New York, NY, USA, 1995.  ISBN 9780471007104.  Kamalika Chaudhuri, Claire Monteleoni, and Anand D. Sarwate. Differentially private empirical  risk minimization. JMLR, 12:1069-1109, 2011.  Sanjoy Dasgupta and Leonard Schulman. A probabilistic analysis of em for mixtures of separated,  spherical gaussians. J. Mach. Learn. Res., 8:203-226, December 2007.  Cynthia Dwork. Differential privacy. In ICALP, 2006.  Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In STOC, 2009.  Cynthia Dwork and Moni Naor. On the difficulties of disclosure prevention, or the case for differ-  ential privacy. Journal of Privacy and Confidentiality, 2(1), 2010.  Cynthia Dwork, Krishnaram Kenthapadi, Frank Mcsherry, Ilya Mironov, and Moni Naor. Our data,  ourselves: Privacy via distributed noise generation. In EUROCRYPT, 2006a.  Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity  in private data analysis. In TCC, 2006b.  Cynthia Dwork, Parikshit Gopalan, Huijia Lin, Toniann Pitassi, Guy Rothblum, Adam Smith, and Sergey Yekhanin. An analysis of the Chaudhuri and Monteleoni algorithm. Innovations in Com- puter Science (poster), 2009. Available as Dwork et al. (2012).  Cynthia Dwork, Parikshit Gopalan, Huijia Lin, Toniann Pitassi, Guy Rothblum, Adam Smith, and Sergey Yekhanin. An analysis of the Chaudhuri and Monteleoni algorithm. Technical Re- port NAS-TR-0156-2012, Network and Security Research Center, Pennsylvania State University, USA, February 2012.  Srivatsava Ranjit Ganta, Shiva Prasad Kasiviswanathan, and Adam Smith. Composition attacks and  auxiliary information in data privacy. In KDD, 2008.  Daniel Kifer and Ashwin Machanavajjhala. No free lunch in data privacy. In SIGMOD, 2011.  Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In FOCS, 2007.  Sahand Negahban, Pradeep Ravikumar, Martin J. Wainwright, and Bin Yu. A unified frame- work for high-dimensional analysis of $m$-estimators with decomposable regularizers. CoRR, abs/1010.2731, 2010.  Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private  data analysis. In STOC, 2007.  Jorge Nocedal and Stephen J. Wright. Numerical Optimization. Springer, 2000. ISBN 0387987932.  25.13   KIFER SMITH THAKURTA  Sofya Raskhodnikova and Adam Smith. Cse 598a, spring 2010: Algorithmic challenges in data  privacy. www.cse.psu.edu/\u02dcasmith/privacy598/, 2010.  Aaron Roth. Cis 800/002, fall 2011: The algorithmic foundations of data privacy. http://www.  cis.upenn.edu/\u02dcaaroth/courses/privacyF11.html, 2011.  Benjamin I. P. Rubinstein, Peter L. Bartlett, Ling Huang, and Nina Taft. Learning in a large function  space: Privacy-preserving mechanisms for svm learning. CoRR, abs/0911.5708, 2009.  Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan. Stochastic Convex  Optimization. In COLT, 2009.  Adam Smith. Privacy-preserving statistical estimation with optimal convergence rates. In STOC,  2011.  David Wipf and Bhaskar Rao. L 0-norm minimization for basis selection. In NIPS, 2005.  A. H. Zemanian. Distribution theory and transform analysis: an introduction to generalized func-  tions, with applications. Dover Publications, Inc., New York, NY, USA, 1987.  "}, "Distributed Learning, Communication Complexity and Privacy": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Distributed Learning, Communication Complexity and Privacy", "abstract": "We consider the problem of PAC-learning from distributed data and analyze fundamental communication complexity questions involved. We provide general upper and lower bounds on the amount of communication needed to learn well, showing that in addition to VC-dimension and covering number, quantities such as the teaching-dimension and mistake-bound of a class play an important role. We also present tight results for a number of common concept classes including conjunctions, parity functions, and decision lists. For linear separators, we show that for non-concentrated distributions, we can use a version of the Perceptron algorithm to learn with much less communication than the number of updates given by the usual margin bound. We also show how boosting can be performed in a generic manner in the distributed setting to achieve communication with only logarithmic dependence on 1/\u03b5 for any concept class, and demonstrate how recent work on agnostic learning from class-conditional queries can be used to achieve low communication in agnostic settings as well. We additionally present an analysis of privacy, considering both differential privacy and a notion of distributional privacy that is especially appealing in this context.", "pdf_url": "http://proceedings.mlr.press/v23/balcan12a/balcan12a.pdf", "keywords": ["Distributed Learning", "Communication Complexity", "Privacy"], "reference": "M.-F. Balcan and S. Hanneke. Robust interactive learning. In Proc. 25th Annual Conference on  Learning Theory (COLT), 2012.  A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical privacy: the SuLQ framework. In Proc.  24th ACM Symposium on Principles of Database Systems (PODS), pages 128-138, 2005.  A. Blum, K. Ligett, and A. Roth. A learning theory approach to non-interactive database privacy.  In Proc. 40th Annual ACM Symp. Theory of Computing, pages 609-618, 2008.  N. H. Bshouty. Exact learning of formulas in parallel. Machine Learning, 26(1):25-41, 1997.  M. Collins, R. E. Schapire, and Y. Singer. Logistic regression, adaboost and bregman distances.  Machine Learning, 48(1-3):253-285, 2002.  H. Daume III, J. Phillips, A. Saha, and S. Venkatasubramanian. Protocols for learning classifiers on distributed data. In International Conference on Artificial Intelligence and Statistics (AIStats), 2012a.  H. Daume III, J. Phillips, A. Saha, and S. Venkatasubramanian. Efficient protocols for distributed  classification and optimization. CoRR, abs/1204.3523, 2012b.  O. Dekel, R. Gilad-Bachrach, O. Shamir, and L. Xiao. Optimal distributed online prediction. In  Proceedings of the 28th International Conference on Machine Learning, 2011.  C. Dwork. Differential privacy. In ICALP (2), pages 1-12, 2006.  C. Dwork. Differential privacy: A survey of results. In TAMC, pages 1-19, 2008.  C. Dwork. The differential privacy frontier (extended abstract). In TCC, pages 496-502, 2009.  C. Dwork and K. Nissim. Privacy-preserving datamining on vertically partitioned databases. In Proceedings of CRYPTO, Lecture Notes in Computer Science, pages 528-544. Springer, 2004.  C. Dwork, G. N. Rothblum, and S. P. Vadhan. Boosting and differential privacy. In FOCS, pages  51-60, 2010.  Y. Freund. Boosting a weak learning algorithm by majority. In COLT, pages 202-216, 1990.  Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an appli-  cation to boosting. J. Comput. Syst. Sci., 55(1):119-139, 1997.  S. A. Goldman and M. J. Kearns. On the complexity of teaching. In Proceedings of COLT \u201991,  pages 303-314. Morgan Kaufmann, 1991.  M. Herlihy and N. Shavit. The art of multiprocessor programming. Morgan Kaufmann, 2008.  J. J\u00b4aJ\u00b4a and V. K. Prasanna. Information transfer in distributed computing with applications to vlsi.  J. ACM, 31(1):150-162, 1984.  26.13   DISTRIBUTED PAC LEARNING  References  M.-F. Balcan and S. Hanneke. Robust interactive learning. In Proc. 25th Annual Conference on  Learning Theory (COLT), 2012.  A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical privacy: the SuLQ framework. In Proc.  24th ACM Symposium on Principles of Database Systems (PODS), pages 128-138, 2005.  A. Blum, K. Ligett, and A. Roth. A learning theory approach to non-interactive database privacy.  In Proc. 40th Annual ACM Symp. Theory of Computing, pages 609-618, 2008.  N. H. Bshouty. Exact learning of formulas in parallel. Machine Learning, 26(1):25-41, 1997.  M. Collins, R. E. Schapire, and Y. Singer. Logistic regression, adaboost and bregman distances.  Machine Learning, 48(1-3):253-285, 2002.  H. Daume III, J. Phillips, A. Saha, and S. Venkatasubramanian. Protocols for learning classifiers on distributed data. In International Conference on Artificial Intelligence and Statistics (AIStats), 2012a.  H. Daume III, J. Phillips, A. Saha, and S. Venkatasubramanian. Efficient protocols for distributed  classification and optimization. CoRR, abs/1204.3523, 2012b.  O. Dekel, R. Gilad-Bachrach, O. Shamir, and L. Xiao. Optimal distributed online prediction. In  Proceedings of the 28th International Conference on Machine Learning, 2011.  C. Dwork. Differential privacy. In ICALP (2), pages 1-12, 2006.  C. Dwork. Differential privacy: A survey of results. In TAMC, pages 1-19, 2008.  C. Dwork. The differential privacy frontier (extended abstract). In TCC, pages 496-502, 2009.  C. Dwork and K. Nissim. Privacy-preserving datamining on vertically partitioned databases. In Proceedings of CRYPTO, Lecture Notes in Computer Science, pages 528-544. Springer, 2004.  C. Dwork, G. N. Rothblum, and S. P. Vadhan. Boosting and differential privacy. In FOCS, pages  51-60, 2010.  Y. Freund. Boosting a weak learning algorithm by majority. In COLT, pages 202-216, 1990.  Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an appli-  cation to boosting. J. Comput. Syst. Sci., 55(1):119-139, 1997.  S. A. Goldman and M. J. Kearns. On the complexity of teaching. In Proceedings of COLT \u201991,  pages 303-314. Morgan Kaufmann, 1991.  M. Herlihy and N. Shavit. The art of multiprocessor programming. Morgan Kaufmann, 2008.  J. J\u00b4aJ\u00b4a and V. K. Prasanna. Information transfer in distributed computing with applications to vlsi.  J. ACM, 31(1):150-162, 1984.  26.13   BALCAN BLUM FINE MANSOUR  S. Kasiviswanathan, H. Lee, K. Nissim, S. Raskhodnikova, and A. Smith. What Can We Learn Privately? In Proc. 49th Annual IEEE Symposium on Foundations of Computer Science (FOCS), pages 531-540, 2008.  M. Kearns. Efficient noise-tolerant learning from statistical queries. Journal of the ACM, 45(6):  983-1006, 1998.  NIPS, 2011.  E. Kushilevitz and N. Nisan. Communication complexity. Cambridge University Press, 1997.  P. Long and R. Servedio. Algorithms and hardness results for parallel large margin learning. In  D. Peleg. Distributed computing: a locality-sensitive approach. Society for Industrial and Applied  Mathematics, Philadelphia, PA, USA, 2000. ISBN 0-89871-464-8.  R. L. Rivest and R. Sloan. Learning complicated concepts reliably and usefully. In Proceedings  AAAI-88, pages 635-639, Aug. 1988.  R. E. Schapire. The strength of weak learnability. Machine Learning, 5:197-227, 1990.  R. Servedio. Perceptron, Winnow, and PAC learning. SIAM Journal on Computing, 31(5), 2002.  M. Zinkevich, M. Weimer, A. J. Smola, and L. Li. Parallelized stochastic gradient descent. In NIPS,  pages 2595-2603, 2010.  26.14   DISTRIBUTED PAC LEARNING  "}, "A Characterization of Scoring Rules for Linear Properties": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "A Characterization of Scoring Rules for Linear Properties", "abstract": "We consider the design of proper scoring rules, equivalently proper losses, when the goal is to elicit some function, known as a property, of the underlying distribution. We provide a full characterization of the class of proper scoring rules when the property is linear as a function of the input distribution. A key conclusion is that any such scoring rule can be written in the form of a Bregman divergence for some convex function. We also apply our results to the design of prediction market mechanisms, showing a strong equivalence between scoring rules for linear properties and automated prediction market makers.", "pdf_url": "http://proceedings.mlr.press/v23/abernethy12/abernethy12.pdf", "keywords": [], "reference": "market-making. 297-306, 2011.  J. Abernethy, Y. Chen, and J. Wortman Vaughan. An optimization-based framework for automated In Proceedings of the 12th ACM conference on Electronic commerce, pages  J. D. Abernethy and R. M. Frongillo. A collaborative mechanism for crowdsourcing prediction In J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Weinberger, editors,  problems. Advances in Neural Information Processing Systems 24, pages 2600-2608. 2011.  A. Banerjee, S. Merugu, I. Dhillon, and J. Ghosh. Clustering with bregman divergences. The  Journal of Machine Learning Research, 6:1705-1749, 2005.  H. Bauer. Measure and integration theory, volume 26. Walter de Gruyter, 2001.  G. Brier. Verification of forecasts expressed in terms of probability. Monthly weather review, 78(1):  1-3, 1950. ISSN 1520-0493.  Y. Chen and D. Pennock. A utility framework for bounded-loss market makers. In Proceedings of  the 23rd Conference on Uncertainty in Artificial Intelligence, pages 49-56, 2007.  Y. Chen and J. Vaughan. A new understanding of prediction markets via no-regret learning. Proceedings of the 11th ACM conference on Electronic commerce, pages 189-198, 2010.  In  27.12   ABERNETHY FRONGILLO  If in addition B reduces to A, we say A and B are equivalent.  The central result of Abernethy and Frongillo (2011) is a strong connection between APMMs and L-incentivized CLMs for loss functions L based on a Bregman divergence. To relate these loss functions to our Bregman scores, we extend our definition slightly: for f differentiable let a (f, \u03c1, \u03c8) Bregman score be defined by s[r](\u03c9) = \u2212Df (\u03c1(\u03c9), \u03c8(r)). Now using our notion of equivalence we can restate their results as follows.  Theorem 14 (Abernethy and Frongillo (2011)) Let H, H(cid:48) be hypothesis spaces with H(cid:48) = relint(H(cid:48)), and let \u03c8 : H \u2192 H(cid:48) such that \u03c1(O) \u2286 \u03c8(H). Then APMM (H, O, \u03c1, C) is equivalent to an L- incentivized CLM for some differentiable C if and only if s[w](X) = \u2212L(w; X) is a (f, \u03c1, \u03c8) Bregman score for some differentiable f .  Combining this result with that of Section 4, we have the following.  Theorem 15 Let H, H(cid:48), \u03c8, \u03c1 be as in Theorem 14, and let \u03c8\u22121 be a right inverse of \u03c8. Then the following are equivalent:  1. APMM (H, O, \u03c1, C) is equivalent to an L-incentivized CLM for some differentiable C  2. s[w](X) = \u2212L(w; X) is a (f, \u03c1, \u03c8) Bregman score for some differentiable f  3. Scoring rule s[r](X) = \u2212L(\u03c8\u22121(r); X) is proper for linear property \u0393 : P (cid:55)\u2192 EX\u223cP \u03c1(X)  References  market-making. 297-306, 2011.  J. Abernethy, Y. Chen, and J. Wortman Vaughan. An optimization-based framework for automated In Proceedings of the 12th ACM conference on Electronic commerce, pages  J. D. Abernethy and R. M. Frongillo. A collaborative mechanism for crowdsourcing prediction In J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Weinberger, editors,  problems. Advances in Neural Information Processing Systems 24, pages 2600-2608. 2011.  A. Banerjee, S. Merugu, I. Dhillon, and J. Ghosh. Clustering with bregman divergences. The  Journal of Machine Learning Research, 6:1705-1749, 2005.  H. Bauer. Measure and integration theory, volume 26. Walter de Gruyter, 2001.  G. Brier. Verification of forecasts expressed in terms of probability. Monthly weather review, 78(1):  1-3, 1950. ISSN 1520-0493.  Y. Chen and D. Pennock. A utility framework for bounded-loss market makers. In Proceedings of  the 23rd Conference on Uncertainty in Artificial Intelligence, pages 49-56, 2007.  Y. Chen and J. Vaughan. A new understanding of prediction markets via no-regret learning. Proceedings of the 11th ACM conference on Electronic commerce, pages 189-198, 2010.  In  27.12   A CHARACTERIZATION OF SCORING RULES FOR LINEAR PROPERTIES  Y. Chen, L. Fortnow, E. Nikolova, and D. Pennock. Betting on permutations. In Proceedings of the  8th ACM Conference on Electronic Commerce, pages 326-335, 2007.  Y. Chen, L. Fortnow, N. Lambert, D. M. Pennock, and J. Wortman. Complexity of combinatorial market makers. In Proceedings of the 9th ACM conference on Electronic commerce, pages 190- 199, 2008.  A. P. Dawid. The geometry of proper scoring rules. Annals of the Institute of Statistical Mathemat- ics, 59:77-93, Dec. 2006. ISSN 0020-3157, 1572-9052. doi: 10.1007/s10463-006-0099-8. URL http://www.springerlink.com/index/10.1007/s10463-006-0099-8.  T. Gneiting and A. Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the  American Statistical Association, 102(477):359-378, 2007.  P. Gr\u00a8unwald and A. Dawid. Game theory, maximum entropy, minimum discrepancy and robust  bayesian decision theory. the Annals of Statistics, 32(4):1367-433, 2004.  R. Hanson. Combinatorial information market design. Information Systems Frontiers, 5(1):107-  119, 2003.  N. S. Lambert, D. M. Pennock, and Y. Shoham. Eliciting properties of probability distributions. In  Proceedings of the 9th ACM Conference on Electronic Commerce, pages 129-138, 2008.  M. Reid and R. Williamson. Composite binary losses. The Journal of Machine Learning Research,  11:2387-2422, 2010.  R. Rockafellar. Convex analysis, volume 28. Princeton Univ Pr, 1997.  L. Savage. Elicitation of personal probabilities and expectations. Journal of the American Statistical  Association, pages 783-801, 1971.  E. Vernet, R. Williamson, and M. Reid. Composite multiclass losses. NIPS, 2011.  27.13   "}, "Divergences and Risks for Multiclass Experiments": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Divergences and Risks for Multiclass Experiments", "abstract": "Csisz\u00e1r\u2019s $f$-divergence is a way to measure the similarity of two probability distributions. We study the extension of $f$-divergence to more than two distributions to measure their joint similarity. By exploiting classical results from the comparison of experiments literature we prove the resulting divergence satisfies all the same properties as the traditional binary one. Considering the multidistribution case actually makes the proofs simpler. The key to these results is a formal bridge between these multidistribution $f$-divergences and Bayes risks for multiclass classification problems.", "pdf_url": "http://proceedings.mlr.press/v23/garcia12/garcia12.pdf", "keywords": ["f -divergence", "Bayes risk", "comparison of experiments", "multiclass losses", "affinity", "information distance", "similarity"]}, "A Conjugate Property between Loss Functions and Uncertainty Sets in Classification Problems": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "A Conjugate Property between Loss Functions and Uncertainty Sets in Classification Problems", "abstract": "In binary classification problems, mainly two approaches have been proposed; one is loss function approach and the other is minimum distance approach. The loss function approach is applied to major learning algorithms such as support vector machine (SVM) and boosting methods. The loss function represents the penalty of the decision function on the training samples. In the learning algorithm, the empirical mean of the loss function is minimized to obtain the classifier. Against a backdrop of the development of mathematical programming, nowadays learning algorithms based on loss functions are widely applied to real-world data analysis. In addition, statistical properties of such learning algorithms are well-understood based on a lots of theoretical works. On the other hand, some learning methods such as \u03c5-SVM, mini-max probability machine (MPM) can be formulated as minimum distance problems. In the minimum distance approach, firstly, the so-called uncertainty set is defined for each binary label based on the training samples. Then, the best separating hyperplane between the two uncertainty sets is employed as the decision function. This is regarded as an extension of the maximum-margin approach. The minimum distance approach is considered to be useful to construct the statistical models with an intuitive geometric interpretation, and the interpretation is helpful to develop the learning algorithms. However, the statistical properties of the minimum distance approach have not been intensively studied. In this paper, we consider the relation between the above two approaches. We point out that the uncertainty set in the minimum distance approach is described by using the level set of the conjugate of the loss function. Based on such relation, we study statistical properties of the minimum distance approach.", "pdf_url": "http://proceedings.mlr.press/v23/kanamori12/kanamori12.pdf", "keywords": ["loss function", "minimum distance problem", "uncertainty set", "Legendre transformation", "consistency"], "reference": "P. L. Bartlett, M. I. Jordan, and J. D. McAuliffe. Convexity, classification, and risk bounds. Journal  of the American Statistical Association, 101:138-156, 2006.  K. P. Bennett and E. J. Bredensteiner. Duality and geometry in SVM classifiers. In Proceedings of  International Conference on Machine Learning, pages 57-64, 2000.  D. Bertsekas, A. Nedic, and A. Ozdaglar. Convex Analysis and Optimization. Athena Scientific,  Belmont, MA, 2003.  D. J. Crisp and C. J. C. Burges. A geometric interpretation of \u03bd-SVM classifiers. In S. A. Solla, T. K. Leen, and K.-R. M\u00a8uller, editors, Advances in Neural Information Processing Systems 12, pages 244-250. MIT Press, 2000.  F. Cucker and S. Smale. On the mathematical foundations of learning. Bulletin of the American  Mathematical Society, 39:1-49, 2002.  G. R.G. Lanckriet, L. El Ghaoui, C. Bhattacharyya, and M. I. Jordan. A robust minimax approach  to classification. Journal of Machine Learning Research, 3:555-582, 2003.  M. E. Mavroforakis and S. Theodoridis. A geometric approach to support vector machine (svm)  classification. IEEE Transactions on Neural Networks, 17(3):671-682, 2006.  J. S. Nath and C. Bhattacharyya. Maximum margin classifiers with specified false positive and false negative error rates. In C. Apte, B. Liu, S. Parthasarathy, and D. Skillicorn, editors, Proceedings of the seventh SIAM International Conference on Data mining, pages 35-46. SIAM, 2007.  R. T. Rockafellar. Convex Analysis. Princeton University Press, Princeton, NJ, USA, 1970.  29.12   KANAMORI TAKEDA SUZUKI  the derivative \u00af(cid:96)(cid:48)(z) is Lipschitz continuous and the Lipschitz constant is equal to 1/(2w), we have \u00af(cid:96)(cid:48)(\u03c1 + z) \u2212 \u00af(cid:96)(cid:48)(\u03c1 \u2212 z) \u2264 z/w. Therefore, the inequality sup\u03c1\u2265\u2212\u00af(cid:96)(0)/2 \u03be(z, \u03c1) \u2264 sup\u03c1\u2265\u2212\u00af(cid:96)(0)/2 = z/w 4w\u22121 z \u2264 2z holds. We see that \u00af\u03be(z) = 2z satisfies the sufficient conditions in Lemma \u00af(cid:96)(cid:48)(\u2212\u00af(cid:96)(0)/2) 7. Hence, the loss function corresponding to the revised uncertainty set satisfies the conditions for statistical consistency, though the original uncertainty set with the estimation error does not correspond to the empirical mean of a loss function.  \u2264 4w  z/w \u00af(cid:96)(cid:48)(\u03c1)  5. Conclusion  In this paper, we studied the relation between the loss function approach and the minimum distance approach in binary classification problems. We proposed the learning algorithm based on the revised minimum distance problem, and proved the statistical consistency. In our proof, the hinge loss used in \u03bd-SVM is excluded, though Steinwart (2003) proved the statistical consistency of \u03bd-SVM with a nice choice of the regularization parameter. A future work is to relax the assumptions of our theoretical result so as to include the hinge loss function and other popular loss functions such as the logistic loss. Also, it is important to derive the convergence rate of the proposed learning method. Developing an optimization algorithm is needed for practical data analysis by the statistical learning with uncertainty sets.  References  P. L. Bartlett, M. I. Jordan, and J. D. McAuliffe. Convexity, classification, and risk bounds. Journal  of the American Statistical Association, 101:138-156, 2006.  K. P. Bennett and E. J. Bredensteiner. Duality and geometry in SVM classifiers. In Proceedings of  International Conference on Machine Learning, pages 57-64, 2000.  D. Bertsekas, A. Nedic, and A. Ozdaglar. Convex Analysis and Optimization. Athena Scientific,  Belmont, MA, 2003.  D. J. Crisp and C. J. C. Burges. A geometric interpretation of \u03bd-SVM classifiers. In S. A. Solla, T. K. Leen, and K.-R. M\u00a8uller, editors, Advances in Neural Information Processing Systems 12, pages 244-250. MIT Press, 2000.  F. Cucker and S. Smale. On the mathematical foundations of learning. Bulletin of the American  Mathematical Society, 39:1-49, 2002.  G. R.G. Lanckriet, L. El Ghaoui, C. Bhattacharyya, and M. I. Jordan. A robust minimax approach  to classification. Journal of Machine Learning Research, 3:555-582, 2003.  M. E. Mavroforakis and S. Theodoridis. A geometric approach to support vector machine (svm)  classification. IEEE Transactions on Neural Networks, 17(3):671-682, 2006.  J. S. Nath and C. Bhattacharyya. Maximum margin classifiers with specified false positive and false negative error rates. In C. Apte, B. Liu, S. Parthasarathy, and D. Skillicorn, editors, Proceedings of the seventh SIAM International Conference on Data mining, pages 35-46. SIAM, 2007.  R. T. Rockafellar. Convex Analysis. Princeton University Press, Princeton, NJ, USA, 1970.  29.12   CONJUGATE PROPERTY IN CLASSIFICATION  B. Sch\u00a8olkopf and A. J. Smola. Learning with Kernels: Support Vector Machines, Regularization,  Optimization, and Beyond. MIT Press, 2001.  B. Sch\u00a8olkopf, A. Smola, R. Williamson, and P. Bartlett. New support vector algorithms. Neural  Computation, 12(5):1207-1245, 2000.  I. Steinwart. On the optimal parameter choice for v-support vector machines. IEEE Trans. Pattern  Anal. Mach. Intell., 25(10):1274-1284, 2003.  I. Steinwart. Consistency of support vector machines and other regularized kernel classifiers. IEEE  Transactions on Information Theory, 51(1):128-142, 2005.  I. Steinwart and A. Christmann. Support Vector Machines. Springer Publishing Company, Incorpo-  rated, 1st edition, 2008.  V. Vapnik. Statistical Learning Theory. Wiley, 1998.  D.-X. Zhou. The covering number in learning theory. Journal of Complexity, 18(3):739-767, 2002.  "}, "New Bounds for Learning Intervals with Implications for Semi-Supervised Learning": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "New Bounds for Learning Intervals with Implications for Semi-Supervised Learning", "abstract": "We study learning of initial intervals in the prediction model. We show that for each distribution \\emphD over the domain, there is an algorithm \\emphA_D, whose probability of a mistake in round m is at most \\emph(\u00bd + o(1))/m. We also show that the best possible bound that can be achieved in the case in which the same algorithm \\emphA must be applied for all distributions \\emphD is at least (^1\u2044_\u221a\\emphe - o(1))^1\u2044_\\emphm > (^3\u2044_5-o(1))^1\u2044_\\emphm. Informally, \u201cknowing\u201d the distribution \\emphD enables an algorithm to reduce its error rate by a constant factor strictly greater than 1. As advocated by Ben-David et al. (2008), knowledge of \\emphD can be viewed as an idealized proxy for a large number of unlabeled examples.", "pdf_url": "http://proceedings.mlr.press/v23/helmbold12/helmbold12.pdf", "keywords": ["Prediction model", "initial intervals", "semi-supervised learning", "error bounds"], "reference": "M. Balcan and A. Blum. A discriminative model for semi-supervised learning. JACM, 57(3), 2010.  30.12   HELMBOLD LONG  points are in Ti, and (b) some training point is in Ti+1 (i.e. some training point is 3(cid:96)+i+1). Let EXACTcm/2 be the event that no training point is labeled \u201c\u2212\u201d. Therefore the EXACTi events are disjoint and MISSi = (cid:83)  j\u2265i EXACTj.  Note that if EXACTi occurs, then the smallest negative example is 3(cid:96)+i+1. Furthermore, all points in Ti are less then half this value and the maximum margin algorithm predicts incorrectly on exactly the i points in Ti, so Pr(error|EXACTi) = i/(cm). Thus, for m > 2c, we have  cm/2 (cid:88)  i=1  Pr(error) =  Pr(error|EXACTi) Pr(EXACTi) =  Pr(EXACTi)  =  1 cm  cm/2 (cid:88)  i=1  Pr(MISSi) =  1 cm  cm/2 (cid:88)  i=1  (cid:19)m  (cid:18) cm \u2212 i cm  \u2265  1 cm  c2 (cid:88)  (cid:18)  1 \u2212  i=1  (cid:19)m  .  i/c m  cm/2 (cid:88)  i=1  i cm  For i \u2264 c2, in the limit as m \u2192 \u221e, relative to the constant c) we can continue as follows.  1 \u2212 i/c m  (cid:16)  (cid:17)m  \u2192 exp(\u2212i/c), so for large enough m (large  Pr(error) \u2265  (1 \u2212 (cid:15)) exp(\u2212i/c) =  exp(\u22121/c)i  1 cm  c2 (cid:88)  i=1  1 \u2212 (cid:15) cm  c2 (cid:88)  i=1  =  =  exp(\u22121/c)  1 \u2212 (cid:15) cm (1 \u2212 (cid:15))(1 \u2212 (cid:15)2) cm  1 \u2212 exp(\u22121/c)c2 1 \u2212 exp(\u22121/c) exp(\u22121/c) 1 \u2212 exp(\u22121/c)  =  1 \u2212 (cid:15) cm  exp(\u22121/c)  1 \u2212 exp(\u2212c) 1 \u2212 exp(\u22121/c)  where (cid:15)2 = e\u2212c. Now, replacing 1/c by a we get: Pr(error) \u2265 (1\u2212(cid:15))(1\u2212(cid:15)2) a exp(\u2212a) 1\u2212exp(\u2212a) Using L\u2019Hopitals rule, we see that the limit of the second fraction as a \u2192 0 is 1. So for large enough c, the second fraction is at least 1 \u2212 (cid:15)3 and Pr(error) \u2265 (1\u2212(cid:15))(1\u2212(cid:15)2)(1\u2212(cid:15)3) . Thus, by making the constant c large enough, and choosing m large enough compared to c, the expected error of the maximum margin algorithm can be made arbitrarily close to 1/m.  m  m  6. Conclusion  Algorithms that know the underlying marginal distribution D over the instances can learn signifi- cantly more accurately than algorithms that do not. Since knowledge of D has been proposed as a proxy for a large number of unlabeled examples, our results indicate a benefit for semi-supervised learning. It is particularly intriguing that our analysis shows the benefit of semi-supervised learning when the distribution is nearly uniform, but slightly concentrated near the decision boundary. This is in sharp contrast to previous analyses showing the benefits of semi-supervised learning, which typically rely on a \u201ccluster assumption\u201d postulating that examples are sparse along the decision boundary.  References  M. Balcan and A. Blum. A discriminative model for semi-supervised learning. JACM, 57(3), 2010.  30.12   NEW BOUNDS FOR INTERVALS  S. Ben-David, T. Lu, and D. Pal. Does unlabeled data provably help? Worst-case analysis of the  sample complexity of semi-supervised learning. COLT, 2008.  B. E. Boser, I. M. Guyon, and V. N. Vapnik. A training algorithm for optimal margin classifiers. Proceedings of the 1992 Workshop on Computational Learning Theory, pages 144-152, 1992.  O. Chapelle, B. Sch\u00a8olkopf, and A. Zien. Semi-Supervised Learning. MIT Press, 2006.  Malte Darnst\u00a8adt and Hans-Ulrich Simon. Smart pac-learners. Theor. Comput. Sci., 412(19):1756-  1766, 2011.  A. Ehrenfeucht, D. Haussler, M. Kearns, and L. G. Valiant. A general lower bound on the number  of examples needed for learning. Information and Computation, 82(3):247-251, 1989.  D. Haussler, N. Littlestone, and M. K. Warmuth. Predicting {0, 1}-functions on randomly drawn  points. Information and Computation, 115(2):129-161, 1994.  R. Herbrich, T. Graepel, and C. Campbell. Bayes point machines. Journal of Machine Learning  Research, 1:245-279, 2001.  M. K\u00a8a\u00a8ari\u00a8ainen. Generalization error bounds using unlabeled data. COLT, 2005.  Y. Li, P. M. Long, and A. Srinivasan. The one-inclusion graph algorithm is near-optimal for the prediction model of learning. IEEE Transactions on Information Theory, 47(3):1257-1261, 2001.  P.A.P. Moran. The random division of an interval. Supplement to the Journal of the Royal Statistical  L. Pitt and M. K. Warmuth. Prediction preserving reducibility. Journal of Computer and System  R. Urner, S. Shalev-Shwartz, and S. Ben-David. Access to unlabeled data can speed up prediction  V. N. Vapnik and A. Lerner. Pattern recognition using generalized portrait method. Automation and  X. Zhu and A. B. Goldberg.  Introduction to Semi-Supervised Learning. Synthesis Lectures on  Artificial Intelligence and Machine Learning. Morgan-Claypool, 2009.  Society, 9(1):92-98, 1947.  Sciences, 41(3), 1990.  time. ICML, 2011.  remote control, 24, 1963.  "}, "Tight Bounds on Proper Equivalence Query Learning of DNF": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Tight Bounds on Proper Equivalence Query Learning of DNF", "abstract": "We prove a new structural lemma for partial Boolean functions \\emphf, which we call the \\emphseed lemma for \\emphDNF. Using the lemma, we give the first subexponential algorithm for proper learning of poly(\\emphn)-term DNF in Angluin\u2019s Equivalence Query (EQ) model. The algorithm has time and query complexity 2^(\u00d5\u221a\\emphn), which is optimal. We also give a new result on certificates for DNF-size, a simple algorithm for properly PAC-learning DNF, and new results on EQ-learning log \\emphn-term DNF and decision trees.", "pdf_url": "http://proceedings.mlr.press/v23/hellerstein12/hellerstein12.pdf", "keywords": ["query learning", "exact learning", "proper learning", "DNF", "certificates"], "reference": "M. Alekhnovich, M. Braverman, V. Feldman, A. Klivans, and T. Pitassi. Learnability and autom- atizability. In Proceedings of the 45th IEEE Symposium on Foundations of Computer Science, pages 621\u2013630, 2004.  Michael Alekhnovich, Mark Braverman, Vitaly Feldman, Adam Klivans, and Toniann Pitassi. The complexity of properly learning simple concept classes. Journal of Computer & System Sciences, 74(1):16\u201334, 2009.  Dana Angluin. Queries and concept learning. Machine Learning, 2:319\u2013342, 1988.  Dana Angluin. Negative results for equivalence queries. Machine Learning, 5:121\u2013150, 1990.  Dana Angluin. Computational Learning Theory: Survey and Selected Bibliography. In Proceedings  of the 24rd ACM Symposium on Theory of Computation, pages 351\u2013369, 1992.  31.12   HELLERSTEIN KLETENIK SELLIE SERVEDIO  algorithm we consider two mutually exclusive possibilities for the counterexample a which is given in response to hCON :  Case 1: a \u2208 Z. In this case, since h(a) agrees with the majority of the values f1(a), . . . , fN (a),  such a counterexample causes the size of CON to be multiplied by at most 1/2.  Case 2: a /\u2208 Z. In this case we have Na,0, Na,1 \u2265 1  size of CON to be multiplied by at most (cid:0)1 \u2212 1 nk  (cid:1) . This proves Theorem 9.  nk so the counterexample a must cause the  8. Membership queries provably help for learning log n-term DNF  The following is a sharpening of the arguments from Section 6 to apply to log(n)-term DNF.  Theorem 11 Let A be any algorithm which learns the class of all log n-term DNF formulas using only equivalence queries which are DNF formulas with at most nlog n terms. Then A must make at least n(log n)/3 equivalence queries in the worst case.  Sketch of Proof of Theorem 11: As in the proof of Theorem 6 we consider M (n, t, s), the class of all monotone DNF over n variables with exactly t distinct terms each of length exactly s. For this proof we fix s and t both to be log n. We will show that given any DNF formula with at most nlog n terms, there is an assignment such that at most a 1/n(log n)/3 fraction of the DNFs in M (n, t, s) agree with f on that assignment; this implies the theorem by the arguments of Theorem 6. Details are in "}, "Distance Preserving Embeddings for General n-Dimensional Manifolds": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Distance Preserving Embeddings for General n-Dimensional Manifolds", "abstract": "Low dimensional embeddings of manifold data have gained popularity in the last decade. However, a systematic finite sample analysis of manifold embedding algorithms largely eludes researchers. Here we present two algorithms that, given access to just the samples, embed the underlying n- dimensional manifold into R^d (where d only depends on some key manifold properties such as its intrinsic dimension, volume and curvature) and \\emphguarantee to approximately preserve all interpoint geodesic distances.", "pdf_url": "http://proceedings.mlr.press/v23/verma12/verma12.pdf", "keywords": ["Manifold Learning", "Isometric Embeddings", "Nash\u2019s Embedding Theorem"], "reference": "tional Mathematics, 2007.  R. Baraniuk and M. Wakin. Random projections of smooth manifolds. Foundations of Computa-  M. Bernstein, V. de Silva, J. Langford, and J. Tenebaum. Graph approximations to geodesics on  embedded manifolds. Techical Report, 2000.  K. Clarkson. Tighter bounds for random projections of manifolds. Comp. Geometry, 2007.  S. Dasgupta and Y. Freund. Random projection trees and low dimensional manifolds. ACM Sym-  posium on Theory of Computing, 2008.  M. do Carmo. Riemannian Geometry. Birkhauser, 1992.  Q. Han and J. Hong. Isometric embedding of Riemannian manifolds in Euclidean spaces. American  Mathematical Society, 2006.  W. Johnson and J. Lindenstrauss. Extensions of Lipschitz mappings into a Hilbert space. Conf. in  Modern Analysis and Probability, pages 189\u2013206, 1984.  J. Milnor. Topology from the differential viewpoint. Univ. of Virginia Press, 1972.  J. Nash. C1 isometric imbeddings. Annals of Mathematics, 60(3):383\u2013396, 1954.  P. Niyogi, S. Smale, and S. Weinberger. Finding the homology of submanifolds with high con\ufb01dence  from random samples. Disc. Computational Geometry, 2006.  J. Tenebaum, V. de Silva, and J. Langford. A global geometric framework for nonlinear dimension-  ality reduction. Science, 290, 2000.  Report CS2011-0971, 2011.  N. Verma. A note on random projections for preserving paths on a manifold. UC San Diego, Tech.  H. Whitney. Differentiable manifolds. Annals of Mathematics, 37:645\u2013680, 1936.  Appendix A. Properties of a Well-conditioned Manifold  Throughout this section we will assume that M is a compact submanifold of RD of dimension n, and condition number 1/\u03c4 . The following are some properties of such a manifold that would be useful throughout the text.  Lemma 16 (relating closeby tangent vectors \u2013 implicit in the proof of Proposition 6.2 Niyogi et al. (2006)) Pick any two (path-connected) points p, q \u2208 M . Let u \u2208 TpM be a unit length tangent vector and v \u2208 TqM be its parallel transport along the (shortest) geodesic path to q. Then2, i) u \u00b7 v \u2265 1 \u2212 DG(p, q)/\u03c4 , ii) (cid:107)u \u2212 v(cid:107) \u2264 (cid:112)2DG(p, q)/\u03c4 .  2. Technically, it is not possible to directly compare two vectors that reside in different tangent spaces. However, since we only deal with manifolds that are immersed in some ambient space, we can treat the tangent spaces as n-dimensional af\ufb01ne subspaces. We can thus parallel translate the vectors to the origin of the ambient space, and do the necessary comparison (such as take the dot product, etc.). We will make a similar abuse of notation for any calculation that uses vectors from different af\ufb01ne subspaces to mean to \ufb01rst translate the vectors and then perform the necessary calculation.  32.13   DISTANCE PRESERVING EMBEDDINGS FOR MANIFOLDS  References  tional Mathematics, 2007.  R. Baraniuk and M. Wakin. Random projections of smooth manifolds. Foundations of Computa-  M. Bernstein, V. de Silva, J. Langford, and J. Tenebaum. Graph approximations to geodesics on  embedded manifolds. Techical Report, 2000.  K. Clarkson. Tighter bounds for random projections of manifolds. Comp. Geometry, 2007.  S. Dasgupta and Y. Freund. Random projection trees and low dimensional manifolds. ACM Sym-  posium on Theory of Computing, 2008.  M. do Carmo. Riemannian Geometry. Birkhauser, 1992.  Q. Han and J. Hong. Isometric embedding of Riemannian manifolds in Euclidean spaces. American  Mathematical Society, 2006.  W. Johnson and J. Lindenstrauss. Extensions of Lipschitz mappings into a Hilbert space. Conf. in  Modern Analysis and Probability, pages 189-206, 1984.  J. Milnor. Topology from the differential viewpoint. Univ. of Virginia Press, 1972.  J. Nash. C1 isometric imbeddings. Annals of Mathematics, 60(3):383-396, 1954.  P. Niyogi, S. Smale, and S. Weinberger. Finding the homology of submanifolds with high confidence  from random samples. Disc. Computational Geometry, 2006.  J. Tenebaum, V. de Silva, and J. Langford. A global geometric framework for nonlinear dimension-  ality reduction. Science, 290, 2000.  Report CS2011-0971, 2011.  N. Verma. A note on random projections for preserving paths on a manifold. UC San Diego, Tech.  H. Whitney. Differentiable manifolds. Annals of Mathematics, 37:645-680, 1936.  "}, "A Method of Moments for Mixture Models and Hidden Markov Models": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "A Method of Moments for Mixture Models and Hidden Markov Models", "abstract": "Mixture models are a fundamental tool in applied statistics and machine learning for treating data taken from multiple subpopulations. The current practice for estimating the parameters of such models relies on local search heuristics (\\emphe.g., the EM algorithm) which are prone to failure, and existing consistent methods are unfavorable due to their high computational and sample complexity which typically scale exponentially with the number of mixture components. This work develops an efficient \\emphmethod of moments approach to parameter estimation for a broad class of high-dimensional mixture models with many components, including multi-view mixtures of Gaussians (such as mixtures of axis-aligned Gaussians) and hidden Markov models. The new method leads to rigorous unsupervised learning results for mixture models that were not achieved by previous works; and, because of its simplicity, it offers a viable alternative to EM for practical deployment.", "pdf_url": "http://proceedings.mlr.press/v23/anandkumar12/anandkumar12.pdf", "keywords": [], "reference": "D. Achlioptas and F. McSherry. On spectral learning of mixtures of distributions. In COLT, 2005.  R. Ahlswede and A. Winter. Strong converse for identification via quantum channels. IEEE Trans-  actions on Information Theory, 48(3):569-579, 2002.  S. Arora and R. Kannan. Learning mixtures of arbitrary Gaussians. In STOC, 2001.  M. Belkin and K. Sinha. Polynomial learning of distribution families. In FOCS, 2010.  M. B. Blaschko and C. H. Lampert. Correlational spectral clustering. In CVPR, 2008.  D. L. Boley, F. T. Luk, and D. Vandevoorde. Vandermonde factorization of a Hankel matrix. In  Scientific Computing, 1997.  S. C. Brubaker and S. Vempala. Isotropic PCA and affine-invariant clustering. In FOCS, 2008.  J. T. Chang. Full reconstruction of Markov models on evolutionary trees: Identifiability and consis-  tency. Mathematical Biosciences, 137:51-73, 1996.  K. Chaudhuri and S. Rao. Learning mixtures of product distributions using correlations and inde-  pendence. In COLT, 2008.  K. Chaudhuri, S. M. Kakade, K. Livescu, and K. Sridharan. Multi-view clustering via canonical  correlation analysis. In ICML, 2009.  S. Dasgupta. Learning mixutres of Gaussians. In FOCS, 1999.  S. Dasgupta and A. Gupta. An elementary proof of a theorem of Johnson and Lindenstrauss. Ran-  dom Structures and Algorithms, 22(1):60-65, 2003.  S. Dasgupta and L. Schulman. A probabilistic analysis of EM for mixtures of separated, spherical  Gaussians. Journal of Machine Learning Research, 8(Feb):203-226, 2007.  J. Feldman, R. O\u2019Donnell, and R. Servedio. Learning mixtures of product distributions over discrete  domains. In FOCS, 2005.  33.12   ANANDKUMAR HSU KAKADE  and the parameters of the resulting three-view mixture model on (h, (cid:126)x1, (cid:126)x2, (cid:126)x3) are (cid:126)w := T (cid:126)\u03c0, M1 := O diag((cid:126)\u03c0)T (cid:62) diag(T (cid:126)\u03c0)\u22121, M2 := O, and M3 := OT .  3 OT )\u22121. There- From Proposition 8, it is easy to verify that B3,1,2((cid:126)\u03b7) = (U (cid:62) fore, after recovering the observation conditional mean matrix O using Algorithm B, the Markov chain transition matrix can be recovered using the matrix of right eigenvectors R of B3,1,2((cid:126)\u03b7) and the equation (U (cid:62)  3 O)\u22121R = T (up to scaling of the columns).  3 OT ) diag(O(cid:62)(cid:126)\u03b7)(U (cid:62)  We thank Kamalika Chaudhuri and Tong Zhang for many useful discussions, Karl Stratos for com- ments on an early draft, and David Sontag and an anonymous reviewer for some pointers to related work.  Acknowledgments  References  D. Achlioptas and F. McSherry. On spectral learning of mixtures of distributions. In COLT, 2005.  R. Ahlswede and A. Winter. Strong converse for identification via quantum channels. IEEE Trans-  actions on Information Theory, 48(3):569-579, 2002.  S. Arora and R. Kannan. Learning mixtures of arbitrary Gaussians. In STOC, 2001.  M. Belkin and K. Sinha. Polynomial learning of distribution families. In FOCS, 2010.  M. B. Blaschko and C. H. Lampert. Correlational spectral clustering. In CVPR, 2008.  D. L. Boley, F. T. Luk, and D. Vandevoorde. Vandermonde factorization of a Hankel matrix. In  Scientific Computing, 1997.  S. C. Brubaker and S. Vempala. Isotropic PCA and affine-invariant clustering. In FOCS, 2008.  J. T. Chang. Full reconstruction of Markov models on evolutionary trees: Identifiability and consis-  tency. Mathematical Biosciences, 137:51-73, 1996.  K. Chaudhuri and S. Rao. Learning mixtures of product distributions using correlations and inde-  pendence. In COLT, 2008.  K. Chaudhuri, S. M. Kakade, K. Livescu, and K. Sridharan. Multi-view clustering via canonical  correlation analysis. In ICML, 2009.  S. Dasgupta. Learning mixutres of Gaussians. In FOCS, 1999.  S. Dasgupta and A. Gupta. An elementary proof of a theorem of Johnson and Lindenstrauss. Ran-  dom Structures and Algorithms, 22(1):60-65, 2003.  S. Dasgupta and L. Schulman. A probabilistic analysis of EM for mixtures of separated, spherical  Gaussians. Journal of Machine Learning Research, 8(Feb):203-226, 2007.  J. Feldman, R. O\u2019Donnell, and R. Servedio. Learning mixtures of product distributions over discrete  domains. In FOCS, 2005.  33.12   A METHOD OF MOMENTS FOR MIXTURE MODELS AND HMMS  J. Feldman, R. O\u2019Donnell, and R. Servedio. PAC learning mixtures of axis-aligned Gaussians with  no separation assumption. In COLT, 2006.  A. M. Frieze, M. Jerrum, and R. Kannan. Learning linear transformations. In FOCS, 1996.  W. A. Gale, K. W. Church, and D. Yarowsky. One sense per discourse. In 4th DARPA Speech and  Natural Language Workshop, 1992.  N. Gravin, J. Lasserre, D. Pasechnik, and S. Robins. The inverse moment problem for convex  polytopes. Discrete and Computational Geometry, 2012. To appear.  H. Hotelling. The most predictable criterion. Journal of Educational Psychology, 26(2):139-142,  D. Hsu, S. M. Kakade, and T. Zhang. A spectral algorithm for learning hidden Markov models. In  D. Hsu, S. M. Kakade, and T. Zhang. A spectral algorithm for learning hidden Markov models.  Journal of Computer and System Sciences, 2012. To appear.  A. Hyv\u00a8arinen and E. Oja. Independent component analysis: algorithms and applications. Neural  Networks, 13(4-5):411-430, 2000.  H. Jaeger. Observable operator models for discrete stochastic time series. Neural Computation, 12  A. T. Kalai, A. Moitra, and G. Valiant. Efficiently learning mixtures of two Gaussians. In STOC,  R. Kannan, H. Salmasian, and S. Vempala. The spectral method for general mixture models. In  B. G. Lindsay. Moment matrices: applications in mixtures. Annals of Statistics, 17(2):722-740,  B. G. Lindsay. Mixture models: theory, geometry and applications. American Statistical Associa-  B. G. Lindsay and P. Basak. Multivariate normal mixtures: a fast consistent method. Journal of the  American Statistical Association, 88(422):468-476, 1993.  F. McSherry. Spectral partitioning of random graphs. In FOCS, 2001.  A. Moitra and G. Valiant. Settling the polynomial learnability of mixtures of Gaussians. In FOCS,  E. Mossel and S. Roch. Learning nonsingular phylogenies and hidden Markov models. Annals of  Applied Probability, 16(2):583-614, 2006.  P. Q. Nguyen and O. Regev. Learning a parallelepiped: Cryptanalysis of GGH and NTRU signa-  tures. Journal of Cryptology, 22(2):139-160, 2009.  1935.  COLT, 2009.  (6), 2000.  2010.  COLT, 2005.  1989.  tion, 1995.  2010.  33.13   ANANDKUMAR HSU KAKADE  (cid:126)x1  (cid:126)x2  \u00b7 \u00b7 \u00b7  (cid:126)x(cid:96)  h  (a)  h1  (cid:126)x1  h2  (cid:126)x2  (b)  \u00b7 \u00b7 \u00b7  h(cid:96)  (cid:126)x(cid:96)  Figure 3: (a) The multi-view mixture model. (b) A hidden Markov model.  K. Pearson. Contributions to the mathematical theory of evolution. Philosophical Transactions of  the Royal Society, London, A., page 71, 1894.  B. Recht. A simpler approach to matrix completion, 2009. arXiv:0910.0651v2.  R. A. Redner and H. F. Walker. Mixture densities, maximum likelihood and the EM algorithm.  SIAM Review, 26(2):195-239, 1984.  M. P. Sch\u00a8utzenberger. On the definition of a family of automata.  Information and Control, 4:  245-270, 1961.  tions. Wiley, 1985.  2002.  G. W. Stewart and Ji-Guang Sun. Matrix Perturbation Theory. Academic Press, 1990.  D. M. Titterington, A. F. M. Smith, and U. E. Makov. Statistical analysis of finite mixture distribu-  S. Vempala and G. Wang. A spectral algorithm for learning mixtures of distributions. In FOCS,  R. Vershynin.  Introduction to the non-asymptotic analysis of random matrices.  In Y. Eldar and G. Kutyniok, editors, Compressed Sensing, Theory and Applications, chapter 5, pages 210-268. Cambridge University Press, 2012.  "}, "A Correlation Clustering Approach to Link Classification in Signed Networks": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "A Correlation Clustering Approach to Link Classification in Signed Networks", "abstract": "Motivated by social balance theory, we develop a theory of link classification in signed networks using the correlation clustering index as measure of label regularity. We derive learning bounds in terms of correlation clustering within three fundamental transductive learning settings: online, batch and active. Our main algorithmic contribution is in the active setting, where we introduce a new family of efficient link classifiers based on covering the input graph with small circuits. These are the first active algorithms for link classification with mistake bounds that hold for arbitrary signed networks.", "pdf_url": "http://proceedings.mlr.press/v23/cesa-bianchi12/cesa-bianchi12.pdf", "keywords": ["Online learning", "transductive learning", "active learning", "social balance theory"], "reference": "89-113, 2004.  A Blum, N. Bansal, and S. Chawla. Correlation clustering. Machine Learning Journal, 56(1/3):  B. Bollobas. Combinatorics. Cambridge University Press, 1986.  D. Cartwright and F. Harary. Structure balance: A generalization of Heider\u2019s theory. Psychological  review, 63(5):277-293, 1956.  N. Cesa-Bianchi, C. Gentile, and F. Vitale. Fast and optimal prediction of a labeled tree. In Pro-  ceedings of the 22nd Annual Conference on Learning Theory. Omnipress, 2009.  N. Cesa-Bianchi, C. Gentile, F. Vitale, and G. Zappella. Random spanning trees and the prediction of weighted graphs. In Proceedings of the 27th International Conference on Machine Learning. Omnipress, 2010.  K. Chiang, N. Natarajan, A. Tewari, and I. Dhillon. Exploiting longer cycles for link prediction in signed networks. In Proceedings of the 20th ACM Conference on Information and Knowledge Management (CIKM). ACM, 2011.  E.D. Demaine, D. Emanuel, A. Fiat, and N. Immorlica. Correlation clustering in general weighted  graphs. Theoretical Computer Science, 361(2-3):172-187, 2006.  R. El-Yaniv and D. Pechyony. Transductive rademacher complexity and its applications. Journal of  Artificial Intelligence Research, 35(1):193-234, 2009.  M. Elkin, Y. Emek, D.A. Spielman, and S.-H. Teng. Lower-stretch spanning trees. SIAM Journal  on Computing, 38(2):608-628, 2010.  34.12   CESA-BIANCHI GENTILE VITALE ZAPPELLA  (cid:17)  (cid:16)(cid:113) |VG| \u03c1  log |VG|  , respectively, provided |C(G)| = \u2126(|EG|) and \u03c1 \u2264 (cid:112)|VG|. For instance, O when the input graph G = (VG, EG) has a quadratic number of edges, SCCCC has an amortized time per prediction which is only logarithmic in |VG|. In all cases, both algorithms need linear space in the size of the input graph. In addition, each do-while loop execution within CCCC can be run in parallel.  5. Conclusions and ongoing research  In this paper we initiated a rigorous study of link classification in signed graphs. Motivated by social balance theory, we adopted the correlation clustering index as a natural regularity measure for the problem. We proved upper and lower bounds on the number of prediction mistakes in three fundamental transductive learning models: online, batch and active. Our main algorithmic contribution is for the active model, where we introduced a new family of algorithms based on the notion of circuit covering. Our algorithms are efficient, relatively easy to implement, and have mistake bounds that hold on any signed graph. We are currently working on extensions of our techniques based on recursive decompositions of the input graph. Experiments on social network datasets are also in progress.  References  89-113, 2004.  A Blum, N. Bansal, and S. Chawla. Correlation clustering. Machine Learning Journal, 56(1/3):  B. Bollobas. Combinatorics. Cambridge University Press, 1986.  D. Cartwright and F. Harary. Structure balance: A generalization of Heider\u2019s theory. Psychological  review, 63(5):277-293, 1956.  N. Cesa-Bianchi, C. Gentile, and F. Vitale. Fast and optimal prediction of a labeled tree. In Pro-  ceedings of the 22nd Annual Conference on Learning Theory. Omnipress, 2009.  N. Cesa-Bianchi, C. Gentile, F. Vitale, and G. Zappella. Random spanning trees and the prediction of weighted graphs. In Proceedings of the 27th International Conference on Machine Learning. Omnipress, 2010.  K. Chiang, N. Natarajan, A. Tewari, and I. Dhillon. Exploiting longer cycles for link prediction in signed networks. In Proceedings of the 20th ACM Conference on Information and Knowledge Management (CIKM). ACM, 2011.  E.D. Demaine, D. Emanuel, A. Fiat, and N. Immorlica. Correlation clustering in general weighted  graphs. Theoretical Computer Science, 361(2-3):172-187, 2006.  R. El-Yaniv and D. Pechyony. Transductive rademacher complexity and its applications. Journal of  Artificial Intelligence Research, 35(1):193-234, 2009.  M. Elkin, Y. Emek, D.A. Spielman, and S.-H. Teng. Lower-stretch spanning trees. SIAM Journal  on Computing, 38(2):608-628, 2010.  34.12   A CORRELATION CLUSTERING APPROACH TO LINK CLASSIFICATION  G. Facchetti, G. Iacono, and C. Altafini. Computing global structural balance in large-scale signed  social networks. PNAS, 2011.  I. Giotis and V. Guruswami. Correlation clustering with a fixed number of clusters. In Proceedings of the Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1167-1176. ACM, 2006.  R. Guha, R. Kumar, P. Raghavan, and A. Tomkins. Propagation of trust and distrust. In Proceedings  of the 13th international conference on World Wide Web, pages 403-412. ACM, 2004.  F. Harary. On the notion of balance of a signed graph. Michigan Mathematical Journal, 2(2):  143-146, 1953.  F. Heider. Attitude and cognitive organization. J. Psychol, 21:107-122, 1946.  M. Herbster and M. Pontil. Prediction on a graph with the Perceptron. Information Processing Systems 21, pages 577-584. MIT Press, 2007.  In Advances in Neural  Y.P. Hou. Bounds for the least Laplacian eigenvalue of a signed graph. Acta Mathematica Sinica,  21(4):955-960, 2005.  J. Kunegis, A. Lommatzsch, and C. Bauckhage. The Slashdot Zoo: Mining a social network with negative edges. In Proceedings of the 18th International Conference on World Wide Web, pages 741-750. ACM, 2009.  J. Leskovec, D. Huttenlocher, and J. Kleinberg. Signed networks in social media. In Proceedings of the 28th International Conference on Human Factors in Computing Systems, pages 1361-1370. ACM, 2010a.  J. Leskovec, D. Huttenlocher, and J. Kleinberg. Predicting positive and negative links in online social networks. In Proceedings of the 19th International Conference on World Wide Web, pages 641-650. ACM, 2010b.  N. Littlestone. Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms. PhD thesis,  University of California at Santa Cruz, 1989.  N. Littlestone and M.K. Warmuth. The weighted majority algorithm. Information and Computation,  108:212-261, 1994.  R. Lyons and Y. Peres. Probability on trees and networks. Manuscript, 2009.  U. Von Luxburg. A tutorial on spectral clustering. Statistics and Computing, 17(4):395-416, 2007.  "}, "Spectral Clustering of Graphs with General Degrees in the Extended Planted Partition Model": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Spectral Clustering of Graphs with General Degrees in the Extended Planted Partition Model", "abstract": "In this paper, we examine a spectral clustering algorithm for similarity graphs drawn from a simple random graph model, where nodes are allowed to have varying degrees, and we provide theoretical bounds on its performance. The random graph model we study is the Extended Planted Partition (EPP) model, a variant of the classical planted partition model. The standard approach to spectral clustering of graphs is to compute the bottom \\emphk singular vectors or eigenvectors of a suitable graph Laplacian, project the nodes of the graph onto these vectors, and then use an iterative clustering algorithm on the projected nodes. However a challenge with applying this approach to graphs generated from the EPP model is that unnormalized Laplacians do not work, and normalized Laplacians do not concentrate well when the graph has a number of low degree nodes. We resolve this issue by introducing the notion of a degree-corrected graph Laplacian. For graphs with many low degree nodes, degree correction has a regularizing effect on the Laplacian. Our spectral clustering algorithm projects the nodes in the graph onto the bottom \\emphk right singular vectors of the degree-corrected random-walk Laplacian, and clusters the nodes in this subspace. We show guarantees on the performance of this algorithm, demonstrating that it outputs the correct partition under a wide range of parameter values. Unlike some previous work, our algorithm does not require access to any generative parameters of the model.", "pdf_url": "http://proceedings.mlr.press/v23/chaudhuri12/chaudhuri12.pdf", "keywords": ["Spectral clustering", "unsupervised learning", "normalized Laplacian"], "reference": "D. Achiloptas and F. McSherry. On spectral learning of mixtures of distributions. In Proceedings  of the 18th Annual Conference on Learning Theory, pages 458-469, Bertinoro, Italy, 2005.  S. Arora and R. Kannan. Learning mixtures of arbitrary Gaussians. In Proceedings of the 33rd  Annual Symposium on Theory of Computing, pages 247-257, Heraklion, Greece, 2001.  S. Balakrishnan, M. Xu, A. Krishnamurthy, and A. Singh. Noise thresholds for spectral clustering.  In Advances in Neural Information Processing Systems, 2011.  R. B. Boppana. Eigenvalues and graph bisection: An average-case analysis.  In Proceedings of the 28th Annual Symposium on Foundations of Computer Science, pages 280-285, Los Angeles, California, 1987.  N. H. Bshouty and P. Long. Finding planted partitions in nearly linear time using arrested spectral In Proceedings of the 27th International Conference on Machine Learning, pages  clustering. 135-142, Haifa, Israel, 2010.  K. Chaudhuri and S. Rao. Learning mixtures of product distributions using correlations and in- dependence. In Proceedings of the 21st Annual Conference on Learning Theory, pages 9-20, Helsinki, Finland, 2008.  D. Choi, P. Wolfe, and E. Airoldi. Stochastic blockmodels with growing number of classes.  Biometrika, 2011.  F. Chung. Spectral Graph Theory. American Mathematical Society, Providence, RI, 1997.  F. Chung and L. Lu. Complex Graphs and Networks. American Mathematical Society, Boston,  Massachusetts, 2006.  binatorics, 18(1), 2011.  F. Chung and M. Radcliffe. On the spectra of general random graphs. Electronic Journal of Com-  A. Coja-Oghlan and A. Lanka. Finding planted partitions in random graphs with general degree  distributions. Journal on Discrete Mathematics, 23(4):1682-1714, 2009.  A. Condon and R. M. Karp. Algorithms for graph partitioning on the planted partition model.  Random Structures and Algorithms, 18(2):116-140, 2001.  T. M. Cover and J. A. Thomas. Elements of Information Theory, 2nd Edition. Wiley, New York,  2006.  A. Dasgupta, J. E. Hopcroft, and F. McSherry. Spectral analysis of random graphs with skewed degree distributions. In Proceedings of the 45th Annual Symposium on Foundations of Computer Science, pages 602-610, Rome, Italy, 2004.  W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the  American Statistical Association, 58(301):13-30, 1963.  35.13   SPECTRAL CLUSTERING OF GRAPHS WITH GENERAL DEGREES IN THE EXTENDED PLANTED PARTITION MODEL  References  D. Achiloptas and F. McSherry. On spectral learning of mixtures of distributions. In Proceedings  of the 18th Annual Conference on Learning Theory, pages 458-469, Bertinoro, Italy, 2005.  S. Arora and R. Kannan. Learning mixtures of arbitrary Gaussians. In Proceedings of the 33rd  Annual Symposium on Theory of Computing, pages 247-257, Heraklion, Greece, 2001.  S. Balakrishnan, M. Xu, A. Krishnamurthy, and A. Singh. Noise thresholds for spectral clustering.  In Advances in Neural Information Processing Systems, 2011.  R. B. Boppana. Eigenvalues and graph bisection: An average-case analysis.  In Proceedings of the 28th Annual Symposium on Foundations of Computer Science, pages 280-285, Los Angeles, California, 1987.  N. H. Bshouty and P. Long. Finding planted partitions in nearly linear time using arrested spectral In Proceedings of the 27th International Conference on Machine Learning, pages  clustering. 135-142, Haifa, Israel, 2010.  K. Chaudhuri and S. Rao. Learning mixtures of product distributions using correlations and in- dependence. In Proceedings of the 21st Annual Conference on Learning Theory, pages 9-20, Helsinki, Finland, 2008.  D. Choi, P. Wolfe, and E. Airoldi. Stochastic blockmodels with growing number of classes.  Biometrika, 2011.  F. Chung. Spectral Graph Theory. American Mathematical Society, Providence, RI, 1997.  F. Chung and L. Lu. Complex Graphs and Networks. American Mathematical Society, Boston,  Massachusetts, 2006.  binatorics, 18(1), 2011.  F. Chung and M. Radcliffe. On the spectra of general random graphs. Electronic Journal of Com-  A. Coja-Oghlan and A. Lanka. Finding planted partitions in random graphs with general degree  distributions. Journal on Discrete Mathematics, 23(4):1682-1714, 2009.  A. Condon and R. M. Karp. Algorithms for graph partitioning on the planted partition model.  Random Structures and Algorithms, 18(2):116-140, 2001.  T. M. Cover and J. A. Thomas. Elements of Information Theory, 2nd Edition. Wiley, New York,  2006.  A. Dasgupta, J. E. Hopcroft, and F. McSherry. Spectral analysis of random graphs with skewed degree distributions. In Proceedings of the 45th Annual Symposium on Foundations of Computer Science, pages 602-610, Rome, Italy, 2004.  W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the  American Statistical Association, 58(301):13-30, 1963.  35.13   CHAUDHURI CHUNG TSIATAS  M. Jerrum and G. B. Sorkin. Simulated annealing for graph bisection. In Proceedings of the 34th Annual Symposium on Foundations of Computer Science, pages 94-103, Washington, DC, 1993.  R. Kannan, H. Salmasian, and S. Vempala. The spectral method for general mixture models. In Proceedings of the 18th Annual Conference on Learning Theory, pages 444-457, Bertinoro, Italy, 2005.  B. Karrer and M. E. J. Newman. Stochastic blockmodels and community structure in networks.  Physical Review E, 83(1):016107, 2011.  A. Kumar and R. Kannan. Clustering with spectral norm and the k-means algorithm. In Proceedings of the 51st Annual Symposium on Foundations of Computer Science, pages 299-308, Las Vegas, Nevada, 2010.  F. McSherry. Spectral partitioning of random graphs. In Proceedings of the 42nd Annual Symposium  on Foundations of Computer Science, pages 529-537, Las Vegas, Nevada, 2001.  M. Mihail and C. H. Papadimitriou. On the eigenvalue power law. In Proceedings of the 6th Intera- tional Workshop on Randomization and Approximation Techniques, pages 254-262, Cambridge, Massachusetts, 2002.  A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral clustering: analysis and an algorithm. Advances  in Neural Information Processing Systems, 14(2):849-856, 2002.  R. I. Oliviera. Concentration of the adjacency matrix and of the laplacian in random graphs with  independent edges. Available at arXiv:0911.0600, 2010.  K. Rohe, S. Chatterjee, and B. Yu. Spectral clustering and the high-dimensional stochastic block-  model. Annals of Statistics, 39(4):1878-1915, 2011.  J. Shi and J. Malik. Normalized cuts and image segmentation.  IEEE Transactions on Pattern  Analysis and Machine Intelligence, 22(8):888-905, 2000.  J. A. Tropp. User-friendly tail bounds for sums of random matrices. Found. Comput. Math., 2011.  U. von Luxburg. A tutorial on spectral clustering. Statistics and Computing, 17(4):395-416, 2007.  U. von Luxburg, M. Belkin, and O. Bousquet. Consistency of spectral clustering. Ann. Statist., 36  (2):555-586, 2008. ISSN 0090-5364. doi: 10.1214/009053607000000640.  "}, "Toward Understanding Complex Spaces: Graph Laplacians on Manifolds with Singularities and Boundaries": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Toward Understanding Complex Spaces: Graph Laplacians on Manifolds with Singularities and Boundaries", "abstract": "In manifold learning, algorithms based on graph Laplacian constructed from data have received considerable attention both in practical applications and theoretical analysis. Much of the existing work has been done under the assumption that the data is sampled from a manifold without boundaries and singularities or that the functions of interest are evaluated away from such points. At the same time, it can be argued that singularities and boundaries are an important aspect of the geometry of realistic data. Boundaries occur whenever the process generating data has a bounding constraint; while singularities appear when two different manifolds intersect or if a process undergoes a \u201cphase transition\", changing non-smoothly as a function of a parameter. In this paper we consider the behavior of graph Laplacians at points at or near boundaries and two main types of other singularities: , where different manifolds come together and sharp , where a manifold sharply changes direction. We show that the behavior of graph Laplacian near these singularities is quite different from that in the interior of the manifolds. In fact, a phenomenon somewhat reminiscent of the Gibbs effect in the analysis of Fourier series, can be observed in the behavior of graph Laplacian near such points. Unlike in the interior of the domain, where graph Laplacian converges to the Laplace-Beltrami operator, near singularities graph Laplacian tends to a first-order differential operator, which exhibits different scaling behavior as a function of the kernel width. One important implication is that while points near the singularities occupy only a small part of the total volume, the difference in scaling results in a disproportionately large contribution to the total behavior. Another significant finding is that while the scaling behavior of the operator is the same near different types of singularities, they are very distinct at a more refined level of analysis. We believe that a comprehensive understanding of these structures in addition to the standard case of a smooth manifold can take us a long way toward better methods for analysis of complex non-linear data and can lead to significant progress in algorithm design.", "pdf_url": "http://proceedings.mlr.press/v23/belkin12/belkin12.pdf", "keywords": ["Graph Laplacian", "singularities", "limit analysis"], "reference": "M. Aanjaneya, F. Chazal, D. Chen, M. Glisse, L. Guibas, and D. Morozov. Metric graph recon-  struction from noisy data. In Proc. 27th Sympos. Comput. Geom., pages 37-46, 2011.  M. Belkin. Problems of learning on manifold. PhD thesis, University of Chicago, 2003.  M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation.  Neural Comp, 15(6):1373-1396, 2003.  M. Belkin and P. Niyogi. Convergence of laplacian eigenmaps. preprint, short version appeared in  NIPS 2007, 2008a.  M. Belkin and P. Niyogi. Towards a theoretical foundation for laplacian-based manifold methods.  Journal of Computer and System Sciences, 74(8):1289-1308, 2008b.  P. Bendich, B. Wang, and S. Mukherjee. Local homology transfer and stratification learning. In  Proceedings of ACM-SIAM Symposium on Discrete Algorithms, 2012.  O. Chapelle, B. Sch\u00a8olkopf, and A. Zien. Semi-supervised Learning. MIT Press, 2006.  F. Chazal and S. Oudot. Towards persistence-based reconstruction in Euclidean spaces. In Proc.  24th ACM Sympos. on Comput. Geom., pages 232-241, 2008.  F. Chazal, D. Cohen-Steiner, and A. Lieutier. A sampling theory for compact sets in euclidean  space. Discrete & Computational Geometry, 41(3):461-479, 2009.  G. Chen and G. Lerman. Foundations of a multi-way spectral clustering framework for hybrid linear  modeling. Foundations of Computational Mathematics, 9(5):517-558, 2009.  R. R. Coifman and S. Lafon. Diffusion maps. Applied and Computational Harmonic Analysis, 21  (1):5-30, 2006.  E. Gin\u00b4e and V. Koltchinskii. Empirical graph laplacian approximation of laplace-beltrami operators:  Large sample results. 51:238-259, 2006.  A. Goldberg, X. Zhu, A. Singh, Z. Xu, , and R. Nowak. Multi-manifold semi-supervised learning.  In Artificial Intelligence and Statistics, AISTATS, 2009.  A. Grigor\u2019yan. Heat kernels on weighted manifolds and applications. Cont. Math., 398:93-191,  2006.  W. H\u00a8ardle. Applied Nonparametric Regression. Cambridge Univeristy Press, 1992.  G. Haro, G. Randall, and G. Sapiro. Translated poisson mixture model for stratification learning.  International Journal of Computer Vision, 80(3):358-374, 2008.  M. Hein. Geometrical aspects of statistical learning theory. PhD thesis, Wissenschaftlicher Mitar- beiter am Max-Planck-Institut f\u00a8ur biologische Kybernetik in T\u00a8ubingen in der Abteilung, 2005.  M. Hein, J. yves Audibert, and U. V. Luxburg. Graph laplacians and their convergence on random  neighborhood graphs. Journal of Machine Learning Research, 8:1325-1368, 2007.  36.13   GRAPH LAPLACIANS ON SINGULAR MANIFOLDS  References  M. Aanjaneya, F. Chazal, D. Chen, M. Glisse, L. Guibas, and D. Morozov. Metric graph recon-  struction from noisy data. In Proc. 27th Sympos. Comput. Geom., pages 37-46, 2011.  M. Belkin. Problems of learning on manifold. PhD thesis, University of Chicago, 2003.  M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation.  Neural Comp, 15(6):1373-1396, 2003.  M. Belkin and P. Niyogi. Convergence of laplacian eigenmaps. preprint, short version appeared in  NIPS 2007, 2008a.  M. Belkin and P. Niyogi. Towards a theoretical foundation for laplacian-based manifold methods.  Journal of Computer and System Sciences, 74(8):1289-1308, 2008b.  P. Bendich, B. Wang, and S. Mukherjee. Local homology transfer and stratification learning. In  Proceedings of ACM-SIAM Symposium on Discrete Algorithms, 2012.  O. Chapelle, B. Sch\u00a8olkopf, and A. Zien. Semi-supervised Learning. MIT Press, 2006.  F. Chazal and S. Oudot. Towards persistence-based reconstruction in Euclidean spaces. In Proc.  24th ACM Sympos. on Comput. Geom., pages 232-241, 2008.  F. Chazal, D. Cohen-Steiner, and A. Lieutier. A sampling theory for compact sets in euclidean  space. Discrete & Computational Geometry, 41(3):461-479, 2009.  G. Chen and G. Lerman. Foundations of a multi-way spectral clustering framework for hybrid linear  modeling. Foundations of Computational Mathematics, 9(5):517-558, 2009.  R. R. Coifman and S. Lafon. Diffusion maps. Applied and Computational Harmonic Analysis, 21  (1):5-30, 2006.  E. Gin\u00b4e and V. Koltchinskii. Empirical graph laplacian approximation of laplace-beltrami operators:  Large sample results. 51:238-259, 2006.  A. Goldberg, X. Zhu, A. Singh, Z. Xu, , and R. Nowak. Multi-manifold semi-supervised learning.  In Artificial Intelligence and Statistics, AISTATS, 2009.  A. Grigor\u2019yan. Heat kernels on weighted manifolds and applications. Cont. Math., 398:93-191,  2006.  W. H\u00a8ardle. Applied Nonparametric Regression. Cambridge Univeristy Press, 1992.  G. Haro, G. Randall, and G. Sapiro. Translated poisson mixture model for stratification learning.  International Journal of Computer Vision, 80(3):358-374, 2008.  M. Hein. Geometrical aspects of statistical learning theory. PhD thesis, Wissenschaftlicher Mitar- beiter am Max-Planck-Institut f\u00a8ur biologische Kybernetik in T\u00a8ubingen in der Abteilung, 2005.  M. Hein, J. yves Audibert, and U. V. Luxburg. Graph laplacians and their convergence on random  neighborhood graphs. Journal of Machine Learning Research, 8:1325-1368, 2007.  36.13   BELKIN QUE WANG ZHOU  S. Lafon. Diffusion Maps and Geodesic Harmonics. PhD thesis, Yale University, 2004.  G. Lerman and T. Zhang. Probabilistic recovery of multiple subspaces in point clouds by geometric  lp minimization, 2010.  P. Niyogi, S. Smale, and S. Weinberger. Finding the homology of submanifolds with high confidence  from random samples. Discrete & Computational Geometry, 39(1-3):419-441, 2008.  P. Niyogi, S. Smale, and S. Weinberger. A topological view of unsupervised learning from noisy  data. SIAM J. Comput., 40(3):646-663, 2011.  S. T. Roweis and L. K. Saul. Nonlinear dimensionality reduction by locally linear embedding.  Science, 290(5500):2323-2326, 2000.  A. Singer. From graph to manifold laplacian: The convergence rate. Appl. Comput. Harmon. Anal.,  21:128-134, 2006.  J. B. Tenenbaum, V. de Silva, and J. C. Langford. A global geometric framework for nonlinear  dimensionality reduction. Science, 290(5500):2319-2323, 2000.  R. Vidal, Y. Ma, and S. Sastry. Generalized principal component analysis (gpca). IEEE Transactions  on Pattern Analysis and Machine Intelligence, pages 1945-1959, 2005.  U. von Luxburg. A tutorial on spectral clustering. In Statistics and Computing, volume 17, pages  X. Zhu. Semi-supervised learning literature survey. Computer Science, University of Wisconsin-  395-416, 2007.  Madison, 2006.  36.14   GRAPH LAPLACIANS ON SINGULAR MANIFOLDS  "}, "Exact Recovery of Sparsely-Used Dictionaries": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Exact Recovery of Sparsely-Used Dictionaries", "abstract": "We consider the problem of learning sparsely used dictionaries with an arbitrary square dictionary and a random, sparse coefficient matrix. We prove that \\emphO(n log \\emphn) samples are sufficient to uniquely determine the coefficient matrix. Based on this proof, we design a polynomial-time algorithm, called Exact Recovery of Sparsely-Used Dictionaries (ER-SpUD), and prove that it probably recovers the dictionary and coefficient matrix when the coefficient matrix is sufficiently sparse. Simulation results show that ER-SpUD reveals the true dictionary as well as the coefficients with probability higher than many state-of-the-art algorithms.", "pdf_url": "http://proceedings.mlr.press/v23/spielman12/spielman12.pdf", "keywords": ["Dictionary learning", "matrix decomposition", "matrix sparsification"], "reference": "[1] M. Aharon, M. Elad, and A. Bruckstein. The K-SVD: An algorithm for designing overcom- plete dictionaries for sparse representation. IEEE Transactions on Signal Processing, 54(11): 4311-4322, 2006.  37.12   SPIELMAN WANG WRIGHT  (a) ER-SpUD(SC)  (b) SIV  (c) K-SVD  (d) Online  (e) Rel. Newton  Figure 1: Mean relative errors over 10 trials, with varying support k (y-axis, increase from bottom to top) and basis size n(x-axis, increase from left to right). Here, p = 5n loge n. Our algorithm using a column of Y as r (ER-SpUD), SIV [9], K-SVD [1], online dictionary learning [14], and the relative Newton method for source separation [21].  9. Discussion  The main contribution of this work is a dictionary learning algorithm with provable performance guarantees under a random coefficient model. To our knowledge, this result is the first of its kind. However, it has two clear limitations: the algorithm requires that the reconstruction be exact, i.e., Y = AX and it requires A to be square. It would be interesting to address both of these issues (see also [2] for investigation in this direction). Finally, while our results pertain to a specific coefficient model, our analysis generalizes to other distributions. Seeking meaningful, deterministic assumptions on X that will allow correct recovery is another interesting direction for future work.  This material is based in part upon work supported by the National Science Foundation under Grant No. 0915487. JW also acknowledges support from Columbia University.  Acknowledgments  References  [1] M. Aharon, M. Elad, and A. Bruckstein. The K-SVD: An algorithm for designing overcom- plete dictionaries for sparse representation. IEEE Transactions on Signal Processing, 54(11): 4311-4322, 2006.  37.12   ER-SPUD  [2] F. Bach, J. Mairal, and J. Ponce.  Techni- cal report, Technical report HAL-00345747, http://hal.archives-ouvertes.fr/ hal-00354771/fr/, 2008.  Convex sparse matrix factorizations.  [3] A. M. Bruckstein, D. L. Donoho, and M. Elad. From sparse solutions of systems of equations  to sparse modeling of signals and images. SIAM Review, 51(1):34-81, 2009.  [4] P. Comon. Independent component analysis: A new concept? Signal Processing, 36:287-314,  1994.  [5] K. Engan, S. Aase, and J. Hakon-Husoy. Method of optimal directions for frame design. In  ICASSP, volume 5, pages 2443-2446, 1999.  [6] P. Erd\u00a8os. On a lemma of Littlewood and Offord. Bulletin of the American Mathematical  Society, 51:898-902, 1945.  CoRR, 2011.  [7] Q. Geng and J. Wright. On the local correctness of (cid:96)1 minimization for dictionary learning.  [8] P. Georgiev, F. Theis, and A. Cichocki. Sparse component analysis and blind source separation  of underdetermined mixtures. IEEE Transactions on Neural Networks, 16(4), 2005.  [9] L.-A. Gottlieb and T. Neylon. Matrix sparsication and the sparse null space problem. APPROX  and RANDOM, 6302:205-218, 2010.  [10] R. Gribonval and K. Schnass. Dictionary identification-sparse matrix-factorisation via l1-  minimisation. IEEE Transactions on Information Theory, 56(7):3523-3539, 2010.  [11] F. Jaillet, R. Gribonval, M. Plumbley, and H. Zayyani. An l1 criterion for dictionary learning by subspace identification. In IEEE Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 5482-5485, 2010.  [12] K. Kreutz-Delgado, J. Murray, B. Rao, K. Engan, T. Lee, and T. Sejnowski. Dictionary learn- ing algorithms for sparse representation. Neural Computation, 15(20):349-396, 2003.  [13] M. E. M. Aharon and A. Bruckstein. On the uniqueness of overcomplete dictionaries, and a practical way to retrieve them. Linear Algebra and its Applications, 416:48-67, 2006.  [14] J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary learning for sparse coding. Proceedings of the 26th Annual International Conference on Machine Learning, pages 689- 696, 2009.  [15] J. Matousek.  On variants of the johnson-lindenstrauss lemma. Wiley InterScience  (www.interscience.wiley.com).  [16] B. Olshausen and D. Field. Emergence of simple-cell receptive field properties by learning a  sparse code for natural images. Nature, 381(6538):607-609, 1996.  [17] M. Plumbley. Dictionary learning for (cid:96)1-exact sparse coding.  In Independent Component  Analysis and Signal Separation, pages 406-413, 2007.  37.13   SPIELMAN WANG WRIGHT  [18] R. Rubinstein, A. Bruckstein, and M. Elad. Dictionaries for sparse representation modeling.  Proceedings of the IEEE, 98(6):1045-1057, 2010.  [19] D. Vainsencher, S. Mannor, and A. Bruckstein. The sample complexity of dictionary learning.  In Proc. Conference on Learning Theory, 2011.  [20] J. Yang, J. Wright, T. Huang, and Y. Ma. Image super-resolution via sparse representation.  IEEE Transactions on Image Processing, 19(11):2861-2873, 2010.  [21] M. Zibulevsky. Blind source separation with relative newton method. Proceedings ICA, pages  897-902, 2003.  Computation, 13(4), 2001.  [22] M. Zibulevsky and B. Pearlmutter. Blind source separation by sparse decomposition. Neural  "}, "Near-Optimal Algorithms for Online Matrix Prediction": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Near-Optimal Algorithms for Online Matrix Prediction", "abstract": "In several online prediction problems of recent interest the comparison class is composed of matrices with bounded entries. For example, in the online max-cut problem, the comparison class is matrices which represent cuts of a given graph and in online gambling the comparison class is matrices which represent permutations over n teams. Another important example is online collaborative filtering in which a widely used comparison class is the set of matrices with a small trace norm. In this paper we isolate a property of matrices, which we call (\u03b2,\u03c4)-decomposability, and derive an efficient online learning algorithm, that enjoys a regret bound of \\emph\u00d5(\u221a\u03b2\u03c4T ) for all problems in which the comparison class is composed of (\u03b2,\u03c4)-decomposable matrices. By analyzing the decomposability of cut matrices, low trace-norm matrices and triangular matrices, we derive near optimal regret bounds for online max-cut, online collaborative filtering and online gambling. In particular, this resolves (in the affirmative) an open problem posed by Abernethy (2010); Kleinberg et al. (2010). Finally, we derive lower bounds for the three problems and show that our upper bounds are optimal up to logarithmic factors. In particular, our lower bound for the online collaborative filtering problem resolves another open problem posed by Shamir and Srebro (2011).", "pdf_url": "http://proceedings.mlr.press/v23/hazan12b/hazan12b.pdf", "keywords": [], "reference": "J. Abernethy. Can we learn to gamble efficiently? In COLT, 2010. Open Problem.  S. Arora and S. Kale. A combinatorial, primal-dual approach to semidefinite programs. In STOC,  pages 227-236, 2007.  N. Cesa-Bianchi and O. Shamir. Efficient online learning via randomized rounding. In 25th Annual  Conference on Neural Information Processing Systems (NIPS), 2011.  Elad Hazan, Satyen Kale, and Shai Shalev-Shwartz. Near-optimal algorithms for online matrix  prediction. CoRR, abs/1204.0136, 2012.  S. Kakade, S. Shalev-Shwartz, and A. Tewari. Regularization techniques for learning with matrices.  JMLR, 2012.  38.12   HAZAN KALE SHALEV-SHWARTZ  This decomposition is optimal up to constant factors. Consider the matrix W formed by taking m = \u03c4\u221a n rows of an n \u00d7 n Hadamard matrix. In (Hazan et al., 2012) we prove that any (\u03b2, \u02dc\u03c4 )- decomposition of sym(W) must have \u03b2 \u02dc\u03c4 \u2265 1 n. Since the regret bound depends on the product 4 \u03c4 \u03b2 \u02dc\u03c4 , we conclude that the decomposition obtained from Theorem 11 is optimal up to a constant factor.  \u221a  5. Conclusions  In recent years the FTRL (Follow The Regularized Leader) paradigm has become the method of choice for proving regret bounds for online learning problems. In several online learning problems a direct application of this paradigm has failed to give tight regret bounds due to suboptimal \u201ccon- vexification\u201d of the problem. This unsatisfying situation occurred in mainstream applications, such as online collaborative filtering, but also in basic prediction settings such as the online max cut or online gambling settings.  In this paper we single out a common property of these unresolved problems:  they involve structured matrix prediction, in the sense that the matrices involved have certain nice decomposi- tions. We give a unified formulation for three of these structured matrix prediction problems which leads to near-optimal convexification. Applying the standard FTRL algorithm, Matrix Multiplica- tive Weights, now gives efficient and near optimal regret algorithms for these problems. In the process we resolve two COLT open problems. The main conclusion of this paper is that spec- tral analysis in matrix predictions tasks can be surprisingly powerful, even when the connection between the spectrum and the problem may not be obvious on first sight (such as in the online gambling problem).  We leave open the question of bridging the logarithmic gap between known upper and lower bounds for regret in these structured prediction problems. Note that since all the three decom- positions in this paper are optimal up to constant factors, one cannot close the gap by improving the decomposition; some fundamentally different algorithm seems necessary. It would also be in- teresting to see more applications of the (\u03b2, \u03c4 )-decomposition for other online matrix prediction problems.  References  J. Abernethy. Can we learn to gamble efficiently? In COLT, 2010. Open Problem.  S. Arora and S. Kale. A combinatorial, primal-dual approach to semidefinite programs. In STOC,  pages 227-236, 2007.  N. Cesa-Bianchi and O. Shamir. Efficient online learning via randomized rounding. In 25th Annual  Conference on Neural Information Processing Systems (NIPS), 2011.  Elad Hazan, Satyen Kale, and Shai Shalev-Shwartz. Near-optimal algorithms for online matrix  prediction. CoRR, abs/1204.0136, 2012.  S. Kakade, S. Shalev-Shwartz, and A. Tewari. Regularization techniques for learning with matrices.  JMLR, 2012.  38.12   ONLINE MATRIX PREDICTION  V. Kanade and T. Steinke. Learning hurdles for sleeping experts.  In Innovations in Theoretical  Computer Science, 2012.  R. Kleinberg, A. Niculescu-Mizil, and Y. Sharma. Regret bounds for sleeping experts and bandits.  Machine learning, 80(2):245-272, 2010.  O. Shamir and S. Shalev-Shwartz. Collaborative filtering with the trace norm: Learning, bounding,  and transducing. In 24th Annual Conference on Learning Theory (COLT), 2011.  O. Shamir and N. Srebro. Sample complexity of trace-norm? In COLT, 2011. Open Problem.  K. Tsuda, G. Ratsch, and M.K. Warmuth. Matrix exponentiated gradient updates for on-line learning  and bregman projection. Journal of Machine Learning Research, 6(1):995, 2006.  38.13   "}, "Analysis of Thompson Sampling for the Multi-armed Bandit Problem": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Analysis of Thompson Sampling for the Multi-armed Bandit Problem", "abstract": "The multi-armed bandit problem is a popular model for studying exploration/exploitation trade-off in sequential decision problems. Many algorithms are now available for this well-studied problem. One of the earliest algorithms, given by W. R. Thompson, dates back to 1933. This algorithm, referred to as Thompson Sampling, is a natural Bayesian algorithm. The basic idea is to choose an arm to play according to its probability of being the best arm. Thompson Sampling algorithm has experimentally been shown to be close to optimal. In addition, it is efficient to implement and exhibits several desirable properties such as small regret for delayed feedback. However, theoretical understanding of this algorithm was quite limited. In this paper, for the first time, we show that Thompson Sampling algorithm achieves logarithmic expected regret for the stochastic multi-armed bandit problem. More precisely, for the stochastic two-armed bandit problem, the expected regret in time T is O(\\frac\\ln T\u2206 + \\frac1\u2206^3). And, for the stochastic N-armed bandit problem, the expected regret in time T is O(\\left[\\left(\\sum_i=2^N \\frac1\\Delta_i^2\\right)^2\\right] \\ln T). Our bounds are optimal but for the dependence on \\Delta_i and the constant factors in big-Oh.", "pdf_url": "http://proceedings.mlr.press/v23/agrawal12/agrawal12.pdf", "keywords": ["multi-armed bandit", "Thompson Sampling", "Bayesian algorithm", "online learning"], "reference": "P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem.  Machine Learning, 47(2-3):235-256, 2002.  O. Chapelle and L. Li. An empirical evaluation of thompson sampling. In NIPS, 2011.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and beyond. In  Conference on Learning Theory (COLT), 2011.  J. C. Gittins. Multi-armed Bandit Allocation Indices. Wiley Interscience Series in Systems and  Optimization. John Wiley and Son, 1989.  T. Graepel, J. Q. Candela, T. Borchert, and R. Herbrich. Web-scale bayesian click-through rate prediction for sponsored search advertising in microsoft\u2019s bing search engine. In ICML, pages 13-20, 2010.  O.-C. Granmo. Solving two-armed bernoulli bandit problems using a bayesian learning automaton. International Journal of Intelligent Computing and Cybernetics (IJICC), 3(2):207-234, 2010.  K. Jogdeo and S. M. Samuels. Monotone Convergence of Binomial Probabilities and A General- ization of Ramanujan\u2019s equation. The Annals of Mathematical Statistics, (4):1191-1195, 1968.  E. Kaufmann, O. Capp\u00b4e, and A. Garivier. On bayesian upper confidence bounds for bandit prob- In Fifteenth International Conference on Artificial Intelligence and Statistics (AISTAT),  lems. 2012.  T. L. Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Advances in Applied  Mathematics, 6:4-22, 1985.  O.-A. Maillard, R. Munos, and G. Stoltz. Finite-time analysis of multi-armed bandits problems with  kullback-leibler divergences. In Conference on Learning Theory (COLT), 2011.  B. C. May and D. S. Leslie. Simulation studies in optimistic bayesian sampling in contextual-bandit problems. Technical Report 11:02, Statistics Group, Department of Mathematics, University of Bristol, 2011.  B. C. May, N. Korda, A. Lee, and D. S. Leslie. Optimistic bayesian sampling in contextual-bandit problems. Technical Report 11:01, Statistics Group, Department of Mathematics, University of Bristol, 2011.  S. Scott. A modern bayesian look at the multi-armed bandit. Applied Stochastic Models in Business  and Industry, 26:639-658, 2010.  W. R. Thompson. On the likelihood that one unknown probability exceeds another in view of the  evidence of two samples. Biometrika, 25(3-4):285-294, 1933.  39.13   ANALYSIS OF THOMPSON SAMPLING  References  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem.  Machine Learning, 47(2-3):235-256, 2002.  O. Chapelle and L. Li. An empirical evaluation of thompson sampling. In NIPS, 2011.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and beyond. In  Conference on Learning Theory (COLT), 2011.  J. C. Gittins. Multi-armed Bandit Allocation Indices. Wiley Interscience Series in Systems and  Optimization. John Wiley and Son, 1989.  T. Graepel, J. Q. Candela, T. Borchert, and R. Herbrich. Web-scale bayesian click-through rate prediction for sponsored search advertising in microsoft\u2019s bing search engine. In ICML, pages 13-20, 2010.  O.-C. Granmo. Solving two-armed bernoulli bandit problems using a bayesian learning automaton. International Journal of Intelligent Computing and Cybernetics (IJICC), 3(2):207-234, 2010.  K. Jogdeo and S. M. Samuels. Monotone Convergence of Binomial Probabilities and A General- ization of Ramanujan\u2019s equation. The Annals of Mathematical Statistics, (4):1191-1195, 1968.  E. Kaufmann, O. Capp\u00b4e, and A. Garivier. On bayesian upper confidence bounds for bandit prob- In Fifteenth International Conference on Artificial Intelligence and Statistics (AISTAT),  lems. 2012.  T. L. Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Advances in Applied  Mathematics, 6:4-22, 1985.  O.-A. Maillard, R. Munos, and G. Stoltz. Finite-time analysis of multi-armed bandits problems with  kullback-leibler divergences. In Conference on Learning Theory (COLT), 2011.  B. C. May and D. S. Leslie. Simulation studies in optimistic bayesian sampling in contextual-bandit problems. Technical Report 11:02, Statistics Group, Department of Mathematics, University of Bristol, 2011.  B. C. May, N. Korda, A. Lee, and D. S. Leslie. Optimistic bayesian sampling in contextual-bandit problems. Technical Report 11:01, Statistics Group, Department of Mathematics, University of Bristol, 2011.  S. Scott. A modern bayesian look at the multi-armed bandit. Applied Stochastic Models in Business  and Industry, 26:639-658, 2010.  W. R. Thompson. On the likelihood that one unknown probability exceeds another in view of the  evidence of two samples. Biometrika, 25(3-4):285-294, 1933.  39.13   AGRAWAL GOYAL  "}, "Autonomous Exploration For Navigating In MDPs": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Autonomous Exploration For Navigating In MDPs", "abstract": "While intrinsically motivated learning agents hold considerable promise to overcome limitations of more supervised learning systems, quantitative evaluation and theoretical analysis of such agents are difficult. We propose to consider a restricted setting for autonomous learning where systematic evaluation of learning performance is possible. In this setting the agent needs to learn to navigate in a Markov Decision Process where extrinsic rewards are not present or are ignored. We present a learning algorithm for this scenario and evaluate it by the amount of exploration it uses to learn the environment.", "pdf_url": "http://proceedings.mlr.press/v23/lim12/lim12.pdf", "keywords": ["autonomous exploration", "reinforcement learning", "optimism in the face of uncertainty", "computational learning theory"], "reference": "A. Baranes and P.-Y. Oudeyer. R-IAC: Robust Intrinsically Motivated Exploration and Active Learn- ing. IEEE Transactions on Autonomous Mental Development, 1(3):155-169, Oct. 2009. ISSN 1943-0604. doi: 10.1109/TAMD.2009.2037513.  R. I. Brafman and M. Tennenholtz. R-max - a general polynomial time algorithm for near-optimal  reinforcement learning. Journal of Machine Learning Research, 3:213-231, 2002.  T. Jaksch, R. Ortner, and P. Auer. Near-optimal regret bounds for reinforcement learning. J. Mach.  Learn. Res., 99:1563-1600, August 2010. ISSN 1532-4435.  S. M. Kakade. On the Sample Complexity of Reinforcement Learning. PhD thesis, Gatsby Compu-  tationel Neuroscience Unit, University College London, 2003.  M. J. Kearns and S. P. Singh. Near-optimal reinforcement learning in polynominal time. In ICML,  pages 260-268, 1998.  P.-Y. Oudeyer and F. Kaplan. What is Intrinsic Motivation? A Typology of Computational Ap- doi:  proaches. Frontiers in neurorobotics, 1(November):6, Jan. 2007. 10.3389/neuro.12.006.2007.  ISSN 1662-5218.  P.-Y. Oudeyer, F. Kaplan, and V. Hafner. Intrinsic motivation systems for autonomous mental de-  velopment. IEEE Transactions on Evolutionary Computation, 11:265-286, 2007.  J. Schmidhuber. A possibility for implementing curiosity and boredom in model-building neural controllers. In Proceedings of the first international conference on simulation of adaptive behav- ior on From animals to animats, pages 222-227, Cambridge, MA, USA, 1991. MIT Press. ISBN 0-262-63138-5.  40.12   LIM AUER  4.7. Discussion  Our algorithm employs the idea of optimism under uncertainty, which underlies many PAC-MDP algorithms (Kearns and Singh, 1998; Brafman and Tennenholtz, 2002; Kakade, 2003; Strehl et al., 2006; Szita and Szepesv\u00b4ari, 2010). A particular point that we need to clarify is regarding the notion of \u201cknown\u201d states. The meaning of a \u201cknown\u201d state in UcbExplore is very different from that in the R-MAX algorithm (Brafman and Tennenholtz, 2002; Kakade, 2003). In UcbExplore, a state is \u201cknown\u201d if we have learned a good policy to reach it. On the other hand, in R-MAX, a state is \u201cknown\u201d if we have sampled its actions sufficiently often.  It remains an open question if the exploration bound for our algorithm is optimal. One would (cid:17) , but this has not been achieved. New methods  (cid:16) SAL2 expect that the bounds can be improved to \u02dcO (cid:15)2 will be necessary to obtain such an improvement.  We thank the anonymous reviewers for their very valuable comments. The research leading to these results has received funding from the European Community\u2019s Seventh Framework Programme (FP7/2007-2013) under grant agreement n\u25e6 231495 (CompLACS) and n\u25e6 216886 (PASCAL2).  Acknowledgements  References  A. Baranes and P.-Y. Oudeyer. R-IAC: Robust Intrinsically Motivated Exploration and Active Learn- ing. IEEE Transactions on Autonomous Mental Development, 1(3):155-169, Oct. 2009. ISSN 1943-0604. doi: 10.1109/TAMD.2009.2037513.  R. I. Brafman and M. Tennenholtz. R-max - a general polynomial time algorithm for near-optimal  reinforcement learning. Journal of Machine Learning Research, 3:213-231, 2002.  T. Jaksch, R. Ortner, and P. Auer. Near-optimal regret bounds for reinforcement learning. J. Mach.  Learn. Res., 99:1563-1600, August 2010. ISSN 1532-4435.  S. M. Kakade. On the Sample Complexity of Reinforcement Learning. PhD thesis, Gatsby Compu-  tationel Neuroscience Unit, University College London, 2003.  M. J. Kearns and S. P. Singh. Near-optimal reinforcement learning in polynominal time. In ICML,  pages 260-268, 1998.  P.-Y. Oudeyer and F. Kaplan. What is Intrinsic Motivation? A Typology of Computational Ap- doi:  proaches. Frontiers in neurorobotics, 1(November):6, Jan. 2007. 10.3389/neuro.12.006.2007.  ISSN 1662-5218.  P.-Y. Oudeyer, F. Kaplan, and V. Hafner. Intrinsic motivation systems for autonomous mental de-  velopment. IEEE Transactions on Evolutionary Computation, 11:265-286, 2007.  J. Schmidhuber. A possibility for implementing curiosity and boredom in model-building neural controllers. In Proceedings of the first international conference on simulation of adaptive behav- ior on From animals to animats, pages 222-227, Cambridge, MA, USA, 1991. MIT Press. ISBN 0-262-63138-5.  40.12   AUTONOMOUS EXPLORATION FOR NAVIGATING IN MDPS  J. Schmidhuber. Formal theory of creativity, fun, and intrinsic motivation (19902010). Autonomous  Mental Development, IEEE Transactions on, 2(3):230-247, 2010.  S. P. Singh, A. G. Barto, and N. Chentanez. Intrinsically motivated reinforcement learning. In NIPS,  2004.  S. P. Singh, R. L. Lewis, A. G. Barto, and J. Sorg. Intrinsically motivated reinforcement learning:  An evolutionary perspective. IEEE T. Autonomous Mental Development, 2(2):70-82, 2010.  A. L. Strehl, L. Li, E. Wiewiora, J. Langford, and M. L. Littman. Pac model-free reinforcement  learning. In ICML, pages 881-888, 2006.  I. Szita and C. Szepesv\u00b4ari. Model-based reinforcement learning with nearly tight exploration com-  plexity bounds. In ICML, pages 1031-1038, 2010.  "}, "Towards Minimax Policies for Online Linear Optimization with Bandit Feedback": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Towards Minimax Policies for Online Linear Optimization with Bandit Feedback", "abstract": "We address the online linear optimization problem with bandit feedback. Our contribution is twofold. First, we provide an algorithm (based on exponential weights) with a regret of order $\\sqrt{dn \\log N}$ for any finite action set with $N$ actions, under the assumption that the instantaneous loss is bounded by 1. This shaves off an extraneous $\\sqrt{d}$ factor compared to previous works, and gives a regret bound of order $d\\sqrt{n \\log n}$ for any compact set of actions. Without further assumptions on the action set, this last bound is minimax optimal up to a logarithmic factor. Interestingly, our result also shows that the minimax regret for bandit linear optimization with expert advice in $d$ dimension is the same as for the basic $d$-armed bandit with expert advice. Our second contribution is to show how to use the Mirror Descent algorithm to obtain computationally efficient strategies with minimax optimal regret bounds in specific examples. More precisely we study two canonical action sets: the hypercube and the Euclidean ball. In the former case, we obtain the first computationally efficient algorithm with a $d\\sqrt{n}$ regret, thus improving by a factor $\\sqrt{d \\log n}$ over the best known result for a computationally efficient algorithm. In the latter case, our approach gives the first algorithm with a $\\sqrt{dn \\log n}$, again shaving off an extraneous $\\sqrt{d}$ compared to previous works.", "pdf_url": "http://proceedings.mlr.press/v23/bubeck12a/bubeck12a.pdf", "keywords": ["online linear optimization", "multi-armed bandits", "linear bandits with expert advice", "minimax regret", "exponential weights", "mirror descent"], "reference": "J. Abernethy and A. Rakhlin. Beating the adaptive bandit with high probability. In Proceedings of  the 22nd Annual Conference on Learning Theory (COLT), 2009.  J. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An efficient algorithm for bandit linear optimization. In Proceedings of the 21st Annual Conference on Learning Theory (COLT), pages 263-274, 2008.  41.12   BUBECK CESA-BIANCHI KAKADE  Let \u0398(u, v) such that DF \u2217(u, v) = 1  1+(cid:107)v(cid:107) \u0398(u, v). First note that  1 1 + (cid:107)\u2207F (at)(cid:107) (cid:1). Thus, in order to prove (7) it remains to show that \u0398(u, v) \u2264 (cid:107)u\u2212v(cid:107)2, for (u, v) = (cid:0)\u2212\u03b7(cid:101)zt 1, \u2212\u03b7(cid:101)zt\u22121 In fact we shall prove that this inequality holds true as soon as (cid:107)u(cid:107)\u2212(cid:107)v(cid:107) 2 . This is the case for the pair (u, v) under consideration, since by the triangle inequality, equations (6) and (10), and the assumption on \u03b7:  1+(cid:107)v(cid:107) \u2265 \u2212 1  = 1 \u2212 (cid:107)at(cid:107) .  (10)Now using that log(1 + x) \u2265 x \u2212 x2, \u2200x \u2265 \u2212 1  (cid:107)u(cid:107) \u2212 (cid:107)v(cid:107) 1 + (cid:107)v(cid:107)  \u2265 \u2212  \u2265 \u2212\u03b7d \u2265 \u2212  \u03b7(cid:107)(cid:101)zt(cid:107) 1 1 + (cid:107)v(cid:107) 2 2 , we obtain that for u, v such that (cid:107)u(cid:107)\u2212(cid:107)v(cid:107)  .  1+(cid:107)v(cid:107) \u2265 \u2212 1 2 ,  \u0398(u, v) \u2264  + (cid:107)u(cid:107) \u00b7 (cid:107)v(cid:107) \u2212 v(cid:62)u  ((cid:107)u(cid:107) \u2212 (cid:107)v(cid:107))2 1 + (cid:107)v(cid:107)  \u2264 ((cid:107)u(cid:107) \u2212 (cid:107)v(cid:107))2 + (cid:107)u(cid:107) \u00b7 (cid:107)v(cid:107) \u2212 v(cid:62)u = (cid:107)u(cid:107)2 + (cid:107)v(cid:107)2 \u2212 (cid:107)u(cid:107) \u00b7 (cid:107)v(cid:107) \u2212 v(cid:62)u = (cid:107)u \u2212 v(cid:107)2 + 2v(cid:62)u \u2212 (cid:107)u(cid:107) \u00b7 (cid:107)v(cid:107) \u2212 v(cid:62)u \u2264 (cid:107)u \u2212 v(cid:107)2  which concludes the proof of (7). Now for the proof of (8) it suffices to note that:  E  (cid:104)(cid:0)1 \u2212 (cid:107)at(cid:107)(cid:1)(cid:107)(cid:101)zt(cid:107)2(cid:105)  = (1 \u2212 (cid:107)at(cid:107))  d (cid:88)  i=1  1 \u2212 (cid:107)at(cid:107) d  d2 (1 \u2212 (cid:107)at(cid:107))2 (z(cid:62)  t ei)2 = d(cid:107)zt(cid:107)2 \u2264 d  along with straightforward computations.  Acknowledgments  We warmly thank the COLT reviewers for their careful reading and insightful comments. The first author would like to thank Csaba Szepesv\u00b4ari for bringing to his attention the problem of optimal regret on the Euclidean ball, as well as Alexander Rakhlin for illuminating discussions regarding sampling schemes. He also thanks Ramon Van Handel, Vianney Perchet and Philippe Rigollet for stimulating discussions on this topic. The second author gratefully acknowledges partial support by the PASCAL2 Network of Excellence under EC grant no. 216886. This publication only re\ufb02ects the authors\u2019 views.  References  J. Abernethy and A. Rakhlin. Beating the adaptive bandit with high probability. In Proceedings of  the 22nd Annual Conference on Learning Theory (COLT), 2009.  J. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An efficient algorithm for bandit linear optimization. In Proceedings of the 21st Annual Conference on Learning Theory (COLT), pages 263-274, 2008.  41.12   TOWARDS MINIMAX POLICIES FOR ONLINE LINEAR OPTIMIZATION WITH BANDIT FEEDBACK  A. Agarwal, O. Dekel, and L. Xiao. Optimal algorithms for online convex optimization with multi-point bandit feedback. In Proceedings of the 23rd Annual Conference on Learning Theory (COLT), 2010.  J.-Y. Audibert and S. Bubeck. Minimax policies for adversarial and stochastic bandits. In Proceed-  ings of the 22nd Annual Conference on Learning Theory (COLT), 2009.  J.-Y. Audibert and S. Bubeck. Regret bounds and minimax policies under partial monitoring. Jour-  nal of Machine Learning Research, 11:2635-2686, 2010.  J.-Y. Audibert, S. Bubeck, and G. Lugosi. Minimax policies for combinatorial prediction games. In  Proceedings of the 24th Annual Conference on Learning Theory (COLT), 2011.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. Schapire. The non-stochastic multi-armed bandit  problem. SIAM Journal on Computing, 32(1):48-77, 2002.  B. Awerbuch and R. Kleinberg. Adaptive routing with end-to-end feedback: distributed learning and geometric approaches. In STOC \u201904: Proceedings of the thirty-sixth annual ACM symposium on Theory of computing, pages 45-53, 2004.  K. Ball. An elementary introduction to modern convex geometry. In S. Levy, editor, Flavors of  Geometry, pages 1-58. Cambridge University Press, 1997.  S. Bubeck. Introduction to online optimization. Lecture Notes, 2011.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press,  N. Cesa-Bianchi and G. Lugosi. Combinatorial bandits. Journal of Computer and System Sciences,  2006.  2011. To appear.  W. Chu, L. Li, L. Reyzin, and R.E. Schapire. Contextual bandits with linear payoff functions. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics. JMLR Conference and Workshop Proceedings, 2011.  V. Dani, T. Hayes, and S. Kakade. The price of bandit information for online optimization.  In  Advances in Neural Information Processing Systems (NIPS), volume 20, pages 345-352, 2008.  Martin Gr\u00a8otschel, L\u00b4aszlo Lov\u00b4asz, and Alexander Schrijver. Geometric Algorithms and Combinato- rial Optimization, volume 2 of Algorithms and Combinatorics. Springer, second corrected edition edition, 1993. ISBN 3-540-56740-2, 0-387-56740-2 (U.S.).  E. Hazan. The convex optimization approach to regret minimization. In S. Sra, S. Nowozin, and  S. Wright, editors, Optimization for Machine Learning, pages 287-303. MIT press, 2011.  S. Kakade, S. Shalev-Shwartz, and A. Tewari. Regularization techniques for learning with matrices.  arXiv:0910.0610v2, 2010.  J. Kivinen and M. Warmuth. Relative loss bounds for multidimensional regression problems. Ma-  chine Learning, 45:301-329, 2001.  41.13   BUBECK CESA-BIANCHI KAKADE  H. McMahan and A. Blum. Online geometric optimization in the bandit setting against an adaptive adversary. In In Proceedings of the 17th Annual Conference on Learning Theory (COLT), pages 109-123, 2004.  A. Nemirovski. Advances in convex optimiza- tion: Conic programming. In Proceedings of the In- ternational Congress of Mathematicians, 2006. EMS-European Mathematical Society Publishing House, 2007.  A. Nemirovski and D. Yudin. Problem Complexity and Method Efficiency in Optimization. Wiley  Interscience, 1983.  A. Rakhlin. Lecture notes on online learning. 2009.  N. Srebro, K. Sridharan, and A. Tewari. On the universality of online mirror descent. In Advances  in Neural Information Processing Systems (NIPS), 2011.  M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Pro-  ceedings of the Twentieth International Conference on Machine Learning (ICML), 2003.  41.14   "}, "The Best of Both Worlds: Stochastic and Adversarial Bandits": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "The Best of Both Worlds: Stochastic and Adversarial Bandits", "abstract": "We present a new bandit algorithm, SAO (Stochastic and Adversarial Optimal) whose regret is (essentially) optimal both for adversarial rewards and for stochastic rewards. Specifically, SAO combines the \\emphO(\u221a\\emphn) worst-case regret of Exp3 (Auer et al., 2002b) and the (poly)logarithmic regret of UCB1 (Auer et al., 2002a) for stochastic rewards. Adversarial rewards and stochastic rewards are the two main settings in the literature on multi-armed bandits (MAB). Prior work on MAB treats them separately, and does not attempt to jointly optimize for both. This result falls into the general agenda to design algorithms that combine the optimal worst-case performance with improved guarantees for \u201cnice\u201d problem instances.", "pdf_url": "http://proceedings.mlr.press/v23/bubeck12b/bubeck12b.pdf", "keywords": [], "reference": "Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the Dark: An Efficient Algorithm for  Bandit Linear Optimization. In 21th Conf. on Learning Theory (COLT), pages 263-274, 2008.  J.-Y. Audibert, R. Munos, and Cs. Szepesv\u00b4ari. Exploration-exploitation trade-off using variance estimates in  multi-armed bandits. Theoretical Computer Science, 410:1876-1902, 2009.  J.Y. Audibert and S. Bubeck. Regret Bounds and Minimax Policies under Partial Monitoring. J. of Machine Learning Research (JMLR), 11:2785-2836, 2010. A preliminary version has been published in COLT 2009.  P. Auer and R. Ortner. Ucb revisited: Improved regret bounds for the stochastic multi-armed bandit problem.  Periodica Mathematica Hungarica, 61:55-65, 2010.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem.  Machine Learning, 47(2-3):235-256, 2002a. Preliminary version in 15th ICML, 1998.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multiarmed bandit  problem. SIAM J. Comput., 32(1):48-77, 2002b. Preliminary version in 36th IEEE FOCS, 1995.  Moshe Babaioff, Yogeshwer Sharma, and Aleksandrs Slivkins. Characterizing truthful multi-armed bandit  mechanisms. In 10th ACM Conf. on Electronic Commerce (EC), pages 79-88, 2009.  Moshe Babaioff, Robert Kleinberg, and Aleksandrs Slivkins. Truthful mechanisms with implicit payment computation. In 11th ACM Conf. on Electronic Commerce (EC), pages 43-52, 2010. Best Paper Award.  S. Bubeck. Bandits Games and Clustering Foundations. PhD thesis, Universit\u00b4e Lille 1, 2010.  S\u00b4ebastien Bubeck, R\u00b4emi Munos, Gilles Stoltz, and Csaba Szepesvari. Online Optimization in X-Armed Bandits. J. of Machine Learning Research (JMLR), 12:1587-1627, 2011. Preliminary version in NIPS 2008.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, learning, and games. Cambridge Univ. Press, 2006.  Nicolo Cesa-Bianchi, Yishay Mansour, and Gilles Stoltz. Improved second-order bounds for prediction with  expert advice. Machine Learning, 66:321-352, 2007. Preliminary version in COLT 2005.  Varsha Dani, Thomas P. Hayes, and Sham Kakade. Stochastic Linear Optimization under Bandit Feedback.  In 21th Conf. on Learning Theory (COLT), 2008.  Nikhil Devanur and Sham M. Kakade. The price of truthfulness for pay-per-click auctions. In 10th ACM  Conf. on Electronic Commerce (EC), pages 99-106, 2009.  D. A. Freedman. On tail probabilities for martingales. The Annals of Probability, 3:100-118, 1975.  Aur\u00b4elien Garivier and Olivier Capp\u00b4e. The KL-UCB Algorithm for Bounded Stochastic Bandits and Beyond.  In 24th Conf. on Learning Theory (COLT), 2011.  Elad Hazan and Satyen Kale. Better algorithms for benign bandits. In 20th ACM-SIAM Symp. on Discrete  Algorithms (SODA), pages 38-47, 2009.  W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American  Statistical Association, 58:13-30, 1963.  J. Honda and A. Takemura. An asymptotically optimal bandit algorithm for bounded support models. In 23rd  annual conference on learning theory, 2010.  42.13   THE BEST OF BOTH WORLDS: STOCHASTIC AND ADVERSARIAL BANDITS  References  Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the Dark: An Efficient Algorithm for  Bandit Linear Optimization. In 21th Conf. on Learning Theory (COLT), pages 263-274, 2008.  J.-Y. Audibert, R. Munos, and Cs. Szepesv\u00b4ari. Exploration-exploitation trade-off using variance estimates in  multi-armed bandits. Theoretical Computer Science, 410:1876-1902, 2009.  J.Y. Audibert and S. Bubeck. Regret Bounds and Minimax Policies under Partial Monitoring. J. of Machine Learning Research (JMLR), 11:2785-2836, 2010. A preliminary version has been published in COLT 2009.  P. Auer and R. Ortner. Ucb revisited: Improved regret bounds for the stochastic multi-armed bandit problem.  Periodica Mathematica Hungarica, 61:55-65, 2010.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem.  Machine Learning, 47(2-3):235-256, 2002a. Preliminary version in 15th ICML, 1998.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multiarmed bandit  problem. SIAM J. Comput., 32(1):48-77, 2002b. Preliminary version in 36th IEEE FOCS, 1995.  Moshe Babaioff, Yogeshwer Sharma, and Aleksandrs Slivkins. Characterizing truthful multi-armed bandit  mechanisms. In 10th ACM Conf. on Electronic Commerce (EC), pages 79-88, 2009.  Moshe Babaioff, Robert Kleinberg, and Aleksandrs Slivkins. Truthful mechanisms with implicit payment computation. In 11th ACM Conf. on Electronic Commerce (EC), pages 43-52, 2010. Best Paper Award.  S. Bubeck. Bandits Games and Clustering Foundations. PhD thesis, Universit\u00b4e Lille 1, 2010.  S\u00b4ebastien Bubeck, R\u00b4emi Munos, Gilles Stoltz, and Csaba Szepesvari. Online Optimization in X-Armed Bandits. J. of Machine Learning Research (JMLR), 12:1587-1627, 2011. Preliminary version in NIPS 2008.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, learning, and games. Cambridge Univ. Press, 2006.  Nicolo Cesa-Bianchi, Yishay Mansour, and Gilles Stoltz. Improved second-order bounds for prediction with  expert advice. Machine Learning, 66:321-352, 2007. Preliminary version in COLT 2005.  Varsha Dani, Thomas P. Hayes, and Sham Kakade. Stochastic Linear Optimization under Bandit Feedback.  In 21th Conf. on Learning Theory (COLT), 2008.  Nikhil Devanur and Sham M. Kakade. The price of truthfulness for pay-per-click auctions. In 10th ACM  Conf. on Electronic Commerce (EC), pages 99-106, 2009.  D. A. Freedman. On tail probabilities for martingales. The Annals of Probability, 3:100-118, 1975.  Aur\u00b4elien Garivier and Olivier Capp\u00b4e. The KL-UCB Algorithm for Bounded Stochastic Bandits and Beyond.  In 24th Conf. on Learning Theory (COLT), 2011.  Elad Hazan and Satyen Kale. Better algorithms for benign bandits. In 20th ACM-SIAM Symp. on Discrete  Algorithms (SODA), pages 38-47, 2009.  W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American  Statistical Association, 58:13-30, 1963.  J. Honda and A. Takemura. An asymptotically optimal bandit algorithm for bounded support models. In 23rd  annual conference on learning theory, 2010.  42.13   BUBECK SLIVKINS  Robert Kleinberg and Aleksandrs Slivkins. Sharp Dichotomies for Regret Minimization in Metric Spaces. In  21st ACM-SIAM Symp. on Discrete Algorithms (SODA), 2010.  Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal. Multi-Armed Bandits in Metric Spaces. In 40th ACM  Symp. on Theory of Computing (STOC), pages 681-690, 2008.  T.L. Lai and Herbert Robbins. Asymptotically efficient Adaptive Allocation Rules. Advances in Applied  Mathematics, 6:4-22, 1985.  Odalric-Ambrym Maillard and R\u00b4emi Munos. Adaptive Bandits: Towards the best history-dependent strategy.  In 24th Conf. on Learning Theory (COLT), 2011.  Colin McDiarmid. Concentration. In M. Habib. C. McDiarmid. J. Ramirez and B. Reed, editors, Probabilistic  Methods for Discrete Mathematics, pages 195-248. Springer-Verlag, Berlin, 1998.  V. Perchet and P. Rigollet. The multi-armed bandit problem with covariates. Arxiv preprint arXiv:1110.6084,  2011.  527-535, 1952.  (COLT), 2011.  Herbert Robbins. Some Aspects of the Sequential Design of Experiments. Bull. Amer. Math. Soc., 58:  Aleksandrs Slivkins. Contextual Bandits with Similarity Information.  In 24th Conf. on Learning Theory  G. Stoltz. Incomplete Information and Internal Regret in Prediction of Individual Sequences. PhD thesis,  Universit\u00b4e Paris-Sud, Orsay, France, May 2005.  "}, "Open Problem: Regret Bounds for Thompson Sampling": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Open Problem: Regret Bounds for Thompson Sampling", "abstract": "", "pdf_url": "http://proceedings.mlr.press/v23/li12/li12.pdf", "keywords": [], "reference": "A. Agarwal, M. Dud\u00b4\u0131k, S. Kale, J. Langford, and R. E. Schapire. Contextual bandit learning under  the realizability assumption. In AISTATS, 2012.  S. Agrawal and N. Goyal. Analysis of Thompson sampling for the multi-armed bandit problem.  CoRR, abs/1111.1797, 2011.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed bandit  problem. SIAM Journal on Computing, 32(1):48-77, 2002.  O. Chapelle and L. Li. An empirical evaluation of Thompson sampling. In Advances in Neural  Information Processing Systems 24, pages 2249-2257, 2012.  M. Dud\u00b4\u0131k, D. Hsu, S. Kale, N. Karampatziakis, J. Langford, L. Reyzin, and T. Zhang. Efficient  optimal learning for contextual bandits. In UAI, pages 169-178, 2011.  T. Graepel, J. Q. Candela, T. Borchert, and R. Herbrich. Web-scale Bayesian click-through rate prediction for sponsored search advertising in Microsoft\u2019s Bing search engine. In ICML, pages 13-20, 2010.  O.-C. Granmo. Solving two-armed bernoulli bandit problems using a bayesian learning automaton.  Int\u2019l Journal of Intellient Computing and Cybernetics, 3(2):207-234, 2010.  T.L. Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Advances in Applied  Mathematics, 6:4-22, 1985.  J. Langford and T. Zhang. The epoch-greedy algorithm for contextual multi-armed bandits.  In  Advances in Neural Information Processing Systems 20, pages 1096-1103, 2008.  B. C. May and D.S. Leslie. Simulation studies in optimistic Bayesian sampling in contextual-bandit  problems. Technical Report 11:02, Dept. of Mathematics, Univ. of Bristol, 2011.  B. C. May, N. Korda, A. Lee, and D.S. Leslie. Optimistic Bayesian sampling in contextual-bandit  problems. Technical Report 11:01, Dept. of Mathematics, Univ. of Bristol, 2011.  S. Scott. A modern Bayesian look at the multi-armed bandit. Applied Stochastic Models in Business  and Industry, 26:639-658, 2010.  W. R. Thompson. On the likelihood that one unknown probability exceeds another in view of the  evidence of two samples. Biometrika, 25(3-4):285-294, 1933.  43.3   REGRET BOUNDS FOR THOMPSON SAMPLING  done in EXP4 (Auer et al., 2002), but the regret bound becomes O(T 2/3), no better than the simple epoch-greedy algorithm (Langford and Zhang, 2008).  We appreciate helpful discussions with John Langford and Miroslav Dud\u00b4\u0131k.  Acknowledgments  References  A. Agarwal, M. Dud\u00b4\u0131k, S. Kale, J. Langford, and R. E. Schapire. Contextual bandit learning under  the realizability assumption. In AISTATS, 2012.  S. Agrawal and N. Goyal. Analysis of Thompson sampling for the multi-armed bandit problem.  CoRR, abs/1111.1797, 2011.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed bandit  problem. SIAM Journal on Computing, 32(1):48-77, 2002.  O. Chapelle and L. Li. An empirical evaluation of Thompson sampling. In Advances in Neural  Information Processing Systems 24, pages 2249-2257, 2012.  M. Dud\u00b4\u0131k, D. Hsu, S. Kale, N. Karampatziakis, J. Langford, L. Reyzin, and T. Zhang. Efficient  optimal learning for contextual bandits. In UAI, pages 169-178, 2011.  T. Graepel, J. Q. Candela, T. Borchert, and R. Herbrich. Web-scale Bayesian click-through rate prediction for sponsored search advertising in Microsoft\u2019s Bing search engine. In ICML, pages 13-20, 2010.  O.-C. Granmo. Solving two-armed bernoulli bandit problems using a bayesian learning automaton.  Int\u2019l Journal of Intellient Computing and Cybernetics, 3(2):207-234, 2010.  T.L. Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Advances in Applied  Mathematics, 6:4-22, 1985.  J. Langford and T. Zhang. The epoch-greedy algorithm for contextual multi-armed bandits.  In  Advances in Neural Information Processing Systems 20, pages 1096-1103, 2008.  B. C. May and D.S. Leslie. Simulation studies in optimistic Bayesian sampling in contextual-bandit  problems. Technical Report 11:02, Dept. of Mathematics, Univ. of Bristol, 2011.  B. C. May, N. Korda, A. Lee, and D.S. Leslie. Optimistic Bayesian sampling in contextual-bandit  problems. Technical Report 11:01, Dept. of Mathematics, Univ. of Bristol, 2011.  S. Scott. A modern Bayesian look at the multi-armed bandit. Applied Stochastic Models in Business  and Industry, 26:639-658, 2010.  W. R. Thompson. On the likelihood that one unknown probability exceeds another in view of the  evidence of two samples. Biometrika, 25(3-4):285-294, 1933.  43.3   "}, "Open Problem: Better Bounds for Online Logistic Regression": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Open Problem: Better Bounds for Online Logistic Regression", "abstract": "Known algorithms applied to online logistic regression on a feasible set of \\emphL_2 diameter \\emphD achieve regret bounds like \\emphO(\\emphe^D log \\emphT) in one dimension, but we show a bound of \\emphO(\u221a\\emphD  + log \\emphT) is possible in a binary 1-dimensional problem. Thus, we pose the following question: Is it possible to achieve a regret bound for online logistic regression that is \\emphO(poly(\\emphD) log(\\emphT))? Even if this is not possible in general, it would be interesting to have a bound that reduces to our bound in the one-dimensional case.", "pdf_url": "http://proceedings.mlr.press/v23/mcmahan12/mcmahan12.pdf", "keywords": ["online convex optimization", "online learning", "regret bounds"], "reference": "Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex  optimization. Mach. Learn., 69, December 2007.  H. Brendan McMahan and Matthew Streeter. Adaptive bound optimization for online convex opti-  mization. In COLT, 2010.  ICML, 2003.  Martin Zinkevich. Online convex programming and generalized in\ufb01nitesimal gradient ascent. In  Appendix A. The Exp-Concavity of the Logistic Loss  Theorem 1 The logistic loss function (cid:96)(wt; xt, yt) = log(1 + exp(\u2212ytwt \u00b7 xt)), from Eq. (1), is \u03b1-exp-concave with \u03b1 = exp(\u2212D/2) over set W = {w | (cid:107)w(cid:107)2 \u2264 D/2} when (cid:107)xt(cid:107)2 \u2264 1 and yt \u2208 {\u22121, 1}.  Proof Recall that a function (cid:96) is \u03b1-exp-concave if (cid:79)2 exp(\u2212\u03b1(cid:96)(w)) (cid:22) 0. When (cid:96)(w) = g(w \u00b7 x) for x \u2208 Rn, we have (cid:79)2 exp(\u2212\u03b1(cid:96)(w)) = (cid:79)2f (cid:48)(cid:48)(z)xx(cid:62), where f (z) = exp(\u2212\u03b1g(z)). For the logistic loss, we have g(z) = log(1 + exp(z)) (without loss of generality, we consider a negative example), and so f (z) = (1 + exp(z))\u2212\u03b1. Then,  f (cid:48)(cid:48)(z) = \u03b1ez(1 + ez)\u2212\u03b1\u22122(\u03b1ez \u2212 1).  We need the largest \u03b1 such that f (cid:48)(cid:48)(z) \u2264 0, given a \ufb01xed z. We can see by inspection that \u03b1 = 0 is a zero. Since ez(1 + ez)\u2212\u03b1\u22122 > 0, from the term (\u03b1ez \u2212 1) we conclude \u03b1 = e\u2212z is the largest value of \u03b1 where f (cid:48)(cid:48)(z) \u2264 0. Note that z = wt \u00b7 xt, and so |z| \u2264 D/2 since (cid:107)xt(cid:107)2 \u2264 1, and so taking the worst case over wt \u2208 W and xt with (cid:107)xt(cid:107)2 \u2264 1, we have \u03b1 = exp(\u2212D/2).  44.3   OPEN PROBLEM: ONLINE LOGISTIC REGRESSION  Thus, if we let T \u2212 = {t | yt = \u22121}, we have  (cid:88)  t\u2208T \u2212  ft(wt) \u2212 ft(wt+1) \u2264  NT(cid:88)  N =0  1 N + \u03bb  \u2264  +  1 \u03bb  NT(cid:88)  N =1  1 N  1 \u03bb  \u2264  + log(NT ) + 1.  Applying a similar argument to rounds with positive labels and summing over the rounds with  positive and negative labels independently gives  Regret \u2264 \u03bb(|w\u2217| + 2 log 2) + log(PT ) + log(NT ) +  + 2.  2 \u03bb  Note log(PT ) + log(NT ) \u2264 2 log T . We wish to compete with w\u2217 where |w\u2217| \u2264 D/2, so we can choose \u03bb = 1\u221a  which gives  D/2  \u221a  Regret \u2264 O(  D + log T ).  References  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex  optimization. Mach. Learn., 69, December 2007.  H. Brendan McMahan and Matthew Streeter. Adaptive bound optimization for online convex opti-  mization. In COLT, 2010.  ICML, 2003.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In  "}, "Open Problem: Learning Dynamic Network Models from a Static Snapshot": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Open Problem: Learning Dynamic Network Models from a Static Snapshot", "abstract": "In this paper we consider the problem of learning a graph generating process given the evolving graph at a single point in time. Given a graph of sufficient size, can we learn the (repeatable) process that generated it? We formalize the generic problem and then consider two simple instances which are variations on the well-know graph generation models by Erd\u00f3s-R\u00e9nyi and Albert-Barabasi.", "pdf_url": "http://proceedings.mlr.press/v23/ramon12/ramon12.pdf", "keywords": [], "reference": "509-512, 1999.  45.3   LEARNING NETWORK DYNAMICS  E0,1 = p(1 \u2212 p)/(pw + 1) + (1 \u2212 p)p/(1 + w \u2212 pw). From these several equations one can solve w and put confidence bounds on it.  v (l, G, v) = N 0  l (1) = p and f lb  l (0) = 1 \u2212 p. Let w > 0. Let f lb  A labeled Barab\u00b4asi-Albert model For another example, consider a different network generation process: the vertices of the graph can be assigned two labels, 0 and 1 with probability (1 \u2212 p) and p as above (i.e. f lb d (d) = \u03b4(m, d) ensure that every new vertex is attached to exactly m existing vertices. Let N l G(v) = {u \u2208 NG(v) | \u03bb(u) = l}. Then, f lb G(v) + w.N 1 G(v). Just as in the Barabasi-Albert model, the probability of attachment to existing vertices is proportional to the degree of these existing vertices, but here a \u2019weighted\u2019 degree is used where vertices with label 1 have a weight w instead of a weight 1. Contrar- ily to the previously discussed case, one can show that asymptotically (E0,0/E, E1,1/E, E0,1/E) = ((1\u2212p)2, p2, 2 p) is not a function of w, i.e. the weight w that is part of the graph generation process cannot be computed directly from the edge-endpoint-pair distribution, nor the vertex label distribu- tion of the graph.  4. Conclusion  Solving the problem of learning dynamics (a preferential attachment function) from a snapshot of the evolving network at a particular point in time, will probably involve methods used to study the asymptotic properties of such networks, augmented with an analysis of the confidence of the estimations of the model parameters. To the best of our knowledge, the amount of work in this direction is limited.  This work was supported by ERC Starting Grant 240186 \u2019MiGraNT: Mining Graphs and Networks, a Theory-based approach\u2019.  A. L. Barab\u00b4asi and R. Albert. Emergence of scaling in random networks. Science, 286(5439):  B. Bollob\u00b4as. Random Graphs. Cambridge University Press, 2001.  B. Edmonds, C. Hernandez, and K. G. Troitzsch. Social Simulation: Technologies, Advances and  New Discoveries. IGI Publishing, 2007.  P. Erd\u02ddos and A. R\u00b4enyi. On random graphs i. Publicationes Mathematicae Debrecen, 6:290, 1959.  D. J. Watts and S. H. Strogatz. Collective dynamics of small-world networks. Nature, 393(6684):  440-442, 1998.  Acknowledgements  References  509-512, 1999.  45.3   "}, "Open Problem: Does AdaBoost Always Cycle?": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Open Problem: Does AdaBoost Always Cycle?", "abstract": "We pose the question of whether the distributions computed by AdaBoost always converge to a cycle.", "pdf_url": "http://proceedings.mlr.press/v23/rudin12/rudin12.pdf", "keywords": [], "reference": "Yali Amit and Gilles Blanchard. Multiple randomized classifiers (MRCL). Unpublished manuscript, 2001. Bruno Caprile, Cesare Furlanello, and Stefano Merler. Highlighting hard patterns via AdaBoost weights evolution. In J. Kittler and F. Roli, editors, Multiple Classifier Systems, pages 72-80. Springer, 2002. Michael Collins, Robert E. Schapire, and Yoram Singer. Logistic regression, AdaBoost and Bregman dis-  tances. Machine Learning, 48(1/2/3), 2002.  Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an applica-  tion to boosting. Journal of Computer and System Sciences, 55(1):119-139, August 1997.  Samuel Kutin. Algorithmic stability and ensemble-based learning. PhD thesis, University of Chicago, 2002.  Tien-Yien Li and James A Yorke. Period three implies chaos. The American Mathematical Monthly, 82(10):  pages 249-250.  985-992, December 1975.  46.3   DOES ADABOOST ALWAYS CYCLE?  Figure 2: A plot of rt over 30,000 iterations of AdaBoost on a small matrix M.  result (Li and Yorke, 1975) does not apply. (In fact, there are matrices M where every distribution must converge to a 3-cycle.)  From our previous studies (Rudin et al., 2004), we know there are some simple matrices M for which the distributions must converge to a cycle, and the iterated map provably forms a contraction in which nearby distributions Dt must get closer to the cycle points over time. (There are multiple possible cycles, but every possible distribution must converge to one of them.) Also, there is some- times an analytical expression for these cycle points, and sometimes it is possible to prove there exists a unique solution for the cycle points if there is no closed-form solution.  In experiments on small matrices M, we have observed cycles of many different lengths, in- cluding odd and even lengths. Sometimes, AdaBoost takes a very long time to converge to a cycle. If one of the cycle points is close to the boundary between regions of the simplex, as the distribution is converging to the cycle, it could cross the boundary. At that point the distributions could map to a different part of the simplex altogether, and leave the region of attraction. This is illustrated in Fig. 2 where one of AdaBoost\u2019s parameters (rt) is plotted over 30,000 iterations of AdaBoost. The apparent lines in the figure are made as AdaBoost alternates between a small number of possible values of rt as it cycles. Around iteration 9,000, the weight vector crosses one of the regions in the simplex and no longer follows its previous cycle. Eventually, it finds this cycle and converges again. The open problem is to prove or disprove that AdaBoost\u2019s distributions Dt converge to a cycle in all cases, that is, for every {\u22121, +1}-valued matrix M. A reward of $100 is offered for a complete and general resolution of this problem.  References  Yali Amit and Gilles Blanchard. Multiple randomized classifiers (MRCL). Unpublished manuscript, 2001. Bruno Caprile, Cesare Furlanello, and Stefano Merler. Highlighting hard patterns via AdaBoost weights evolution. In J. Kittler and F. Roli, editors, Multiple Classifier Systems, pages 72-80. Springer, 2002. Michael Collins, Robert E. Schapire, and Yoram Singer. Logistic regression, AdaBoost and Bregman dis-  tances. Machine Learning, 48(1/2/3), 2002.  Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an applica-  tion to boosting. Journal of Computer and System Sciences, 55(1):119-139, August 1997.  Samuel Kutin. Algorithmic stability and ensemble-based learning. PhD thesis, University of Chicago, 2002.  Tien-Yien Li and James A Yorke. Period three implies chaos. The American Mathematical Monthly, 82(10):  pages 249-250.  985-992, December 1975.  46.3   RUDIN SCHAPIRE DAUBECHIES  Cynthia Rudin, Ingrid Daubechies, and Robert E. Schapire. The dynamics of AdaBoost: Cyclic behavior and  convergence of margins. Journal of Machine Learning Research, 5:1557-1595, Dec 2004. Robert E. Schapire and Yoav Freund. Boosting: Foundations and Algorithms. MIT Press, 2012.  46.4   "}, "Open Problem: Is Averaging Needed for Strongly Convex Stochastic Gradient Descent?": {"volumn": "v23", "url": "http://proceedings.mlr.press/v23/", "header": "Open Problem: Is Averaging Needed for Strongly Convex Stochastic Gradient Descent?", "abstract": "Stochastic gradient descent (SGD) is a simple and very popular iterative method to solve stochastic optimization problems which arise in machine learning. A common practice is to return the average of the SGD iterates. While the utility of this is well-understood for general convex problems, the situation is much less clear for strongly convex problems (such as solving SVM). Although the standard analysis in the strongly convex case requires averaging, it was recently shown that this actually degrades the convergence rate, and a better rate is obtainable by averaging just a suffix of the iterates. The question we pose is whether averaging is needed at all to get optimal rates.", "pdf_url": "http://proceedings.mlr.press/v23/shamir12/shamir12.pdf", "keywords": [], "reference": "Learning, 69(2-3):169-192, 2007.  optimization. In ICML, 2012.  E. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex optimization. Machine  A. Rakhlin, O. Shamir, and K. Sridharan. Making gradient descent optimal for strongly convex stochastic  S. Shalev-Shwartz, Y. Singer, N. Srebro, and A. Cotter. Pegasos: primal estimated sub-gradient solver for  svm. Mathematical Programming, 127(1):3-30, 2011.  47.3  0F(w)=12w20F(w)=12w2+|w|0F(w)=12w2+max{w,0} IS AVERAGING NEEDED FOR STRONGLY CONVEX STOCHASTIC GRADIENT DESCENT?  We conjecture that this should be possible. For example, consider the scalar function F (w) = (so that w\u2217 = 0 - see figure above), and suppose we take \u03b7t = 1/t. A straightforward  w  1 2 w2 + | calculation reveals that  |  E[w2  t+1]  (1  \u2264  \u2212  2\u03b7t) E[w2 t ]  2\u03b7tE[  \u2212  ] +  wt |  |  O  (cid:0)\u03b72 t  (cid:1) .  This is stronger than Eq. (1), due to the ] component. Intuitively, the fact that F is non- | smooth and \u201cpointy\u201d around the optimum makes wt converge faster. This seems to compensate for rather than w2 (as in the smooth case). Indeed, the fact that F (w) w | if we ignore the fact that we deal with expectations, and consider a recursive inequality of the form  F (w\u2217) now scales down like  wt  \u2212  \u2212  |  E[ |  x2 t+1 \u2264  (1  2\u03b7t) x2  t \u2212  2\u03b7txt +  (cid:0)\u03b72 t  (cid:1) ,  \u2212 t scales down as 1/t2. This seems to suggest that E[w2 and \u03b7t = \u0398(1/t), it can be shown that x2 T ] (1/T 2) and not just indeed converges as (1/T ) as required.  (1/T ), leading to E[F (wT )  F (w\u2217)]  \u2264 O  O  O  O  \u2212  Even if such a result can be proven formally, we don\u2019t know how to generalize this approach to more complex functions. For example, consider the function F (w) = 1 (see figure above). This function is simultaneously smooth around w\u2217 = 0 in the negative direction, and non-smooth in the positive direction. In this case, any bound on E[w2 ] will not be enough, as it would correspond to different suboptimality rates in the positive and negative direction. In this particular example, a delicate case analysis might be possible, but it\u2019s not clear how to make things work with multi-dimensional functions, where the amount of \u201cnon-smoothness\u201d can vary continuously in different directions.  { T ] or even E[  2 w2 + max  wT |  w, 0  }  |  References  Learning, 69(2-3):169-192, 2007.  optimization. In ICML, 2012.  E. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex optimization. Machine  A. Rakhlin, O. Shamir, and K. Sridharan. Making gradient descent optimal for strongly convex stochastic  S. Shalev-Shwartz, Y. Singer, N. Srebro, and A. Cotter. Pegasos: primal estimated sub-gradient solver for  svm. Mathematical Programming, 127(1):3-30, 2011.  47.3  0F(w)=12w20F(w)=12w2+|w|0F(w)=12w2+max{w,0} "}}