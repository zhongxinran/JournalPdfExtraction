{"1": "Shipra Agrawal and Navin Goyal. Analysis of thompson sampling for the multi-armed bandit  problem. In COLT, pages 39-1, 2012.  Philippe Artzner, Freddy Delbaen, Jean-Marc Eber, and David Heath. Coherent measures of risk.  Mathematical finance, 9(3):203-228, 1999.  Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. Gambling in a rigged casino: The adversarial multi-armed bandit problem. In Foundations of Computer Science, 1995. Proceedings., 36th Annual Symposium on, pages 322-331. IEEE, 1995.  Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2-3):235-256, 2002.  S\u00b4ebastien Bubeck and Nicolo Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi- armed bandit problems. Foundations and Trends R(cid:13) in Machine Learning, 5(1):1-122, 2012.  Nicolas Galichet, Michele Sebag, and Olivier Teytaud. Exploration vs exploitation vs safety: Risk-  aware multi-armed bandits. In ACML, pages 245-260, 2013.  Tze Leung Lai and Herbert Robbins. Asymptotically efficient adaptive allocation rules. Advances  in applied mathematics, 6(1):4-22, 1985.  Odalric-Ambrym Maillard. Robust risk-averse stochastic multi-armed bandits. Conference on Algorithmic Learning Theory, pages 218-233. Springer, 2013.  In International  Odalric-Ambrym Maillard, R\u00b4emi Munos, and Gilles Stoltz. A finite-time analysis of multi-armed  bandits problems with kullback-leibler divergences. In COLT, pages 497-514, 2011.  11   RISK CRITERIA IN MULTI-ARMED BANDITS  6. Open Problems and Future Directions  One main question that we leave open is the dependence of the regret on problem parameters such as the number of arms K, and the sub-optimality gaps \u2206i. As our regret analysis passes through the proxy regret, the optimal order of the regret remains open as well. This will likely be resolved by means of a matching lower bound. Future directions may include a more complete taxonomy of performance criteria, or an extension of this framework to different settings (e.g., adversarial or contextual). Additionally, we note that the majority of our proof techniques also apply to non- quasiconvex criteria. If such criteria are found to be of interest then extending the framework to this case may be appealing.  We thank Ron Amit, Guy Tennenholtz, Nir Baram and Nadav Merlis for helpful discussions of this work, and the anonymous reviewers for their helpful comments. This work was partially funded by the Israel Science Foundation under contract 1380/16 and by the European Community\u2019s Seventh Framework Programme (FP7/2007-2013) under grant agreement 306638 (SUPREL).  Acknowledgments  References  Shipra Agrawal and Navin Goyal. Analysis of thompson sampling for the multi-armed bandit  problem. In COLT, pages 39-1, 2012.  Philippe Artzner, Freddy Delbaen, Jean-Marc Eber, and David Heath. Coherent measures of risk.  Mathematical finance, 9(3):203-228, 1999.  Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. Gambling in a rigged casino: The adversarial multi-armed bandit problem. In Foundations of Computer Science, 1995. Proceedings., 36th Annual Symposium on, pages 322-331. IEEE, 1995.  Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2-3):235-256, 2002.  S\u00b4ebastien Bubeck and Nicolo Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi- armed bandit problems. Foundations and Trends R(cid:13) in Machine Learning, 5(1):1-122, 2012.  Nicolas Galichet, Michele Sebag, and Olivier Teytaud. Exploration vs exploitation vs safety: Risk-  aware multi-armed bandits. In ACML, pages 245-260, 2013.  Tze Leung Lai and Herbert Robbins. Asymptotically efficient adaptive allocation rules. Advances  in applied mathematics, 6(1):4-22, 1985.  Odalric-Ambrym Maillard. Robust risk-averse stochastic multi-armed bandits. Conference on Algorithmic Learning Theory, pages 218-233. Springer, 2013.  In International  Odalric-Ambrym Maillard, R\u00b4emi Munos, and Gilles Stoltz. A finite-time analysis of multi-armed  bandits problems with kullback-leibler divergences. In COLT, pages 497-514, 2011. RISK CRITERIA IN MULTI-ARMED BANDITS  Pascal Massart. The tight constant in the dvoretzky-kiefer-wolfowitz inequality. The annals of  Probability, 18(3):1269-1283, 1990.  Herbert Robbins. Some aspects of the sequential design of experiments. Bulletin of the American  Mathematical Society, 58(5):527-535, 1952.  R Tyrrell Rockafellar and Stanislav Uryasev. Optimization of conditional value-at-risk. Journal of  risk, 2:21-42, 2000.  Amir Sani, Alessandro Lazaric, and R\u00b4emi Munos. Risk-aversion in multi-armed bandits.  In  Advances in Neural Information Processing Systems, pages 3275-3283, 2012.  Michel Simonnet. The Strong Law of Large Numbers, pages 311-325. Springer New York, New York, NY, 1996. ISBN 978-1-4612-4012-9. doi: 10.1007/978-1-4612-4012-9 15. URL http: //dx.doi.org/10.1007/978-1-4612-4012-9_15.  Sattar Vakili and Qing Zhao. Risk-averse multi-armed bandit problems under mean-variance  measure. IEEE Journal of Selected Topics in Signal Processing, 10(6):1093-1111, 2016.  Aad W Van der Vaart. Asymptotic statistics, volume 3. Cambridge university press, 2000.  Alexander Zimin, Rasmus Ibsen-Jensen, and Krishnendu Chatterjee. Generalized risk-aversion in  stochastic multi-armed bandits. arXiv preprint arXiv:1405.0833, 2014."}