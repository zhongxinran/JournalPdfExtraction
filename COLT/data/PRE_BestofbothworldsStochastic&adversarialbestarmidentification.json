{"1": "Robin Allesiardo and Rapha\u00a8el F\u00b4eraud. Selection of learning experts. In International Joint Confer-  ence on Neural Networks, 2017.  Robin Allesiardo, Rapha\u00a8el F\u00b4eraud, and Odalric-Ambrym Maillard. The non-stationary stochastic  multi-armed bandit problem. International Journal of Data Science and Analytics, 2017.  Jason Altschuler, Victor-Emmanuel Brunel, and Alan Malek. Best-arm identification for contami-  nated bandits. arXiv preprint arXiv:1802.09514, 2018.  Jean-Yves Audibert, S\u00b4ebastien Bubeck, and R\u00b4emi Munos. Best-arm identification in multi-armed  bandits. In Conference on Learning Theory, 2010.  Peter Auer and Chao-Kai Chiang. An algorithm with nearly optimal pseudo-regret for both In Conference on Learning Theory and arXiv preprint  stochastic and adversarial bandits. arXiv:1605.08722, 2016.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multi-  armed bandit problem. SIAM Journal on Computing, 32(1), 2002.  S\u00b4ebastian Bubeck, Tengyao Wang, and Nitin Viswanathan. Multiple identifications in multi-armed  bandits. In International Conference on Machine Learning, 2013.  S\u00b4ebastien Bubeck and Nicol`o Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-  armed bandit problems. Foundations and Trends in Machine Learning, 5(1), 2012.  S\u00b4ebastien Bubeck and Aleksandrs Slivkins. The best of both worlds: stochastic and adversarial  bandits. In Conference on Learning Theory, 2012.  S\u00b4ebastien Bubeck, R\u00b4emi Munos, and Gilles Stoltz. Pure exploration in multi-armed bandit prob-  lems. In Algorithmic Learning Theory, 2009.  Alexandra Carpentier and Andrea Locatelli. Tight (lower) bounds for the fixed budget best-arm  identification bandit problem. In Conference on Learning Theory, 2016.  Alexandra Carpentier and Michal Valko. Extreme bandits. In Neural Information Processing Sys-  tems, 2014.  13   BEST OF BOTH WORLDS: STOCHASTIC & ADVERSARIAL BEST-ARM IDENTIFICATION  Acknowledgements  We gratefully acknowledge the support of the NSF through grant IIS-1619362 and of the Aus- tralian Research Council through an Australian Laureate Fellowship (FL110100281) and through the Australian Research Council Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS). The research presented was also supported by European CHIST-ERA project DELTA, French Ministry of Higher Education and Research, Nord-Pas-de-Calais Regional Council, Inria and Otto-von-Guericke-Universit\u00a8at Magdeburg associated-team north-european project Allocate, and French National Research Agency projects ExTra-Learn (n.ANR-14-CE24-0010-01) and BoB (n.ANR-16-CE23-0003). We would like to thank Iosif Pinelis for a useful discussion on Bernstein inequalities.  References  Robin Allesiardo and Rapha\u00a8el F\u00b4eraud. Selection of learning experts. In International Joint Confer-  ence on Neural Networks, 2017.  Robin Allesiardo, Rapha\u00a8el F\u00b4eraud, and Odalric-Ambrym Maillard. The non-stationary stochastic  multi-armed bandit problem. International Journal of Data Science and Analytics, 2017.  Jason Altschuler, Victor-Emmanuel Brunel, and Alan Malek. Best-arm identification for contami-  nated bandits. arXiv preprint arXiv:1802.09514, 2018.  Jean-Yves Audibert, S\u00b4ebastien Bubeck, and R\u00b4emi Munos. Best-arm identification in multi-armed  bandits. In Conference on Learning Theory, 2010.  Peter Auer and Chao-Kai Chiang. An algorithm with nearly optimal pseudo-regret for both In Conference on Learning Theory and arXiv preprint  stochastic and adversarial bandits. arXiv:1605.08722, 2016.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multi-  armed bandit problem. SIAM Journal on Computing, 32(1), 2002.  S\u00b4ebastian Bubeck, Tengyao Wang, and Nitin Viswanathan. Multiple identifications in multi-armed  bandits. In International Conference on Machine Learning, 2013.  S\u00b4ebastien Bubeck and Nicol`o Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-  armed bandit problems. Foundations and Trends in Machine Learning, 5(1), 2012.  S\u00b4ebastien Bubeck and Aleksandrs Slivkins. The best of both worlds: stochastic and adversarial  bandits. In Conference on Learning Theory, 2012.  S\u00b4ebastien Bubeck, R\u00b4emi Munos, and Gilles Stoltz. Pure exploration in multi-armed bandit prob-  lems. In Algorithmic Learning Theory, 2009.  Alexandra Carpentier and Andrea Locatelli. Tight (lower) bounds for the fixed budget best-arm  identification bandit problem. In Conference on Learning Theory, 2016.  Alexandra Carpentier and Michal Valko. Extreme bandits. In Neural Information Processing Sys-  tems, 2014. BEST OF BOTH WORLDS: STOCHASTIC & ADVERSARIAL BEST-ARM IDENTIFICATION  Eyal Even-Dar, Shie Mannor, and Yishay Mansour. Action elimination and stopping conditions for the multi-armed Bandit and reinforcement-learning problems. Journal of Machine Learning Research, 7:1079-1105, 2006.  David A. Freedman. On tail probabilities for martingales. The Annals of Probability, pages 100-  118, 1975.  Aur\u00b4elien Garivier and Emilie Kaufmann. Optimal best-arm identification with fixed confidence. In  Conference on Learning Theory, 2016.  Kevin Jamieson and Ameet Talwalkar. Non-stochastic best-arm identification and hyperparameter  optimization. In International Conference on Artificial Intelligence and Statistics, 2016.  Rob Kaas and Jan M. Buhrman. Mean, median and mode in binomial distributions. Statistica  Neerlandica, 34(1):13-18, 1980.  Shivaram Kalyanakrishnan, Ambuj Tewari, Peter Auer, and Peter Stone. PAC subset selection in  stochastic multi-armed bandits. In International Conference on Machine Learning, 2012.  Zohar Karnin, Tomer Koren, and Oren Somekh. Almost optimal exploration in multi-armed bandits.  In International Conference on Machine Learning, 2013.  Emilie Kaufmann and Shivaram Kalyanakrishnan. Information complexity in bandit subset selec-  tion. In Conference on Learning Theory, 2013.  Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet Talwalkar. Hyperband: A novel bandit-based approach to hyperparameter optimization. arXiv preprint arXiv:1603.06560, 2016.  Andrea Locatelli, Maurilio Gutzeit, and Alexandra Carpentier. An optimal algorithm for the thresh-  olding bandit problem. In International Conference on Machine Learning, 2016.  Shie Mannor and John N. Tsitsiklis. The sample complexity of exploration in the multi-armed  bandit problem. Journal of Machine Learning Research, 5(Jun), 2004.  Oded Maron and Andrew Moore. Hoeffding Races: Accelerating model-selection search for clas-  sification and function approximation. In Neural Information Processing Systems, 1993.  Volodymyr Mnih, Csaba Szepesv\u00b4ari, and Jean-Yves Audibert. Empirical Bernstein stopping. In  International Conference on Machine Learning, 2008.  Yevgeny Seldin and G\u00b4abor Lugosi. An improved parametrization and analysis of the EXP3++ algo-  rithm for stochastic and adversarial bandits. In Conference on Learning Theory, 2017.  Yevgeny Seldin and Aleksandrs Slivkins. One practical algorithm for both stochastic and adversarial  bandits. In International Conference on Machine Learning, 2014. BEST OF BOTH WORLDS: STOCHASTIC & ADVERSARIAL BEST-ARM IDENTIFICATION"}