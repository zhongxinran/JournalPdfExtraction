{"1": "Jacob D Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An efficient In Conference on Learning Theory, pages 263-274,  algorithm for bandit linear optimization. 2008.  Zeyuan Allen-Zhu, S\u00b4ebastien Bubeck, and Yuanzhi Li. Make the minority great again: First-order regret bound for contextual bandits. In International Conference on Machine Learning, 2018.  Peter Auer and Chao-Kai Chiang. An algorithm with nearly optimal pseudo-regret for both stochas-  tic and adversarial bandits. In Conference on Learning Theory, pages 116-120, 2016.  Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. The nonstochastic multi-  armed bandit problem. SIAM journal on computing, 32(1):48-77, 2002.  Omar Besbes, Yonatan Gur, and Assaf Zeevi. Non-stationary stochastic optimization. Operations  research, 63(5):1227-1244, 2015.  S\u00b4ebastien Bubeck and Ronen Eldan. The entropic barrier: a simple and optimal universal self-  concordant barrier. In Conference on Learning Theory, 2015.  S\u00b4ebastien Bubeck, Nicolo Cesa-Bianchi, and Sham Kakade. Towards minimax policies for online  linear optimization with bandit feedback. In Conference on Learning Theory, 2012.  S\u00b4ebastien Bubeck, Michael B. Cohen, and Yuanzhi Li. Sparsity, variance and curvature in multi-  armed bandits. In International Conference on Algorithmic Learning Theory, 2018.  Nicolo Cesa-Bianchi, Ofer Dekel, and Ohad Shamir. Online learning with switching costs and other adaptive adversaries. In Advances in Neural Information Processing Systems, pages 1160-1168, 2013.  Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin, and Shenghuo Zhu. Online optimization with gradual variations. In Conference on Learning Theory, 2012.  Chao-Kai Chiang, Chia-Jung Lee, and Chi-Jen Lu. Beating bandits in gradually evolving worlds.  In Conference on Learning Theory, pages 210-227, 2013.  Ashok Cutkosky and Francesco Orabona. Black-box reductions for parameter-free online learning  in banach spaces. In Conference on Learning Theory, 2018.  Varsha Dani, Sham M Kakade, and Thomas P Hayes. The price of bandit information for online optimization. In Advances in Neural Information Processing Systems, pages 345-352, 2008.  Joel Friedman and Nathan Linial. On convex body chasing. Discrete & Computational Geometry,  9(3):293-321, 1993.  13   IMPROVED PATH-LENGTH REGRET BOUNDS FOR BANDITS  The authors would like to thank all the anonymous reviewers for their valuable comments. HL and CYW are supported by NSF Grant #1755781.  Acknowledgments  References  Jacob D Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An efficient In Conference on Learning Theory, pages 263-274,  algorithm for bandit linear optimization. 2008.  Zeyuan Allen-Zhu, S\u00b4ebastien Bubeck, and Yuanzhi Li. Make the minority great again: First-order regret bound for contextual bandits. In International Conference on Machine Learning, 2018.  Peter Auer and Chao-Kai Chiang. An algorithm with nearly optimal pseudo-regret for both stochas-  tic and adversarial bandits. In Conference on Learning Theory, pages 116-120, 2016.  Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. The nonstochastic multi-  armed bandit problem. SIAM journal on computing, 32(1):48-77, 2002.  Omar Besbes, Yonatan Gur, and Assaf Zeevi. Non-stationary stochastic optimization. Operations  research, 63(5):1227-1244, 2015.  S\u00b4ebastien Bubeck and Ronen Eldan. The entropic barrier: a simple and optimal universal self-  concordant barrier. In Conference on Learning Theory, 2015.  S\u00b4ebastien Bubeck, Nicolo Cesa-Bianchi, and Sham Kakade. Towards minimax policies for online  linear optimization with bandit feedback. In Conference on Learning Theory, 2012.  S\u00b4ebastien Bubeck, Michael B. Cohen, and Yuanzhi Li. Sparsity, variance and curvature in multi-  armed bandits. In International Conference on Algorithmic Learning Theory, 2018.  Nicolo Cesa-Bianchi, Ofer Dekel, and Ohad Shamir. Online learning with switching costs and other adaptive adversaries. In Advances in Neural Information Processing Systems, pages 1160-1168, 2013.  Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin, and Shenghuo Zhu. Online optimization with gradual variations. In Conference on Learning Theory, 2012.  Chao-Kai Chiang, Chia-Jung Lee, and Chi-Jen Lu. Beating bandits in gradually evolving worlds.  In Conference on Learning Theory, pages 210-227, 2013.  Ashok Cutkosky and Francesco Orabona. Black-box reductions for parameter-free online learning  in banach spaces. In Conference on Learning Theory, 2018.  Varsha Dani, Sham M Kakade, and Thomas P Hayes. The price of bandit information for online optimization. In Advances in Neural Information Processing Systems, pages 345-352, 2008.  Joel Friedman and Nathan Linial. On convex body chasing. Discrete & Computational Geometry,  9(3):293-321, 1993. IMPROVED PATH-LENGTH REGRET BOUNDS FOR BANDITS  Elad Hazan and Satyen Kale. Better algorithms for benign bandits. Journal of Machine Learning  Research, 12(Apr):1287-1311, 2011.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex  optimization. Machine Learning, 69(2-3):169-192, 2007.  Ali Jadbabaie, Alexander Rakhlin, Shahin Shahrampour, and Karthik Sridharan. Online optimiza- tion: Competing with dynamic comparators. In Artificial Intelligence and Statistics, pages 398- 406, 2015.  Haipeng Luo, Chen-Yu Wei, and Kai Zheng. Efficient online portfolio with logarithmic regret. In  Advances in Neural Information Processing Systems, 2018.  Aryan Mokhtari, Shahin Shahrampour, Ali Jadbabaie, and Alejandro Ribeiro. Online optimization In 55th IEEE  in dynamic environments: Improved regret rates for strongly convex problems. Conference on Decision and Control, pages 7195-7201, 2016.  Alexander Rakhlin and Karthik Sridharan. Online learning with predictable sequences. In Confer-  ence on Learning Theory, pages 993-1019, 2013.  Mark Sellke. Chasing convex bodies optimally. arXiv preprint arXiv:1905.11968, 2019.  Jacob Steinhardt and Percy Liang. Adaptivity and optimism: An improved exponentiated gradient  algorithm. In International Conference on Machine Learning, pages 1593-1601, 2014.  Chen-Yu Wei and Haipeng Luo. More adaptive algorithms for adversarial bandits. In Conference  on Learning Theory, 2018.  Chen-Yu Wei, Yi-Te Hong, and Chi-Jen Lu. Tracking the best expert in non-stationary stochastic environments. In Advances in Neural Information Processing Systems, pages 3972-3980, 2016.  Tianbao Yang, Lijun Zhang, Rong Jin, and Jinfeng Yi. Tracking slowly moving clairvoyant: Opti- mal dynamic regret of online learning with true and noisy gradient. In International Conference on Machine Learning, pages 449-457, 2016.  Lijun Zhang, Tianbao Yang, Jinfeng Yi, Jing Rong, and Zhi-Hua Zhou. Improved dynamic regret In Advances in Neural Information Processing Systems, pages  for non-degenerate functions. 732-741, 2017.  Lijun Zhang, Shiyin Lu, and Zhi-Hua Zhou. Adaptive online learning in dynamic environments. In  Advances in Neural Information Processing Systems, pages 1330-1340, 2018.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In  International Conference on Machine Learning, 2003. IMPROVED PATH-LENGTH REGRET BOUNDS FOR BANDITS"}