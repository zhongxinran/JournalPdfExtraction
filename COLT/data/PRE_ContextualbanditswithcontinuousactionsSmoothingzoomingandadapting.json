{"1": "Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert Schapire. Taming the monster: A fast and simple algorithm for contextual bandits. In International Conference on Machine Learning, 2014.  Alekh Agarwal, Sarah Bird, Markus Cozowicz, Luong Hoang, John Langford, Stephen Lee, Jiaji Li, Dan Melamed, Gal Oshri, Oswaldo Ribas, Siddhartha Sen, and Alex Slivkins. Making contextual decisions with low technical debt. arxiv:1606.03966, 2017.  Rajeev Agrawal. The continuum-armed bandit problem. SIAM Journal on Control and Optimization,  1995.  Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. The nonstochastic multiarmed  bandit problem. SIAM Journal on Computing, 2002.  S\u00e9bastien Bubeck, R\u00e9mi Munos, Gilles Stoltz, and Csaba Szepesv\u00e1ri. X-armed bandits. Journal of  Machine Learning Research, 2011.  Robert Kleinberg. Nearly tight bounds for the continuum-armed bandit problem. In Advances in  Neural Information Processing Systems, 2004.  Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal. Bandits and experts in metric spaces. Journal of the ACM, 2019. To appear. Merged and revised version of conference papers in ACM STOC 2008 and ACM-SIAM SODA 2010. Also available at http://arxiv.org/abs/1312.1277.  John Langford and Tong Zhang. The epoch-greedy algorithm for contextual multi-armed bandits. In  Advances in Neural Information Processing Systems, 2007.  Aleksandrs Slivkins. Contextual bandits with similarity information. The Journal of Machine  Learning Research, 2014.  3   CONTEXTUAL BANDITS WITH CONTINUOUS ACTIONS  References  Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert Schapire. Taming the monster: A fast and simple algorithm for contextual bandits. In International Conference on Machine Learning, 2014.  Alekh Agarwal, Sarah Bird, Markus Cozowicz, Luong Hoang, John Langford, Stephen Lee, Jiaji Li, Dan Melamed, Gal Oshri, Oswaldo Ribas, Siddhartha Sen, and Alex Slivkins. Making contextual decisions with low technical debt. arxiv:1606.03966, 2017.  Rajeev Agrawal. The continuum-armed bandit problem. SIAM Journal on Control and Optimization,  1995.  Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. The nonstochastic multiarmed  bandit problem. SIAM Journal on Computing, 2002.  S\u00e9bastien Bubeck, R\u00e9mi Munos, Gilles Stoltz, and Csaba Szepesv\u00e1ri. X-armed bandits. Journal of  Machine Learning Research, 2011.  Robert Kleinberg. Nearly tight bounds for the continuum-armed bandit problem. In Advances in  Neural Information Processing Systems, 2004.  Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal. Bandits and experts in metric spaces. Journal of the ACM, 2019. To appear. Merged and revised version of conference papers in ACM STOC 2008 and ACM-SIAM SODA 2010. Also available at http://arxiv.org/abs/1312.1277.  John Langford and Tong Zhang. The epoch-greedy algorithm for contextual multi-armed bandits. In  Advances in Neural Information Processing Systems, 2007.  Aleksandrs Slivkins. Contextual bandits with similarity information. The Journal of Machine  Learning Research, 2014."}