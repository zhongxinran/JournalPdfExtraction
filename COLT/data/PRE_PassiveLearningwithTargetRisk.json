{"1": "M. Anthony and P.L. Bartlett. Neural network learning: Theoretical foundations. Cam-  bridge University Press, 1999.  13   Passive Learning with Target Risk  By combining the bounds in (13) and (15), under the assumption that at least one of the two conditions in (12) and (14) is true, by setting (cid:22) = B=8, we have  L( bwk+1) (cid:0) L(w(cid:3)) (cid:20) 1 T1  (  \u221a  2(cid:24)(cid:12)  T1 +  [ (cid:24)3(cid:12)d + 2(cid:24)(cid:12)  p  ]  d  ln  )  s (cid:14)  \u22062  k +  \u03f5prior;  4 (cid:24)  implying  \u2225 bwk+1 (cid:0) w(cid:3)\u2225 (cid:20) 2 (cid:11)T1  (  \u221a  2(cid:24)(cid:12)  T1 +  [ (cid:24)3(cid:12)d + 2(cid:24)(cid:12)  p  ]  d  ln  )  s (cid:14)  \u22062  k +  \u03f5prior:  8 (cid:11)(cid:24)  We complete the proof by using Lemma 8, which states that the probability for either of the two conditions hold is no less than 1 (cid:0) (cid:14).  6. Conclusions  In this paper, we have studied the sample complexity of passive learning when the target expected risk is given to the learner as prior knowledge. The crucial fact about target risk assumption is that, it can be fully exploited by the learning algorithm and stands in contrast to most common types of prior knowledges that usually enter into the generalization bounds and are often perceived as a rather crude way to incorporate such assumptions. We showed that by explicitly employing the target risk \u03f5prior in a properly designed stochastic optimization algorithm, it is possible to attain the given target risk \u03f5prior with a logarithmic , under the assumption that the loss function is both strongly sample complexity log convex and smooth.  1 \u03f5prior  )  (  There are various directions for future research. The current study is restricted to the parametric setting where the hypothesis space is of (cid:12)nite dimension. It would be interesting to see how to achieve a logarithmic sample complexity in a non-parametric setting where hy- potheses lie in a functional space of in(cid:12)nite dimension. Evidently, it is impossible to extend the current algorithm for the non-parametric setting; therefore additional analysis tools are needed to address the challenge of in(cid:12)nite dimension arising from the non-parametric set- ting. It is also an interesting problem to relate target risk assumption we made here to the low noise margin condition which is often made in active learning for binary classi(cid:12)cation since both settings appear to share the same sample complexity. However it is currently unclear how to derive a connection between these two settings. We believe this issue is worthy of further exploration and leave it as an open problem.  Acknowledgments  The authors would like to thank the PC for insightful discussions and three anonymous reviewers for their constructive comments and helpful suggestions on the original version of this paper. This work is partially supported by O(cid:14)ce of Navy Research (ONR Award N00014-09-1-0663 and N000141210431).  References  M. Anthony and P.L. Bartlett. Neural network learning: Theoretical foundations. Cam-  bridge University Press, 1999. Mahdavi Jin  Maria-Florina Balcan, Steve Hanneke, and Jennifer Wortman Vaughan. The true sample  complexity of active learning. Machine Learning, 80(2-3):111{139, 2010.  P.L. Bartlett, O. Bousquet, and S. Mendelson. Local rademacher complexities. The Annals  of Statistics, 33(4):1497{1537, 2005.  Shai Ben-David, David Pal, and Shai Shalev-Shwartz. Agnostic online learning. In COLT,  2009.  Anselm Blumer, A. Ehrenfeucht, David Haussler, and Manfred K. Warmuth. Learnability  and the vapnik-chervonenkis dimension. J. ACM, 36(4):929{965, 1989.  Nicol(cid:18)o Cesa-Bianchi and G(cid:19)abor Lugosi. Prediction, learning, and games. Cambridge Uni-  versity Press, 2006.  Andrew Cotter, Ohad Shamir, Nati Srebro, and Karthik Sridharan. Better mini-batch  algorithms via accelerated gradient methods. In NIPS, pages 1647{1655, 2011.  John C. Duchi, Peter L. Bartlett, and Martin J. Wainwright. Randomized smoothing for  stochastic optimization. SIAM Journal on Optimization, 22(2):674{701, 2012.  A. Ehrenfeucht, D. Haussler, M. Kearns, and L. Valiant. A general lower bound on the number of examples needed for learning. Information and Computation, 82(3):247{261, 1989.  Steve Hanneke. Theoretical Foundations of Active Learning. PhD thesis, 2009.  Elad Hazan and Satyen Kale. Beyond the regret minimization barrier: an optimal algorithm  for stochastic strongly-convex optimization. COLT, 2011.  Elad Hazan and Tomer Koren. Optimal algorithms for ridge and lasso regression with  partially observed attributes. CoRR, 2011.  Elad Hazan, Adam Kalai, Satyen Kale, and Amit Agarwal. Logarithmic regret algorithms  for online convex optimization. In COLT, pages 499{513, 2006.  Anatoli  Iouditski  and Yuri Nesterov. minimizing convex ouvertes.fr/docs/00/50/89/33/PDF/Strong-hal.pdf, 2010.  Primal-dual  functions.  uniformly  available  subgradient methods  for http://hal.archives-  at  Sham M. Kakade, Karthik Sridharan, and Ambuj Tewari. On the complexity of linear prediction: Risk bounds, margin bounds, and regularization. In NIPS, pages 793{800, 2008.  Vladimir Koltchinskii. Oracle Inequalities in Empirical Risk Minimization and Sparse Re-  covery Problems. Lecture Notes in mathematics. Springer, 2011.  Wee Sun Lee, Peter L. Bartlett, and Robert C. Williamson. The importance of convexity in learning with squared loss. IEEE Transactions on Information Theory, 44(5):1974{1980, 1998. Passive Learning with Target Risk  A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approximation approach to stochastic programming. SIAM Journal on Optimization, 19(4):1574{1609, 2009.  A.S. Nemirovsky and D.B. Yudin. Problem complexity and method e(cid:14)ciency in optimiza-  tion. Wiley Interscience Series in Discrete Mathematics, 1983.  Yurii Nesterov. Introductory Lectures on Convex Optimization: A Basic Course. Kluwer  Academic Publishers, 2004.  Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning: Random  averages, combinatorial parameters, and learnability. CoRR, abs/1006.1138, 2010.  Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan. Making gradient descent optimal  for strongly convex stochastic optimization. In ICML, 2012.  Aaditya Ramdas and Aarti Singh. Optimal stochastic convex optimization through the lens  of active learning. In ICML, 2013.  S. Shalev-Shwartz, O. Shamir, K. Sridharan, and N. Srebro. Learnability and stability in  the general learning setting. COLT, 2009a.  S. Shalev-Shwartz, O. Shamir, K. Sridharan, and N. Srebro. Stochastic convex optimization.  COLT, 2009b.  Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan. Learnability, stability and uniform convergence. Journal of Machine Learning Research, 11:2635{2670, 2010.  Nathan Srebro, Karthik Sridharan, and Ambuj Tewari. Smoothness, low noise and fast  rates. In NIPS, pages 2199{2207, 2010.  Karthik Sridharan. Learning from an optimization viewpoint. PhD Thesis, 2012.  Karthik Sridharan, Shai Shalev-Shwartz, and Nathan Srebro. Fast rates for regularized  objectives. In NIPS, pages 1545{1552, 2008.  V.N. Vapnik and A.Y. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and Its Applications, 16(2):264{280, 1971. Mahdavi Jin"}