{"1": "925-936, 2010.  Emmanuel J Candes and Yaniv Plan. Matrix completion with noise. Proceedings of the IEEE, 98(6):  M. Charikar, J. Steinhardt, and G. Valiant. Learning from untrusted data. In Symposium on Theory of  Computing (to appear), 2017.  Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. Robust estimators in high dimensions without the computational intractability. In Foundations of Computer Science (FOCS), 2016 IEEE 57th Annual Symposium on, pages 655-664. IEEE, 2016.  Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. Learning geometric concepts with nasty noise.  arXiv preprint arXiv:1707.01242, 2017a.  Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. List-decodable robust mean estimation and  learning mixtures of spherical gaussians. arXiv preprint arXiv:1711.07211, 2017b.  12   A DATA PRISM  To this end, our algorithm only ever considers \u201csingle-hop\u201d implications of proposed assignments: an assignment to a set of r variables is considered \u201coptimistic\u201d if it directly implies values for a significant fraction of the other variables. It is easy to imagine extending this definition to also consider longer chains of implication. Perhaps a specific assignment to r variables would imply values to c1 additional variables, which in turn would imply values to c2 variables, etc. Indeed, in the basic setting of r =2, this approach can be realized to yield an algorithm that only requires constraints on a random subset of size O(n3/2), as opposed to O(n2) constraints.  From a computational perspective, it seems unlikely that such an approach could be pushed to yield an efficient algorithm for the regime in which fewer than nr/2 sets of r variables have nontrivial constraints. Indeed, even for random instances of r\u2212SAT with a planted solution, efficient algorithms below this threshold have been elusive (see, for example, the recent related work on random CSPs with planted assignments (Feldman et al., 2015; Raghavendra et al., 2016)).  From a purely information theoretic perspective\u2014the picture is not entirely clear either. In contrast to random CSPs with planted assignments, for which constraints are placed on random r-tuples and the constraints are chosen randomly subject to respecting the planted assignment, our setting is complicated by the adversarial nature of the constraints that are placed on the r-tuples. In a fully adversarial CSP model, for which both the choices of the r-tuples as well as the constraints themselves are chosen adversarially\u2014to the best of our knowledge\u2014very little is known. Of course, in this setting, the goal is to find a satisfying assignment (that might not necessarily correspond to the planted assignment). In the semi-adversarial CSP model, where the identities of the r-tuple sets are picked at random, and the adversary chooses the constraints, our results show that we can recover an assignment, provided we can selectively query O(n) (cid:1) possible constraints. In these settings it is not immediately clear how to analyze the extent to of the (cid:0)n r which implications \u201cpropagate\u201d. A second difficulty is that the goal of our setting is not just to find a satisfying assignment, but to find something close to a specific planted assignment. Our results imply, for the settings we consider, that there are at most a constant number of solution clusters. It seems interesting to investigate the extent to which this holds for semi-adversarial CSPs with fewer constraints, perhaps with constraints chosen adversarially corresponding to only N (cid:28)(cid:0)n (cid:1) random r-tuples; in this setting it seems r plausible that N =nr/2 is the threshold between a constant and super-constant number of such solution clusters, though this might be difficult to prove.  References  925-936, 2010.  Emmanuel J Candes and Yaniv Plan. Matrix completion with noise. Proceedings of the IEEE, 98(6):  M. Charikar, J. Steinhardt, and G. Valiant. Learning from untrusted data. In Symposium on Theory of  Computing (to appear), 2017.  Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. Robust estimators in high dimensions without the computational intractability. In Foundations of Computer Science (FOCS), 2016 IEEE 57th Annual Symposium on, pages 655-664. IEEE, 2016.  Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. Learning geometric concepts with nasty noise.  arXiv preprint arXiv:1707.01242, 2017a.  Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. List-decodable robust mean estimation and  learning mixtures of spherical gaussians. arXiv preprint arXiv:1711.07211, 2017b. A DATA PRISM  Vitaly Feldman, Will Perkins, and Santosh Vempala. On the complexity of random satisfiability problems with planted solutions. In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, pages 77-86. ACM, 2015.  Frank R Hampel, Elvezio M Ronchetti, Peter J Rousseeuw, and Werner A Stahel. Robust statistics: the  approach based on influence functions, volume 114. John Wiley & Sons, 2011.  David Haussler. Sphere packing numbers for subsets of the boolean n-cube with bounded vapnik-  chervonenkis dimension. Journal of Combinatorial Theory, Series A, 69(2):217-232, 1995.  Peter J Huber. Robust statistics. Springer, 2011.  Raghunandan H Keshavan, Andrea Montanari, and Sewoong Oh. Matrix completion from a few entries.  IEEE Transactions on Information Theory, 56(6):2980-2998, 2010.  Pravesh K Kothari and Jacob Steinhardt. Better agnostic clustering via relaxed tensor norms. arXiv  preprint arXiv:1711.07465, 2017.  preprint arXiv:1711.11581, 2017.  Pravesh K Kothari and David Steurer. Outlier-robust moment-estimation via sum-of-squares. arXiv  Kevin A Lai, Anup B Rao, and Santosh Vempala. Agnostic estimation of mean and covariance. In Founda- tions of Computer Science (FOCS), 2016 IEEE 57th Annual Symposium on, pages 665-674. IEEE, 2016.  Prasad Raghavendra, Satish Rao, and Tselil Schramm. Strongly refuting random csps below the spectral  threshold. arXiv preprint arXiv:1605.00058, 2016.  Jacob Steinhardt, Gregory Valiant, and Moses Charikar. Avoiding imposters and delinquents: Adversarial crowdsourcing and peer prediction. In Advances in Neural Information Processing Systems, pages 4439-4447, 2016.  Jacob Steinhardt, Moses Charikar, and Gregory Valiant. Resilience: A criterion for learning in the presence  of arbitrary outliers. In Innovations in Theoretical Computer Science (ITCS), 2018.  John W Tukey. A survey of sampling from contaminated distributions. Contributions to probability and  statistics, 2:448-485, 1960."}