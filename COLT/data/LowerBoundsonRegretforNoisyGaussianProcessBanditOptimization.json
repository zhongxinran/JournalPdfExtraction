{"1": "In this paper, we consider the problem of sequentially optimizing a black-box function $f$ based on noisy samples and bandit feedback.  We assume that $f$ is smooth in the sense of having a bounded norm in some reproducing kernel Hilbert space (RKHS), yielding a commonly-considered non-Bayesian form of Gaussian process bandit optimization.  We provide algorithm-independent lower bounds on the simple regret, measuring the suboptimality of a single point reported after $T$ rounds, and on the cumulative regret, measuring the sum of regrets over the $T$ chosen points. For the isotropic squared-exponential kernel in $d$ dimensions, we find that an average simple regret of $\u03b5$ requires $T = \u03a9\\big(\\frac1\u03b5^2 (\\log\\frac1\u03b5)^d/2\\big)$, and the average cumulative regret is at least $\u03a9\\big( \\sqrt{T}(\\log T)^d \\big)$, thus matching existing upper bounds up to the replacement of $d/2$ by $d+O(1)$ in both cases.  For the Mat\u00e9rn-$\u03bd$ kernel, we give analogous bounds of the form $\u03a9\\big( (\\frac1\u03b5)^2+d/\u03bd\\big)$ and $\u03a9\\big( T^\\frac\u03bd+ d2\u03bd+ d \\big)$, and discuss the resulting gaps to the existing upper bounds."}