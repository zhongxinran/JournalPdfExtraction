{"1": "Elizabeth S Allman, Catherine Matias, and John A Rhodes. Identifiability of parameters in latent structure models with many observed variables. The Annals of Statistics, 37(6A):3099-3132, 2009.  Elizabeth S Allman, Sonia Petrovic, John A Rhodes, and Seth Sullivant.  Identifiability of two- tree mixtures for group-based models. Computational Biology and Bioinformatics, IEEE/ACM Transactions on, 8(3):710-722, 2011.  Anima Anandkumar, Rong Ge, Daniel Hsu, Sham M Kakade, and Matus Telgarsky. Tensor decom-  positions for learning latent variable models. arXiv preprint arXiv:1210.7559, 2012a.  Anima Anandkumar, Daniel Hsu, Furong Huang, and Sham Kakade. Learning mixtures of tree graphical models. In Advances in Neural Information Processing Systems 25, pages 1061-1069, 2012b.  Animashree Anandkumar, Daniel Hsu, and Sham M Kakade. A method of moments for mixture  models and hidden markov models. arXiv preprint arXiv:1203.0683, 2012c.  Joseph Anderson, Mikhail Belkin, Navin Goyal, Luis Rademacher, and James R. Voss. The more, the merrier: the blessing of dimensionality for learning large gaussian mixtures. CoRR, abs/1311.2891, 2013.  Saugata Basu, Richard Pollack, and Marie-Franc\u00b8oise Roy. On the combinatorial and algebraic complexity of quantifier elimination. J. ACM, 43(6):1002-1045, November 1996. ISSN 0004- 5411. doi: 10.1145/235809.235813. URL http://doi.acm.org/10.1145/235809. 235813.  Mikhail Belkin and Kaushik Sinha. Polynomial learning of distribution families. In Foundations of Computer Science (FOCS), 2010 51st Annual IEEE Symposium on, pages 103-112. IEEE, 2010.  Aditya Bhaskara, Moses Charikar, Ankur Moitra, and Aravindan Vijayaraghavan. Smoothed anal- ysis of tensor decompositions. In Proceedings of the 46th annual ACM Symposium on Theory of Computing (STOC). ACM, 2014.  Joseph T Chang. Full reconstruction of markov models on evolutionary trees: identifiability and  consistency. Mathematical biosciences, 137(1):51-73, 1996.  L. Chiantini and G. Ottaviani. On generic identifiability of 3-tensors of small rank. SIAM Journal  on Matrix Analysis and Applications, 33(3):1018-1037, 2012. doi: 10.1137/110829180.  L. De Lathauwer, J. Castaing, and J. Cardoso. Fourth-order cumulant-based blind identification of  underdetermined mixtures. IEEE Trans. on Signal Processing, 55(6):2965-2973, 2007.  13   UNIQUENESS OF TENSOR DECOMPOSITIONS  We thank Ravi Kannan for valuable discussions about the algorithmic results in this work, and Daniel Hsu for helpful pointers to the literature. The third author would also like to thank Siddharth Gopal for some useful pointers about HMM models in speech and image recognition.  Acknowledgments  References  Elizabeth S Allman, Catherine Matias, and John A Rhodes. Identifiability of parameters in latent structure models with many observed variables. The Annals of Statistics, 37(6A):3099-3132, 2009.  Elizabeth S Allman, Sonia Petrovic, John A Rhodes, and Seth Sullivant.  Identifiability of two- tree mixtures for group-based models. Computational Biology and Bioinformatics, IEEE/ACM Transactions on, 8(3):710-722, 2011.  Anima Anandkumar, Rong Ge, Daniel Hsu, Sham M Kakade, and Matus Telgarsky. Tensor decom-  positions for learning latent variable models. arXiv preprint arXiv:1210.7559, 2012a.  Anima Anandkumar, Daniel Hsu, Furong Huang, and Sham Kakade. Learning mixtures of tree graphical models. In Advances in Neural Information Processing Systems 25, pages 1061-1069, 2012b.  Animashree Anandkumar, Daniel Hsu, and Sham M Kakade. A method of moments for mixture  models and hidden markov models. arXiv preprint arXiv:1203.0683, 2012c.  Joseph Anderson, Mikhail Belkin, Navin Goyal, Luis Rademacher, and James R. Voss. The more, the merrier: the blessing of dimensionality for learning large gaussian mixtures. CoRR, abs/1311.2891, 2013.  Saugata Basu, Richard Pollack, and Marie-Franc\u00b8oise Roy. On the combinatorial and algebraic complexity of quantifier elimination. J. ACM, 43(6):1002-1045, November 1996. ISSN 0004- 5411. doi: 10.1145/235809.235813. URL http://doi.acm.org/10.1145/235809. 235813.  Mikhail Belkin and Kaushik Sinha. Polynomial learning of distribution families. In Foundations of Computer Science (FOCS), 2010 51st Annual IEEE Symposium on, pages 103-112. IEEE, 2010.  Aditya Bhaskara, Moses Charikar, Ankur Moitra, and Aravindan Vijayaraghavan. Smoothed anal- ysis of tensor decompositions. In Proceedings of the 46th annual ACM Symposium on Theory of Computing (STOC). ACM, 2014.  Joseph T Chang. Full reconstruction of markov models on evolutionary trees: identifiability and  consistency. Mathematical biosciences, 137(1):51-73, 1996.  L. Chiantini and G. Ottaviani. On generic identifiability of 3-tensors of small rank. SIAM Journal  on Matrix Analysis and Applications, 33(3):1018-1037, 2012. doi: 10.1137/110829180.  L. De Lathauwer, J. Castaing, and J. Cardoso. Fourth-order cumulant-based blind identification of  underdetermined mixtures. IEEE Trans. on Signal Processing, 55(6):2965-2973, 2007. BHASKARA CHARIKAR VIJAYARAGHAVAN  Navin Goyal, Santosh Vempala, and Ying Xiao. Fourier pca. In Proceedings of the 46th annual  ACM Symposium on Theory of Computing (STOC). ACM, 2014.  Nick Gravin, Jean Lasserre, Dmitrii V Pasechnik, and Sinai Robins. The inverse moment problem  for convex polytopes. Discrete & Computational Geometry, 48(3):596-621, 2012.  Richard A Harshman. Foundations of the parafac procedure: models and conditions for an explana-  tory multimodal factor analysis. 1970.  Tao Jiang and Nicholas D Sidiropoulos. Kruskal\u2019s permutation lemma and the identification of candecomp/parafac and bilinear models with constant modulus constraints. Signal Processing, IEEE Transactions on, 52(9):2625-2636, 2004.  Joseph B Kruskal. Three-way arrays: rank and uniqueness of trilinear decompositions, with appli- cation to arithmetic complexity and statistics. Linear algebra and its applications, 18(2):95-138, 1977.  J.M. Landsberg. Tensors:: Geometry and Applications. Graduate Studies in Mathematics Se- ries. American Mathematical Society, 2012. ISBN 9780821869079. URL http://books. google.com.au/books?id=JTjv3DTvxZIC.  S. Leurgans, R. Ross, and R. Abel. A decomposition for three-way arrays. SIAM Journal on Matrix  Analysis and Applications, 14(4):1064-1083, 1993.  Ankur Moitra and Gregory Valiant. Settling the polynomial learnability of mixtures of gaussians. In Foundations of Computer Science (FOCS), 2010 51st Annual IEEE Symposium on, pages 93- 102. IEEE, 2010.  Elchanan Mossel and S\u00b4ebastien Roch. Learning nonsingular phylogenies and hidden markov mod-  els. The Annals of Applied Probability, pages 583-614, 2006.  Karl Pearson. Contributions to the mathematical theory of evolution. Philosophical Transactions  of the Royal Society of London. A, 185:71-110, 1894.  John A Rhodes. A concise proof of kruskal\u2019s theorem on tensor decomposition. Linear Algebra  and Its Applications, 432(7):1818-1824, 2010.  John A Rhodes and Seth Sullivant. Identifiability of large phylogenetic mixture models. Bulletin of  mathematical biology, 74(1):212-231, 2012.  Nicholas D Sidiropoulos and Rasmus Bro. On the uniqueness of multilinear decomposition of  n-way arrays. Journal of chemometrics, 14(3):229-239, 2000.  Alwin Stegeman and Nicholas D Sidiropoulos. On kruskal\u2019s uniqueness condition for the cande-  comp/parafac decomposition. Linear Algebra and its applications, 420(2):540-552, 2007.  GM Tallis and P Chesson. Identifiability of mixtures. J. Austral. Math. Soc. Ser. A, 32(3):339-348,  Henry Teicher. Identifiability of mixtures. The annals of Mathematical statistics, 32(1):244-248,  1982.  1961. UNIQUENESS OF TENSOR DECOMPOSITIONS  Henry Teicher. Identifiability of mixtures of product measures. The Annals of Mathematical Statis-  tics, 38(4):1300-1302, 1967."}