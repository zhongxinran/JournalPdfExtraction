{"1": "P. Bachman, O. Alsharif, and D. Precup. Learning with pseudo-ensembles. NIPS, 2014.  P. Baldi and P. Sadowski. The dropout learning algorithm. Artificial intelligence, 210:78-122, 2014.  Pierre Baldi and Peter J Sadowski. Understanding dropout. In Advances in Neural Information  Processing Systems, pages 2814-2822, 2013.  P. L. Bartlett, M. I. Jordan, and J. D. McAuliffe. Convexity, classification, and risk bounds. Journal  of the American Statistical Association, 101(473):138-156, 2006.  L. Breiman. Some infinity theory for predictor ensembles. Annals of Statistics, 32(1):1-11, 2004.  18   HELMBOLD LONG  2013; Gal and Ghahramani, 2015; Wager et al., 2014)), including the possibility that dropout reduces the amount of coadaptation in a network\u2019s weights (Hinton et al., 2012).  The dropout criterion is an expected loss over dropout patterns, and the variance in the output values over dropout patterns contributes to this expected loss. Therefore dropout may co-adapt weights in order to reduce this (artificial) variance. We prove that this happens even in very simple situations where nothing in the training data justifies negative weights (Theorem 8). This indicates that the relationship between dropout and co-adaption is not a simple one.  The effects of dropout in deep neural networks are rather complicated, and approximations can be misleading since the dropout penalty is very non-convex even in 1-layer networks (Helmbold and Long, 2015). In Section 3 we show that dropout does enjoy several scale-invariance properties that are not shared by weight-decay. A perhaps surprising consequence of these invariances is that there are never isolated local minima when learning a deep network with dropout. Further exploration of these scale invariance properties is warranted to see if they are a contributor to dropout\u2019s empirical success or can be exploited to facilitate training. While contrasting dropout to weight-decay in simple situations, we found that a degenerate all-zero network results (Theorem 7) when the L2 regularization parameter is above a threshold. This is in dramatic contrast to our previous intuition from the 1-layer case.  In (Wager et al., 2013), dropout was viewed as a regularization method, adding a data dependent penalty to the empirical loss of (presumably) undesirable solutions. Section 5 shows that, unlike the generalized linear models case analyzed there, the dropout penalty in deeper networks can be negative and depends on the labels in the training data, and thus behaves unlike most regularizers. On the other hand, the dropout penalty can grow exponentially in the depth of the network, and thus may better re\ufb02ect the complexity of the underlying model space than L2 regularization.  This paper uncovers a number of dropout\u2019s interesting fundamental properties using formal analysis of simple cases. However, the effects of using dropout training in deep networks are subtle and complex, and we hope that this paper lays a foundation to promote further formal analysis of dropout\u2019s properties and behavior.  We are very grateful to Peter Bartlett, Seshadhri Comandur, and anonymous reviewers for valuable communications.  Acknowledgments  References  P. Bachman, O. Alsharif, and D. Precup. Learning with pseudo-ensembles. NIPS, 2014.  P. Baldi and P. Sadowski. The dropout learning algorithm. Artificial intelligence, 210:78-122, 2014.  Pierre Baldi and Peter J Sadowski. Understanding dropout. In Advances in Neural Information  Processing Systems, pages 2814-2822, 2013.  P. L. Bartlett, M. I. Jordan, and J. D. McAuliffe. Convexity, classification, and risk bounds. Journal  of the American Statistical Association, 101(473):138-156, 2006.  L. Breiman. Some infinity theory for predictor ensembles. Annals of Statistics, 32(1):1-11, 2004. DROPOUT IN DEEP NETWORKS  Caffe. Caffe, 2016. http://caffe.berkeleyvision.edu.  Danqi Chen and Christopher D Manning. A fast and accurate dependency parser using neural  networks. In EMNLP, pages 740-750, 2014.  G. E. Dahl. Deep learning how I did it: Merck 1st place interview, 2012. http://blog.kaggle.com.  G. E. Dahl, T. N. Sainath, and G. E. Hinton. Improving deep neural networks for LVCSR using  rectified linear units and dropout. ICASSP, 2013.  L. Deng, J. Li, J. Huang, K. Yao, D. Yu, F. Seide, M. L. Seltzer, G. Zweig, X. He, J. Williams, Y. Gong, and A. Acero. Recent advances in deep learning for speech research at microsoft. ICASSP, 2013.  Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian approximation: Representing model  uncertainty in deep learning. arXiv:1506.02142, 2015.  Yarin Gal and Zoubin Ghahramani. A theoretically grounded application of dropout in recurrent neural networks. In Advances in Neural Information Processing Systems, pages 1019-1027, 2016.  Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron C. Courville, and Yoshua Bengio.  Maxout networks. In ICML, pages 1319-1327, 2013.  Mohammad Havaei, Axel Davy, David Warde-Farley, Antoine Biard, Aaron Courville, Yoshua Bengio, Chris Pal, Pierre-Marc Jodoin, and Hugo Larochelle. Brain tumor segmentation with deep neural networks. Medical image analysis, 35:18-31, 2017.  Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing  human-level performance on imagenet classification. In ICCV, pages 1026-1034, 2015.  D. P. Helmbold and P. M. Long. On the inductive bias of dropout. JMLR, 16:3403-3454, 2015.  G. E. Hinton. Dropout: a simple and effective way to improve neural networks, 2012. videolec-  tures.net.  G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors, 2012. Arxiv, arXiv:1207.0580v1.  Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. A convolutional neural network for  modelling sentences. In ACL, pages 655-665, 2014.  P. M. Long and R. A. Servedio. Random classification noise defeats all convex potential boosters.  Machine Learning, 78(3):287-304, 2010.  Vinod Nair and Geoffrey E Hinton. Rectified linear units improve restricted boltzmann machines. In  ICML, pages 807-814, 2010.  Behnam Neyshabur, Ryota Tomioka, and Nathan Srebro. Norm-based capacity control in neural  networks. In COLT, pages 1376-1401, 2015.  J\u00fcrgen Schmidhuber. Deep learning in neural networks: An overview. Neural Networks, 61:85-117,  2015. HELMBOLD LONG  N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: A simple way  to prevent neural networks from overfitting. JMLR, 15:1929-1958, 2014.  Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. CVPR, 2015.  TensorFlow. Tensor\ufb02ow, 2016. https://www.tensor\ufb02ow.org.  Torch. Torch, 2016. http://torch.ch.  COLT, pages 949-974, 2014.  T. Van Erven, W. Kot\u0142owski, and M. K. Warmuth. Follow the leader with dropout perturbations.  S. Wager, S. Wang, and P. Liang. Dropout training as adaptive regularization. NIPS, 2013.  S. Wager, W. Fithian, S. Wang, and P. S. Liang. Altitude training: Strong bounds for single-layer  dropout. NIPS, 2014.  L. Wan, M. Zeiler, S. Zhang, Y. Le Cun, and R. Fergus. Regularization of neural networks using  dropconnect. In ICML, pages 1058-1066, 2013.  Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, and Alex Smola. Stacked attention networks for image question answering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 21-29, 2016.  T. Zhang. Statistical behavior and consistency of classification methods based on convex risk  minimization. Annals of Statistics, 32(1):56-85, 2004. DROPOUT IN DEEP NETWORKS"}