{"1": "Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic  multiarmed bandit problem. SIAM Journal on Computing, 32(1):48-77, 2002.  Avrim Blum and Yishay Mansour. From external to internal regret. Journal of Machine  Learning Research, 8:1307-1324, 2007.  Olivier Bousquet and Manfred Warmuth. Tracking a small set of experts by mixing past  posteriors. Journal of Machine Learning Research, 3:363-396, 2002.  S\u00b4ebastien Bubeck and Nicol`o Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.  N. Cesa-Bianchi, Y. Mansour, and G. Stoltz. Improved second-order bounds for prediction  with expert advice. Machine Learning, 66(2-3):321-352, 2007.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  In NIPS, pages 297-305, 2009.  Kamalika Chaudhuri, Yoav Freund, and Daniel Hsu. A parameter-free hedging algorithm.  13   Regret Minimization for Branching Experts  random variable denoting Exp3.C\u2019s total loss with respect to the sequence I1, . . . , IT of random draws.  R+ such that for every Theorem 12 Let \u03b71, \u03b72, . . . be a sequence of functions \u03b7t : N . . . (in what follows, we write \u03b7t = \u03b7t(Nt) k2 \u2264 k1 \u2264 \u2265 for short). If i0, . . . , iT = m(T ) are the actions on the path from the root to the best action m(T ), then  . . ., it holds that \u03b71(k1)  \u03b72(k2)  \u2192  \u2265  T  T  E RT  1 2  \u2264  Nt\u03b7t +  ln  |  1 \u03b7t  Nt  C(it, t + 1)  Nt+1  |  +  ln NT +1 \u03b7T  .  t=1 X If Exp3.C is run with \u03b7t(k) =  t=1 X ln ek tk , then  E RT  \u2264T NT ln eNT  1 +  C(it, t + 1)  ln  T t=1 |  2 ln eNT  Q  .  |  !     q  p  (2)  (3)  Acknowledgments  We wish to thank the anonymous reviewers for their helpful comments. This research was supported in part by the Google Inter-university center for Electronic Markets and Auctions, by a grant from the Israel Science Foundation, by a grant from United States- Israel Binational Science Foundation (BSF), by a grant from the Israeli Ministry of Science (MoS), and by The Israeli Centers of Research Excellence (I-CORE) program (Center No. 4/11). This work is part of Ph.D. thesis research carried out by the first author at Tel Aviv University.  References  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic  multiarmed bandit problem. SIAM Journal on Computing, 32(1):48-77, 2002.  Avrim Blum and Yishay Mansour. From external to internal regret. Journal of Machine  Learning Research, 8:1307-1324, 2007.  Olivier Bousquet and Manfred Warmuth. Tracking a small set of experts by mixing past  posteriors. Journal of Machine Learning Research, 3:363-396, 2002.  S\u00b4ebastien Bubeck and Nicol`o Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.  N. Cesa-Bianchi, Y. Mansour, and G. Stoltz. Improved second-order bounds for prediction  with expert advice. Machine Learning, 66(2-3):321-352, 2007.  Nicol`o Cesa-Bianchi and G\u00b4abor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  In NIPS, pages 297-305, 2009.  Kamalika Chaudhuri, Yoav Freund, and Daniel Hsu. A parameter-free hedging algorithm. Gofer Cesa-Bianchi Gentile Mansour  Alexey V. Chernov and Vladimir Vovk. Prediction with advice of unknown number of  experts. In UAI, pages 117-125, 2010.  Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin, and Shenghuo Zhu. Online optimization with gradual variations. Journal of Machine Learning Research - Proceedings Track, 23:6.1-6.20, 2012.  Peter DeMarzo, Ilan Kremer, and Yishay Mansour. Online trading algorithms and robust  option pricing. In STOC, pages 477-486, 2006.  Y. Freund, R. Schapire, Y. Singer, and M. Warmuth. Using and combining predictors that specialize. In Proceedings of the 29th Annual ACM Symposium on the Theory of Computing, pages 334-343. ACM Press, 1997.  Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. In Euro-COLT, pages 23-37. Springer-Verlag, 1995.  E. Gofer and Y. Mansour. Pricing exotic derivatives using regret minimization. In Proc. of  the 4th Symposium on Algorithmic Game Theory (SAGT), 2011.  E. Hazan and S. Kale. Extracting certainty from uncertainty: regret bounded by variation  in costs. In COLT, pages 57-68, 2008.  M. Herbster and M.K. Warmuth. Tracking the best expert. Machine Learning, 32(2):  151-178, 1998.  A. Kalai and S. Vempala. E\ufb03cient algorithms for online decision problems. Journal of  Computer and System Sciences, 71(3):291-307, 2005.  R. Kleinberg, A. Niculescu-Mizil, and Y. Sharma. Regret bounds for sleeping experts and  bandits. Machine learning, 80(2):245-272, 2010.  Wouter Koolen, Dmitry Adamskiy, and Manfred Warmuth. Putting Bayes to sleep.  In  NIPS, pages 135-143, 2012.  N. Littlestone and M.K. Warmuth. The weighted majority algorithm. Information and  Computation, 108:212-261, 1994.  Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V. Vazirani. Algorithmic Game Theory. Cambridge University Press, New York, NY, USA, 2007. ISBN 0521872820.  Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan. Relax and localize: From value  to algorithms. arXiv preprint arXiv:1204.0870, 2012.  Cosma Rohilla Shalizi, Abigail Z. Jacobs, and Aaron Clauset. Adapting to non-stationarity  with growing expert ensembles. CoRR, abs/1103.0949, 2011.  V.G. Vovk. Aggregating strategies. In Proceedings of the 3rd Annual Workshop on Com-  putational Learning Theory, pages 372-383, 1990. Regret Minimization for Branching Experts"}