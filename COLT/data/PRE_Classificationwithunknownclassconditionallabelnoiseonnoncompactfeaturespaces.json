{"1": "J-Y Audibert. Classification under polynomial entropy and margin assumptions and randomized  estimators. www.proba.jussieu.fr/mathdoc/textes/PMA-908.pdf., 2004.  Jean-Yves Audibert, Alexandre B Tsybakov, et al. Fast learning rates for plug-in classifiers. The  Annals of statistics, 35(2):608-633, 2007.  L Birg\u00b4e. A new look at an old result: Fano\u2019s lemma. Technical Report, Universite Paris VI., 2001. Gilles Blanchard, Gyemin Lee, and Clayton Scott. Semi-supervised novelty detection. Journal of  Machine Learning Research, 11(Nov):2973-3009, 2010.  Gilles Blanchard, Marek Flaska, Gregory Handy, Sara Pozzi, and Clayton Scott. Classification with asymmetric label noise: Consistency and maximal denoising. Electronic Journal of Statistics, 10 (2):2780-2824, 2016.  Jakramate Bootkrajang and Ata Kab\u00b4an. Learning kernel logistic regression in the presence of class  label noise. Pattern Recognition, 47(11):3641-3655, 2014.  S\u00b4ebastien Bubeck, R\u00b4emi Munos, Gilles Stoltz, and Csaba Szepesv\u00b4ari. X-armed bandits. Journal of  Machine Learning Research, 12(May):1655-1695, 2011.  T. I. Cannings, Y. Fan, and R. J. Samworth. Classification with imperfect training labels. ArXiv  e-prints, May 2018.  Timothy I. Cannings, Thomas B. Berrett, and Richard J. Samworth. Local nearest neighbour clas-  sification with applications to semi-supervised learning. CoRR, abs/1704.00642, 2017.  Kamalika Chaudhuri and Sanjoy Dasgupta. Rates of convergence for nearest neighbor classification.  In Advances in Neural Information Processing Systems, pages 3437-3445, 2014.  Imre Csisz\u00b4ar and Zsolt Talata. Context tree estimation for not necessarily finite memory processes,  via bic and mdl. IEEE Transactions on Information theory, 52(3):1007-1016, 2006.  Sanjoy Dasgupta and Samory Kpotufe. Optimal rates for k-nn density and mode estimation. In  Advances in Neural Information Processing Systems, pages 2555-2563, 2014.  Maik D\u00a8oring, L\u00b4aszl\u00b4o Gy\u00a8orfi, and Harro Walk. Rate of convergence of k-nearest-neighbor classifi-  cation rule. Journal of Machine Learning Research, 18:227:1-227:16, 2017.  Charles Elkan and Keith Noto. Learning classifiers from only positive and unlabeled data.  In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201908, New York, NY, USA, 2008. ACM.  Beno\u02c6\u0131t Fr\u00b4enay and Michel Verleysen. Classification in the presence of label noise: A survey. IEEE  Trans. Neural Netw. Learning Syst., 25(5):845-869, 2014.  S\u00b4ebastien Gadat, Thierry Klein, and Cl\u00b4ement Marteau. Classification in general finite dimensional spaces with the k nearest neighbour rule. The Annals of Statistics, 44(3):982-1009, 06 2016. Wei Gao, Xin-Yi Niu, and Zhi-Hua Zhou. On the consistency of exact and approximate nearest  neighbor with noisy data. Arxiv, abs/1607.07526, 2018.  Heinrich Jiang. Non-asymptotic uniform rates of consistency for k-nn regression. In Proceedings  of the 33rd AAAI Conference on Artificial Intelligence. AAAI, 2019.  13   CLASSIFICATION WITH LABEL NOISE ON NON-COMPACT FEATURE SPACES  This work is funded by EPSRC under Fellowship grant EP/P004245/1. The authors would like to thank Nikolaos Nikolaou and Timothy I. Cannings for useful discussions. We would also like to thank the anonymous reviewers for their careful feedback which led to several improvements in the presentation.  Acknowledgments  References  J-Y Audibert. Classification under polynomial entropy and margin assumptions and randomized  estimators. www.proba.jussieu.fr/mathdoc/textes/PMA-908.pdf., 2004.  Jean-Yves Audibert, Alexandre B Tsybakov, et al. Fast learning rates for plug-in classifiers. The  Annals of statistics, 35(2):608-633, 2007.  L Birg\u00b4e. A new look at an old result: Fano\u2019s lemma. Technical Report, Universite Paris VI., 2001. Gilles Blanchard, Gyemin Lee, and Clayton Scott. Semi-supervised novelty detection. Journal of  Machine Learning Research, 11(Nov):2973-3009, 2010.  Gilles Blanchard, Marek Flaska, Gregory Handy, Sara Pozzi, and Clayton Scott. Classification with asymmetric label noise: Consistency and maximal denoising. Electronic Journal of Statistics, 10 (2):2780-2824, 2016.  Jakramate Bootkrajang and Ata Kab\u00b4an. Learning kernel logistic regression in the presence of class  label noise. Pattern Recognition, 47(11):3641-3655, 2014.  S\u00b4ebastien Bubeck, R\u00b4emi Munos, Gilles Stoltz, and Csaba Szepesv\u00b4ari. X-armed bandits. Journal of  Machine Learning Research, 12(May):1655-1695, 2011.  T. I. Cannings, Y. Fan, and R. J. Samworth. Classification with imperfect training labels. ArXiv  e-prints, May 2018.  Timothy I. Cannings, Thomas B. Berrett, and Richard J. Samworth. Local nearest neighbour clas-  sification with applications to semi-supervised learning. CoRR, abs/1704.00642, 2017.  Kamalika Chaudhuri and Sanjoy Dasgupta. Rates of convergence for nearest neighbor classification.  In Advances in Neural Information Processing Systems, pages 3437-3445, 2014.  Imre Csisz\u00b4ar and Zsolt Talata. Context tree estimation for not necessarily finite memory processes,  via bic and mdl. IEEE Transactions on Information theory, 52(3):1007-1016, 2006.  Sanjoy Dasgupta and Samory Kpotufe. Optimal rates for k-nn density and mode estimation. In  Advances in Neural Information Processing Systems, pages 2555-2563, 2014.  Maik D\u00a8oring, L\u00b4aszl\u00b4o Gy\u00a8orfi, and Harro Walk. Rate of convergence of k-nearest-neighbor classifi-  cation rule. Journal of Machine Learning Research, 18:227:1-227:16, 2017.  Charles Elkan and Keith Noto. Learning classifiers from only positive and unlabeled data.  In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201908, New York, NY, USA, 2008. ACM.  Beno\u02c6\u0131t Fr\u00b4enay and Michel Verleysen. Classification in the presence of label noise: A survey. IEEE  Trans. Neural Netw. Learning Syst., 25(5):845-869, 2014.  S\u00b4ebastien Gadat, Thierry Klein, and Cl\u00b4ement Marteau. Classification in general finite dimensional spaces with the k nearest neighbour rule. The Annals of Statistics, 44(3):982-1009, 06 2016. Wei Gao, Xin-Yi Niu, and Zhi-Hua Zhou. On the consistency of exact and approximate nearest  neighbor with noisy data. Arxiv, abs/1607.07526, 2018.  Heinrich Jiang. Non-asymptotic uniform rates of consistency for k-nn regression. In Proceedings  of the 33rd AAAI Conference on Artificial Intelligence. AAAI, 2019. CLASSIFICATION WITH LABEL NOISE ON NON-COMPACT FEATURE SPACES  Samory Kpotufe. k-nn regression adapts to local intrinsic dimension. In Advances in Neural Infor-  mation Processing Systems, pages 729-737, 2011.  Samory Kpotufe and Vikas Garg. Adaptivity to local smoothness and dimension in kernel regres-  sion. In Advances in neural information processing systems, pages 3075-3083, 2013.  Oleg V Lepski and Vladimir G Spokoiny. Optimal pointwise adaptive methods in nonparametric  estimation. The Annals of Statistics, pages 2512-2546, 1997.  Fuyi Li, Yang Zhang, Anthony W Purcell, Geoffrey I Webb, Kuo-Chen Chou, Trevor Lithgow, Chen Li, and Jiangning Song. Positive-unlabelled learning of glycosylation sites in the human proteome. BMC bioinformatics, 20(1):112, 2019.  Andrea Locatelli and Alexandra Carpentier. Adaptivity to smoothness in x-armed bandits. In Con-  ference on Learning Theory, pages 1463-1492, 2018.  Enno Mammen and Alexandre B. Tsybakov. Smooth discrimination analysis. Ann. Statist., 27(6):  1808-1829, 12 1999. doi: 10.1214/aos/1017939240.  Aditya Menon, Brendan van Rooyen, Cheng Soon Ong, and Bob Williamson. Learning from cor- rupted binary labels via class-probability estimation. In International Conference on Machine Learning, pages 125-134, 2015.  Aditya Krishna Menon, Brendan van Rooyen, and Nagarajan Natarajan. Learning from binary  labels with instance-dependent noise. Machine Learning, 107(8):1561-1595, Sep 2018.  Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with noisy labels. In Advances in neural information processing systems, pages 1196-1204, 2013. Nagarajan Natarajan, Inderjit S. Dhillon, Pradeep Ravikumar, and Ambuj Tewari. Cost-sensitive  learning with noisy labels. Journal of Machine Learning Research, 18(155):1-33, 2018.  Harish Ramaswamy, Clayton Scott, and Ambuj Tewari. Mixture proportion estimation via kernel In International Conference on Machine Learning, pages 2052-  embeddings of distributions. 2060, 2016.  Henry W. J. Reeve and Ata Kab\u00b4an. Fast rates for a knn classifier robust to unknown asymmetric label noise. In Proceedings of the 36th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, Long Beach, California, 10-15 Jul 2019. PMLR. Clayton Scott. A rate of convergence for mixture proportion estimation, with application to learning  from noisy labels. In Artificial Intelligence and Statistics, pages 838-846, 2015.  Clayton Scott, Gilles Blanchard, and Gregory Handy. Classification with asymmetric label noise: Consistency and maximal denoising. In Conference On Learning Theory, pages 489-511, 2013. Brendan van Rooyen and Robert C Williamson. A theory of learning with corrupted labels. Journal  of Machine Learning Research, 18(228):1-50, 2018. CLASSIFICATION WITH LABEL NOISE ON NON-COMPACT FEATURE SPACES"}