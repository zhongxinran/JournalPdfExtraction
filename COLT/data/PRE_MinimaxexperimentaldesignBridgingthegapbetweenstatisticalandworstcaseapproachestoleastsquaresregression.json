{"1": "Zeyuan Allen-Zhu, Yuanzhi Li, Aarti Singh, and Yining Wang. Near-optimal design of experiments via regret minimization. In Proceedings of the 34th International Conference on Machine Learn- ing, volume 70 of Proceedings of Machine Learning Research, pages 126-135, Sydney, Australia, August 2017. URL http://proceedings.mlr.press/v70/allen-zhu17e.html.  Haim Avron and Christos Boutsidis. Faster subset selection for matrices and applications. SIAM  Journal on Matrix Analysis and Applications, 34(4):1464-1499, 2013.  Christos Boutsidis, Petros Drineas, and Malik Magdon-Ismail. Near-optimal coresets for least-  squares regression. IEEE Trans. Information Theory, 59(10):6880-6892, 2013.  Kathryn Chaloner and Isabella Verdinelli. Bayesian experimental design: A review. Statist. Sci., 10 (3):273-304, 08 1995. doi: 10.1214/ss/1177009939. URL https://doi.org/10.1214/ ss/1177009939.  Xue Chen and Eric Price. Active regression via linear-sample sparsification. In Proceedings of the  32nd Conference on Learning Theory, 2019.  Micha\u0142 Derezi\u00b4nski. Fast determinantal point processes via distortion-free intermediate sampling. In  Proceedings of the 32nd Conference on Learning Theory, 2019.  Micha\u0142 Derezi\u00b4nski and Manfred K. Warmuth. Unbiased estimates for linear regression via volume sampling. In Advances in Neural Information Processing Systems 30, pages 3087-3096, Long Beach, CA, USA, December 2017.  Micha\u0142 Derezi\u00b4nski and Manfred K. Warmuth. Subsampling for ridge regression via regularized volume sampling. In Amos Storkey and Fernando Perez-Cruz, editors, Proceedings of the Twenty- First International Conference on Artificial Intelligence and Statistics, pages 716-725, Playa Blanca, Lanzarote, Canary Islands, April 2018.  Micha\u0142 Derezi\u00b4nski and Manfred K. Warmuth. Reverse iterative volume sampling for linear regres- sion. Journal of Machine Learning Research, 19(23):1-39, 2018. URL http://jmlr.org/ papers/v19/17-781.html.  Micha\u0142 Derezi\u00b4nski, Manfred K. Warmuth, and Daniel Hsu. Leveraged volume sampling for linear regression. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 2510-2519. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/ 7517-leveraged-volume-sampling-for-linear-regression.pdf.  13   MINIMAX EXPERIMENTAL DESIGN  MWM would like to acknowledge ARO, DARPA, NSF and ONR for providing partial support of this work. Also, MWM and MD thank the NSF for funding via the NSF TRIPODS program. Part of this work was done while MD, KLC and MWM were visiting the Simons Institute for the Theory of Computing and while MKW was at UC Santa Cruz, supported by NSF grant IIS-1619271.  Acknowledgments  References  Zeyuan Allen-Zhu, Yuanzhi Li, Aarti Singh, and Yining Wang. Near-optimal design of experiments via regret minimization. In Proceedings of the 34th International Conference on Machine Learn- ing, volume 70 of Proceedings of Machine Learning Research, pages 126-135, Sydney, Australia, August 2017. URL http://proceedings.mlr.press/v70/allen-zhu17e.html.  Haim Avron and Christos Boutsidis. Faster subset selection for matrices and applications. SIAM  Journal on Matrix Analysis and Applications, 34(4):1464-1499, 2013.  Christos Boutsidis, Petros Drineas, and Malik Magdon-Ismail. Near-optimal coresets for least-  squares regression. IEEE Trans. Information Theory, 59(10):6880-6892, 2013.  Kathryn Chaloner and Isabella Verdinelli. Bayesian experimental design: A review. Statist. Sci., 10 (3):273-304, 08 1995. doi: 10.1214/ss/1177009939. URL https://doi.org/10.1214/ ss/1177009939.  Xue Chen and Eric Price. Active regression via linear-sample sparsification. In Proceedings of the  32nd Conference on Learning Theory, 2019.  Micha\u0142 Derezi\u00b4nski. Fast determinantal point processes via distortion-free intermediate sampling. In  Proceedings of the 32nd Conference on Learning Theory, 2019.  Micha\u0142 Derezi\u00b4nski and Manfred K. Warmuth. Unbiased estimates for linear regression via volume sampling. In Advances in Neural Information Processing Systems 30, pages 3087-3096, Long Beach, CA, USA, December 2017.  Micha\u0142 Derezi\u00b4nski and Manfred K. Warmuth. Subsampling for ridge regression via regularized volume sampling. In Amos Storkey and Fernando Perez-Cruz, editors, Proceedings of the Twenty- First International Conference on Artificial Intelligence and Statistics, pages 716-725, Playa Blanca, Lanzarote, Canary Islands, April 2018.  Micha\u0142 Derezi\u00b4nski and Manfred K. Warmuth. Reverse iterative volume sampling for linear regres- sion. Journal of Machine Learning Research, 19(23):1-39, 2018. URL http://jmlr.org/ papers/v19/17-781.html.  Micha\u0142 Derezi\u00b4nski, Manfred K. Warmuth, and Daniel Hsu. Leveraged volume sampling for linear regression. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 2510-2519. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/ 7517-leveraged-volume-sampling-for-linear-regression.pdf. MINIMAX EXPERIMENTAL DESIGN  Micha\u0142 Derezi\u00b4nski, Manfred K. Warmuth, and Daniel Hsu. Correcting the bias in least squares regression with volume-rescaled sampling. In Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics, 2019.  Petros Drineas and Michael W. Mahoney. RandNLA: Randomized numerical linear algebra. Com-  munications of the ACM, 59:80-90, 2016.  Petros Drineas and Michael W. Mahoney. Lectures on randomized numerical linear algebra. Techni- cal report, 2017. Preprint: arXiv:1712.08880; To appear in: Lectures of the 2016 PCMI Summer School on Mathematics of Data.  Petros Drineas, Michael W Mahoney, and S. Muthukrishnan. Sampling algorithms for (cid:96)2 regression and applications. In Proceedings of the seventeenth annual ACM-SIAM symposium on Discrete algorithm, pages 1127-1136. Society for Industrial and Applied Mathematics, 2006.  Petros Drineas, Malik Magdon-Ismail, Michael W. Mahoney, and David P. Woodruff. Fast approx- imation of matrix coherence and statistical leverage. Journal of Machine Learning Research, 13: 3475-3506, 2012.  Valerii V. Fedorov. Theory of optimal experiments. Probability and mathematical statistics. Aca-  demic Press, New York, NY, USA, 1972.  Robert M. Gray and Lee D. Davisson. An Introduction to Statistical Signal Processing. Cambridge University Press, New York, NY, USA, 1st edition, 2010. ISBN 0521131820, 9780521131827.  J. Ben Hough, Manjunath Krishnapur, Yuval Peres, B\u00b4alint Vir\u00b4ag, et al. Determinantal processes and  independence. Probability surveys, 3:206-229, 2006.  Chengtao Li, Stefanie Jegelka, and Suvrit Sra. Efficient sampling for k-determinantal point pro- In Arthur Gretton and Christian C. Robert, editors, Proceedings of the 19th Interna- cesses. tional Conference on Artificial Intelligence and Statistics, volume 51 of Proceedings of Ma- chine Learning Research, pages 1328-1337, Cadiz, Spain, 09-11 May 2016. PMLR. URL http://proceedings.mlr.press/v51/li16f.html.  Ping Ma, Michael Mahoney, and Bin Yu. A statistical perspective on algorithmic leveraging. In Eric P. Xing and Tony Jebara, editors, Proceedings of the 31st International Conference on Ma- chine Learning, volume 32 of Proceedings of Machine Learning Research, pages 91-99, Bejing, China, 22-24 Jun 2014. PMLR. URL http://proceedings.mlr.press/v32/ma14. html.  Aleksandar Nikolov, Mohit Singh, and Uthaipon Tao Tantipongpipat. Proportional volume sampling and approximation algorithms for a -optimal design. In Proceedings of the Thirtieth Annual ACM- SIAM Symposium on Discrete Algorithms, pages 1369-1386, January 2019.  Beiyan Ou and Julie Zhou. Minimax robust designs for field experiments. Metrika, 69(1):45-54,  Jan 2009.  Friedrich Pukelsheim. Optimal Design of Experiments (Classics in Applied Mathematics) (Classics in Applied Mathematics, 50). Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 2006. ISBN 0898716047. MINIMAX EXPERIMENTAL DESIGN  Garvesh Raskutti and Michael Mahoney. Statistical and algorithmic perspectives on randomized sketching for ordinary least-squares. In Francis Bach and David Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 617-625, Lille, France, 07-09 Jul 2015. PMLR. URL http:// proceedings.mlr.press/v37/raskutti15.html.  Joel A. Tropp. User-friendly tail bounds for sums of random matrices. Foundations of Computa-  tional Mathematics, 12(4):389-434, August 2012.  Yining Wang, Adams W. Yu, and Aarti Singh. On computationally tractable selection of ex- periments in measurement-constrained regression models. J. Mach. Learn. Res., 18(1):5238- 5278, January 2017. ISSN 1532-4435. URL http://dl.acm.org/citation.cfm?id= 3122009.3208024.  Douglas P. Wiens and Pengfei Li. V-optimal designs for heteroscedastic regression. Journal of Statistical Planning and Inference, 145:125 - 138, 2014. ISSN 0378-3758. doi: https://doi. org/10.1016/j.jspi.2013.09.007. URL http://www.sciencedirect.com/science/ article/pii/S0378375813002310.  David P. Woodruff. Sketching as a tool for numerical linear algebra. Foundations and Trends\u00ae in  Theoretical Computer Science, 10(1-2):1-157, 2014. MINIMAX EXPERIMENTAL DESIGN"}