{"1": "Journal, 2008.  A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Machine Learning  Sanjeev Arora, Rong Ge, and Ankur Moitra. Learning topic models - going beyond SVD. In 53rd  Annual IEEE Symposium on Foundations of Computer Science (FOCS), pages 1-10, 2012.  Sanjeev Arora, Rong Ge, and Ankur Moitra. New algorithms for learning incoherent and overcom- plete dictionaries. In Proceedings of The 27th Conference on Learning Theory (COLT), pages 779-806, 2014.  Pranjal Awasthi, Maria-Florina Balcan, and Philip M. Long. The power of localization for efficiently learning linear separators with noise. In Symposium on Theory of Computing (STOC), pages 449- 458, 2014.  M.-F. Balcan and P. M. Long. Active and passive learning of linear separators under log-concave  distributions. In Proceedings of the 26th Annual Conference on Learning Theory, 2013.  T. Bansal, C. Bhattacharyya, and R. Kannan. A provable SVD-based algorithm for learning topics  in dominant admixture corpus. ArXiv e-prints, October 2014.  J. Baxter. A model of inductive bias learning. Journal of Artificial Intelligence Research, 2000.  Jonathan Baxter. A bayesian/information theoretic model of learning to learn via multiple task  sampling. Machine Learning, 28(1):7-39, 1997.  S. Ben-David and R. Schuller. Exploiting task relatedness for multiple task learning. In COLT,  2003.  Y. Bengio. Deep learning of representations: Looking forward, 2013. arXiv report 1305.0445.  Y. Bengio and O. Delalleau. On the expressive power of deep architectures. In ALT, 2011.  G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear algorithms for online multitask classification.  Journal of Machine Learning Research, 2010.  Shimon Edelman. Representation, similarity, and the chorus of prototypes. Minds and Machines, 5  (1):45-68, 1995. URL http://dx.doi.org/10.1007/BF00974189.  Scott E. Fahlman and Christian Lebiere. The cascade-correlation learning architecture.  In Ad- vances in Neural Information Processing Systems 2, [NIPS Conference, Denver, Colorado, USA, November 27-30, 1989], pages 524-532, 1989. URL http://papers.nips.cc/paper/ 207-the-cascade-correlation-learning-architecture.  Michael R. Garey and David S. Johnson. Computers and Intractability: A Guide to the Theory of  NP-Completeness. W. H. Freeman & Co., New York, NY, USA, 1979. ISBN 0716710447.  A. Gopnik, A. Meltzoff, and P. Kuhl. How babies think. Orion, 2001.  S. Hanneke. Personal communication. 2013.  13   LIFELONG LEARNING AND AUTOENCODING  References  Journal, 2008.  A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Machine Learning  Sanjeev Arora, Rong Ge, and Ankur Moitra. Learning topic models - going beyond SVD. In 53rd  Annual IEEE Symposium on Foundations of Computer Science (FOCS), pages 1-10, 2012.  Sanjeev Arora, Rong Ge, and Ankur Moitra. New algorithms for learning incoherent and overcom- plete dictionaries. In Proceedings of The 27th Conference on Learning Theory (COLT), pages 779-806, 2014.  Pranjal Awasthi, Maria-Florina Balcan, and Philip M. Long. The power of localization for efficiently learning linear separators with noise. In Symposium on Theory of Computing (STOC), pages 449- 458, 2014.  M.-F. Balcan and P. M. Long. Active and passive learning of linear separators under log-concave  distributions. In Proceedings of the 26th Annual Conference on Learning Theory, 2013.  T. Bansal, C. Bhattacharyya, and R. Kannan. A provable SVD-based algorithm for learning topics  in dominant admixture corpus. ArXiv e-prints, October 2014.  J. Baxter. A model of inductive bias learning. Journal of Artificial Intelligence Research, 2000.  Jonathan Baxter. A bayesian/information theoretic model of learning to learn via multiple task  sampling. Machine Learning, 28(1):7-39, 1997.  S. Ben-David and R. Schuller. Exploiting task relatedness for multiple task learning. In COLT,  2003.  Y. Bengio. Deep learning of representations: Looking forward, 2013. arXiv report 1305.0445.  Y. Bengio and O. Delalleau. On the expressive power of deep architectures. In ALT, 2011.  G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear algorithms for online multitask classification.  Journal of Machine Learning Research, 2010.  Shimon Edelman. Representation, similarity, and the chorus of prototypes. Minds and Machines, 5  (1):45-68, 1995. URL http://dx.doi.org/10.1007/BF00974189.  Scott E. Fahlman and Christian Lebiere. The cascade-correlation learning architecture.  In Ad- vances in Neural Information Processing Systems 2, [NIPS Conference, Denver, Colorado, USA, November 27-30, 1989], pages 524-532, 1989. URL http://papers.nips.cc/paper/ 207-the-cascade-correlation-learning-architecture.  Michael R. Garey and David S. Johnson. Computers and Intractability: A Guide to the Theory of  NP-Completeness. W. H. Freeman & Co., New York, NY, USA, 1979. ISBN 0716710447.  A. Gopnik, A. Meltzoff, and P. Kuhl. How babies think. Orion, 2001.  S. Hanneke. Personal communication. 2013. BALCAN BLUM VEMPALA  A. R. Klivans, P. M. Long, and A. Tang. Baum\u2019s algorithm learns intersections of halfspaces with  respect to log-concave distributions. In RANDOM, 2009.  A. Kumar and H. Daume. Learning task grouping and overlap in multi-task learning.  In NIPS,  2012.  Nick Littlestone, Philip M. Long, and Manfred K. Warmuth. On-line learning of linear functions.  Computational Complexity, 5(1):1-23, 1995.  L\u00b4aszl\u00b4o Lov\u00b4asz and Santosh Vempala. The geometry of logconcave functions and sampling algo-  rithms. Random Structures & Algorithms, 30(3):307-358, 2007.  A. Maurer and M. Pontil. Excess risk bounds for multitask learning with trace norm regularization.  In Proceedings of the 26th Annual Conference on Learning Theory, 2013.  Andreas Maurer. Algorithmic stability and meta-learning. Journal of Machine Learning Research,  6:967-994, 2005. URL http://www.jmlr.org/papers/v6/maurer05a.html.  Ronald L. Rivest and Robert H. Sloan. Learning complicated concepts reliably and usefully. In  COLT, pages 69-79, 1988.  Volker Roth and Julia E Vogt. A complete analysis of the l 1, p group-lasso. In Proceedings of the  29th International Conference on Machine Learning (ICML-12), pages 185-192, 2012.  R. E. Schapire and L. M. Sellie. Learning sparse multivariate polynomials over a field with queries and counterexamples. In Proceedings of the 6th Annual Conference on Computational Learning Theory, 1993.  D. Spielman. Lecture notes for 18.409: The behavior of algorithms in practice. Lecture 2: On the  condition number. 2002.  S. Thrun. Explanation-Based Neural Network Learning: A Lifelong Learning Approach. Kluwer  Academic Publishers, Boston, MA, 1996.  S. Thrun and L.Y. Pratt, editors. Learning To Learn. Kluwer Academic Publishers, Boston, MA,  Sebastian Thrun and Tom M. Mitchell. Lifelong robot learning. Robotics and Autonomous Systems,  Sebastian Thrun and Tom M. Mitchell. Learning one more thing. In Proc. 14th International Joint  Conference on Artificial Intelligence (IJCAI), pages 1217-1225, 1995b.  L. G. Valiant. A neuroidal architecture for cognitive computation. Journal of the ACM, 2000.  S. Vempala. A random-sampling-based algorithm for learning intersections of halfspaces. JACM,  L. Yang. Mathematical Theories of Interaction with Oracles. PhD thesis, CMU Dept. Machine  1997.  15(1-2):25-46, 1995a.  57(6), 2010.  Learning, 2013. LIFELONG LEARNING AND AUTOENCODING  Acknowledgments  This work was supported in part by NSF grants CCF-0953192, CCF-1451177, CCF-1422910, CCF- 1217793, EAGER-1415498, IIS-1065251, AFOSR grant FA9550-09-1-0538, ONR grant N00014- 09-1-0751, and a Microsoft Research Faculty Fellowship."}