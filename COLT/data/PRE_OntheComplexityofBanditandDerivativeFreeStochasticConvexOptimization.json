{"1": "bandits. In NIPS, 2011.  12  Y. Abbasi-Yadkori, D. P\u00b4al, and C. Szepesv\u00b4ari. Improved algorithms for linear stochastic  \u22120.500.5\u22120.0500.050.10.150.20.250.3 Shamir  Figure 1: The two solid blue lines represents Fe(w) as in Eq. (5), for e = 0.1 and e = \u22120.1, whereas the two dashed black lines represent two quadratic functions with similar minimum points. Close to the minima, Fe(w) and the quadratic functions behave rather similarly. However, as we increase |w|, the two quadratic functions become rather distinguishable, whereas Fe(w) become more and more indistinguishable for the two choices of e. Thus, distinguishing whether e = 0.1 or e = \u22120.1, based only on function values is of Fe(w), is much harder than the quadratic case  situations where these parameters scale with d. Finally, while this paper settles the case of strongly-convex and smooth functions, we still don\u2019t know what is the attainable per- formance for general convex functions, as well as the more specific case of strongly-convex (cid:16)(cid:112)d2/T (possibly non-smooth) functions. Our \u2126 lower bound still holds, but the ex- (cid:110) 4(cid:112)d2/T , (cid:112)d32/T  isting upper bounds are much larger: min  for convex functions, and  (cid:111)  (cid:17)  (cid:110) 3(cid:112)d2/T , (cid:112)d32/T  (cid:111)  for strongly-convex functions (see table 1). We don\u2019t know if the min lower bound or the existing upper bounds are tight. However, it is the current upper bounds which seem less \u201cnatural\u201d, and we suspect that they are the ones that can be considerably improved, using new algorithms which remain undiscovered.  We thank John Duchi, Satyen Kale, Robi Krauthgamer and the anonymous reviewers for helpful discussions and comments.  Acknowledgments  References  bandits. In NIPS, 2011.Y. Abbasi-Yadkori, D. P\u00b4al, and C. Szepesv\u00b4ari. Improved algorithms for linear stochastic  \u22120.500.5\u22120.0500.050.10.150.20.250.3 Complexity of Bandit and Derivative-Free Stochastic Convex Optimization  A. Agarwal, O. Dekel, and L. Xiao. Optimal algorithms for online convex optimization with  multi-point bandit feedback. In COLT, 2010.  A. Agarwal, D. Foster, D. Hsu, S. Kakade, and A. Rakhlin. Stochastic convex optimization  with bandit feedback. In NIPS, 2011.  E. Arias-Castro, E. Cand`es, and M. Davenport. On the fundamental limits of adaptive  sensing. CoRR, abs/1111.4646, 2011.  J.-Y. Audibert and S. Bubeck. Minimax policies for adversarial and stochastic bandits. In  COLT, 2009.  games. COLT, 2011.  J.-Y. Audibert, S. Bubeck, and G. Lugosi. Minimax policies for combinatorial prediction  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. Schapire. The nonstochastic multiarmed  bandit problem. SIAM J. Comput., 32(1):48-77, 2002.  S. Bubeck and N. Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed  bandit problems. CoRR, abs/1204.5721, 2012.  S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in finitely-armed and continuous-  armed bandits. Theoretical Computer Science, 412(19):1832-1852, 2011.  S. Bubeck, N. Cesa-Bianchi, and S. Kakade. Towards minimax policies for online linear  optimization with bandit feedback. In COLT, 2012.  N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge University  T. Cover and J. Thomas. Elements of information theory. Wiley, 2 edition, 2006.  A.B. Cybakov.  Introduction to nonparametric estimation. Springer series in statistics.  V. Dani, T. Hayes, and S. Kakade. The price of bandit information for online optimization.  V. Dani, T. Hayes, and S. Kakade. Stochastic linear optimization under bandit feedback.  A. Flaxman, A. Kalai, and B. McMahan. Online convex optimization in the bandit setting:  gradient descent without a gradient. In SODA, 2005.  E. Hazan and S. Kale. Beyond the regret minimization barrier: an optimal algorithm for  stochastic strongly-convex optimization. In COLT, 2011.  K. Jamieson, R. Nowak, and B. Recht. Query complexity of derivative-free optimization.  CoRR, abs/1209.2434, 2012.  S. Kullback. Information Theory and Statistics. Dover, 1959.  Press, 2006.  Springer, 2009.  In NIPS, 2007.  In COLT, 2008. Shamir  A. Nemirovsky and D. Yudin. Problem Complexity and Method E\ufb03ciency in Optimization.  Wiley-Interscience, 1983.  ECORE Discussion Paper, 2011.  Y. Nesterov. Random gradient-free minimization of convex functions. Technical Report 16,  A. Rakhlin, O. Shamir, and K. Sridharan. Making gradient descent optimal for strongly  convex stochastic optimization. In ICML, 2012.  S. Stich, C. M\u00a8uller, and B. G\u00a8artner. Optimization of convex functions with random pursuit.  CoRR, abs/1111.0194, 2011.  ICML, 2003.  M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In"}