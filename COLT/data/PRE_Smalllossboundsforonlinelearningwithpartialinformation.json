{"1": "Chamy Allenberg, Peter Auer, L\u00b4aszl\u00b4o Gy\u00a8orfi, and Gy\u00a8orgy Ottucs\u00b4ak. Hannan consistency in on-line learning in case of unbounded losses under partial monitoring. In 17th International Conference on Algorithmic Learning Theory (ALT), 2006.  Noga Alon, Nicol Cesa-Bianchi, Claudio Gentile, and Yishay Mansour. From bandits to experts: In 27th Annual Conference on Neural Information  A tale of domination and independence. Processing Systems (NIPS), 2013.  Noga Alon, Nicol`o Cesa-Bianchi, Ofer Dekel, and Tomer Koren. Online learning with feedback graphs: Beyond bandits. In Proceedings of the 28th Conference on Learning Theory (COLT), 2015.  Noga Alon, Nicol Cesa-Bianchi, Claudio Gentile, Shie Mannor, Yishay Mansour, and Ohad Shamir. Nonstochastic multi-armed bandits with graph-structured feedback. SIAM Journal on Computing (SICOMP), 46(6):1785-1826, 2017.  Jean-Yves Audibert and S\u00b4ebastien Bubeck. Regret bounds and minimax policies under partial monitoring. Journal of Machine Learning Research, 11:2785-2836, 2010. URL http:// portal.acm.org/citation.cfm?id=1953023.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochas- ISSN tic multiarmed bandit problem. 0097-5397. doi: 10.1137/S0097539701398375. URL http://dx.doi.org/10.1137/ S0097539701398375.  SIAM J. Comput., 32(1):48-77, January 2003.  Baruch Awerbuch and Robert D. Kleinberg. Adaptive routing with end-to-end feedback: distributed learning and geometric approaches. In Proceedings of the 36th Annual ACM Symposium on Theory of Computing (STOC), 2004.  6   SMALL-LOSS BOUNDS FOR ONLINE LEARNING WITH PARTIAL INFORMATION  important benefit of the freezing technique: it can be extended to handle feedback graphs (via our dual-thresholding). We also combine freezing with multiplicative weights to develop an algorithm we dL(cid:63)) for the pure bandit term GREEN-IX which achieves optimal high-probability small-loss (cid:101)O( setting. Finally, combining freezing with the truncation idea, we obtain the corresponding result for semi-bandits; in contrast, the geometric resampling analysis does not seem to extend to high probability since it does not provide a handle on the variance of the estimated loss.  \u221a  We refer the reader to the full version of the paper that can be found here https://arxiv.org/ abs/1711.03639.  We thank Haipeng Luo for pointing out the connection to the contextual bandit setting, Jake Abernethy, Adam Kalai, and Santosh Vempala for a useful discussion about Follow the Perturbed Leader, and anonymous reviewers for their useful feedback. This work was supported by NSF grants CCF- 1563714 and CDS&E-MSS 1521544, and an NSF-CAREER Award 1750575  Full version  Acknowledgments  References  Chamy Allenberg, Peter Auer, L\u00b4aszl\u00b4o Gy\u00a8orfi, and Gy\u00a8orgy Ottucs\u00b4ak. Hannan consistency in on-line learning in case of unbounded losses under partial monitoring. In 17th International Conference on Algorithmic Learning Theory (ALT), 2006.  Noga Alon, Nicol Cesa-Bianchi, Claudio Gentile, and Yishay Mansour. From bandits to experts: In 27th Annual Conference on Neural Information  A tale of domination and independence. Processing Systems (NIPS), 2013.  Noga Alon, Nicol`o Cesa-Bianchi, Ofer Dekel, and Tomer Koren. Online learning with feedback graphs: Beyond bandits. In Proceedings of the 28th Conference on Learning Theory (COLT), 2015.  Noga Alon, Nicol Cesa-Bianchi, Claudio Gentile, Shie Mannor, Yishay Mansour, and Ohad Shamir. Nonstochastic multi-armed bandits with graph-structured feedback. SIAM Journal on Computing (SICOMP), 46(6):1785-1826, 2017.  Jean-Yves Audibert and S\u00b4ebastien Bubeck. Regret bounds and minimax policies under partial monitoring. Journal of Machine Learning Research, 11:2785-2836, 2010. URL http:// portal.acm.org/citation.cfm?id=1953023.  Peter Auer, Nicol`o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochas- ISSN tic multiarmed bandit problem. 0097-5397. doi: 10.1137/S0097539701398375. URL http://dx.doi.org/10.1137/ S0097539701398375.  SIAM J. Comput., 32(1):48-77, January 2003.  Baruch Awerbuch and Robert D. Kleinberg. Adaptive routing with end-to-end feedback: distributed learning and geometric approaches. In Proceedings of the 36th Annual ACM Symposium on Theory of Computing (STOC), 2004. SMALL-LOSS BOUNDS FOR ONLINE LEARNING WITH PARTIAL INFORMATION  Alina Beygelzimer, John Langford, Lihong Li, Lev Reyzin, and Robert Schapire. Contextual bandit algorithms with supervised learning guarantees. In Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS), 2011.  Avrim Blum and Jason D. Hartline. Near-optimal online auctions. In Proceedings of the 16th Annual  ACM-SIAM Symposium on Discrete Algorithms (SODA), 2005.  Avrim Blum, Eyal Even-Dar, and Katrina Ligett. Routing without regret: On convergence to nash equilibria of regret-minimizing algorithms in routing games. In Proceedings of the 25th Annual ACM Symposium on Principles of Distributed Computing (PODC), 2006.  Avrim Blum, MohammadTaghi Hajiaghayi, Katrina Ligett, and Aaron Roth. Regret minimization and the price of total anarchy. In Proceedings of the 40th Annual ACM Symposium on Theory of Computing (STOC), 2008.  Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge University  Press, New York, NY, USA, 2006. ISBN 0521841089.  Nicol`o Cesa-Bianchi, Claudio Gentile, and Yishay Mansour. Regret minimization for reserve prices in second-price auctions. In Proceedings of the 24th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2013.  Alon Cohen, Tamir Hazan, and Tomer Koren. Online learning with feedback graphs without the graphs. In Proceedings of the 33rd International Conference on International Conference on Machine Learning (ICML), 2016.  Thomas M. Cover. Universal portfolios. Mathematical Finance, 1(1):1-29, 1991. ISSN 1467- 9965. doi: 10.1111/j.1467-9965.1991.tb00002.x. URL http://dx.doi.org/10.1111/j. 1467-9965.1991.tb00002.x.  Dylan J. Foster, Zhiyuan Li, Thodoris Lykouris, Karthik Sridharan, and \u00b4Eva Tardos. Learning in games: Robustness of fast convergence. In 30th Annual Conference on Neural Information Processing Systems (NIPS), 2016.  Yoav Freund and Robert E Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. J. Comput. Syst. Sci., 55(1):119-139, August 1997. ISSN 0022-0000. doi: 10.1006/jcss.1997.1504. URL http://dx.doi.org/10.1006/jcss.1997.1504.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Mach. Learn., 69(2-3):169-192, December 2007. ISSN 0885-6125. doi: 10.1007/ s10994-007-5016-8. URL http://dx.doi.org/10.1007/s10994-007-5016-8.  Mark Herbster and Manfred K. Warmuth. Tracking the best expert. Mach. Learn., 32(2):151-178, August 1998. ISSN 0885-6125. doi: 10.1023/A:1007424614876. URL http://dx.doi. org/10.1023/A:1007424614876.  Adam Kalai and Santosh Vempala. Efficient algorithms for online decision problems. J. Comput. Syst. Sci., 71(3):291-307, October 2005. ISSN 0022-0000. doi: 10.1016/j.jcss.2004.10.016. URL http://dx.doi.org/10.1016/j.jcss.2004.10.016. SMALL-LOSS BOUNDS FOR ONLINE LEARNING WITH PARTIAL INFORMATION  Tom\u00b4as Koc\u00b4ak, Gergely Neu, Michal Valko, and R\u00b4emi Munos. Efficient learning by implicit explo- ration in bandit problems with side observations. In 28th Annual Conference on Neural Information Processing Systems (NIPS), 2014.  Tom\u00b4a\u02c7s Koc\u00b4ak, Gergely Neu, and Michal Valko. Online learning with noisy side observations. In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics (AISTATS), 2016.  T.L Lai and Herbert Robbins. Asymptotically efficient adaptive allocation rules. Adv. Appl. Math., 6(1):4-22, March 1985. ISSN 0196-8858. doi: 10.1016/0196-8858(85)90002-8. URL http: //dx.doi.org/10.1016/0196-8858(85)90002-8.  John Langford and Tong Zhang. The epoch-greedy algorithm for contextual multi-armed bandits. In Proceedings of the 20th International Conference on Neural Information Processing Systems (NIPS), 2007.  Nick Littlestone and Manfred K. Warmuth. The weighted majority algorithm. Inf. Comput., 108 (2):212-261, February 1994. ISSN 0890-5401. doi: 10.1006/inco.1994.1009. URL http: //dx.doi.org/10.1006/inco.1994.1009.  Thodoris Lykouris, Vasilis Syrgkanis, and \u00b4Eva Tardos. Learning and efficiency in games with dynamic population. In Proceedings of the Twenty-Seventh Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2016.  Shie Mannor and Ohad Shamir. From bandits to experts: On the value of side-observations. In 25th  Annual Conference on Neural Information Processing Systems (NIPS), 2011.  Gergely Neu. First-order regret bounds for combinatorial semi-bandits. In Proceedings of the 27th  Annual Conference on Learning Theory (COLT), 2015a.  Gergely Neu. Explore no more: Improved high-probability regret bounds for non-stochastic bandits. In Proceedings of the 28th Annual Conference on Neural Information Processing Systems (NIPS), 2015b.  Gergely Neu and G\u00b4abor Bart\u00b4ok. An efficient algorithm for learning with semi-bandit feedback. In  24th International Conference on Algorithmic Learning Theory (ALT), 2013.  Alexander Rakhlin and Karthik Sridharan. Online learning with predictable sequences. In Proceed-  ings of the 26th Conference on Learning Theory (COLT), 2013.  Tim Roughgarden. Intrinsic robustness of the price of anarchy. Journal of the ACM, 2015.  Tim Roughgarden and Joshua R. Wang. Minimizing regret with multiple reserves. In Proceedings of  the 17th ACM Conference on Economics and Computation (EC), 2016.  Aristide C. Y. Tossou, Christos Dimitrakakis, and Devdatt Dubhashi. Thompson sampling for stochastic bandits with graph feedback. In 14th International Conference on Artificial Intelligence (AAAI), 2017."}