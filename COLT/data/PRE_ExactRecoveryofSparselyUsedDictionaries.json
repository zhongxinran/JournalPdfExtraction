{"1": "[1] M. Aharon, M. Elad, and A. Bruckstein. The K-SVD: An algorithm for designing overcom- plete dictionaries for sparse representation. IEEE Transactions on Signal Processing, 54(11): 4311-4322, 2006.  37.12   SPIELMAN WANG WRIGHT  (a) ER-SpUD(SC)  (b) SIV  (c) K-SVD  (d) Online  (e) Rel. Newton  Figure 1: Mean relative errors over 10 trials, with varying support k (y-axis, increase from bottom to top) and basis size n(x-axis, increase from left to right). Here, p = 5n loge n. Our algorithm using a column of Y as r (ER-SpUD), SIV [9], K-SVD [1], online dictionary learning [14], and the relative Newton method for source separation [21].  9. Discussion  The main contribution of this work is a dictionary learning algorithm with provable performance guarantees under a random coefficient model. To our knowledge, this result is the first of its kind. However, it has two clear limitations: the algorithm requires that the reconstruction be exact, i.e., Y = AX and it requires A to be square. It would be interesting to address both of these issues (see also [2] for investigation in this direction). Finally, while our results pertain to a specific coefficient model, our analysis generalizes to other distributions. Seeking meaningful, deterministic assumptions on X that will allow correct recovery is another interesting direction for future work.  This material is based in part upon work supported by the National Science Foundation under Grant No. 0915487. JW also acknowledges support from Columbia University.  Acknowledgments  References  [1] M. Aharon, M. Elad, and A. Bruckstein. The K-SVD: An algorithm for designing overcom- plete dictionaries for sparse representation. IEEE Transactions on Signal Processing, 54(11): 4311-4322, 2006.  37.12   ER-SPUD  [2] F. Bach, J. Mairal, and J. Ponce.  Techni- cal report, Technical report HAL-00345747, http://hal.archives-ouvertes.fr/ hal-00354771/fr/, 2008.  Convex sparse matrix factorizations.  [3] A. M. Bruckstein, D. L. Donoho, and M. Elad. From sparse solutions of systems of equations  to sparse modeling of signals and images. SIAM Review, 51(1):34-81, 2009.  [4] P. Comon. Independent component analysis: A new concept? Signal Processing, 36:287-314,  1994.  [5] K. Engan, S. Aase, and J. Hakon-Husoy. Method of optimal directions for frame design. In  ICASSP, volume 5, pages 2443-2446, 1999.  [6] P. Erd\u00a8os. On a lemma of Littlewood and Offord. Bulletin of the American Mathematical  Society, 51:898-902, 1945.  CoRR, 2011.  [7] Q. Geng and J. Wright. On the local correctness of (cid:96)1 minimization for dictionary learning.  [8] P. Georgiev, F. Theis, and A. Cichocki. Sparse component analysis and blind source separation  of underdetermined mixtures. IEEE Transactions on Neural Networks, 16(4), 2005.  [9] L.-A. Gottlieb and T. Neylon. Matrix sparsication and the sparse null space problem. APPROX  and RANDOM, 6302:205-218, 2010.  [10] R. Gribonval and K. Schnass. Dictionary identification-sparse matrix-factorisation via l1-  minimisation. IEEE Transactions on Information Theory, 56(7):3523-3539, 2010.  [11] F. Jaillet, R. Gribonval, M. Plumbley, and H. Zayyani. An l1 criterion for dictionary learning by subspace identification. In IEEE Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 5482-5485, 2010.  [12] K. Kreutz-Delgado, J. Murray, B. Rao, K. Engan, T. Lee, and T. Sejnowski. Dictionary learn- ing algorithms for sparse representation. Neural Computation, 15(20):349-396, 2003.  [13] M. E. M. Aharon and A. Bruckstein. On the uniqueness of overcomplete dictionaries, and a practical way to retrieve them. Linear Algebra and its Applications, 416:48-67, 2006.  [14] J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary learning for sparse coding. Proceedings of the 26th Annual International Conference on Machine Learning, pages 689- 696, 2009.  [15] J. Matousek.  On variants of the johnson-lindenstrauss lemma. Wiley InterScience  (www.interscience.wiley.com).  [16] B. Olshausen and D. Field. Emergence of simple-cell receptive field properties by learning a  sparse code for natural images. Nature, 381(6538):607-609, 1996.  [17] M. Plumbley. Dictionary learning for (cid:96)1-exact sparse coding.  In Independent Component  Analysis and Signal Separation, pages 406-413, 2007.  37.13   SPIELMAN WANG WRIGHT  [18] R. Rubinstein, A. Bruckstein, and M. Elad. Dictionaries for sparse representation modeling.  Proceedings of the IEEE, 98(6):1045-1057, 2010.  [19] D. Vainsencher, S. Mannor, and A. Bruckstein. The sample complexity of dictionary learning.  In Proc. Conference on Learning Theory, 2011.  [20] J. Yang, J. Wright, T. Huang, and Y. Ma. Image super-resolution via sparse representation.  IEEE Transactions on Image Processing, 19(11):2861-2873, 2010.  [21] M. Zibulevsky. Blind source separation with relative newton method. Proceedings ICA, pages  897-902, 2003.  Computation, 13(4), 2001.  [22] M. Zibulevsky and B. Pearlmutter. Blind source separation by sparse decomposition. Neural"}