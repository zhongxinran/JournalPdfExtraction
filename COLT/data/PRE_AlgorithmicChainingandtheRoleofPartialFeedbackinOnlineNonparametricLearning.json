{"1": "Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert Schapire. Taming the monster: A fast and simple algorithm for contextual bandits. In International Conference on Machine Learning (ICML), 2014.  Noga Alon, Nicol\u00f2 Cesa-Bianchi, Claudio Gentile, Shie Mannor, Yishay Mansour, and Ohad Shamir. Nonstochastic multi-armed bandits with graph-structured feedback. CoRR, abs/1409.8428, 2014.  Noga Alon, Nicol\u00f2 Cesa-Bianchi, Ofer Dekel, and Tomer Koren. Online learning with feedback  graphs: Beyond bandits. In COLT, pages 23-35, 2015.  Jean-Yves Audibert and S\u00e9bastien Bubeck. Regret bounds and minimax policies under partial  monitoring. Journal of Machine Learning Research, 11(Oct):2785-2836, 2010.  Peter Auer, Nicol\u00f2 Cesa-Bianchi, Yoav Freund, and Robert E Schapire. The nonstochastic multi-  armed bandit problem. SIAM journal on computing, 32(1):48-77, 2002.  S\u00e9bastien Bubeck and Nicol\u00f2 Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-  armed bandit problems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.  S\u00e9bastien Bubeck, R\u00e9mi Munos, Gilles Stoltz, and Csaba Szepesv\u00e1ri. X-armed bandits. Journal of  Machine Learning Research, 12(May):1655-1695, 2011a.  S\u00e9bastien Bubeck, Gilles Stoltz, and Jia Yuan Yu. Lipschitz bandits without the Lipschitz constant. In International Conference on Algorithmic Learning Theory, pages 144-158. Springer, 2011b.  S\u00e9bastien Bubeck, Ronen Eldan, and Yin Tat Lee. Kernel-based methods for bandit convex opti-  mization. arXiv preprint arXiv:1607.03084, 2016.  Nicol\u00f2 Cesa-Bianchi and G\u00e1bor Lugosi. On prediction of individual sequences. The Annals of  Statistics, 27(6):1865-1895, 1999.  Nicol\u00f2 Cesa-Bianchi and G\u00e1bor Lugosi. Prediction, learning, and games. Cambridge university  press, 2006.  Nicol\u00f2 Cesa-Bianchi, Claudio Gentile, and Yishay Mansour. Regret minimization for reserve prices  in second-price auctions. IEEE Transactions on Information Theory, 61(1):549-564, 2015.  Nicol\u00f2 Cesa-Bianchi, Pierre Gaillard, Claudio Gentile, and S\u00e9bastien Gerchinovitz. Algorithmic Chaining and the Role of Partial Feedback in Online Nonparametric Learning. Preprint, February 2017. URL https://arxiv.org/abs/1702.08211.  Emile Contal and Nicolas Vayatis. Stochastic process bandits: Upper confidence bounds algorithms  via generic chaining. arXiv preprint arXiv:1602.04976, 2016.  Emile Contal, C\u00e9dric Malherbe, and Nicolas Vayatis. Optimization for gaussian processes via  chaining. arXiv preprint arXiv:1510.05576, 2015.  15   ALGORITHMIC CHAINING AND THE ROLE OF PARTIAL FEEDBACK IN ONLINE NONPARAMETRIC LEARNING  References  Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert Schapire. Taming the monster: A fast and simple algorithm for contextual bandits. In International Conference on Machine Learning (ICML), 2014.  Noga Alon, Nicol\u00f2 Cesa-Bianchi, Claudio Gentile, Shie Mannor, Yishay Mansour, and Ohad Shamir. Nonstochastic multi-armed bandits with graph-structured feedback. CoRR, abs/1409.8428, 2014.  Noga Alon, Nicol\u00f2 Cesa-Bianchi, Ofer Dekel, and Tomer Koren. Online learning with feedback  graphs: Beyond bandits. In COLT, pages 23-35, 2015.  Jean-Yves Audibert and S\u00e9bastien Bubeck. Regret bounds and minimax policies under partial  monitoring. Journal of Machine Learning Research, 11(Oct):2785-2836, 2010.  Peter Auer, Nicol\u00f2 Cesa-Bianchi, Yoav Freund, and Robert E Schapire. The nonstochastic multi-  armed bandit problem. SIAM journal on computing, 32(1):48-77, 2002.  S\u00e9bastien Bubeck and Nicol\u00f2 Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-  armed bandit problems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.  S\u00e9bastien Bubeck, R\u00e9mi Munos, Gilles Stoltz, and Csaba Szepesv\u00e1ri. X-armed bandits. Journal of  Machine Learning Research, 12(May):1655-1695, 2011a.  S\u00e9bastien Bubeck, Gilles Stoltz, and Jia Yuan Yu. Lipschitz bandits without the Lipschitz constant. In International Conference on Algorithmic Learning Theory, pages 144-158. Springer, 2011b.  S\u00e9bastien Bubeck, Ronen Eldan, and Yin Tat Lee. Kernel-based methods for bandit convex opti-  mization. arXiv preprint arXiv:1607.03084, 2016.  Nicol\u00f2 Cesa-Bianchi and G\u00e1bor Lugosi. On prediction of individual sequences. The Annals of  Statistics, 27(6):1865-1895, 1999.  Nicol\u00f2 Cesa-Bianchi and G\u00e1bor Lugosi. Prediction, learning, and games. Cambridge university  press, 2006.  Nicol\u00f2 Cesa-Bianchi, Claudio Gentile, and Yishay Mansour. Regret minimization for reserve prices  in second-price auctions. IEEE Transactions on Information Theory, 61(1):549-564, 2015.  Nicol\u00f2 Cesa-Bianchi, Pierre Gaillard, Claudio Gentile, and S\u00e9bastien Gerchinovitz. Algorithmic Chaining and the Role of Partial Feedback in Online Nonparametric Learning. Preprint, February 2017. URL https://arxiv.org/abs/1702.08211.  Emile Contal and Nicolas Vayatis. Stochastic process bandits: Upper confidence bounds algorithms  via generic chaining. arXiv preprint arXiv:1602.04976, 2016.  Emile Contal, C\u00e9dric Malherbe, and Nicolas Vayatis. Optimization for gaussian processes via  chaining. arXiv preprint arXiv:1510.05576, 2015. CESA-BIANCHI GAILLARD GENTILE GERCHINOVITZ  Rocco De Rosa, Francesco Orabona, and Nicol\u00f2 Cesa-Bianchi. The ABACOC algorithm: A novel approach for nonparametric classification of data streams. In Proceedings of the IEEE Interna- tional Conference on Data Mining (ICDM), pages 733-738, 2015.  Richard M Dudley. The sizes of compact subsets of Hilbert space and continuity of Gaussian  processes. Journal of Functional Analysis, 1(3):290-330, 1967.  Yoav Freund and Robert E Schapire. A decision-theoretic generalization of on-line learning and an  application to boosting. Journal of Computer and System Sciences, 55(1):119-139, 1997.  Pierre Gaillard and Sebastien Gerchinovitz. A chaining algorithm for online nonparametric regres- sion. In Proceedings of COLT\u201915, volume 40, pages 764-796. JMLR: Workshop and Conference Proceedings, 2015.  S\u00e9bastien Gerchinovitz and Tor Lattimore. Refined lower bounds for adversarial bandits. In Ad-  vances in Neural Information Processing Systems 29 (NIPS\u201916), pages 1198-1206, 2016.  Elad Hazan. Introduction to online convex optimization. Foundations and Trends R(cid:13) in Optimization,  2(3-4):157-325, 2015.  Elad Hazan and Nimrod Megiddo. Online learning with prior knowledge. In International Confer-  ence on Computational Learning Theory (COLT\u201907), pages 499-513. 2007.  Robert Kleinberg. Nearly tight bounds for the continuum-armed bandit problem.  In NIPS, vol-  ume 17, pages 697-704, 2004.  Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal. Multi-armed bandits in metric spaces. In Proceedings of the fortieth annual ACM symposium on Theory of computing, pages 681-690. ACM, 2008.  Tyler Lu, D\u00e1vid P\u00e1l, and Martin P\u00e1l. Contextual multi-armed bandits. In AISTATS, pages 485-492,  2010.  Odalric-Ambrym Maillard and R\u00e9mi Munos. Adaptive bandits: Towards the best history-dependent  strategy. In AISTATS, pages 570-578, 2011.  Michael Ostrovsky and Michael Schwarz. Reserve prices in Internet advertising auctions: a field  experiment. In ACM Conference on Electronic Commerce, pages 59-60, 2011.  Alexander Rakhlin and Karthik Sridharan. Online nonparametric regression with general loss func-  tions. CoRR, abs/1501.06598, 2015.  Alexander Rakhlin and Karthik Sridharan. Bistro: an efficient relaxation-based method for con- textual bandits. In Proceedings of the Twentieth International Conference on Machine Learning (ICML), 2016.  Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning via sequential complex-  ities. Journal of Machine Learning Research, 16:155-186, 2015.  Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends in  Machine Learning, 4(2):107-194, 2011. ALGORITHMIC CHAINING AND THE ROLE OF PARTIAL FEEDBACK IN ONLINE NONPARAMETRIC LEARNING  Aleksandrs Slivkins. Contextual bandits with similarity information. Journal of Machine Learning  Research, 15(1):2533-2568, 2014.  Vasilis Syrgkanis, Akshay Krishnamurthy, and Robert Schapire. Efficient algorithms for adversar- ial contextual learning. In Proceedings of the Twentieth International Conference on Machine Learning (ICML), 2016.  Vladimir Vovk. Competing with wild prediction rules. Machine Learning, 69(2-3):193-212, 2007."}