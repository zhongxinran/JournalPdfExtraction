{"1": "J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learning are equivalent. In Proceedings of the 24th Annual Conference on Learning Theory (COLT \u201911), 2011.  A. Bernstein, S. Mannor, and N. Shimkin. Online classification with specificity constraints.  In NIPS, 2010.  A. Bernstein, S. Mannor, and N. Shimkin.  ized no-regret problems: Full version. Technical report, Technion, http://tx.technion.ac.il/\u02dcandreyb/OppNoRegretColt13Full.pdf.  Opportunistic strategies for general- Israel, 2013.  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of  Mathematicians, volume III, pages 335-338, 1954.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6:1-8, 1956.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, New York, NY, USA, 2006.  A. P. Dawid. The impossibility of inductive inference. Journal of the American Statistical  Association, 80:340-341, 1985.  E. Even-Dar, R. Kleinberg, S. Mannor, and Y. Mansour. Online learning with global cost  functions. 2009.  D. P. Foster and R. V. Vohra. Calibrated learning and correlated equilibrium. Games and  Economic Behavior, 21:40-55, 1997.  D. P. Foster, A. Rakhlin, K. Sridharan, approach to calibration with checking  and A. Tewari.  rules.  In Proceedings of  Complexity-based the 24th  13   Opportunistic No-Regret  solving a zero-sum game in every stage. Specifically, it is sometimes di\ufb03cult to compute the projection to the convex hull of a non-convex set; a step which our approach avoids.  We have applied our opportunistic framework to the problem of constrained regret min- imization, and shown that the best-reward-in-hindsight (rather than its convex relaxation) is attained when the opponent turns out to be stationary in our sense.  It should be of interest to devise alternative algorithms that are computationally e\ufb03cient and have optimal convergence rates. Specifically, we are currently considering a new class of algorithms that is based on online convex optimization methods.  This research was partially supported by the Israel Science Foundation under grant no. 920/12 and by the European Research Counsel under the European Union\u2019s Seventh Framework Program (FP7/2007-2013) / ERC Grant Agreement no. 306638.  Acknowledgments  References  J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learning are equivalent. In Proceedings of the 24th Annual Conference on Learning Theory (COLT \u201911), 2011.  A. Bernstein, S. Mannor, and N. Shimkin. Online classification with specificity constraints.  In NIPS, 2010.  A. Bernstein, S. Mannor, and N. Shimkin.  ized no-regret problems: Full version. Technical report, Technion, http://tx.technion.ac.il/\u02dcandreyb/OppNoRegretColt13Full.pdf.  Opportunistic strategies for general- Israel, 2013.  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of  Mathematicians, volume III, pages 335-338, 1954.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6:1-8, 1956.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  Press, New York, NY, USA, 2006.  A. P. Dawid. The impossibility of inductive inference. Journal of the American Statistical  Association, 80:340-341, 1985.  E. Even-Dar, R. Kleinberg, S. Mannor, and Y. Mansour. Online learning with global cost  functions. 2009.  D. P. Foster and R. V. Vohra. Calibrated learning and correlated equilibrium. Games and  Economic Behavior, 21:40-55, 1997.  D. P. Foster, A. Rakhlin, K. Sridharan, approach to calibration with checking  and A. Tewari.  rules.  In Proceedings of  Complexity-based the 24th Bernstein Mannor Shimkin  Annual Conference on Learning Theory http://jmlr.csail.mit.edu/proceedings/papers/v19/foster11a/foster11a.pdf.  (COLT \u201911),  pages 293-314,  2011.  J. Hannan. Approximation to Bayes risk in repeated play. Contributions to the Theory of  Games, 3:97-139, 1957.  Theory, 98:26-54, 2001.  S. Hart and A. Mas-Colell. A general class of adaptive strategies. Journal of Economic  E. Hazan and S. Kakade.  (weak) Calibration is computationally hard.  CoRR,  abs/1202.4478, 2012. http://arxiv.org/abs/1202.4478.  E. Lehrer. Approachability in infinite dimensional spaces. International Journal of Game  Theory, 31:253-268, 2002.  S. Mannor and N. Shimkin. The empirical Bayes envelope and regret minimization in competitive Markov decision processes. Mathematics of Operations Research, 28(2):327- 345, 2003.  S. Mannor and N. Shimkin. Regret minimization in repeated matrix games with variable  stage duration. Games and Economic Behavior, 63(1):227-258, 2008.  S. Mannor, J. S. Shamma, and G. Arslan. Online calibrated forecasts: Memory e\ufb03ciency  versus universality for learning in games. Machine Learning, 67:77-115, 2007.  S. Mannor, J. N. Tsitsiklis, and J. Y. Yu. Online learning with sample path constraints.  Journal of Machine Learning Research, 10:569-590, 2009.  E. Milman. Approachable sets of vector payo\ufb00s in stochastic games. Games and Economic  Behavior, 56(1):135-147, July 2006.  V. Perchet. Calibration and internal no-regret with partial monitoring. In Proceedings of the 20th International Conference on Algorithmic Learning Theory (ALT \u201909), 2009.  N. Shimkin and A. Shwartz. Guaranteed performance regions in Markovian systems with competing decision makers. IEEE Transactions on Automatic Control, 38(1):84-95, 1993.  A. N. Shiryaev. Probability. Springer, 1995.  X. Spinat. A necessary and su\ufb03cient condition for approachability. Mathematics of Oper-  ations Research, 27(1):31-44, 2002."}