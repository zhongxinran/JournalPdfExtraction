{"1": "Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Improved algorithms for linear stochastic  bandits. In Neural Information Processing Systems, 2011.  Ahmed El Alaoui and Michael W. Mahoney. Fast randomized kernel methods with statistical  guarantees. In Neural Information Processing Systems, 2015.  Daniele Calandriello and Lorenzo Rosasco. Statistical and computational trade-offs in kernel k-means.  In Neural Information Processing Systems, 2018.  Daniele Calandriello, Alessandro Lazaric, and Michal Valko. Distributed adaptive sampling for kernel matrix approximation. In International Conference on Artificial Intelligence and Statistics, 2017a.  Daniele Calandriello, Alessandro Lazaric, and Michal Valko. Second-order kernel online convex optimization with adaptive sketching. In International Conference on Machine Learning, 2017b.  Sayak Ray Chowdhury and Aditya Gopalan. On kernelized multi-armed bandits. In International  Conference on Machine Learning, 2017.  Sayak Ray Chowdhury and Aditya Gopalan. Online learning in kernelized Markov decision processes.  In International Conference on Artificial Intelligence and Statistics, 2019.  Varsha Dani, Thomas P Hayes, and Sham M Kakade. Stochastic linear optimization under bandit  feedback. In Conference on Learning Theory, 2008.  Mina Ghashami, Edo Liberty, Jeff M Phillips, and David P. Woodruff. Frequent directions: Simple  and deterministic matrix sketching. The SIAM Journal of Computing, pages 1-28, 2016.  Avishek Ghosh, Sayak Ray Chowdhury, and Aditya Gopalan. Misspecified linear bandits. In AAAI  Conference on Artificial Intelligence, 2017.  Elad Hazan, Adam Tauman Kalai, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms  for online convex optimization. In Conference on Learning Theory, 2006.  Jonathan H. Huggins, Trevor Campbell, Miko\u0142aj Kasprzak, and Tamara Broderick. Scalable Gaussian process inference with finite-data mean and variance guarantees. In International Conference on Artificial Intelligence and Statistics, 2019.  13   BKB  Acknowledgements This material is based upon work supported by the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award CCF-1231216. L. R. acknowledges the support of the AFOSR projects FA9550-17-1-0390, and BAA-AFRL-AFOSR-2016-0007 (European Office of Aerospace Research and Development), and the EU H2020-MSCA-RISE project NoMADS- DLV-777826. The research was also supported by European CHIST-ERA project DELTA, French Ministry of Higher Education and Research, Nord-Pas-de-Calais Regional Council, Inria and Otto- von-Guericke-Universit\u00e4t Magdeburg associated-team north-European project Allocate, and French National Research Agency project BoB (n.ANR-16-CE23-0003). This research has also benefited from the support of the FMJH Program PGMO and from the support to this program from Criteo.  References  Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Improved algorithms for linear stochastic  bandits. In Neural Information Processing Systems, 2011.  Ahmed El Alaoui and Michael W. Mahoney. Fast randomized kernel methods with statistical  guarantees. In Neural Information Processing Systems, 2015.  Daniele Calandriello and Lorenzo Rosasco. Statistical and computational trade-offs in kernel k-means.  In Neural Information Processing Systems, 2018.  Daniele Calandriello, Alessandro Lazaric, and Michal Valko. Distributed adaptive sampling for kernel matrix approximation. In International Conference on Artificial Intelligence and Statistics, 2017a.  Daniele Calandriello, Alessandro Lazaric, and Michal Valko. Second-order kernel online convex optimization with adaptive sketching. In International Conference on Machine Learning, 2017b.  Sayak Ray Chowdhury and Aditya Gopalan. On kernelized multi-armed bandits. In International  Conference on Machine Learning, 2017.  Sayak Ray Chowdhury and Aditya Gopalan. Online learning in kernelized Markov decision processes.  In International Conference on Artificial Intelligence and Statistics, 2019.  Varsha Dani, Thomas P Hayes, and Sham M Kakade. Stochastic linear optimization under bandit  feedback. In Conference on Learning Theory, 2008.  Mina Ghashami, Edo Liberty, Jeff M Phillips, and David P. Woodruff. Frequent directions: Simple  and deterministic matrix sketching. The SIAM Journal of Computing, pages 1-28, 2016.  Avishek Ghosh, Sayak Ray Chowdhury, and Aditya Gopalan. Misspecified linear bandits. In AAAI  Conference on Artificial Intelligence, 2017.  Elad Hazan, Adam Tauman Kalai, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms  for online convex optimization. In Conference on Learning Theory, 2006.  Jonathan H. Huggins, Trevor Campbell, Miko\u0142aj Kasprzak, and Tamara Broderick. Scalable Gaussian process inference with finite-data mean and variance guarantees. In International Conference on Artificial Intelligence and Statistics, 2019. BKB  Ilja Kuzborskij, Leonardo Cella, and Nicol\u00f2 Cesa-Bianchi. Efficient linear bandits through matrix  sketching. In International Conference on Artificial Intelligence and Statistics, 2019.  Tor Lattimore and Csaba Szepesv\u00e1ri. Bandit algorithms. 2019.  Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. A contextual-bandit approach to personalized news article recommendation. International World Wide Web Conference, 2010.  Haitao Liu, Yew-Soon Ong, Xiaobo Shen, and Jianfei Cai. When Gaussian process meets big data:  A Review of scalable GPs. Technical report, 2018.  Jonas Mockus. Global optimization and the Bayesian approach. 1989.  Mojm\u00edr Mutn\u00fd and Andreas Krause. Efficient high-dimensional Bayesian optimization with additivity  and quadrature Fourier features. In Neural Information Processing Systems, 2018.  Martin Pelikan. Hierarchical Bayesian optimization algorithm. In Studies in Fuzziness and Soft  Computing, pages 105-129. 2005.  Joaquin Quinonero-Candela, Carl Edward Rasmussen, and Christopher K. I. Williams. Approxi- mation methods for gaussian process regression. Large-scale kernel machines, pages 203-224, 2007.  Ali Rahimi and Ben Recht. Random features for large-scale kernel machines. In Neural Information  Processing Systems, 2007.  MIT Press, 2006.  Carl Edward. Rasmussen and Christopher K. I. Williams. Gaussian processes for machine learning.  Herbert Robbins. Some aspects of the sequential design of experiments. Bulletin of the American  Mathematics Society, 58:527-535, 1952.  Jonathan Scarlett, Ilija Bogunovic, and Volkan Cevher. Lower bounds on regret for noisy Gaussian  process bandit optimization. In Conference on Learning Theory, 2017.  Matthias Seeger, Christopher Williams, and Neil Lawrence. Fast forward selection to speed up sparse Gaussian process regression. In International Conference on Artificial Intelligence and Statistics, 2003.  Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical bayesian optimization of machine  learning algorithms. In Neural Information Processing Systems, 2012.  Niranjan Srinivas, Andreas Krause, Sham M. Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. International Conference on Machine Learning, 2010.  Joel Aaron Tropp. An introduction to matrix concentration inequalities. Foundations and Trends in  Machine Learning, 8(1-2):1-230, 2015.  Michal Valko, Nathan Korda, R\u00e9mi Munos, Ilias Flaounas, and Nelo Cristianini. Finite-time analysis  of kernelised contextual bandits. In Uncertainty in Artificial Intelligence, 2013. Grace Wahba. Spline models for observational data. Society for Industrial and Applied Mathematics,  1990.  Zi Wang, Clement Gehring, Pushmeet Kohli, and Stefanie Jegelka. Batched Large-scale Bayesian Optimization in High-dimensional Spaces. In International Conference on Artificial Intelligence and Statistics, 2018.  Xiaotian Yu, Michael R. Lyu, and Irwin King. CBRAP: Contextual bandits with random projection.  In AAAI Conference on Artificial Intelligence, 2017.  BKB"}