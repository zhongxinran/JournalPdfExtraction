{"1": "J-Y. Audibert, S. Bubeck, and R. Munos. Best arm identification in multi-armed bandits.  In Conference on Learning Theory (COLT), 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine Learning, 47(2):235-256, 2002.  S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in finitely armed and continuous armed bandits. Theoretical Computer Science 412, 1832-1852, 412:1832-1852, 2011.  S. Bubeck, T. Wang, and N. Viswanathan. Multiple identifications in multi-armed bandits.  In International Conference on Machine Learning (ICML). To appear, 2013.  O. Capp\u00b4e, A. Garivier, O-A. Maillard, R. Munos, and G. Stoltz. Kullback-Leibler upper to appear in Annals of Statistics,  confidence bounds for optimal sequential allocation. 2013.  T. Cover and J. Thomas. Elements of Information Theory (2nd Edition). Wiley, 2006.  E. Even-Dar, S. Mannor, and Y. Mansour. Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. Journal of Machine Learning Research, 7:1079-1105, 2006.  V. Gabillon, M. Ghavamzadeh, and A. Lazaric. Best arm identification: A unified approach to fixed budget and fixed confidence. In Neural Information and Signal Processing (NIPS), 2012.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and  beyond. In Conference on Learning Theory (COLT), 2011.  V. Heidrich-Meisner and C. Igel. Hoe\ufb00ding and Bernstein races for selecting policies in evo- lutionary direct policy search. In International Conference on Learning Theorey (ICML), 2009.  S. Kalyanakrishnan. Learning Methods for Sequential Decision Making with Imperfect Rep- resentations. PhD thesis, Departement of Computer Science, The University of Texas at Austin, 2011.  S. Kalyanakrishnan and P. Stone. E\ufb03cient selection in multiple bandit arms: Theory and  practice. In International Conference on Machine Learning (ICML), 2010.  S. Kalyanakrishnan, A. Tewari, P. Auer, and P. Stone. PAC subset selection in stochastic multi-armed bandits. In International Conference on Machine Learning (ICML), 2012.  E. Kaufmann, N. Korda, and R. Munos. Thompson sampling : an asymptotically optimal  finite-time analysis. In Algorithmic Learning Theory (ALT), 2012.  T.L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6(1):4-22, 1985.  14   Kaufmann Kalyanakrishnan  References  J-Y. Audibert, S. Bubeck, and R. Munos. Best arm identification in multi-armed bandits.  In Conference on Learning Theory (COLT), 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine Learning, 47(2):235-256, 2002.  S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in finitely armed and continuous armed bandits. Theoretical Computer Science 412, 1832-1852, 412:1832-1852, 2011.  S. Bubeck, T. Wang, and N. Viswanathan. Multiple identifications in multi-armed bandits.  In International Conference on Machine Learning (ICML). To appear, 2013.  O. Capp\u00b4e, A. Garivier, O-A. Maillard, R. Munos, and G. Stoltz. Kullback-Leibler upper to appear in Annals of Statistics,  confidence bounds for optimal sequential allocation. 2013.  T. Cover and J. Thomas. Elements of Information Theory (2nd Edition). Wiley, 2006.  E. Even-Dar, S. Mannor, and Y. Mansour. Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. Journal of Machine Learning Research, 7:1079-1105, 2006.  V. Gabillon, M. Ghavamzadeh, and A. Lazaric. Best arm identification: A unified approach to fixed budget and fixed confidence. In Neural Information and Signal Processing (NIPS), 2012.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and  beyond. In Conference on Learning Theory (COLT), 2011.  V. Heidrich-Meisner and C. Igel. Hoe\ufb00ding and Bernstein races for selecting policies in evo- lutionary direct policy search. In International Conference on Learning Theorey (ICML), 2009.  S. Kalyanakrishnan. Learning Methods for Sequential Decision Making with Imperfect Rep- resentations. PhD thesis, Departement of Computer Science, The University of Texas at Austin, 2011.  S. Kalyanakrishnan and P. Stone. E\ufb03cient selection in multiple bandit arms: Theory and  practice. In International Conference on Machine Learning (ICML), 2010.  S. Kalyanakrishnan, A. Tewari, P. Auer, and P. Stone. PAC subset selection in stochastic multi-armed bandits. In International Conference on Machine Learning (ICML), 2012.  E. Kaufmann, N. Korda, and R. Munos. Thompson sampling : an asymptotically optimal  finite-time analysis. In Algorithmic Learning Theory (ALT), 2012.  T.L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6(1):4-22, 1985. Information Complexity in Bandit Subset Selection  O-A. Maillard, R. Munos, and G. Stoltz. A finite-time analysis of multi-armed bandits problems with Kullback-Leibler divergences. In Conference On Learning Theory (COLT), 2011.  S. Mannor and J. Tsitsiklis. The sample complexity of exploration in the multi-armed  bandit problem. Journal of Machine Learning Research, pages 623-648, 2004.  O. Maron and A. Moore. The racing algorithm: Model selection for lazy learners. Artificial  Intelligence Review, 11(1-5):113-131, 1997.  V. Mnih, C. Szepesv\u00b4ari, and J-Y. Audibert. Empirical Bernstein stopping. In International  Conference on Machine Learning (ICML), 2008.  W.R. Thompson. On the likelihood that one unknown probability exceeds another in view  of the evidence of two samples. Biometrika, 25:285-294, 1933. Kaufmann Kalyanakrishnan"}