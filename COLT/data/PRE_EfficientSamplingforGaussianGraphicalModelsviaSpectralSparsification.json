{"1": "2014.  Sungjin Ahn, Babak Shahbaba, and Max Welling. Distributed stochastic gradient MCMC. In ICML,  Christophe Andrieu, Nando De Freitas, Arnaud Doucet, and Michael I Jordan. An introduction to  MCMC for machine learning. Machine learning, 50, 2003.  Rajendra Bhatia. Positive definite matrices. Princeton University Press, 2007.  Christopher M. Bishop. Pattern recognition and machine learning. springer New York, 2006.  Edmond Chow and Yousef Saad. Preconditioned krylov subspace methods for sampling multivariate  gaussian distributions. SIAM Journal on Scientific Computing, 2014.  Paul Christiano, Jonathan A Kelner, Aleksander Madry, Daniel A Spielman, and Shang-Hua Teng. Electrical \ufb02ows, laplacian systems, and faster approximation of maximum \ufb02ow in undirected graphs. In Proceedings of the forty-third annual ACM symposium on Theory of computing, pages 273-282. ACM, 2011.  Ronald R Coifman, Stephane Lafon, Ann B Lee, Mauro Maggioni, Boaz Nadler, Frederick Warner, and Steven W Zucker. Geometric diffusions as a tool for harmonic analysis and structure defini- tion of data: Multiscale methods. Proceedings of the National Academy of Sciences of the United States of America, 102(21):7432-7437, 2005.  Samuel I. Daitch and Daniel A. Spielman. Faster approximate lossy generalized \ufb02ow via interior point algorithms. In Proceedings of the 40th annual ACM symposium on Theory of computing, STOC \u201908. ACM, 2008.  Joseph Gonzalez, Yucheng Low, Arthur Gretton, and Carlos Guestrin. Parallel gibbs sampling:  From colored fields to thin junction trees. In Proc. of AISTATS\u201911, 2011.  Keith D Gremban. Combinatorial preconditioners for sparse, symmetric, diagonally dominant  linear systems. PhD thesis, Carnegie Mellon University, 1996.  Nicholas J Higham and Lijing Lin. On pth roots of stochastic matrices. Linear Algebra and its  Applications, 435(3):448-463, 2011.  Alexander Ihler, Er T. Ihler, Erik Sudderth, William Freeman, and Alan Willsky. Efficient multiscale  sampling from products of gaussian mixtures. In In NIPS. MIT Press, 2003.  Matthew Johnson, James Saunderson, and Alan Willsky. Analyzing hogwild parallel gaussian gibbs sampling. In C.J.C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 2715-2723. Curran Associates, Inc., 2013.  M. I. Jordan. Learning in Graphical Models. The MIT press, 1998.  Jonathan A Kelner and Alex Levin. Spectral sparsification in the semi-streaming setting. Theory of  Computing Systems, 53(2):243-262, 2013.  13   EFFICIENT GAUSSIAN SAMPLING VIA SPECTRAL SPARSIFICATION  References  2014.  Sungjin Ahn, Babak Shahbaba, and Max Welling. Distributed stochastic gradient MCMC. In ICML,  Christophe Andrieu, Nando De Freitas, Arnaud Doucet, and Michael I Jordan. An introduction to  MCMC for machine learning. Machine learning, 50, 2003.  Rajendra Bhatia. Positive definite matrices. Princeton University Press, 2007.  Christopher M. Bishop. Pattern recognition and machine learning. springer New York, 2006.  Edmond Chow and Yousef Saad. Preconditioned krylov subspace methods for sampling multivariate  gaussian distributions. SIAM Journal on Scientific Computing, 2014.  Paul Christiano, Jonathan A Kelner, Aleksander Madry, Daniel A Spielman, and Shang-Hua Teng. Electrical \ufb02ows, laplacian systems, and faster approximation of maximum \ufb02ow in undirected graphs. In Proceedings of the forty-third annual ACM symposium on Theory of computing, pages 273-282. ACM, 2011.  Ronald R Coifman, Stephane Lafon, Ann B Lee, Mauro Maggioni, Boaz Nadler, Frederick Warner, and Steven W Zucker. Geometric diffusions as a tool for harmonic analysis and structure defini- tion of data: Multiscale methods. Proceedings of the National Academy of Sciences of the United States of America, 102(21):7432-7437, 2005.  Samuel I. Daitch and Daniel A. Spielman. Faster approximate lossy generalized \ufb02ow via interior point algorithms. In Proceedings of the 40th annual ACM symposium on Theory of computing, STOC \u201908. ACM, 2008.  Joseph Gonzalez, Yucheng Low, Arthur Gretton, and Carlos Guestrin. Parallel gibbs sampling:  From colored fields to thin junction trees. In Proc. of AISTATS\u201911, 2011.  Keith D Gremban. Combinatorial preconditioners for sparse, symmetric, diagonally dominant  linear systems. PhD thesis, Carnegie Mellon University, 1996.  Nicholas J Higham and Lijing Lin. On pth roots of stochastic matrices. Linear Algebra and its  Applications, 435(3):448-463, 2011.  Alexander Ihler, Er T. Ihler, Erik Sudderth, William Freeman, and Alan Willsky. Efficient multiscale  sampling from products of gaussian mixtures. In In NIPS. MIT Press, 2003.  Matthew Johnson, James Saunderson, and Alan Willsky. Analyzing hogwild parallel gaussian gibbs sampling. In C.J.C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 2715-2723. Curran Associates, Inc., 2013.  M. I. Jordan. Learning in Graphical Models. The MIT press, 1998.  Jonathan A Kelner and Alex Levin. Spectral sparsification in the semi-streaming setting. Theory of  Computing Systems, 53(2):243-262, 2013. CHENG CHENG LIU PENG TENG  Jonathan A. Kelner, Lorenzo Orecchia, Aaron Sidford, and Zeyuan Allen Zhu. A simple, combina- torial algorithm for solving sdd systems in nearly-linear time. In Proceedings of the Forty-fifth Annual ACM Symposium on Theory of Computing, STOC \u201913, 2013.  Daphne Koller and Nir Friedman. Probabilistic Graphical Models: Principles and Techniques ISBN 0262013193,  - Adaptive Computation and Machine Learning. The MIT Press, 2009. 9780262013192.  Ioannis Koutis. A simple parallel algorithm for spectral sparsification. CoRR, 2014.  Ioannis Koutis, Gary L. Miller, and Richard Peng. Approaching optimality for solving sdd linear systems. In Proceedings of the 2010 IEEE 51st Annual Symposium on Foundations of Computer Science, FOCS \u201910, pages 235-244, 2010.  S. Leang Shieh, Jason Tsai, and Sui Lian. Determining continuous-time state equations from discrete-time state equations via the principal q th root method. Automatic Control, IEEE Trans- actions on, 1986.  Ying Liu, Oliver Kosut, and Alan S. Willsky. Sampling from gaussian graphical models using sub- graph perturbations. In Proceedings of the 2013 IEEE International Symposium on Information Theory, Istanbul, Turkey, July 7-12, 2013, 2013.  Gary L. Miller, Richard Peng, and Shen Chen Xu. Improved parallel algorithms for spanners and  hopsets. CoRR, 2013.  Geng Niu, Benjamin Recht, Christopher Re, and Stephen J. Wright. Hogwild: A lock-free approach  to parallelizing stochastic gradient descent. In NIPS, 2011.  Richard Peng. Algorithm Design Using Spectral Graph Theory. PhD thesis, Carnegie Mellon  University, Pittsburgh, August 2013. CMU CS Tech Report CMU-CS-13-121.  Richard Peng and Daniel A. Spielman. An efficient parallel solver for sdd linear systems.  In Proceedings of the 46th Annual ACM Symposium on Theory of Computing, STOC \u201914. ACM, 2014.  Daniel A. Spielman and Nikil Srivastava. Graph sparsification by effective resistances. SIAM J.  Comput., 40(6):1913-1926, 2011.  Daniel A. Spielman and Shang-Hua Teng. Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems. In Proceedings of the Thirty-sixth Annual ACM Symposium on Theory of Computing, STOC \u201904, 2004.  Daniel A. Spielman and Shang-Hua Teng. Spectral sparsification of graphs. SIAM J. Comput.,  2011.  Daniel A. Spielman and Shang-Hua Teng. Nearly linear time algorithms for preconditioning and solving symmetric, diagonally dominant linear systems. SIAM J. Matrix Analysis and Applica- tions, 35(3):835-885, 2014. EFFICIENT GAUSSIAN SAMPLING VIA SPECTRAL SPARSIFICATION"}