{"1": "Yasin Abbasi-Adkori. Online Least Squares Estimation with Self-Normalized Processes: An Ap-  plication to Bandit Problems. 2011.  Joshua D. Angrist, Guido W. Imbens, and Donald B. Rubin. Identification of causal effects using instrumental variables. Journal of the American Statistical Association, 91(434):444-455, 1996.  Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Du\ufb02o, Christian Hansen, and Whit- ney Newey. Double/debiased/neyman machine learning of treatment effects. American Economic Review, 107(5):261-65, 2017.  Feng Ding. Two-stage least squares based iterative estimation algorithm for CARARMA sys- tem modeling. ISSN 0307904X. doi: 10.1016/j.apm.2012.10.014. URL https://linkinghub.elsevier. com/retrieve/pii/S0307904X12006191.  Applied Mathematical Modelling, 37(7):4798-4808, April 2013.  Mohamad Kazem Shirani Faradonbeh, Ambuj Tewari, and George Michailidis. Finite time identi-  fication in unstable linear systems. Automatica, 96:342-353, 2018.  Miguel Galrinho.  Least squares methods for system identification of structured mod- 2016. URL http://www.diva-portal.org/smash/get/diva2:953835/  els. FULLTEXT01.pdf.  Miguel Galrinho, Cristian Rojas, and H\u00b4akan Hjalmarsson. A weighted least-squares method for parameter estimation in structured models. In 53rd IEEE Conference on Decision and Control, December 2014. doi: 10.1109/CDC.2014.7039903.  Evan Greensmith, Peter L. Bartlett, and Jonathan Baxter. Variance reduction techniques for gradient estimates in reinforcement learning. Journal of Machine Learning Research, 5(Nov):1471-1530, 2004.  Lei Guo and Dawei Huang. Least-squares identification for ARMAX models without the positive real condition. IEEE Transactions on Automatic Control, 34(10):1094-1098, October 1989. ISSN 0018-9286. doi: 10.1109/9.35285.  Lars Peter Hansen and Kenneth J. Singleton. Generalized instrumental variables estimation of nonlinear rational expectations models. Econometrica: Journal of the Econometric Society, pages 1269-1286, 1982.  Moritz Hardt, Tengyu Ma, and Benjamin Recht. Gradient Descent Learns Linear Dynamical Sys-  tems. arXiv:1609.05191, 2016.  M.L.J. Hautus. Strong detectability and observers. Linear Algebra and its applications, 50:353-  368, 1983.  Elad Hazan, Karan Singh, and Cyril Zhang. Learning Linear Dynamical Systems via Spectral  Filtering. In Neural Information Processing Systems, 2017.  13   LEARNING LINEAR DYNAMICAL SYSTEMS WITH SEMI-PARAMETRIC LEAST SQUARES  References  Yasin Abbasi-Adkori. Online Least Squares Estimation with Self-Normalized Processes: An Ap-  plication to Bandit Problems. 2011.  Joshua D. Angrist, Guido W. Imbens, and Donald B. Rubin. Identification of causal effects using instrumental variables. Journal of the American Statistical Association, 91(434):444-455, 1996.  Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Du\ufb02o, Christian Hansen, and Whit- ney Newey. Double/debiased/neyman machine learning of treatment effects. American Economic Review, 107(5):261-65, 2017.  Feng Ding. Two-stage least squares based iterative estimation algorithm for CARARMA sys- tem modeling. ISSN 0307904X. doi: 10.1016/j.apm.2012.10.014. URL https://linkinghub.elsevier. com/retrieve/pii/S0307904X12006191.  Applied Mathematical Modelling, 37(7):4798-4808, April 2013.  Mohamad Kazem Shirani Faradonbeh, Ambuj Tewari, and George Michailidis. Finite time identi-  fication in unstable linear systems. Automatica, 96:342-353, 2018.  Miguel Galrinho.  Least squares methods for system identification of structured mod- 2016. URL http://www.diva-portal.org/smash/get/diva2:953835/  els. FULLTEXT01.pdf.  Miguel Galrinho, Cristian Rojas, and H\u00b4akan Hjalmarsson. A weighted least-squares method for parameter estimation in structured models. In 53rd IEEE Conference on Decision and Control, December 2014. doi: 10.1109/CDC.2014.7039903.  Evan Greensmith, Peter L. Bartlett, and Jonathan Baxter. Variance reduction techniques for gradient estimates in reinforcement learning. Journal of Machine Learning Research, 5(Nov):1471-1530, 2004.  Lei Guo and Dawei Huang. Least-squares identification for ARMAX models without the positive real condition. IEEE Transactions on Automatic Control, 34(10):1094-1098, October 1989. ISSN 0018-9286. doi: 10.1109/9.35285.  Lars Peter Hansen and Kenneth J. Singleton. Generalized instrumental variables estimation of nonlinear rational expectations models. Econometrica: Journal of the Econometric Society, pages 1269-1286, 1982.  Moritz Hardt, Tengyu Ma, and Benjamin Recht. Gradient Descent Learns Linear Dynamical Sys-  tems. arXiv:1609.05191, 2016.  M.L.J. Hautus. Strong detectability and observers. Linear Algebra and its applications, 50:353-  368, 1983.  Elad Hazan, Karan Singh, and Cyril Zhang. Learning Linear Dynamical Systems via Spectral  Filtering. In Neural Information Processing Systems, 2017. LEARNING LINEAR DYNAMICAL SYSTEMS WITH SEMI-PARAMETRIC LEAST SQUARES  Elad Hazan, Holden Lee, Karan Singh, Cyril Zhang, and Yi Zhang. Spectral Filtering for General  Linear Dynamical Systems. 2018.  B. L. Ho and R. E. Kalman. Effective construction of linear state-variable models from input/output  functions. Automatisierungs-Technik, 14(1-12):545-548, 1966.  Sham Kakade, Mengdi Wang, and Lin F Yang. Variance reduction methods for sublinear reinforce-  ment learning. arXiv preprint arXiv:1802.09184, 2018.  Felix Krahmer, Shahar Mendelson, and Holger Rauhut. Suprema of chaos processes and the re- stricted isometry property. Communications on Pure and Applied Mathematics, 67(11):1877- 1904, 2014.  Akshay Krishnamurthy, Zhiwei Steven Wu, and Vasilis Syrgkanis. Semiparametric contextual ban-  dits. arXiv preprint arXiv:1803.04204, 2018.  Sun-Yuan Kung. A new identification and model reduction algorithm via singular value decom- position. In 12th Asilomar Conference on Circuits, Systems and Computers, Pacific Grove, CA, November, 1978, 1978.  Beatrice Laurent and Pascal Massart. Adaptive estimation of a quadratic functional by model selec-  tion. Annals of Statistics, pages 1302-1338, 2000.  Lennart Ljung. System Identification: Theory for the User. 1999.  Samet Oymak. Stochastic gradient descent learns state equations with nonlinear activations. arXiv  preprint arXiv:1809.03019, 2018.  Samet Oymak and Necimye Ozay. Non-asymptotic Identification of LTI Systems from a Single  Trajectory. 2018.  S. Joe Qin. An overview of subspace identification. Computers & Chemical Engineering, 30(10-12): 1502-1513, September 2006. ISSN 00981354. doi: 10.1016/j.compchemeng.2006.05.045. URL https://linkinghub.elsevier.com/retrieve/pii/S009813540600158X.  Tuhin Sarkar and Alexander Rakhlin. How fast can linear dynamical systems be learned? arXiv  preprint arXiv:1812.01251, 2018.  Tuhin Sarkar, Alexander Rakhlin, and Munther A Dahleh. Finite-time system identification for  partially observed lti systems of unknown order. arXiv preprint arXiv:1902.01848, 2019.  Parikshit Shah, Badri Narayan Bhaskar, Gongguo Tang, and Benjamin Recht. Linear System Iden-  tification via Atomic Norm Regularization. In Conference on Decision and Control, 2012.  John Shawe-Taylor, Peter L. Bartlett, Robert C. Williamson, and Martin Anthony. Structural risk minimization over data-dependent hierarchies. IEEE transactions on Information Theory, 44(5): 1926-1940, 1998. LEARNING LINEAR DYNAMICAL SYSTEMS WITH SEMI-PARAMETRIC LEAST SQUARES  Aaron Sidford, Mengdi Wang, Xian Wu, and Yinyu Ye. Variance reduced value iteration and faster algorithms for solving markov decision processes. In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 770-787. Society for Industrial and Ap- plied Mathematics, 2018.  Max Simchowitz, Horia Mania, Stephen Tu, Michael I. Jordan, and Benjamin Recht. Learning without mixing: Towards a sharp analysis of linear system identification. In S\u00b4ebastien Bubeck, Vianney Perchet, and Philippe Rigollet, editors, Proceedings of the 31st Conference On Learning Theory, volume 75 of Proceedings of Machine Learning Research, pages 439-473. PMLR, 06-09 Jul 2018. URL http://proceedings.mlr.press/v75/simchowitz18a.html.  William Spinelli, Luigi Piroddi, and Marco Lovera. On the role of prefiltering in nonlinear sys- tem identification. IEEE Transactions on Automatic Control, 50(10):1597-1602, October 2005. ISSN 0018-9286. doi: 10.1109/TAC.2005.856655. URL http://ieeexplore.ieee. org/document/1516260/.  Elias M. Stein and Rami Shakarchi. Princeton lecture in analysis ii. complex analysis, 2003.  Richard S. Sutton and Andrew G. Barto. Reinforcement Learning. 1998.  Michel Talagrand. Upper and Lower Bounds for Stochastic Processes: Modern Methods and Clas-  sical Problems, volume 60. Springer Science & Business Media, 2014.  Paolo Tilli. Singular values and eigenvalues of non-hermitian block toeplitz matrices. Linear Alge-  bra and its Applications, 272(1-3):59-89, 1998.  George Tucker, Andriy Mnih, Chris J Maddison, John Lawson, and Jascha Sohl-Dickstein. REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models. In Advances in Neural Information Processing Systems, pages 2627-2636, 2017.  Michel Verhaegen. Subspace model identification part 3. analysis of the ordinary output-error state- space model identification algorithm. International Journal of Control, 58(3):555-586, 1993.  Roman Vershynin. High-dimensional Probability: An introduction with Applications in Data Sci-  ence, volume 47. Cambridge University Press, 2018.  Mats Viberg, Bo Wahlberg, and Bj\u00a8orn Ottersten. Analysis of state space system identification methods based on instrumental variables and subspace fitting. Automatica, 33(9):1603-1616, 1997.  D. Q. Wang. Least squares-based recursive and iterative estimation for output error moving average IET Control Theory Applications, 5(14):1648-1657, September  systems using data filtering. 2011. ISSN 1751-8644. doi: 10.1049/iet-cta.2010.0416.  Lex Weaver and Nigel Tao. The optimal reward baseline for gradient-based reinforcement learning. In Proceedings of the Seventeenth Conference on Uncertainty in Artificial iItelligence, pages 538-545. Morgan Kaufmann Publishers Inc., 2001. LEARNING LINEAR DYNAMICAL SYSTEMS WITH SEMI-PARAMETRIC LEAST SQUARES  Yong Zhang. Unbiased identification of a class of multi-input single-output systems with correlated disturbances using bias compensation methods. Mathematical and Computer Modelling, 53(9- 10):1810-1819, May 2011. ISSN 08957177. doi: 10.1016/j.mcm.2010.12.059. URL https: //linkinghub.elsevier.com/retrieve/pii/S0895717711000045.  Wei Xing Zheng. A revisit to least-squares parameter estimation of ARMAX systems. In 2004 43rd IEEE Conference on Decision and Control (CDC) (IEEE Cat. No.04CH37601), volume 4, pages 3587-3592 Vol.4, December 2004. doi: 10.1109/CDC.2004.1429269.  Kemin Zhou, John C. Doyle, and Keith Glover. Robust and Optimal Control, volume 40. Prentice  Hall, 1996. LEARNING LINEAR DYNAMICAL SYSTEMS WITH SEMI-PARAMETRIC LEAST SQUARES  ContentsIntroduction 1.1 Problem Statement 1.2 Prefiltered Least Squares (PF-LS) 1.3 Organization .  .  .  .  .  .  .  .  .  .  .  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  2 Rates for Learning LTI Systems  2.1 Learning without the stability gap . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2 Recovering the System Parameters . . . . . . . . . . . . . . . . . . . . . . . . . .  3 Oracle Inequality for Prefiltered Least Squares  3.1 Statement of the Oracle Inequality . . . . . . . . . . . . . . . . . . . . . . . . . .  4 Proof Sketch for Bounding Opt\u00b5  5 Related Work  Preface  Notation  I Proof of Secondary Results  A Examples of Phase Rank  B Proof of Corollary B.1  B.1 Dependence on and Selection of T and L . . . . . . . . . . . . . . . . . . . . . . B.2 Proof of Corollary B.1 (a) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.3 Proof of Corollary B.1 (b) . . . . . . . . . . . . . . . . . . . . . . . . . . B.4 Proof of Corollary B.1 (c) and (d)  C Lower Bound for OLS for Marginally Stable Systems  C.1 Proof of Proposition C.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.1.1 Proof of Lemma C.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  C.2 Proof of Lemma C.3 .  .  II General Bound for Prefiltered Least Squares  D General Statement and Analysis PF-LS  D.1 Proof of Uniform Bound: Theorem D.1, Part (a) . . . . . . . . . . . . . . . . . . . D.2 Proof of (cid:103)Opt\u00b5 bound, Theorem D.1, Part (b) . . . . . . . . . . . . . . . . . . . . . D.2.1 Proof of Lemma D.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.2.2 Proof of Lemma D.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1 2 3 4  5 6 7  7 9122122  25 26 27 27 27  28 29 30 3133 34 36 37 38   LEARNING LINEAR DYNAMICAL SYSTEMS WITH SEMI-PARAMETRIC LEAST SQUARES  D.2.3 Proof of Lemma D.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  E Semi-Parametric Regression  E.1 Proof of Theorem E.1, Part (a) . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.2 Proof of Theorem E.1, Part (b) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.3 Proof of Lemma E.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.4 Proof of Lemma E.2 .  . .  F Chaining for Self-Normalized Tail Inequalities  F.1 Proof of Proposition E.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Proof of Lemma F.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  F.2 Proof of Theorem F.2 .  F.1.1  .  III Prefiltered Least Squares for Linear Dynamical Systems  G Bounds on (cid:107)\u2206\u03c6(cid:107)op  . .  G.1 Outline of the Proofs G.2 Bounding G(1) . G.3 Bounding G(2) . . G.4 Additional terms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . G.4.1 Process noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . G.4.2 Output noise . G.4.3 Contribution of the initial state . . . . . . . . . . . . . . . . . . . . . . . .  . . . . . .  . . .  H Definition of M , M adv, and Proof of Proposition 2.1 .  .  .  .  .  .  .  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H.2 Proof of Proposition 2.1 . H.3 Proof of Lemma H.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H.4 Selecting the parameter L . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H.4.1 Proof Sketch of Proposition H.4 . . . . . . . . . . . . . . . . . . . . . . .  I Polynomial Approximations and Phase Rank .  I.1 Main Results  .  .  .  .  .  Results for Adversarial Noise Bounds for Disentangling Filters  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . I.1.1 K1 and K2: Controlling Poles and Markov Operator Norms . . . . . . . . I.1.2 Main Results: Stochastic Noise with Block-Scalar Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . I.1.3 . . . . . . . . . . . . . . . . . . . . . . I.1.4 Polynomial Approximations for Linear Dynamical Systems . . . . . . . . . . . . I.2.1 Approximations Using Block-Scalar Filters: Proof of Proposition I.1 . . . . . . . . . . . . . . . . . . . I.2.2 Approximations using Disentangling Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Proof of Theorem I.4 .  I.2  I.339 40 43 44 45  45 47 48 4951 51 53 54 56 56 56 56  57 57 57 60 61 63  64 65 65 67 67 68 69 71 72 72 LEARNING LINEAR DYNAMICAL SYSTEMS WITH SEMI-PARAMETRIC LEAST SQUARES  J Supporting Proofs  .  .  J.1  Proofs for Section I.2 . J.1.1 J.1.2 J.1.3 J.1.4  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Proof of Theorem I.12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . Proof of Proposition I.13 . . . . . . . . . . . . . . . . . . . . . . . . . . . Proof of Theorem I.14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . Proof of Proposition I.11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  J.2 Bounds on Finite System Norms: Proof of Proposition I.2  K Bounds under Strong Observability  K.1 Granular Bounds for Strong Observability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . K.2 Proof of Theorem K.2 . K.3 Proof of Proposition K.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . K.3.1 Proof of Lemma K.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . K.3.2 Proof of Lemma K.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  .  .  73 73 73 74 76 78 82  83 85 85 87 88 88 LEARNING LINEAR DYNAMICAL SYSTEMS WITH SEMI-PARAMETRIC LEAST SQUARES  Preface  The"}