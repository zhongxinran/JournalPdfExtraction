{"1": "Y. Atchad\u00b4e, G. Fort, E. Moulines, and P. Priouret. Adaptive Markov chain Monte Carlo: theory and methods. In Bayesian time series models, pages 32-51. Cambridge Univ. Press, Cambridge, 2011.  R. N. Bhattacharya. Criteria for recurrence and existence of invariant measures for multidimensional  diffusions. Ann. Probab., 6(4):541-553, 08 1978.  11   FURTHER ANALOGY BETWEEN SAMPLING AND OPTIMIZATION  In view of Fubini\u2019s theorem, we arrive at  (cid:90)  R  f (cid:48)(x)2 \u03c0(x) dx =  f (cid:48)(cid:48)(y) \u03c0(y) dy +  f (cid:48)(cid:48)(y) \u03c0(y) dy \u2264 M.  (cid:90) \u221e(cid:90) 0  \u2212\u221e  This completes the proof.  Proof [Proof of Lemma 3] Since the process L is stationary, V (a) has the same distribution as V (0). For this reason, it suffices to prove the claim of the lemma for a = 0 only. Using the Lipschitz continuity of f , we get  E[(cid:107)V (0)(cid:107)2  2] = E  (cid:0)\u2207f (Lt) \u2212 \u2207f (L0) dt(cid:1)(cid:13) 2 (cid:13) (cid:13) 2  (cid:105)  (cid:104)(cid:13) (cid:13) (cid:13) (cid:90) h(cid:90) h  0 E(cid:2)(cid:13)  (cid:90) h\u2264 h  (cid:13)\u2207f (Lt) \u2212 \u2207f (L0)(cid:13) 2 (cid:13) 2  (cid:3) dt  \u2264 hM 2  E(cid:2)(cid:13)  (cid:13)Lt \u2212 L0  (cid:13) 2 (cid:13) 2  (cid:3) dt.  Combining this inequality with the stationarity of Lt, we arrive at  (cid:16)  E[(cid:107)V (0)(cid:107)2 2]  (cid:17)1/2  \u2264  hM 2  \u2207f (Ls) ds +  2 W t  \u221a  (cid:19)1/2  (cid:13) 2 (cid:13) 2  (cid:3) dt  (cid:90) t(cid:90) h  0 (cid:90) hE(cid:2)(cid:13)  (cid:13) \u2212  E(cid:2)(cid:13) (cid:13)  (cid:90) t\u2264  hM 2  (cid:18)  (cid:18)  (cid:18)  \u2264  =  (cid:18) 1 3  \u2207f (Ls) ds(cid:13) 2 (cid:13) 2  (cid:3) dt  (cid:19)1/2  (cid:18)  (cid:90) h  (cid:19)1/2  +  2hpM 2  t dt  hM 2E(cid:2)(cid:13)  (cid:13)\u2207f (L0)(cid:13) 2 (cid:13) 2  (cid:3)  (cid:90) h  (cid:19)1/2  (cid:18)  t2 dt  +  2hpM 2  h4M 2E(cid:2)(cid:13)  (cid:13)\u2207f (L0)(cid:13) 2 (cid:13) 2  + (cid:0)h3M 2p(cid:1)1/2.(cid:3)  (cid:19)1/2  (cid:90) h  (cid:19)1/2t dtTo complete the proof, it suffices to apply Lemma 2.  The work of the author was partially supported by the grant Investissements d\u2019Avenir (ANR-11- IDEX-0003/Labex Ecodec/ANR-11-LABX-0047).  Acknowledgments  References  Y. Atchad\u00b4e, G. Fort, E. Moulines, and P. Priouret. Adaptive Markov chain Monte Carlo: theory and methods. In Bayesian time series models, pages 32-51. Cambridge Univ. Press, Cambridge, 2011.  R. N. Bhattacharya. Criteria for recurrence and existence of invariant measures for multidimensional  diffusions. Ann. Probab., 6(4):541-553, 08 1978. DALALYAN  S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press, Cambridge,  2004.  S. Bubeck, R. Eldan, and J. Lehec. Sampling from a log-concave distribution with Projected  Langevin Monte Carlo. ArXiv e-prints, July 2015.  A. S. Dalalyan. Theoretical guarantees for approximate sampling from smooth and log-concave  densities. ArXiv e-prints, December 2014.  A. S. Dalalyan and A. B. Tsybakov. Sparse regression learning by aggregation and Langevin Monte-  Carlo. J. Comput. System Sci., 78(5):1423-1443, 2012.  A. Durmus and E. Moulines. High-dimensional Bayesian inference via the Unadjusted Langevin  Algorithm. ArXiv e-prints, May 2016.  Alain Durmus, Eric Moulines, and Marcelo Pereyra. Sampling from convex non continuously differentiable functions, when Moreau meets Langevin. February 2016. URL https://hal. archives-ouvertes.fr/hal-01267115.  L. Lov\u00b4asz and S. Vempala. Hit-and-run from a corner. SIAM J. Comput., 35(4):985-1005 (elec-  tronic), 2006a.  L. Lov\u00b4asz and S. Vempala. Fast algorithms for logconcave functions: Sampling, rounding, inte- gration and optimization. In 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2006), 21-24 October 2006, Berkeley, California, USA, Proceedings, pages 57-68, 2006b.  Walter Rudin. Real and complex analysis. McGraw-Hill Book Co., New York, third edition, 1987."}