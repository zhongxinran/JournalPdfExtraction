{"1": "COLT\u201918, 2018.  Naman Agarwal and Elad Hazan. Lower bounds for higher-order convex optimization. In Proc.  Eric Balkanski and Yaron Singer. Parallelization does not accelerate convex optimization: Adaptiv- ity lower bounds for non-smooth convex minimization. arXiv preprint arXiv:1808.03880, 2018.  K. Ball, E. Carlen, and E.H. Lieb. Sharp uniform convexity and smoothness inequalities for trace  norms. Inventiones mathematicae, 115(1):463-482, 1994.  G\u00b4abor Braun, Cristobal Guzman, and Sebastian Pokutta. Lower bounds on the oracle complexity of nonsmooth convex optimization via information theory. IEEE Trans. Information Theory, 63 (7):4709-4724, 2017.  Yair Carmon, John C Duchi, Oliver Hinder, and Aaron Sidford. Lower bounds for finding stationary  points I. arXiv preprint arXiv:1710.11606, 2017.  A. d\u2019Aspremont, C. Guzm\u00b4an, and M. Jaggi. Optimal affine-invariant smooth minimization algo-  rithms. SIAM Journal on Optimization, 28(3):2384-2405, 2018.  John Duchi, Feng Ruan, and Chulhee Yun. Minimax bounds on stochastic batched convex opti-  mization. In Proc. COLT\u201918, 2018.  M. Frank and P. Wolfe. An algorithm for quadratic programming. Naval Research Logistics Quar-  terly, 3:95-110, 1956.  Crist\u00b4obal Guzm\u00b4an and Arkadi Nemirovski. On lower complexity bounds for large-scale smooth  convex optimization. Journal of Complexity, 31(1):1 - 14, 2015.  Uffe Haagerup. The best constants in the Khintchine inequality. Studia Mathematica, 70:231-283,  1981.  13   LOWER BOUNDS FOR PARALLEL AND RANDOMIZED CONVEX OPTIMIZATION  Acknowledgments  Part of this work was done while JD was a Microsoft Research Fellow at the Simons Institute for the Theory of Computing, for the program on Foundations of Data Science, and while she was a postdoctoral researcher at Boston University. JD was partially supported by the NSF grant #CCF- 1740855. CG was partially supported by the FONDECYT project 11160939, and the Millennium Science Initiative of the Ministry of Economy, Development, and Tourism, grant \u201cMillennium Nu- cleus Center for the Discovery of Structures in Complex Data.\u201d  We thank Adam Smith for pointing out the importance of lower bounds in parallel convex op- timization from the local differential privacy perspective, for his useful comments and insights that led to this work, and for many useful discussions. We also thank Ilias Diakonikolas for sharing his expertise on anticoncentration, as well as Yossi Arjevani, Nicolas Casabianca, Vitaly Feldman, and Jos\u00b4e Verschae for valuable discussions and comments regarding this work. An earlier version of this paper made an incorrect use of the orthogonal splittings of (cid:96)p spaces, which has since been corrected. We thank Boris Kashin for pointing out this issue. We also thank an anonymous reviewer who pointed out imprecise conditioning in the proof of Lemma 22, which has since been corrected.  References  COLT\u201918, 2018.  Naman Agarwal and Elad Hazan. Lower bounds for higher-order convex optimization. In Proc.  Eric Balkanski and Yaron Singer. Parallelization does not accelerate convex optimization: Adaptiv- ity lower bounds for non-smooth convex minimization. arXiv preprint arXiv:1808.03880, 2018.  K. Ball, E. Carlen, and E.H. Lieb. Sharp uniform convexity and smoothness inequalities for trace  norms. Inventiones mathematicae, 115(1):463-482, 1994.  G\u00b4abor Braun, Cristobal Guzman, and Sebastian Pokutta. Lower bounds on the oracle complexity of nonsmooth convex optimization via information theory. IEEE Trans. Information Theory, 63 (7):4709-4724, 2017.  Yair Carmon, John C Duchi, Oliver Hinder, and Aaron Sidford. Lower bounds for finding stationary  points I. arXiv preprint arXiv:1710.11606, 2017.  A. d\u2019Aspremont, C. Guzm\u00b4an, and M. Jaggi. Optimal affine-invariant smooth minimization algo-  rithms. SIAM Journal on Optimization, 28(3):2384-2405, 2018.  John Duchi, Feng Ruan, and Chulhee Yun. Minimax bounds on stochastic batched convex opti-  mization. In Proc. COLT\u201918, 2018.  M. Frank and P. Wolfe. An algorithm for quadratic programming. Naval Research Logistics Quar-  terly, 3:95-110, 1956.  Crist\u00b4obal Guzm\u00b4an and Arkadi Nemirovski. On lower complexity bounds for large-scale smooth  convex optimization. Journal of Complexity, 31(1):1 - 14, 2015.  Uffe Haagerup. The best constants in the Khintchine inequality. Studia Mathematica, 70:231-283,  1981. LOWER BOUNDS FOR PARALLEL AND RANDOMIZED CONVEX OPTIMIZATION  Jonathan A. Kelner, Yin Tat Lee, Lorenzo Orecchia, and Aaron Sidford. An almost-linear-time al- gorithm for approximate max \ufb02ow in undirected graphs, and its multicommodity generalizations. In Proc. ACM-SIAM SODA\u201914, 2014.  Yin Tat Lee, Satish Rao, and Nikhil Srivastava. A new approach to computing maximum \ufb02ows  using electrical \ufb02ows. In Proc. ACM STOC\u201913, 2013.  A. Nemirovski. On parallel complexity of nonsmooth convex optimization. Journal of Complexity,  10(4):451-463, 1994.  A. Nemirovskii and Y. Nesterov. Optimal methods of smooth convex optimization (in Russian). Zh.  Vychisl. Mat. i Mat. Fiz., 25(3):356-369, 1985.  A.S. Nemirovsky and D.B. Yudin. Problem complexity and method efficiency in optimization.  Wiley-Interscience, 1983. ISBN 0 471 10345 4.  Y. Nesterov and A. Nemirovski. On First-Order Algorithms for (cid:96)1/Nuclear Norm Minimization.  Acta Numerica, 22, 4 2013.  1 edition, 1989.  G. Pisier. The Volume of Convex Bodies and Banach Space Geometry. Cambridge University Press,  Adam Smith, Abhradeep Thakurta, and Jalaj Upadhyay.  Is interaction necessary for distributed  private learning? In Proc. IEEE SP\u201917, 2017.  N. Srebro and K. Sridharan. On convex optimization, fat shattering and learning. Unpublished,  2012. URL http://ttic.uchicago.edu/\u02dckarthik/optfat.pdf.  Martin J. Wainwright. High-Dimensional Statistics: A Non-Asymptotic Viewpoint, volume 48 of Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, 2019.  Blake Woodworth, Jialei Wang, Adam Smith, Brendan McMahan, and Nati Srebro. Graph oracle models, lower bounds, and gaps for parallel stochastic optimization. In Proc. NeurIPS\u201918, 2018.  Blake E. Woodworth and Nati Srebro. Tight complexity bounds for optimizing composite objec-  tives. In Proc. NIPS\u201916, 2016."}