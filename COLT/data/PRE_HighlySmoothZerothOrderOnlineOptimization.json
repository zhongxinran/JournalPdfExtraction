{"1": "A. Agarwal, O. Dekel, and L. Xiao. Optimal algorithms for online convex optimization with multi-  point bandit feedback. In Proc. COLT, 2010.  A. Agarwal, D. Foster, D. Hsu, S. Kakade, and A. Rakhlin. Stochastic convex optimization with  bandit feedback. SIAM J. Optim., 23:188-212, 2013.  F. Bach. Self-concordant analysis for logistic regression. Electronic Journal of Statistics, 4:384-  414, 2010.  F. Bach and E. Moulines. Non-asymptotic analysis of stochastic approximation algorithms for  machine learning. In Adv. NIPS, 2011.  F. Bach and E. Moulines. Non-strongly-convex smooth stochastic approximation with convergence  rate o(1/n). In Adv. NIPS, 2013.  S. Bubeck. Convex optimization: Algorithms and complexity. Foundations and Trends R (cid:13)  chine Learning, 8(3-4):231-357, 2015.  in Ma-  S. Bubeck and N. Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit  problems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.  H. Chen. Lower rate of convergence for locating a maximum of a function. The Annals of Statistics,  16(3):1330-1334, 1988.  13   HIGHLY-SMOOTH OPTIMIZATION  7. Conclusion  In this paper, we have considered zero-th order online optimization with a special focus on highly- smooth functions such as for online logistic regression. We considered one-point estimates and two-point estimates of the gradient (with then two independent noises). For infinitely differentiable functions, our main result leads to the same dependence on sample size as gradient-based algo- rithms, with an extra dimension-dependent factor.  The present analysis could be extended in a number of ways: (a) we do not cover the bandit setting. A simple extension of our results allows us to recover existing bounds for \u03b2 = 1 (Shamir, 2013) but we are currently unable to obtain high-smoothness improvements for \u03b2 > 1; (b) while the two-point analysis considers unconstrained problems, the one-point analysis still requires a compact set of constraints and queries slightly outside (in a \u03b4 band around it), which might be avoided by using barrier tools like done by Hazan and Levy (2014). Finally, (c) in the strongly-convex case, the dependence on sample size is optimal in the optimization setting (Polyak and Tsybakov, 1990), however, the optimality of the scaling in dimension, of the plain convex case, and beyond the optimization setting remains open.  Part of this work was performed when Francis Bach was holding the Schlumberger chair at IHES and when Vianney Perchet was a researcher at INRIA. Vianney Perchet also acknowledges fundings from the ANR under grant number ANR-13-JS01-0004 and the CNRS under grant project Parasol.  Acknowledgments  References  A. Agarwal, O. Dekel, and L. Xiao. Optimal algorithms for online convex optimization with multi-  point bandit feedback. In Proc. COLT, 2010.  A. Agarwal, D. Foster, D. Hsu, S. Kakade, and A. Rakhlin. Stochastic convex optimization with  bandit feedback. SIAM J. Optim., 23:188-212, 2013.  F. Bach. Self-concordant analysis for logistic regression. Electronic Journal of Statistics, 4:384-  414, 2010.  F. Bach and E. Moulines. Non-asymptotic analysis of stochastic approximation algorithms for  machine learning. In Adv. NIPS, 2011.  F. Bach and E. Moulines. Non-strongly-convex smooth stochastic approximation with convergence  rate o(1/n). In Adv. NIPS, 2013.  S. Bubeck. Convex optimization: Algorithms and complexity. Foundations and Trends R (cid:13)  chine Learning, 8(3-4):231-357, 2015.  in Ma-  S. Bubeck and N. Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit  problems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.  H. Chen. Lower rate of convergence for locating a maximum of a function. The Annals of Statistics,  16(3):1330-1334, 1988. BACH PERCHET  J. Dippon. Accelerated randomized stochastic optimization. Ann. Statist., 31(4):1260-1281, 08  2003.  J. C. Duchi, M. I. Jordan, M. J. Wainwright, and A. Wibisono. Optimal rates for zero-order convex optimization: the power of two function evaluations. Technical Report 1312.2139, arXiv, 2013.  V. Fabian. Stochastic approximation of minima with improved asymptotic speed. Ann. Math.  Statist., 38(1):191-200, 02 1967.  A. D. Flaxman, A. T. Kalai, and H. B. McMahan. Online convex optimization in the bandit setting: gradient descent without a gradient. In Proc. Symposium on Discrete algorithms (SODA). Society for Industrial and Applied Mathematics, 2005.  E. Hazan and K. Levy. Bandit convex optimization: Towards tight bounds. In Adv. NIPS, 2014.  E. Hazan, T. Koren, and K. Levy. Logistic regression: Tight bounds for stochastic and online  optimization. In Proc. Conference On Learning Theory (COLT), 2014.  C. Hu, W. Pan, and J. T. Kwok. Accelerated gradient methods for stochastic optimization and online  learning. In Advances in Neural Information Processing Systems, 2009.  S. M. Kakade, O. Shamir, K. Sridharan, and A. Tewari. Learning exponential families in high-  dimensions: Strong convexity and sparsity. Technical Report 0911.0054-v2, ArXiv, 2009.  H. Kushner and G G. Yin. Stochastic approximation and Recursive Algorithms and Applications,  volume 35. Springer, 2003.  133(1-2):365-397, 2012.  G. Lan. An optimal method for stochastic composite optimization. Mathematical Programming,  G. Lan, A. Nemirovski, and A. Shapiro. Validation analysis of mirror descent stochastic approxi-  mation method. Mathematical programming, 134(2):425-458, 2012.  T. Liang, H. Narayanan, and S. Sakhalin. On zeroth-order stochastic convex optimization via ran-  dom walks. Technical Report 1402.2667, arXiv, 2014.  A. S. Nemirovski and D. B. Yudin. Problem complexity and method efficiency in optimization.  Wiley & Sons, 1983.  2004.  Arkadi Nemirovski. Interior point polynomial time methods in convex programming. Lecture Notes,  Y. Nesterov. Introductory Lectures on Convex Optimization, volume 87 of Applied Optimization.  Kluwer Academic Publishers, Boston, MA, 2004.  Y. Nesterov. Random gradient-free minimization of convex functions. Technical report, Universit\u00b4e  catholique de Louvain (CORE), 2011.  B. T. Polyak and A. B. Tsybakov. Optimal order of accuracy of search algorithms in stochastic  optimization. Problemy Peredachi Informatsii, 26(2):45-53, 1990. HIGHLY-SMOOTH OPTIMIZATION  B. Recht, G. G. Jamieson, and R. Nowak. Query complexity of derivative-free optimization. In Adv.  H. Robbins and S. Monro. A stochastic approximation method. Annals of Mathematical Statistics,  NIPS, 2012.  22(3):400-407, 1951.  A. Saha and A. Tewari. Improved regret guarantees for online smooth convex optimization with bandit feedback. In Proc. International Conference on Artificial Intelligence and Statistics (AIS- TATS), 2011.  M. Schmidt, N. Le Roux, and F. Bach. Convergence rates of inexact proximal-gradient methods for convex optimization. In Advances in neural information processing systems, pages 1458-1466, 2011.  S. Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends in  Machine Learning, 4(2):107-194, 2011.  O. Shamir. On the complexity of bandit and derivative-free stochastic convex optimization. In Proc.  Conference on Learning Theory, 2013.  J. C. Spall. Introduction to stochastic search and optimization: estimation, simulation, and control,  volume 65. John Wiley & Sons, 2005.  L. Xiao. Dual averaging methods for regularized stochastic learning and online optimization. Jour-  nal of Machine Learning Research, 9:2543-2596, 2010. BACH PERCHET"}