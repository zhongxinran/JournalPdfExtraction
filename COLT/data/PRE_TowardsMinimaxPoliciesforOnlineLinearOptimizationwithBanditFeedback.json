{"1": "J. Abernethy and A. Rakhlin. Beating the adaptive bandit with high probability. In Proceedings of  the 22nd Annual Conference on Learning Theory (COLT), 2009.  J. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An efficient algorithm for bandit linear optimization. In Proceedings of the 21st Annual Conference on Learning Theory (COLT), pages 263-274, 2008.  41.12   BUBECK CESA-BIANCHI KAKADE  Let \u0398(u, v) such that DF \u2217(u, v) = 1  1+(cid:107)v(cid:107) \u0398(u, v). First note that  1 1 + (cid:107)\u2207F (at)(cid:107) (cid:1). Thus, in order to prove (7) it remains to show that \u0398(u, v) \u2264 (cid:107)u\u2212v(cid:107)2, for (u, v) = (cid:0)\u2212\u03b7(cid:101)zt 1, \u2212\u03b7(cid:101)zt\u22121 In fact we shall prove that this inequality holds true as soon as (cid:107)u(cid:107)\u2212(cid:107)v(cid:107) 2 . This is the case for the pair (u, v) under consideration, since by the triangle inequality, equations (6) and (10), and the assumption on \u03b7:  1+(cid:107)v(cid:107) \u2265 \u2212 1  = 1 \u2212 (cid:107)at(cid:107) .  (10)Now using that log(1 + x) \u2265 x \u2212 x2, \u2200x \u2265 \u2212 1  (cid:107)u(cid:107) \u2212 (cid:107)v(cid:107) 1 + (cid:107)v(cid:107)  \u2265 \u2212  \u2265 \u2212\u03b7d \u2265 \u2212  \u03b7(cid:107)(cid:101)zt(cid:107) 1 1 + (cid:107)v(cid:107) 2 2 , we obtain that for u, v such that (cid:107)u(cid:107)\u2212(cid:107)v(cid:107)  .  1+(cid:107)v(cid:107) \u2265 \u2212 1 2 ,  \u0398(u, v) \u2264  + (cid:107)u(cid:107) \u00b7 (cid:107)v(cid:107) \u2212 v(cid:62)u  ((cid:107)u(cid:107) \u2212 (cid:107)v(cid:107))2 1 + (cid:107)v(cid:107)  \u2264 ((cid:107)u(cid:107) \u2212 (cid:107)v(cid:107))2 + (cid:107)u(cid:107) \u00b7 (cid:107)v(cid:107) \u2212 v(cid:62)u = (cid:107)u(cid:107)2 + (cid:107)v(cid:107)2 \u2212 (cid:107)u(cid:107) \u00b7 (cid:107)v(cid:107) \u2212 v(cid:62)u = (cid:107)u \u2212 v(cid:107)2 + 2v(cid:62)u \u2212 (cid:107)u(cid:107) \u00b7 (cid:107)v(cid:107) \u2212 v(cid:62)u \u2264 (cid:107)u \u2212 v(cid:107)2  which concludes the proof of (7). Now for the proof of (8) it suffices to note that:  E  (cid:104)(cid:0)1 \u2212 (cid:107)at(cid:107)(cid:1)(cid:107)(cid:101)zt(cid:107)2(cid:105)  = (1 \u2212 (cid:107)at(cid:107))  d (cid:88)  i=1  1 \u2212 (cid:107)at(cid:107) d  d2 (1 \u2212 (cid:107)at(cid:107))2 (z(cid:62)  t ei)2 = d(cid:107)zt(cid:107)2 \u2264 d  along with straightforward computations.  Acknowledgments  We warmly thank the COLT reviewers for their careful reading and insightful comments. The first author would like to thank Csaba Szepesv\u00b4ari for bringing to his attention the problem of optimal regret on the Euclidean ball, as well as Alexander Rakhlin for illuminating discussions regarding sampling schemes. He also thanks Ramon Van Handel, Vianney Perchet and Philippe Rigollet for stimulating discussions on this topic. The second author gratefully acknowledges partial support by the PASCAL2 Network of Excellence under EC grant no. 216886. This publication only re\ufb02ects the authors\u2019 views.  References  J. Abernethy and A. Rakhlin. Beating the adaptive bandit with high probability. In Proceedings of  the 22nd Annual Conference on Learning Theory (COLT), 2009.  J. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An efficient algorithm for bandit linear optimization. In Proceedings of the 21st Annual Conference on Learning Theory (COLT), pages 263-274, 2008.  41.12   TOWARDS MINIMAX POLICIES FOR ONLINE LINEAR OPTIMIZATION WITH BANDIT FEEDBACK  A. Agarwal, O. Dekel, and L. Xiao. Optimal algorithms for online convex optimization with multi-point bandit feedback. In Proceedings of the 23rd Annual Conference on Learning Theory (COLT), 2010.  J.-Y. Audibert and S. Bubeck. Minimax policies for adversarial and stochastic bandits. In Proceed-  ings of the 22nd Annual Conference on Learning Theory (COLT), 2009.  J.-Y. Audibert and S. Bubeck. Regret bounds and minimax policies under partial monitoring. Jour-  nal of Machine Learning Research, 11:2635-2686, 2010.  J.-Y. Audibert, S. Bubeck, and G. Lugosi. Minimax policies for combinatorial prediction games. In  Proceedings of the 24th Annual Conference on Learning Theory (COLT), 2011.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. Schapire. The non-stochastic multi-armed bandit  problem. SIAM Journal on Computing, 32(1):48-77, 2002.  B. Awerbuch and R. Kleinberg. Adaptive routing with end-to-end feedback: distributed learning and geometric approaches. In STOC \u201904: Proceedings of the thirty-sixth annual ACM symposium on Theory of computing, pages 45-53, 2004.  K. Ball. An elementary introduction to modern convex geometry. In S. Levy, editor, Flavors of  Geometry, pages 1-58. Cambridge University Press, 1997.  S. Bubeck. Introduction to online optimization. Lecture Notes, 2011.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press,  N. Cesa-Bianchi and G. Lugosi. Combinatorial bandits. Journal of Computer and System Sciences,  2006.  2011. To appear.  W. Chu, L. Li, L. Reyzin, and R.E. Schapire. Contextual bandits with linear payoff functions. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics. JMLR Conference and Workshop Proceedings, 2011.  V. Dani, T. Hayes, and S. Kakade. The price of bandit information for online optimization.  In  Advances in Neural Information Processing Systems (NIPS), volume 20, pages 345-352, 2008.  Martin Gr\u00a8otschel, L\u00b4aszlo Lov\u00b4asz, and Alexander Schrijver. Geometric Algorithms and Combinato- rial Optimization, volume 2 of Algorithms and Combinatorics. Springer, second corrected edition edition, 1993. ISBN 3-540-56740-2, 0-387-56740-2 (U.S.).  E. Hazan. The convex optimization approach to regret minimization. In S. Sra, S. Nowozin, and  S. Wright, editors, Optimization for Machine Learning, pages 287-303. MIT press, 2011.  S. Kakade, S. Shalev-Shwartz, and A. Tewari. Regularization techniques for learning with matrices.  arXiv:0910.0610v2, 2010.  J. Kivinen and M. Warmuth. Relative loss bounds for multidimensional regression problems. Ma-  chine Learning, 45:301-329, 2001.  41.13   BUBECK CESA-BIANCHI KAKADE  H. McMahan and A. Blum. Online geometric optimization in the bandit setting against an adaptive adversary. In In Proceedings of the 17th Annual Conference on Learning Theory (COLT), pages 109-123, 2004.  A. Nemirovski. Advances in convex optimiza- tion: Conic programming. In Proceedings of the In- ternational Congress of Mathematicians, 2006. EMS-European Mathematical Society Publishing House, 2007.  A. Nemirovski and D. Yudin. Problem Complexity and Method Efficiency in Optimization. Wiley  Interscience, 1983.  A. Rakhlin. Lecture notes on online learning. 2009.  N. Srebro, K. Sridharan, and A. Tewari. On the universality of online mirror descent. In Advances  in Neural Information Processing Systems (NIPS), 2011.  M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Pro-  ceedings of the Twentieth International Conference on Machine Learning (ICML), 2003.  41.14"}