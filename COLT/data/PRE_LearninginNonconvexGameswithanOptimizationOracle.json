{"1": "S\u00b4ebastien Bubeck, Nicolo Cesa-Bianchi, et al. Regret analysis of stochastic and nonstochas- tic multi-armed bandit problems. Foundations and Trends R(cid:13) in Machine Learning, 5(1): 1-122, 2012.  Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  university press, 2006. ISBN 9780511546921. doi: 10.1017/CBO9780511546921.  Nicol`o Cesa-Bianchi, Alex Conconi, and Claudio Gentile. On the Generalization Ability of Online Learning Algorithms for Pairwise Loss Functions. IEEE Transactions on Infor- mation Theory, 50:2050\u2014-2057, 2004. URL http://arxiv.org/abs/1305.2505.  Alon Cohen and Tamir Hazan. Following the perturbed leader for online structured learning.  In International Conference on Machine Learning, pages 1034-1042, 2015.  Luc Devroye, G\u00b4abor Lugosi, and Gergely Neu. Prediction by random-walk perturbation.  In Conference on Learning Theory, pages 460-473, 2013.  Miroslav Dudik, Nika Haghtalab, Haipeng Luo, Robert E. Schapire, Vasilis Syrgkanis, and Jennifer Wortman Vaughan. Oracle-e\ufb03cient online learning and auction design.  11   Learning in Non-convex Games with an Optimization Oracle  scores to samples re\ufb02ecting the probability of being generated from the true distribution. Formally, by choosing a parameter x \u2208 X and drawing a random noise z, the x-th player produces a sample denote Gx(z). Conversely, the y-th player chooses a parameter y \u2208 Y and assign the score Dy(Gx(z)) \u2208 [0, 1] to the sample Gx(z). The function F usually corresponds to the log-likelihood of mistakenly assigning an high score to a synthetic example and vice versa. the network parameters. As a result, e\ufb03cient convergence to GANs is established by assuming an access to an o\ufb04ine oracle.  It is reasonable to assume that F is Lipschitz and bounded w.r.t.  5. Discussion  Our work establishes a computational equivalence between online and statistical learning in the non-convex setting. We shed light on the hardness result of (Hazan and Koren, 2016) by demonstrating that online learning is significantly more di\ufb03cult than statistical learning only when no structure is assumed.  One interesting direction for further investigation is to refine the comparison model and study the polynomial dependencies more carefully. One obvious question is to un- derstand the gap in terms of the horizon parameter T between the regret bounds for the one-dimensional and the multidimensional settings.  Acknowledgements  We thank Karan Singh for recognizing a bug in our original proof and several discussions. We also thank Alon Cohen and Roi Livni for fruitful discussions. Elad Hazan acknowledges funding from NSF award Number 1704860.  References  S\u00b4ebastien Bubeck, Nicolo Cesa-Bianchi, et al. Regret analysis of stochastic and nonstochas- tic multi-armed bandit problems. Foundations and Trends R(cid:13) in Machine Learning, 5(1): 1-122, 2012.  Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  university press, 2006. ISBN 9780511546921. doi: 10.1017/CBO9780511546921.  Nicol`o Cesa-Bianchi, Alex Conconi, and Claudio Gentile. On the Generalization Ability of Online Learning Algorithms for Pairwise Loss Functions. IEEE Transactions on Infor- mation Theory, 50:2050\u2014-2057, 2004. URL http://arxiv.org/abs/1305.2505.  Alon Cohen and Tamir Hazan. Following the perturbed leader for online structured learning.  In International Conference on Machine Learning, pages 1034-1042, 2015.  Luc Devroye, G\u00b4abor Lugosi, and Gergely Neu. Prediction by random-walk perturbation.  In Conference on Learning Theory, pages 460-473, 2013.  Miroslav Dudik, Nika Haghtalab, Haipeng Luo, Robert E. Schapire, Vasilis Syrgkanis, and Jennifer Wortman Vaughan. Oracle-e\ufb03cient online learning and auction design. Learning in Non-convex Games with an Optimization Oracle  In Annual Symposium on Foundations of Computer Science - Proceedings, 2017. ISBN 9781538634646. doi: 10.1109/FOCS.2017.55.  Alon Gonen and Shai Shalev-Shwartz. Fast Rates for Empirical Risk Minimization of Strict Saddle Problems. In Ohad Shamir and Satyen Kale, editors, Proceedings of the 2017 Conference on Learning Theory, pages 1043\u2014-1063. PMLR, 2017. URL http: //arxiv.org/abs/1701.04271.  James Hannan. Approximation to bayes risk in repeated play. Contributions to the Theory  of Games, 3:97-139, 1957.  Elad Hazan.  Introduction to Online Convex Optimization. Foundations and Trends R(cid:13) in Optimization, 2(3-4):157-325, 2016. ISSN 2167-3888. doi: 10.1561/2400000013. URL http://ocobook.cs.princeton.edu/OCObook.pdfhttp://www.nowpublishers. com/article/Details/OPT-013.  Elad Hazan and Satyen Kale. Online submodular minimization. Journal of Machine Learn-  ing Research, 13(Oct):2903-2922, 2012.  Elad Hazan and Tomer Koren. The Computational Power of Optimization in Online Learn- ing. In Proceedings of the forty-eighth annual ACM symposium on Theory of Computing, pages 128-141. ACM, 2016. URL https://arxiv.org/pdf/1504.02089.pdf.  Elad Hazan, Karan Singh, and Cyril Zhang. E\ufb03cient regret minimization in non-convex  games. In International Conference on Machine Learning, pages 1433-1441, 2017.  Adam Kalai and Santosh Vempala. E\ufb03cient Algorithms for Online Decision Problems.  Journal of Computer and System Sciences, 2004.  Naveen Kodali, Jacob Abernethy, James Hays, and Zsolt Kira. On Convergence and Sta- bility of GANs. arXiv preprint arXiv:1705.07215, 2017. URL https://github.com/ kodalinaveen3/DRAGANhttp://arxiv.org/abs/1705.07215.  Dale Schuurmans and Martin A Zinkevich. Deep learning games. In Advances in Neural  Information Processing Systems, pages 1678-1686, 2016.  Shai Shalev-Shwartz. Online Learning and Online Convex Optimization. Foundations and ISSN 1935-8237. doi: 10.1561/  Trends R(cid:13) in Machine Learning, 4(2):107-194, 2011. 2200000018. URL http://www.nowpublishers.com/article/Details/MAL-018.  Tim Van Erven, Wojciech Kot(cid:32)lowski, and Manfred K Warmuth. Follow the leader with  dropout perturbations. In Conference on Learning Theory, pages 949-974, 2014.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the 20th International Conference on Machine Learning (ICML-03), pages 928-936, 2003."}