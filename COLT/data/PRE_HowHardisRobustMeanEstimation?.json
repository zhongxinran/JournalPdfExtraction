{"1": "Frank J Anscombe. Rejection of outliers. Technometrics, 2(2):123-146, 1960.  Benny Applebaum, Boaz Barak, and David Xiao. On basing lower-bounds for learning on worst-  case assumptions. In FOCS, pages 211-220. IEEE Computer Society, 2008.  Sivaraman Balakrishnan, Simon S Du, Jerry Li, and Aarti Singh. Computationally efficient robust sparse estimation in high dimensions. In Conference on Learning Theory, pages 169-212, 2017.  Boaz Barak. Sum of squares upper bounds, lower bounds, and open questions. 2014. URL https:  //www.boazbarak.org/sos/prev/files/all-notes.pdf.  Boaz Barak, Fernando G. S. L. Brand\u02dcao, Aram Wettroth Harrow, Jonathan A. Kelner, David Steurer, In STOC,  and Yuan Zhou. Hypercontractivity, sum-of-squares proofs, and their applications. pages 307-326. ACM, 2012a.  Boaz Barak, Fernando G. S. L. Brand\u02dcao, Aram Wettroth Harrow, Jonathan A. Kelner, David Steurer, and Yuan Zhou. Hypercontractivity, sum-of-squares proofs, and their applications. CoRR, abs/1205.4484, 2012b.  Thorsten Bernholt. Robust estimators are hard to compute. Technical report, Technical Re-  port/Universit\u00a8at Dortmund, SFB 475 Komplexit\u00a8atsreduktion in ?, 2006.  S\u00b4ebastien Bubeck, Yin Tat Lee, Eric Price, and Ilya Razenshteyn. Adversarial examples from  cryptographic pseudo-random generators. arXiv preprint arXiv:1811.06418, 2018.  12   HOW HARD IS ROBUST MEAN ESTIMATION?  Hypothesis 17 (\u2264-Small-Set Expansion Hypothesis (SSEH\u2264)) For every constant (cid:15) > 0 there is a small-enough \u03b4 > 0 such that the following problem is NP-hard. Given a graph G, distinguish between \u03a6\u2264  G(\u03b4) \u2265 1 \u2212 (cid:15) and \u03a6\u2264  G(\u03b4) \u2264 (cid:15).  We are not aware of any equivalences or implications between these two (apparently very simi- lar) problems. However, both versions of the problem have been widely used and called the \u201cSmall- Set Expansion Hypothesis\u201d in the literature, see e.g. Barak et al. (2012a).  We remark that while these two problems are very similar, there do appear to be some subtle qualitative differences between them. In particular, in the context of this paper, SSEH= (and vari- ants thereof) implies hardness for problems related to resilience, whereas SSEH\u2264 implies hardness for problems related to bounded moments. At a high level, this is because bounded moments is equivalent to resilience at every scale (see Corollary 32), and thus to control moments, we need to know what occurs at all sets of size at most \u03b4, not just in a neighborhood around \u03b4.  We thank Prasad Raghavendra for numerous helpful discussion regarding this paper, and in partic- ular for the suggestion to use random walks to prove the upper bound in Section 3. We also thank David Steurer for answering emergency questions about small-set expansion.  Acknowledgments  References  Frank J Anscombe. Rejection of outliers. Technometrics, 2(2):123-146, 1960.  Benny Applebaum, Boaz Barak, and David Xiao. On basing lower-bounds for learning on worst-  case assumptions. In FOCS, pages 211-220. IEEE Computer Society, 2008.  Sivaraman Balakrishnan, Simon S Du, Jerry Li, and Aarti Singh. Computationally efficient robust sparse estimation in high dimensions. In Conference on Learning Theory, pages 169-212, 2017.  Boaz Barak. Sum of squares upper bounds, lower bounds, and open questions. 2014. URL https:  //www.boazbarak.org/sos/prev/files/all-notes.pdf.  Boaz Barak, Fernando G. S. L. Brand\u02dcao, Aram Wettroth Harrow, Jonathan A. Kelner, David Steurer, In STOC,  and Yuan Zhou. Hypercontractivity, sum-of-squares proofs, and their applications. pages 307-326. ACM, 2012a.  Boaz Barak, Fernando G. S. L. Brand\u02dcao, Aram Wettroth Harrow, Jonathan A. Kelner, David Steurer, and Yuan Zhou. Hypercontractivity, sum-of-squares proofs, and their applications. CoRR, abs/1205.4484, 2012b.  Thorsten Bernholt. Robust estimators are hard to compute. Technical report, Technical Re-  port/Universit\u00a8at Dortmund, SFB 475 Komplexit\u00a8atsreduktion in ?, 2006.  S\u00b4ebastien Bubeck, Yin Tat Lee, Eric Price, and Ilya Razenshteyn. Adversarial examples from  cryptographic pseudo-random generators. arXiv preprint arXiv:1811.06418, 2018. HOW HARD IS ROBUST MEAN ESTIMATION?  Mark Bun and Mark Zhandry. Order-revealing encryption and the hardness of private learning. In  Theory of Cryptography Conference, pages 176-206. Springer, 2016.  Moses Charikar, Jacob Steinhardt, and Gregory Valiant. Learning from untrusted data. In STOC,  pages 47-60. ACM, 2017.  Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. Robust estimators in high dimensions without the computational intractability. In FOCS, pages 655-664. IEEE Computer Society, 2016.  Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. In ICML, volume 70 of Proceedings of  Being robust (in high dimensions) can be practical. Machine Learning Research, pages 999-1008. PMLR, 2017a.  Ilias Diakonikolas, Gautam Kamath, Daniel M Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. In International Conference on Machine  Being robust (in high dimensions) can be practical. Learning, pages 999-1008, 2017b.  Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. Statistical query lower bounds for robust estimation of high-dimensional gaussians and gaussian mixtures. In Foundations of Computer Science (FOCS), 2017 IEEE 58th Annual Symposium on, pages 73-84. IEEE, 2017c.  Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. List-decodable robust mean estimation and learning mixtures of spherical gaussians. In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, pages 1047-1060. ACM, 2018.  Ilias Diakonikolas, Weihao Kong, and Alistair Stewart. Efficient algorithms and lower bounds for robust linear regression. In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 2745-2754. SIAM, 2019.  Vitaly Feldman and Varun Kanade. Computational bounds on statistical query learning. In Confer-  ence on Learning Theory, pages 16-1, 2012.  Vitaly Feldman, Parikshit Gopalan, Subhash Khot, and Ashok Kumar Ponnuswami. New results for learning noisy parities and halfspaces. In 2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS\u201906), pages 563-574. IEEE, 2006.  Venkatesan Guruswami and Prasad Raghavendra. Hardness of learning halfspaces with noise. SIAM  J. Comput., 39(2):742-765, 2009.  Moritz Hardt and Ankur Moitra. Algorithms and hardness for robust subspace recovery. In Confer-  ence on Learning Theory, pages 354-375, 2013.  Samuel B Hopkins and Jerry Li. Mixture models, robustness, and sum of squares proofs. In Pro- ceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, pages 1021- 1034. ACM, 2018.  Peter J Huber. Robust estimation of a location parameter. The annals of mathematical statistics, 35  (1):73-101, 1964. HOW HARD IS ROBUST MEAN ESTIMATION?  David S Johnson and Franco P Preparata. The densest hemisphere problem. Theoretical Computer  Science, 6(1):93-107, 1978.  William B Johnson, Gideon Schechtman, and Joel Zinn. Best constants in moment inequalities for linear combinations of independent and exchangeable random variables. The Annals of Proba- bility, pages 234-253, 1985.  Michael Kearns, Yishay Mansour, Dana Ron, Ronitt Rubinfeld, Robert E Schapire, and Linda Sellie. In Proceedings of the twenty-sixth annual ACM  On the learnability of discrete distributions. symposium on Theory of computing, pages 273-282. ACM, 1994.  Adam R. Klivans and Pravesh Kothari. Embedding hard learning problems into gaussian space. In APPROX-RANDOM, volume 28 of LIPIcs, pages 793-809. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2014.  Pravesh K Kothari, Jacob Steinhardt, and David Steurer. Robust moment estimation and improved clustering via sum of squares. In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, pages 1035-1046. ACM, 2018.  Kevin A. Lai, Anup B. Rao, and Santosh Vempala. Agnostic estimation of mean and covariance. In  FOCS, pages 665-674. IEEE Computer Society, 2016.  Jerry Li. Principled Approaches to Robust Machine Learning and Beyond. 2018.  Prasad Raghavendra and David Steurer. Graph expansion and the unique games conjecture.  In  STOC, pages 755-764. ACM, 2010.  Prasad Raghavendra, David Steurer, and Madhur Tulsiani. Reductions between expansion problems. In IEEE Conference on Computational Complexity, pages 64-73. IEEE Computer Society, 2012.  Oded Regev. On lattices, learning with errors, random linear codes, and cryptography. J. ACM, 56  (6):34:1-34:40, 2009.  Jacob Steinhardt. Talk at stoc 2018 workshop on computational phase transitions. 2018a.  Jacob Steinhardt. Robust Learning: Information Theory and Algorithms. Stanford University,  Thesis, 2018b.  Jacob Steinhardt, Moses Charikar, and Gregory Valiant. Resilience: A criterion for learning in the  presence of arbitrary outliers. arXiv preprint arXiv:1703.04940, 2017.  David Steurer. Subexponential algorithms for d-to-1 two-prover games and for certifying almost  perfect expansion. Available at the authors website, pages 2-1, 2010a.  David Steurer. On the complexity of unique games and graph expansion. Citeseer, 2010b.  John W Tukey. Mathematics and the picturing of data. In Proceedings of the International Congress  of Mathematicians, Vancouver, 1975, volume 2, pages 523-531, 1975.  J.W. Tukey. A survey of sampling from contaminated distributions. Contributions to probability  and statistics, 2:448-485, 1960. HOW HARD IS ROBUST MEAN ESTIMATION?"}