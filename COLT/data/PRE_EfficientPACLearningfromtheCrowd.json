{"1": "Martin Anthony and Peter L Bartlett. Neural Network Learning: Theoretical Foundations. Cam-  bridge University Press, 1999.  Pranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab, and Ruth Urner. Efficient learning of lin- ear separators under bounded noise. In Proceedings of the 28th Conference on Computational Learning Theory (COLT), pages 167-190, 2015.  Pranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab, and Hongyang Zhang. Learning and 1-bit compressed sensing under asymmetric noise. In Proceedings of the 29th Conference on Compu- tational Learning Theory (COLT), pages 152-192, 2016.  Ashwinkumar Badanidiyuru, Robert Kleinberg, and Yaron Singer. Learning on a budget: posted price mechanisms for online procurement. In Proceedings of the 13th ACM Conference on Eco- nomics and Computation (EC), pages 128-145. ACM, 2012.  Ashwinkumar Badanidiyuru, Robert Kleinberg, and Aleksandrs Slivkins. Bandits with knapsacks: Dynamic procurement for crowdsourcing. In The 3rd Workshop on Social Computing and User Generated Content, co-located with ACM EC, 2013.  17   EFFICIENT PAC LEARNING FROM THE CROWD  i, j \u2208 [n],  (cid:12) (cid:12) (cid:12) (cid:12)  DISAGREE(i, j) \u2212 Pr  (cid:12) (cid:12) [gi(x) (cid:54)= gj(x)] (cid:12) (cid:12)  <  (cid:15) 2  .  x\u223cD|X  Therefore, for any pair of good labelers i and j tested by the algorithm, DISAGREE(i, j) < 2.5(cid:15), and for any pair of labelers i and j that one is good and the other is bad, DISAGREE(i, j) \u2265 2.5(cid:15). Therefore, the connected components of such a graph only include labelers from a single commu- nity.  Next, we show that at step 2 of Algorithm 4 with probability 1 \u2212 \u03b4 there exists at least one  connected component of size n/4 of good labelers.  To see this we first prove that for any two good labelers i and j, the probability of (i, j) existing is at least \u0398(1/n). Let Vg be the set of nodes corresponding to good labelers. For i, j \u2208 Vg, we have  Pr[(i, j) \u2208 G] = 1 \u2212  1 \u2212  (cid:18)  (cid:19)4 ln(2)n  1 n2  \u2248  4 ln(2) n  \u2265  2 ln(2) |Vg|  .  By the properties of random graphs, with very high probability there is a component of size \u03b2|Vg| in a random graph whose edges exists with probability c/|Vg|, for \u03b2 + e\u2212\u03b2c = 1 (Janson et al., 2011). Therefore, with probability 1 \u2212 \u03b4, there is a component of size |Vg|/2 > n/4 over the vertices in Vg. Finally, at step 3 the algorithm considers smaller connected components and tests whether they join any of the bigger components, by measuring the disagreement of two arbitrary labelers from these components.,At this point, all good labelers form one single connected component of size > n  2 . So, the algorithm succeeds in identifying all good labelers. Next, we brie\ufb02y discuss the expected load per labeler in Algorithm 4. Each labeler participates (cid:15) ln(n/\u03b4)) queries. So, in  in O(1) pairs of disagreement tests in expectation, each requiring O( 1 expectation each labeler labels O( 1  (cid:15) ln(n/\u03b4)) instances.  References  Martin Anthony and Peter L Bartlett. Neural Network Learning: Theoretical Foundations. Cam-  bridge University Press, 1999.  Pranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab, and Ruth Urner. Efficient learning of lin- ear separators under bounded noise. In Proceedings of the 28th Conference on Computational Learning Theory (COLT), pages 167-190, 2015.  Pranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab, and Hongyang Zhang. Learning and 1-bit compressed sensing under asymmetric noise. In Proceedings of the 29th Conference on Compu- tational Learning Theory (COLT), pages 152-192, 2016.  Ashwinkumar Badanidiyuru, Robert Kleinberg, and Yaron Singer. Learning on a budget: posted price mechanisms for online procurement. In Proceedings of the 13th ACM Conference on Eco- nomics and Computation (EC), pages 128-145. ACM, 2012.  Ashwinkumar Badanidiyuru, Robert Kleinberg, and Aleksandrs Slivkins. Bandits with knapsacks: Dynamic procurement for crowdsourcing. In The 3rd Workshop on Social Computing and User Generated Content, co-located with ACM EC, 2013. AWASTHI BLUM HAGHTALAB MANSOUR  Maria-Florina Balcan, Alina Beygelzimer, and John Langford. Agnostic active learning. Journal of  Computer and System Sciences, 75(1):78-89, 2009.  St\u00b4ephane Boucheron, Olivier Bousquet, and G\u00b4abor Lugosi. Theory of classification: A survey of  some recent advances. ESAIM: Probability and Statistics, 9:323-375, 2005.  David Cohn, Les Atlas, and Richard Ladner. Improving generalization with active learning. Ma-  chine learning, 15(2):201-221, 1994.  Sanjoy Dasgupta. Coarse sample complexity bounds for active learning. In Proceedings of the 19th Annual Conference on Neural Information Processing Systems (NIPS), pages 235-242, 2005.  Ofer Dekel and Ohad Shamir. Vox populi: Collecting high-quality labels from a crowd. In Pro- ceedings of the 22nd Conference on Computational Learning Theory (COLT), pages 377-386, 2009.  Willliam Feller. An introduction to probability theory and its applications, volume 2. John Wiley  & Sons, 2008.  Yoav Freund. Boosting a weak learning algorithm by majority. In Proceedings of the 22nd Confer-  ence on Computational Learning Theory (COLT), volume 90, pages 202-216, 1990.  Yoav Freund and Robert E Schapire. A desicion-theoretic generalization of on-line learning and an application to boosting. In European conference on computational learning theory, pages 23-37. Springer, 1995.  Steve Hanneke. Rates of convergence in active learning. The Annals of Statistics, 39(1):333-361,  2011.  Chien-Ju Ho, Shahin Jabbari, and Jennifer Wortman Vaughan. Adaptive task assignment for crowd- sourced classification. Proceedings of the 30th International Conference on Machine Learning (ICML), 2013.  Panagiotis G Ipeirotis, Foster Provost, and Jing Wang. Quality management on amazon mechanical turk. In Proceedings of the International Conference on Knowledge Discovery and Data Mining (KDD), pages 64-67. ACM, 2010.  Svante Janson, Tomasz Luczak, and Andrzej Rucinski. Random graphs, volume 45. John Wiley &  Sons, 2011.  David R Karger, Sewoong Oh, and Devavrat Shah. Iterative learning for reliable crowdsourcing sys- tems. In Proceedings of the 25th Annual Conference on Neural Information Processing Systems (NIPS), pages 1953-1961, 2011.  David R Karger, Sewoong Oh, and Devavrat Shah. Budget-optimal task allocation for reliable  crowdsourcing systems. Operations Research, 62(1):1-24, 2014.  Aniket Kittur, Ed H Chi, and Bongwon Suh. Crowdsourcing user studies with mechanical turk. In Proceedings of the SIGCHI conference on human factors in computing systems, pages 453-456. ACM, 2008. EFFICIENT PAC LEARNING FROM THE CROWD  Vladimir Koltchinskii. Rademacher complexities and bounding the excess risk in active learning.  Journal of Machine Learning Research, 11:2457-2485, 2010.  Ronald L Rivest and Robert Sloan. A formal model of hierarchical concept-learning. Information  and Computation, 114(1):88-114, 1994.  Robert E Schapire. The strength of weak learnability. Machine learning, 5(2):197-227, 1990.  Adish Singla and Andreas Krause. Truthful incentives in crowdsourcing tasks using regret mini- mization mechanisms. In Proceedings of the 22nd international conference on World Wide Web, pages 1167-1178. ACM, 2013.  Aleksandrs Slivkins and Jennifer Wortman Vaughan. Online decision making in crowdsourcing  markets: Theoretical challenges. ACM SIGecom Exchanges, 12(2):4-23, 2014.  Jacob Steinhardt, Gregory Valiant, and Moses Charikar. Avoiding imposters and delinquents: Ad- versarial crowdsourcing and peer prediction. In Proceedings of the 30th Annual Conference on Neural Information Processing Systems (NIPS), pages 4439-4447, 2016.  Long Tran-Thanh, Sebastian Stein, Alex Rogers, and Nicholas R Jennings. Efficient crowdsourcing of unknown experts using bounded multi-armed bandits. Artificial Intelligence, 214:89-111, 2014.  Leslie G Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134-1142, 1984.  Paul Wais, Shivaram Lingamneni, Duncan Cook, Jason Fennell, Benjamin Goldenberg, Daniel Lubarov, David Marin, and Hari Simons. Towards building a high-quality workforce with me- chanical turk. Presented at the NIPS Workshop on Computational Social Science and the Wisdom of Crowds, pages 1-5, 2010.  Songbai Yan, Kamalika Chaudhuri, and Tara Javidi. Active learning from imperfect labelers. In Proceedings of the 30th Annual Conference on Neural Information Processing Systems (NIPS), pages 2128-2136, 2016.  Chicheng Zhang and Kamalika Chaudhuri. Active learning from weak and strong labelers.  In Proceedings of the 29th Annual Conference on Neural Information Processing Systems (NIPS), pages 703-711, 2015. AWASTHI BLUM HAGHTALAB MANSOUR"}