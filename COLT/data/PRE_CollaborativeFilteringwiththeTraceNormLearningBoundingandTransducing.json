{"1": "9:1019-1048, 2008.  F. Bach. Consistency of trace-norm minimization. Journal of Machine Learning Research,  O. Bousquet Boucheron, S. and G. Lugosi. Theory of classification: A survey of some recent  advances. ESAIM: Probability and Statistics, 9:323 - 375, 2005.  E. Cand`es and B. Recht. Exact matrix completion via convex optimization. Foundations  of Computational Mathematics, 9, 2009.  E. Cand`es and T. Tao. The power of convex relaxation: Near-optimal matrix completion.  IEEE Trans. Inform. Theory, 56(5):2053-2080, 2009.  Ran El-Yaniv and Dmitry Pechyoni. Transductive rademacher complexity and its applica-  tions. Journal of AI Research, 35:193-234, 2009.  M. Jaggi and M. Sulovsk\u00b4y. A simple algorithm for nuclear norm regularized problems. In  ICML, 2010.  L. Kozma, A. Ilin, and T. Raiko. Binary principal component analysis in the net\ufb02ix collab-  orative filtering task. In IEEE MLSP Workshop, 2009.  R. Lata(cid:32)la. Some estimates of norms of random matrices. Proceedings of the AMS, 133(5):  1273-1282, 2005.  J. Lee, B. Recht, R. Salakhutdinov, N. Srebro, and J. Tropp. Practical large-scale optimiza-  tion for max-norm regularization. In NIPS, 2010.  674   Shamir Shalev-Shwartz  which applies to all the settings we have discussed earlier. Currently, we do not know how to bridge this gap. Another issue is understanding the implications of our analysis to other types of matrix regularization, such as weighted trace-norm (Salakhutdinov and Srebro (2010)).  As to the use of bounded models, we note that although they seem beneficial in our experiments, they can also lead to non-convex optimization problems. While this did not seem to hurt performance in our experiments, it might be more harmful in other datasets of applications. One possible way to enforce boundeded predictions while maintaining con- vexity is using \u221e-norm constraints, as in Thm. 4. Minimizing the average loss with respect to such constraints is a convex optimization problem, and can be done with a generic SDP solver. However, a generic solver won\u2019t scale to large datasets. Thus, designing an e\ufb03cient convex optimization algorithm, which combines trace-norm and \u221e-norm constraints, is a potentially useful, yet non-trivial challenge.  We thank Nati Srebro and Ruslan Salakhutdinov for helpful discussions, as well as the anonymous reviewers for valuable comments.  Acknowledgements  References  9:1019-1048, 2008.  F. Bach. Consistency of trace-norm minimization. Journal of Machine Learning Research,  O. Bousquet Boucheron, S. and G. Lugosi. Theory of classification: A survey of some recent  advances. ESAIM: Probability and Statistics, 9:323 - 375, 2005.  E. Cand`es and B. Recht. Exact matrix completion via convex optimization. Foundations  of Computational Mathematics, 9, 2009.  E. Cand`es and T. Tao. The power of convex relaxation: Near-optimal matrix completion.  IEEE Trans. Inform. Theory, 56(5):2053-2080, 2009.  Ran El-Yaniv and Dmitry Pechyoni. Transductive rademacher complexity and its applica-  tions. Journal of AI Research, 35:193-234, 2009.  M. Jaggi and M. Sulovsk\u00b4y. A simple algorithm for nuclear norm regularized problems. In  ICML, 2010.  L. Kozma, A. Ilin, and T. Raiko. Binary principal component analysis in the net\ufb02ix collab-  orative filtering task. In IEEE MLSP Workshop, 2009.  R. Lata(cid:32)la. Some estimates of norms of random matrices. Proceedings of the AMS, 133(5):  1273-1282, 2005.  J. Lee, B. Recht, R. Salakhutdinov, N. Srebro, and J. Tropp. Practical large-scale optimiza-  tion for max-norm regularization. In NIPS, 2010. Collaborative Filtering with the Trace Norm  H. Ma, H. Yang, M. Lyu, and I. King. Sorec: social recommendation using probabilistic  matrix factorization. In CIKM, 2008.  R. Meir and T. Zhang. Generalization error bounds for bayesian mixture algorithms. Journal  of Machine Learning Research, 4:839-860, 2003.  S. Negahban and M. Wainwright. Restricted strong convexity and weighted matrix com-  pletion: Optimal bounds with noise. arXiv:1009.2118, 2010.  M. Piotte and M. Chabbert. The pragmatic theory solution to the net\ufb02ix grand Available at http://www.netflixprize.com/assets/GrandPrize2009_BPC_  prize. PragmaticTheory.pdf, 2009.  R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. In NIPS, 2007.  R. Salakhutdinov and N. Srebro. Collaborative filtering in a non-uniform world: Learning  with the weighted trace norm. In NIPS, 2010.  Yoav Seginer. The expected norm of random matrices. Combinatorics, Probability & Com-  puting, 9(2):149-166, 2000.  N. Srebro and A. Shraibman. Rank, trace-norm and max-norm. In COLT, 2005.  N. Srebro, J. Rennie, and T. Jaakkola. Maximum-margin matrix factorization. In NIPS,  N. Srebro, K. Sridharan, and A. Tewari. Smoothness, low-noise and fast rates. In NIPS,  2004.  2010.  K. Toh and S. Yun. An accelerated proximal gradient algorithm for nuclear norm regularized  least squares problems. Optimization Online, 2009.  V. Vapnik. Statistical Learning Theory. Wiley, 1998."}