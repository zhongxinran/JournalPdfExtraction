{"1": "S. Agrawal, N.R. Devanur, and L. Li. An efficient algorithm for contextual bandits with knapsacks, and an extension to concave objectives. In 29th Conf. on Learning Theory (COLT), June 23-26, New York, pages 4-18, 2016.  J.-Y. Audibert, S. Bubeck, and R. Munos. Best arm identification in multi-armed bandits. In 23rd  Conf. on Learning Theory (COLT), June 27-29, Haifa, pages 41-53, 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem.  Mach. Learn., 47(2-3):235-256, 2002.  A. Badanidiyuru, R. Kleinberg, and A. Slivkins. Bandits with knapsacks. J. ACM, 65(3):13:1-  13:55, 2018.  S. Bubeck, R. Munos, G. Stoltz, and C. Szepesv\u00b4ari. X-armed bandits. JMLR, 12:1655-1695, 2011.  A. Cassel, S. Mannor, and A. Zeevi. A general approach to multi-armed bandits under risk criteria.  In 31st Conf. on Learning Theory (COLT), July 6-9, Stockholm, pages 1295-1306, 2018.  W. Ding, T. Qin, X.-D. Zhang, and T.-Y. Liu. Multi-armed bandit with budget constraint and variable  costs. In 27th AAAI Conf. on Artificial Intelligence, July 14-18, Bellevue, WA, USA, 2013.  N. Galichet, M. Sebag, and O. Teytaud. Exploration vs exploitation vs safety: Risk-aware multi- armed bandits. In 5th Asian Conf. on Mach. Learn. (ACML), Nov. 13-15, Canberra, pages 245- 260, 2013.  T. Koren, R. Livni, and Y. Mansour. Multi-armed bandits with metric movement costs. In 31st Conf. on Neural Information Processing Systems (NIPS), Dec. 4-9, Long Beach, pages 4122- 4131, 2017.  O.-A. Maillard. Robust risk-averse stochastic multi-armed bandits. In 24th Int. Conf. on Algorithmic  Learning Theory (ALT), Oct. 6-9, Singapore, pages 218-233, 2013.  A. Sani, A. Lazaric, and R. Munos. Risk-aversion in multi-armed bandits. In 26th Conf. on Neural  Information Processing Systems (NIPS), Dec. 3-6, Lake Tahoe, pages 3284-3292, 2012.  S. Vakili and Q. Zhao. Risk-averse multi-armed bandit problems under mean-variance measure.  Signal Processing, 10(6):1093-1111, 2016.  Y. Wu, R. Shariff, T. Lattimore, and C. Szepesvari. Conservative bandits. In 33rd Int. Conf. on  Mach. Learn. (ICML), June 20-22, New York, pages 1254-1262, 2016.  Y. Xia, T. Qin, W. Ding, H. Li, X.-D. Zhang, N. Yu, and T.-Y. Liu. Finite budget analysis of  multi-armed bandit problems. Neurocomputing, 258:13-29, 2017.  D.P. Zhou and C.J. Tomlin. Budget-constrained multi-armed bandits with multiple plays. In 32nd  AAAI Conf. on Artificial Intelligence, Feb. 2-7, New Orleans, 2018.  4   OPEN PROBLEM: RISK OF RUIN IN MULTIARMED BANDITS  a B-MAB, transferring their theoretical guarantees? and finally (c) what kind of method or strategy must an agent follow to optimally solve a S-MAB?  References  S. Agrawal, N.R. Devanur, and L. Li. An efficient algorithm for contextual bandits with knapsacks, and an extension to concave objectives. In 29th Conf. on Learning Theory (COLT), June 23-26, New York, pages 4-18, 2016.  J.-Y. Audibert, S. Bubeck, and R. Munos. Best arm identification in multi-armed bandits. In 23rd  Conf. on Learning Theory (COLT), June 27-29, Haifa, pages 41-53, 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem.  Mach. Learn., 47(2-3):235-256, 2002.  A. Badanidiyuru, R. Kleinberg, and A. Slivkins. Bandits with knapsacks. J. ACM, 65(3):13:1-  13:55, 2018.  S. Bubeck, R. Munos, G. Stoltz, and C. Szepesv\u00b4ari. X-armed bandits. JMLR, 12:1655-1695, 2011.  A. Cassel, S. Mannor, and A. Zeevi. A general approach to multi-armed bandits under risk criteria.  In 31st Conf. on Learning Theory (COLT), July 6-9, Stockholm, pages 1295-1306, 2018.  W. Ding, T. Qin, X.-D. Zhang, and T.-Y. Liu. Multi-armed bandit with budget constraint and variable  costs. In 27th AAAI Conf. on Artificial Intelligence, July 14-18, Bellevue, WA, USA, 2013.  N. Galichet, M. Sebag, and O. Teytaud. Exploration vs exploitation vs safety: Risk-aware multi- armed bandits. In 5th Asian Conf. on Mach. Learn. (ACML), Nov. 13-15, Canberra, pages 245- 260, 2013.  T. Koren, R. Livni, and Y. Mansour. Multi-armed bandits with metric movement costs. In 31st Conf. on Neural Information Processing Systems (NIPS), Dec. 4-9, Long Beach, pages 4122- 4131, 2017.  O.-A. Maillard. Robust risk-averse stochastic multi-armed bandits. In 24th Int. Conf. on Algorithmic  Learning Theory (ALT), Oct. 6-9, Singapore, pages 218-233, 2013.  A. Sani, A. Lazaric, and R. Munos. Risk-aversion in multi-armed bandits. In 26th Conf. on Neural  Information Processing Systems (NIPS), Dec. 3-6, Lake Tahoe, pages 3284-3292, 2012.  S. Vakili and Q. Zhao. Risk-averse multi-armed bandit problems under mean-variance measure.  Signal Processing, 10(6):1093-1111, 2016.  Y. Wu, R. Shariff, T. Lattimore, and C. Szepesvari. Conservative bandits. In 33rd Int. Conf. on  Mach. Learn. (ICML), June 20-22, New York, pages 1254-1262, 2016.  Y. Xia, T. Qin, W. Ding, H. Li, X.-D. Zhang, N. Yu, and T.-Y. Liu. Finite budget analysis of  multi-armed bandit problems. Neurocomputing, 258:13-29, 2017.  D.P. Zhou and C.J. Tomlin. Budget-constrained multi-armed bandits with multiple plays. In 32nd  AAAI Conf. on Artificial Intelligence, Feb. 2-7, New Orleans, 2018."}