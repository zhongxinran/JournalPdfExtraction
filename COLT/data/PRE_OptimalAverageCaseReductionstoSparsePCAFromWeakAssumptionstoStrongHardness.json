{"1": "Jinho Baik, G\u00b4erard Ben Arous, and Sandrine P\u00b4ech\u00b4e. Phase transition of the largest eigenvalue for nonnull complex sample covariance matrices. The Annals of Probability, 33(5):1643-1697, 2005.  Quentin Berthet and Philippe Rigollet. Complexity theoretic lower bounds for sparse principal  component detection. In COLT, pages 1046-1066, 2013a.  Quentin Berthet and Philippe Rigollet. Optimal detection of sparse principal components in high  dimension. The Annals of Statistics, 41(4):1780-1815, 2013b.  Matthew Brennan, Guy Bresler, and Wasim Huleihel. Reducibility and computational lower bounds  for problems with planted sparse structure. In COLT, pages 48-166, 2018.  Chao Gao, Zongming Ma, and Harrison H Zhou. Sparse CCA: adaptive estimation and computa-  tional barriers. The Annals of Statistics, 45(5):2074-2101, 2017.  Iain M Johnstone and Arthur Yu Lu.  Sparse principal components analysis. Unpublished  manuscript, 2004.  Tengyao Wang, Quentin Berthet, and Richard J Samworth. Statistical and computational trade-offs in estimation of sparse principal components. The Annals of Statistics, 44(5):1896-1930, 2016.  2   STRONG REDUCTIONS TO SPARSE PCA  canonical generative model, the spiked covariance model. Also, these lower bounds all quickly de- grade with the exponent in the PC conjecture. When only given the PC conjecture up to K = o(N \u03b1) where \u03b1 < 1/2, there is no sparsity k at which they remain tight. If \u03b1 \u2264 1/3 these reductions fail to even show the existence of a statistical-computational gap at any sparsity k. Our main results are:  \u2022 We give a reduction from PC that yields the first full characterization of the computational barrier in the spiked covariance model, providing tight lower bounds at all sparsities k. This partially resolves a question raised in Brennan et al. (2018).  \u2022 We show the surprising result that weaker forms of the PC conjecture up to clique size K = o(N \u03b1) for any given \u03b1 \u2208 (0, 1/2] imply tight computational lower bounds for sparse PCA at sparsities k = o(n\u03b1/3). Our reduction also shows that even a mild improvement in the signal strength needed by the best known polynomial-time sparse PCA algorithms would imply that the hardness threshold for PC is polylog(N ), rather than on the order N 1/2.  Our second result essentially shows that whether or not there are better efficient algorithms for PC is irrelevant to the statistical-computational gap for sparse PCA in the practically relevant highly sparse regime. This is the first instance of a suboptimal hardness assumption implying optimal lower bounds for another problem in unsupervised learning.  The reduction proving this result is more algorithmically involved than prior reductions to sparse PCA, making crucial use of a collection of average-case reduction primitives and introducing new techniques based on several decomposition and comparison properties of random matrices. Our lower bounds remain unchanged assuming hardness of planted dense subgraph instead of PC, which also has implications for the existence of algorithms slower than polynomial time. As a key step, our reduction maps an instance of PC to the empirical covariance matrix of sparse PCA samples, which proves to be a delicate task because of dependence among the entries of this matrix.  References  Jinho Baik, G\u00b4erard Ben Arous, and Sandrine P\u00b4ech\u00b4e. Phase transition of the largest eigenvalue for nonnull complex sample covariance matrices. The Annals of Probability, 33(5):1643-1697, 2005.  Quentin Berthet and Philippe Rigollet. Complexity theoretic lower bounds for sparse principal  component detection. In COLT, pages 1046-1066, 2013a.  Quentin Berthet and Philippe Rigollet. Optimal detection of sparse principal components in high  dimension. The Annals of Statistics, 41(4):1780-1815, 2013b.  Matthew Brennan, Guy Bresler, and Wasim Huleihel. Reducibility and computational lower bounds  for problems with planted sparse structure. In COLT, pages 48-166, 2018.  Chao Gao, Zongming Ma, and Harrison H Zhou. Sparse CCA: adaptive estimation and computa-  tional barriers. The Annals of Statistics, 45(5):2074-2101, 2017.  Iain M Johnstone and Arthur Yu Lu.  Sparse principal components analysis. Unpublished  manuscript, 2004.  Tengyao Wang, Quentin Berthet, and Richard J Samworth. Statistical and computational trade-offs in estimation of sparse principal components. The Annals of Statistics, 44(5):1896-1930, 2016."}