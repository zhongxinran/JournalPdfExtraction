{"1": "Loss functions are central to machine learning because they are the means by which the quality of a prediction is evaluated. Any loss that is not proper, or can not be transformed to be proper via a link function is inadmissible. All admissible losses for n-class problems can be obtained in terms of a convex body in \\mathbbR^n.  We show this explicitly and show how some existing results simplify when viewed from this perspective.  This  allows the development of a rich algebra of losses induced by binary operations on convex bodies (that return a convex body).  Furthermore it allows us to define an \u201cinverse loss\u201d which provides a universal \u201csubstitution function\u201d for the Aggregating Algorithm.  In doing so we show a formal connection between proper losses and norms."}