{"1": "Noga Alon, Shay Moran, and Amir Yehudayoff. Sign rank versus VC dimension. In Vitaly Feldman, Alexander Rakhlin, and Ohad Shamir, editors, Proceedings of the 29th Conference on Learning Theory, COLT 2016, New York, USA, June 23-26, 2016, volume 49 of JMLR Workshop and Conference Proceedings, pages 47-80. JMLR.org, 2016.  Hassan Ashtiani, Shai Ben-David, Nicholas Harvey, Christopher Liaw, Abbas Mehrabian, and Yaniv Plan. Nearly tight sample complexity bounds for learning mixtures of gaussians via sample compression schemes. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 3416- 3425. Curran Associates, Inc., 2018a.  Hassan Ashtiani, Shai Ben-David, and Abbas Mehrabian. Sample-efficient learning of mixtures. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pages 2679-2686, 2018b.  Raef Bassily, Kobbi Nissim, Adam Smith, Thomas Steinke, Uri Stemmer, and Jonathan Ullman. Algorithmic stability for adaptive data analysis. In Proceedings of the Forty-eighth Annual ACM Symposium on Theory of Computing, STOC \u201916, pages 1046-1059, New York, NY, USA, 2016. ACM. ISBN 978-1-4503-4132-5. doi: 10.1145/2897518.2897566.  Siu-on Chan, Ilias Diakonikolas, Rocco A. Servedio, and Xiaorui Sun. Near-optimal density esti- mation in near-linear time using variable-width histograms. In NIPS, pages 1844-1852, 2014.  Amit Daniely and Shai Shalev-Shwartz. Optimal learners for multiclass problems. In Maria-Florina Balcan, Vitaly Feldman, and Csaba Szepesv\u00b4ari, editors, Proceedings of The 27th Conference on Learning Theory, COLT 2014, Barcelona, Spain, June 13-15, 2014, volume 35 of JMLR Workshop and Conference Proceedings, pages 287-316. JMLR.org, 2014.  L. Devroye and L. Gyorfi. Nonparametric Density Estimation: The L1 View. Wiley Interscience  Series in Discrete Mathematics. Wiley, 1985. ISBN 9780471816461.  L. Devroye and G. Lugosi. Combinatorial methods in density estimation. Springer, 2001.  Luc Devroye and G\u00b4abor Lugosi. Bin width selection in multivariate histograms by the combinatorial  method. Test, 13(1):129-145, Jun 2004. ISSN 1863-8260. doi: 10.1007/BF02603004.  Ilias Diakonikolas. Learning structured distributions. In Handbook of Big Data, pages 267-283.  Chapman and Hall/CRC, 2016.  Ilias Diakonikolas, Daniel M. Kane, and Alistair Stewart. Statistical query lower bounds for robust estimation of high-dimensional gaussians and gaussian mixtures. In FOCS, pages 73-84. IEEE Computer Society, 2017.  Ilias Diakonikolas, Daniel M. Kane, and Alistair Stewart. List-decodable robust mean estimation  and learning mixtures of spherical gaussians. In STOC, pages 1047-1060. ACM, 2018a.  13   THE OPTIMAL APPROXIMATION FACTOR IN DENSITY ESTIMATION  References  Noga Alon, Shay Moran, and Amir Yehudayoff. Sign rank versus VC dimension. In Vitaly Feldman, Alexander Rakhlin, and Ohad Shamir, editors, Proceedings of the 29th Conference on Learning Theory, COLT 2016, New York, USA, June 23-26, 2016, volume 49 of JMLR Workshop and Conference Proceedings, pages 47-80. JMLR.org, 2016.  Hassan Ashtiani, Shai Ben-David, Nicholas Harvey, Christopher Liaw, Abbas Mehrabian, and Yaniv Plan. Nearly tight sample complexity bounds for learning mixtures of gaussians via sample compression schemes. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 3416- 3425. Curran Associates, Inc., 2018a.  Hassan Ashtiani, Shai Ben-David, and Abbas Mehrabian. Sample-efficient learning of mixtures. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pages 2679-2686, 2018b.  Raef Bassily, Kobbi Nissim, Adam Smith, Thomas Steinke, Uri Stemmer, and Jonathan Ullman. Algorithmic stability for adaptive data analysis. In Proceedings of the Forty-eighth Annual ACM Symposium on Theory of Computing, STOC \u201916, pages 1046-1059, New York, NY, USA, 2016. ACM. ISBN 978-1-4503-4132-5. doi: 10.1145/2897518.2897566.  Siu-on Chan, Ilias Diakonikolas, Rocco A. Servedio, and Xiaorui Sun. Near-optimal density esti- mation in near-linear time using variable-width histograms. In NIPS, pages 1844-1852, 2014.  Amit Daniely and Shai Shalev-Shwartz. Optimal learners for multiclass problems. In Maria-Florina Balcan, Vitaly Feldman, and Csaba Szepesv\u00b4ari, editors, Proceedings of The 27th Conference on Learning Theory, COLT 2014, Barcelona, Spain, June 13-15, 2014, volume 35 of JMLR Workshop and Conference Proceedings, pages 287-316. JMLR.org, 2014.  L. Devroye and L. Gyorfi. Nonparametric Density Estimation: The L1 View. Wiley Interscience  Series in Discrete Mathematics. Wiley, 1985. ISBN 9780471816461.  L. Devroye and G. Lugosi. Combinatorial methods in density estimation. Springer, 2001.  Luc Devroye and G\u00b4abor Lugosi. Bin width selection in multivariate histograms by the combinatorial  method. Test, 13(1):129-145, Jun 2004. ISSN 1863-8260. doi: 10.1007/BF02603004.  Ilias Diakonikolas. Learning structured distributions. In Handbook of Big Data, pages 267-283.  Chapman and Hall/CRC, 2016.  Ilias Diakonikolas, Daniel M. Kane, and Alistair Stewart. Statistical query lower bounds for robust estimation of high-dimensional gaussians and gaussian mixtures. In FOCS, pages 73-84. IEEE Computer Society, 2017.  Ilias Diakonikolas, Daniel M. Kane, and Alistair Stewart. List-decodable robust mean estimation  and learning mixtures of spherical gaussians. In STOC, pages 1047-1060. ACM, 2018a. BOUSQUET KANE MORAN  Ilias Diakonikolas, Jerry Li, and Ludwig Schmidt. Fast and sample near-optimal algorithms for In S\u00b4ebastien Bubeck, Vianney Perchet, and Philippe learning multidimensional histograms. Rigollet, editors, Proceedings of the 31st Conference On Learning Theory, volume 75 of Pro- ceedings of Machine Learning Research, pages 819-842. PMLR, 06-09 Jul 2018b.  Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Aaron Roth. The reusable holdout: Preserving validity in adaptive data analysis. Science, 349(6248):636-638, 2015. ISSN 0036-8075. doi: 10.1126/science.aaa9375.  J. Jiao, Y. Han, and T. Weissman. Minimax estimation of the l1 distance. IEEE Transactions on Information Theory, 64(10):6672-6706, Oct 2018. ISSN 0018-9448. doi: 10.1109/TIT.2018. 2846245.  Adam Tauman Kalai, Ankur Moitra, and Gregory Valiant. Disentangling gaussians. Commun.  ACM, 55(2):113-120, 2012. doi: 10.1145/2076450.2076474.  Pravesh K. Kothari, Jacob Steinhardt, and David Steurer. Robust moment estimation and improved clustering via sum of squares. In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2018, Los Angeles, CA, USA, June 25-29, 2018, pages 1035-1046, 2018. doi: 10.1145/3188745.3188970.  G\u00b4abor Lugosi and Andrew Nobel. Consistency of data-driven histogram methods for density esti- mation and classification. Ann. Statist., 24(2):687-706, 04 1996. doi: 10.1214/aos/1032894460.  Satyaki Mahalanabis and Daniel Stefankovic. Density estimation in linear time.  In Rocco A. Servedio and Tong Zhang, editors, 21st Annual Conference on Learning Theory - COLT 2008, Helsinki, Finland, July 9-12, 2008, pages 503-512. Omnipress, 2008.  Alfred M\u00a8uller. Integral probability metrics and their generating classes of functions. Advances in  Applied Probability, 29(2):429-443, 1997.  K. Pearson. Contributions to the mathematical theory of evolution. ii. skew variation in homoge-  neous material. Philosophical Trans. of the Royal Society of London, 186:343-414, 1895.  N. Sauer. On the density of families of sets. J. Comb. Theory, Ser. A, 13:145-147, 1972. ISSN  0097-3165. doi: 10.1016/0097-3165(72)90019-2.  Robert E Schapire and Yoav Freund. Boosting: Foundations and algorithms. MIT press, 2012.  V.N. Vapnik and A.Ya. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Theory Probab. Appl., 16:264-280, 1971. ISSN 0040-585X; 1095-7219/e. doi: 10.1137/1116025.  J. von Neumann. Zur theorie der gesellschaftsspiele. Mathematische Annalen, 100:295-320, 1928.  Yannis G. Yatracos. Rates of convergence of minimum distance estimators and kolmogorov\u2019s en-  tropy. Ann. Statist., 13(2):768-774, 06 1985. doi: 10.1214/aos/1176349553.  Bin Yu. Assouad, Fano, and Le Cam. In Festschrift for Lucien Le Cam, pages 423-435. Springer,  1997. THE OPTIMAL APPROXIMATION FACTOR IN DENSITY ESTIMATION  Binary search  Input: vectors y, h, and n functions Fi as in Lemma 12, and a sample access to the target distribution p. Output: an index j such that y + (cid:15)  2 ej \u2264 v\u2217.  1. Set nmin = 1, nmax = n. While nmin < nmax:  (a) Set nmid = (cid:98) nmin+nmax(cid:99), (cid:96) = (cid:80)nmid  i=nmin  hi, u = (cid:80)nmax  i=nmid+1 hi, and  L(x) = (1/(cid:96))  (cid:0)Fi(x) \u2212 Eqi[Fi] \u2212 yi  (cid:1)  hi  U (x) = (1/u)  (cid:0)Fi(x) \u2212 Eqi[Fi] \u2212 yi  (cid:1).  hi  nmid(cid:88)  i=nmin  nmax(cid:88)  i=nmid+1  (b) Submit statistical queries to derive estimates \u02c6\u00b5L, \u02c6\u00b5U of Ep[L(x)], Ep[U (x)] re- (cid:15) 2 log n .  spectively up to an additive error of  (c) If \u02c6\u00b5L \u2265 \u02c6\u00b5U then set nmin = nmin, nmax = nmid, and normalize hi = hi  (cid:96) for nmin \u2264 i \u2264 nmax and else set nmin = nmid + 1, nmax = nmax, and normalize hi = hi  u for nmin \u2264 i \u2264 nmax.  2. Output nmin (= nmax).  Figure 2: Binary search for an appropriate index i"}