{"1": "J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learn- ing are equivalent. In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory (COLT\u201911). Omnipress, 2011.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6:1-8, 1956a.  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of  Mathematicians, 1954, Amsterdam, vol. III, pages 336-338, 1956b.  A. Blum and Y. Mansour. From external to internal regret. Journal of Machine Learning  Research, 8:1307-1324, 2007.  Press, 2006.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  N. Cesa-Bianchi, G. Lugosi, and G. Stoltz. Regret minimization under partial monitoring.  Mathematics of Operations Research, 31:562-580, 2006.  D. Foster and R. Vohra. Regret in the on-line decision problem. Games and Economic  Behavior, 29:7-36, 1999.  S. Hart and A. Mas-Colell. A simple adaptive procedure leading to correlated equilibrium.  Econometrica, 68:1127-1150, 2000.  S. Hart and A. Mas-Colell. A general class of adaptive strategies. Journal of Economic  Theory, 98:26-54, 2001.  E. Lehrer and E. Solan. Learning to play partially-specified equilibrium. Mimeo, 2007.  534   Mannor Perchet Stoltz  Lemma 17 Given a polytope C, the (r, H)-approachability of C and the (cid:0)rC, H(cid:1)-approachability of Rd \u2212 are equivalent in the sense that all strategies for one problem translates to a strategy for the other problem.  In addition, Condition 1 holds for (r, H) and C if and only if it holds for (cid:0)rC, H(cid:1) and  Rd \u2212.  Via the lemma above, Theorem 16 indicates that Condition 1 for (r, H) and C is a  su\ufb03cient condition for the (r, H)-approachability of C and provides a strategy to do so.  4.3.3. Approachability of general convex sets in the case of general games  A general closed convex set can always be approximated arbitrarily well by a polytope (where the number of vertices of the latter however increases as the quality of the approx- imation does). There, via a doubling trick, Condition 1 is also seen to be su\ufb03cient to (r, H)-approach any general closed convex set C, However, the computational complexity of the resulting strategy is much larger: the per-round complexity increases over time (as the numbers of vertices of the approximating polytopes do).  References  J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and low-regret learn- ing are equivalent. In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory (COLT\u201911). Omnipress, 2011.  D. Blackwell. An analog of the minimax theorem for vector payo\ufb00s. Pacific Journal of  Mathematics, 6:1-8, 1956a.  D. Blackwell. Controlled random walks. In Proceedings of the International Congress of  Mathematicians, 1954, Amsterdam, vol. III, pages 336-338, 1956b.  A. Blum and Y. Mansour. From external to internal regret. Journal of Machine Learning  Research, 8:1307-1324, 2007.  Press, 2006.  N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University  N. Cesa-Bianchi, G. Lugosi, and G. Stoltz. Regret minimization under partial monitoring.  Mathematics of Operations Research, 31:562-580, 2006.  D. Foster and R. Vohra. Regret in the on-line decision problem. Games and Economic  Behavior, 29:7-36, 1999.  S. Hart and A. Mas-Colell. A simple adaptive procedure leading to correlated equilibrium.  Econometrica, 68:1127-1150, 2000.  S. Hart and A. Mas-Colell. A general class of adaptive strategies. Journal of Economic  Theory, 98:26-54, 2001.  E. Lehrer and E. Solan. Learning to play partially-specified equilibrium. Mimeo, 2007. Robust approachability and regret minimization in games with partial monitoring  G. Lugosi, S. Mannor, and G. Stoltz. Strategies for prediction under imperfect monitor- ing. Mathematics of Operations Research, 33:513-528, 2008. An extended abstract was presented at COLT\u201907.  S. Mannor and N. Shimkin. On-line learning with imperfect monitoring.  In Proceed- ings of the Sixteenth Annual Conference on Learning Theory (COLT\u201903), pages 552-567. Springer, 2003.  S. Mannor and N. Shimkin. Regret minimization in repeated matrix games with variable  stage duration. Games and Economic Behavior, 63(1):227-258, 2008.  S. Mannor, J. Tsitsiklis, and J. Y. Yu. Online learning with sample path constraints. Journal  of Machine Learning Research, 10(Mar):569-590, 2009.  S. Mannor, V. Perchet, and G. Stoltz. Robust approachability and regret minimization in games with partial monitoring. 2011a. URL http://hal.archives-ouvertes.fr/ hal-00595695.  S. Mannor, V. Perchet, and G. Stoltz. Corrigendum to \u201cRobust approachability and 2011b. URL http://hal.  regret minimization in games with partial monitoring\u201d. archives-ouvertes.fr/hal-00617554.  J.-F. Mertens, S. Sorin, and S. Zamir. Repeated games. Technical Report no. 9420, 9421,  9422, Universit\u00b4e de Louvain-la-Neuve, 1994.  V. Perchet. Calibration and internal no-regret with random signals. In Proceedings of the Twentieth International Conference on Algorithmic Learning Theory (ALT\u201909), pages 68-82, 2009.  V. Perchet. Approachability of convex sets in games with partial monitoring. Journal of  Optimization Theory and Applications, 149:665-677, 2011a.  V. Perchet. Internal regret with partial monitoring calibration-based optimal algorithms.  Journal of Machine Learning Research, 2011b. In press.  A. Piccolboni and C. Schindelhauer. Discrete prediction games with arbitrary feedback and In Proceedings of the Fourteenth Annual Conference on Computational Learning  loss. Theory (COLT\u201901), pages 208-223, 2001.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Beyond regret. In Proceedings of the Twenty-Fourth Annual Conference on Learning Theory (COLT\u201911). Omnipress, 2011.  J. Rambau and G. Ziegler. Projections of polytopes and the generalized Baues conjecture.  Discrete and Computational Geometry, 16:215-237, 1996.  A. Rustichini. Minimizing regret: The general case. Games and Economic Behavior, 29:  224-243, 1999. Mannor Perchet Stoltz  Acknowledgments  Shie Mannor was partially supported by the ISF under contract 890015. Vianney Perchet benefited from the support of the ANR under grant ANR-10-BLAN 0112. Gilles Stoltz acknowledges support from the French National Research Agency (ANR) under grant EX- PLO/RA (\u201cExploration-exploitation for e\ufb03cient resource allocation\u201d) and by the PAS- CAL2 Network of Excellence under EC grant no. 506778."}