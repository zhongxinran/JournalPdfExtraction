{"1": "495-519, 2006.  M. Aigner. Turan\u2019s graph theorem. American Mathematical Monthly, 102(9):808-816, 1995.  Y. Bilu and N. Linial. Lifts, discrepancy and nearly optimal spectral gap. Combinatorica, 26(5):  S. Hoory, N. Linial, and A. Wigderson. Expander graphs and their applications. Bulletin of the  American Mathematical Society, 43(4):439-561, 2006.  G. Kol, R. Raz, and A. Tal. Time-space hardness of learning sparse parities. In Proc. 49th ACM  Symp. on Theory of Computing, 2017.  M. Krivelevich and B. Sudakov. Pseudo-random graphs. In More sets, graphs and numbers, pages  199-262. Springer, 2006.  F.J. MacWilliams and N.J.A Sloane. The theory of error correcting codes. Elsevier, 1977.  50   MOSHKOVITZ MOSHKOVITZ  A code C \u2286 {0, 1}n can be viewed as an hypothesis class HC: the hypotheses correspond to the codewords, the examples correspond to the n coordinates, and an hypothesis hc \u2208 HC is defined by hc(i) which is equal to the i-th coordinate of c. So the number of labeled examples X , is |X | = 2n. 2 \u2212 (cid:15), then the number of common neighbors of any two  If a code C has distance at least \u03b4 \u2265 1  hypotheses is at most  (1 \u2212 \u03b4)n = (1 \u2212 \u03b4)  \u2264  + (cid:15)  |X | 2  (cid:18) 1 2  (cid:19) |X | 2  =  (cid:18) 1 2  (cid:19)2  |X | + (cid:15)  |X | 2  Denote \u00b5 = (cid:15) |X | codewords from C as hypotheses) and then we can bound the mixing parameter by  2 . To use Theorem 25 we need to make sure that |C| \u2265 2n (and take only 2n  (cid:115)(cid:18) 1 2  + \u00b5  (cid:19) |X | 2  = (cid:112)|X | \u00b7  (cid:114)  1 4  +  (cid:15)|X | 4  Summing up the discussion so far, using Theorem 23 with the mixing parameter d2 = |X | and |H| = |X | = 2n, we have the following theorem.  4 (1+(cid:15)|X |)  Theorem 28 For any code C \u2286 {0, 1}n with |C| = 2n and relative distance at least 1 constant s \u2208 (0, 1), if the number of memory states is bounded by  2 \u2212 (cid:15) and any  (cid:18) 4|C|  (cid:19)1.25  1 + 2(cid:15)n  \u00b7  1 (5 + 8(cid:15)n)1.25 |C|s  ,  then any learning algorithm for HC that outputs the underlying hypothesis (or an approximation of it) with probability at least 1/3 must use at least |C|s/130 examples.  Note that the theorem is useful for codes that have very small rate but very high distance (for  reference, see, e.g., MacWilliams and Sloane (1977)).  References  495-519, 2006.  M. Aigner. Turan\u2019s graph theorem. American Mathematical Monthly, 102(9):808-816, 1995.  Y. Bilu and N. Linial. Lifts, discrepancy and nearly optimal spectral gap. Combinatorica, 26(5):  S. Hoory, N. Linial, and A. Wigderson. Expander graphs and their applications. Bulletin of the  American Mathematical Society, 43(4):439-561, 2006.  G. Kol, R. Raz, and A. Tal. Time-space hardness of learning sparse parities. In Proc. 49th ACM  Symp. on Theory of Computing, 2017.  M. Krivelevich and B. Sudakov. Pseudo-random graphs. In More sets, graphs and numbers, pages  199-262. Springer, 2006.  F.J. MacWilliams and N.J.A Sloane. The theory of error correcting codes. Elsevier, 1977. MIXING IMPLIES LOWER BOUNDS FOR SPACE BOUNDED LEARNING  D. Moshkovitz and M. Moshkovitz. Mixing implies strong lower bounds for space bounded learn-  ing. Manuscript, 2017.  R. Raz. Fast learning requires good memory: A time-space lower bound for parity learning. In  Proc. 57th IEEE Symp. on Foundations of Computer Science, 2016.  R. Raz. A time-space lower bound for a large class of learning problems. Technical report, ECCC  Report TR17-020, 2017.  O. Shamir. Fundamental limits of online and distributed algorithms for statistical learning and esti- mation. In Proceedings of the 27th International Conference on Neural Information Processing Systems, NIPS\u201914, pages 163-171, 2014.  J. Steinhardt, G. Valiant, and S. Wager. Memory, communication, and statistical queries. In Con-  ference on Learning Theory (COLT), 2016.  A. Thomason. Dense expanders and pseudo-random bipartite graphs. Discrete Mathematics, 75  (1-3):381-386, 1989.  LG. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134-1142, 1984."}