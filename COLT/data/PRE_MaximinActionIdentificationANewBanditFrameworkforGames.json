{"1": "J-Y. Audibert, S. Bubeck, and R. Munos. Best Arm Identification in Multi-armed Bandits. In Proceedings  of the 23rd Conference on Learning Theory, 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine  Learning, 47(2):235-256, 2002.  347(6218):145-149, January 2015.  M. Bowling, N. Burch, M. Johanson, and O. Tammelin. Heads-up limit hold\u2019em poker is solved. Science,  C. Browne, E. Powley, D. Whitehouse, S. Lucas, P. Cowling, P. Rohlfshagen, S. Tavener, D. Perez, S. Samothrakis, and S. Colton. A survey of monte carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in games,, 4(1):1-49, 2012.  S. Bubeck and N. Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit  problems. Fondations and Trends in Machine Learning, 5(1):1-122, 2012.  S. Bubeck, R. Munos, and G. Stoltz. Pure Exploration in Finitely Armed and Continuous Armed Bandits.  Theoretical Computer Science 412, 1832-1852, 412:1832-1852, 2011.  O. Capp\u00b4e, A. Garivier, O-A. Maillard, R. Munos, and G. Stoltz. Kullback-Leibler upper confidence  bounds for optimal sequential allocation. Annals of Statistics, 41(3):1516-1541, 2013.  E. Even-Dar, S. Mannor, and Y. Mansour. Action Elimination and Stopping Conditions for the Multi- Armed Bandit and Reinforcement Learning Problems. Journal of Machine Learning Research, 7: 1079-1105, 2006.  J. Filar and K. Vrieze. Competitive Markov Decision Processes. Springer, 1996.  V. Gabillon, M. Ghavamzadeh, and A. Lazaric. Best Arm Identification: A Unified Approach to Fixed  Budget and Fixed Confidence. In Advances in Neural Information Processing Systems, 2012.  Aur\u00b4elien Garivier and Emilie Kaufmann. Optimal best arm identification with fixed confidence.  In  Proceedings of the 29th Conference On Learning Theory (to appear), 2016.  S. Gelly, L. Kocsis, M. Schoenauer, M. Sebag, D. Silver, C. Szepesv\u00b4ari, and O. Teytaud. The grand challenge of computer go: Monte carlo tree search and extensions. Commun. ACM, 55(3):106-113, 2012.  K. Jamieson, M. Malloy, R. Nowak, and S. Bubeck.  lil\u2019UCB: an Optimal Exploration Algorithm for  Multi-Armed Bandits. In Proceedings of the 27th Conference on Learning Theory, 2014.  14   GARIVIER, KAUFMANN AND KOOLEN  Acknowledgments  This work was partially supported by the CIMI (Centre International de Math\u00b4ematiques et d\u2019Informa- tique) Excellence program while Emilie Kaufmann visited Toulouse in November 2015. Garivier and Kaufmann acknowledge the support of the French Agence Nationale de la Recherche (ANR), under grants ANR-13-BS01-0005 (project SPADRO) and ANR-13-CORD-0020 (project ALICIA). Koolen acknowledges support from the Netherlands Organization for Scientific Research (NWO) under Veni grant 639.021.439.  References  J-Y. Audibert, S. Bubeck, and R. Munos. Best Arm Identification in Multi-armed Bandits. In Proceedings  of the 23rd Conference on Learning Theory, 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine  Learning, 47(2):235-256, 2002.  347(6218):145-149, January 2015.  M. Bowling, N. Burch, M. Johanson, and O. Tammelin. Heads-up limit hold\u2019em poker is solved. Science,  C. Browne, E. Powley, D. Whitehouse, S. Lucas, P. Cowling, P. Rohlfshagen, S. Tavener, D. Perez, S. Samothrakis, and S. Colton. A survey of monte carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in games,, 4(1):1-49, 2012.  S. Bubeck and N. Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit  problems. Fondations and Trends in Machine Learning, 5(1):1-122, 2012.  S. Bubeck, R. Munos, and G. Stoltz. Pure Exploration in Finitely Armed and Continuous Armed Bandits.  Theoretical Computer Science 412, 1832-1852, 412:1832-1852, 2011.  O. Capp\u00b4e, A. Garivier, O-A. Maillard, R. Munos, and G. Stoltz. Kullback-Leibler upper confidence  bounds for optimal sequential allocation. Annals of Statistics, 41(3):1516-1541, 2013.  E. Even-Dar, S. Mannor, and Y. Mansour. Action Elimination and Stopping Conditions for the Multi- Armed Bandit and Reinforcement Learning Problems. Journal of Machine Learning Research, 7: 1079-1105, 2006.  J. Filar and K. Vrieze. Competitive Markov Decision Processes. Springer, 1996.  V. Gabillon, M. Ghavamzadeh, and A. Lazaric. Best Arm Identification: A Unified Approach to Fixed  Budget and Fixed Confidence. In Advances in Neural Information Processing Systems, 2012.  Aur\u00b4elien Garivier and Emilie Kaufmann. Optimal best arm identification with fixed confidence.  In  Proceedings of the 29th Conference On Learning Theory (to appear), 2016.  S. Gelly, L. Kocsis, M. Schoenauer, M. Sebag, D. Silver, C. Szepesv\u00b4ari, and O. Teytaud. The grand challenge of computer go: Monte carlo tree search and extensions. Commun. ACM, 55(3):106-113, 2012.  K. Jamieson, M. Malloy, R. Nowak, and S. Bubeck.  lil\u2019UCB: an Optimal Exploration Algorithm for  Multi-Armed Bandits. In Proceedings of the 27th Conference on Learning Theory, 2014. MAXIMIN ACTION IDENTIFICATION  S. Kalyanakrishnan, A. Tewari, P. Auer, and P. Stone. PAC subset selection in stochastic multi-armed  bandits. In International Conference on Machine Learning (ICML), 2012.  E. Kaufmann and S. Kalyanakrishnan. Information complexity in bandit subset selection. In Proceeding  of the 26th Conference On Learning Theory., 2013.  E. Kaufmann, O. Capp\u00b4e, and A. Garivier. On the Complexity of Best Arm Identification in Multi-Armed  Bandit Models. Journal of Machine Learning Research (to appear), 2015.  L. Kocsis and C. Szepesv\u00b4ari. Bandit based monte-carlo planning. In Proceedings of the 17th European Conference on Machine Learning, ECML\u201906, pages 282-293, Berlin, Heidelberg, 2006. Springer- Verlag. ISBN 3-540-45375-X, 978-3-540-45375-8.  O. Maron and A. Moore. The Racing algorithm: Model selection for Lazy learners. Artificial Intelligence  Review, 11(1-5):113-131, 1997.  R. Munos. From bandits to Monte-Carlo Tree Search: The optimistic principle applied to optimization  and planning., volume 7(1). Foundations and Trends in Machine Learning, 2014.  D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, D. Grewe, J. Nham, N. Kalchbren- ner, I. Sutskever, T. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel, and D. Hassabis. Mastering the game of go with deep neural networks and tree search. Nature, 529:484-489, 2016.  B. Szorenyi, G. Kedenburg, and R. Munos. Optimistic planning in markov decision processes using a  generative model. In Advances in Neural Information Processing Systems, 2014."}