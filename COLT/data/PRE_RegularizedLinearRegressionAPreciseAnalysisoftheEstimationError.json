{"1": "Radoslaw Adamczak, Alexander E Litvak, Alain Pajor, and Nicole Tomczak-Jaegermann. Re- stricted isometry property of matrices with independent columns and neighborly polytopes by random sampling. Constructive Approximation, 34(1):61-88, 2011.  Per Kragh Andersen and Richard D Gill. Cox\u2019s regression model for counting processes: a large  sample study. The annals of statistics, pages 1100-1120, 1982.  Arindam Banerjee, Sheng Chen, Farideh Fazayeli, and Vidyashankar Sivakumar. Estimation with norm regularization. In Advances in Neural Information Processing Systems, pages 1556-1564, 2014.  Mohsen Bayati and Andrea Montanari. The lasso risk for gaussian matrices. Information Theory,  IEEE Transactions on, 58(4):1997-2017, 2012.  Alexandre Belloni, Victor Chernozhukov, and Lie Wang. Square-root lasso: pivotal recovery of  sparse signals via conic programming. Biometrika, 98(4):791-806, 2011.  Dimitri P Bertsekas, Angelia Nedi\u00b4c, and Asuman E Ozdaglar. Convex analysis and optimization.  Athena Scientific Belmont, 2003.  Peter J Bickel, Yaacov Ritov, and Alexandre B Tsybakov. Simultaneous analysis of lasso and  dantzig selector. The Annals of Statistics, 37(4):1705-1732, 2009.  St\u00b4ephane Boucheron, G\u00b4abor Lugosi, and Pascal Massart. Concentration inequalities: A nonasymp-  totic theory of independence. Oxford University Press, 2013.  Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2009.  Emmanuel Cand`es and Terence Tao. The dantzig selector: Statistical estimation when p is much  larger than n. The Annals of Statistics, pages 2313-2351, 2007.  Emmanuel J Cand`es. Mathematics of sparsity (and few other things). 2014.  Emmanuel J Cand`es, Justin Romberg, and Terence Tao. Robust uncertainty principles: Exact sig- Information Theory, IEEE  nal reconstruction from highly incomplete frequency information. Transactions on, 52(2):489-509, 2006.  Emmanuel J Cand`es, Yonina C Eldar, Deanna Needell, and Paige Randall. Compressed sensing with coherent and redundant dictionaries. Applied and Computational Harmonic Analysis, 31 (1):59-73, 2011.  Venkat Chandrasekaran, Benjamin Recht, Pablo A Parrilo, and Alan S Willsky. The convex ge- ometry of linear inverse problems. Foundations of Computational Mathematics, 12(6):805-849, 2012.  David L Donoho. Compressed sensing. Information Theory, IEEE Transactions on, 52(4):1289-  1306, 2006.  13   PRECISE ERROR ANALYSIS FOR REGULARIZED LINEAR REGRESSION  References  Radoslaw Adamczak, Alexander E Litvak, Alain Pajor, and Nicole Tomczak-Jaegermann. Re- stricted isometry property of matrices with independent columns and neighborly polytopes by random sampling. Constructive Approximation, 34(1):61-88, 2011.  Per Kragh Andersen and Richard D Gill. Cox\u2019s regression model for counting processes: a large  sample study. The annals of statistics, pages 1100-1120, 1982.  Arindam Banerjee, Sheng Chen, Farideh Fazayeli, and Vidyashankar Sivakumar. Estimation with norm regularization. In Advances in Neural Information Processing Systems, pages 1556-1564, 2014.  Mohsen Bayati and Andrea Montanari. The lasso risk for gaussian matrices. Information Theory,  IEEE Transactions on, 58(4):1997-2017, 2012.  Alexandre Belloni, Victor Chernozhukov, and Lie Wang. Square-root lasso: pivotal recovery of  sparse signals via conic programming. Biometrika, 98(4):791-806, 2011.  Dimitri P Bertsekas, Angelia Nedi\u00b4c, and Asuman E Ozdaglar. Convex analysis and optimization.  Athena Scientific Belmont, 2003.  Peter J Bickel, Yaacov Ritov, and Alexandre B Tsybakov. Simultaneous analysis of lasso and  dantzig selector. The Annals of Statistics, 37(4):1705-1732, 2009.  St\u00b4ephane Boucheron, G\u00b4abor Lugosi, and Pascal Massart. Concentration inequalities: A nonasymp-  totic theory of independence. Oxford University Press, 2013.  Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2009.  Emmanuel Cand`es and Terence Tao. The dantzig selector: Statistical estimation when p is much  larger than n. The Annals of Statistics, pages 2313-2351, 2007.  Emmanuel J Cand`es. Mathematics of sparsity (and few other things). 2014.  Emmanuel J Cand`es, Justin Romberg, and Terence Tao. Robust uncertainty principles: Exact sig- Information Theory, IEEE  nal reconstruction from highly incomplete frequency information. Transactions on, 52(2):489-509, 2006.  Emmanuel J Cand`es, Yonina C Eldar, Deanna Needell, and Paige Randall. Compressed sensing with coherent and redundant dictionaries. Applied and Computational Harmonic Analysis, 31 (1):59-73, 2011.  Venkat Chandrasekaran, Benjamin Recht, Pablo A Parrilo, and Alan S Willsky. The convex ge- ometry of linear inverse problems. Foundations of Computational Mathematics, 12(6):805-849, 2012.  David L Donoho. Compressed sensing. Information Theory, IEEE Transactions on, 52(4):1289-  1306, 2006. THRAMPOULIDIS OYMAK HASSIBI  David L Donoho, Arian Maleki, and Andrea Montanari. The noise-sensitivity phase transition in compressed sensing. Information Theory, IEEE Transactions on, 57(10):6920-6941, 2011a.  David L Donoho, Arian Maleki, and Andrea Montanari. The noise-sensitivity phase transition in compressed sensing. Information Theory, IEEE Transactions on, 57(10):6920-6941, 2011b.  Theodoros Evgeniou, Massimiliano Pontil, and Tomaso Poggio. Regularization networks and sup-  port vector machines. Advances in computational mathematics, 13(1):1-50, 2000.  Rina Foygel and Lester Mackey. Corrupted sensing: Novel guarantees for separating structured  signals. Information Theory, IEEE Transactions on, 60(2):1223-1247, 2014.  Yehoram Gordon. Some inequalities for gaussian processes and applications.  Israel Journal of  Mathematics, 50(4):265-289, 1985.  Yehoram Gordon. Elliptically contoured distributions. Probability theory and related fields, 76(4):  Yehoram Gordon. On Milman\u2019s inequality and random subspaces which escape through a mesh in  429-438, 1987.  Rn. Springer, 1988.  preprint arXiv:1401.2188, 2014.  volume 23. Springer, 1991.  Guillaume Lecu\u00b4e and Shahar Mendelson. Sparse recovery under weak moment assumptions. arXiv  Michel Ledoux and Michel Talagrand. Probability in Banach Spaces: isoperimetry and processes,  Shahar Mendelson. Learning without concentration. In Proceedings of The 27th Conference on  Learning Theory, pages 25-39, 2014.  Sahand N Negahban, Pradeep Ravikumar, Martin J Wainwright, and Bin Yu. A unified frame- work for high-dimensional analysis of m-estimators with decomposable regularizers. Statistical Science, 27(4):538-557, 2012.  Whitney K Newey and Daniel McFadden. Large sample estimation and hypothesis testing. Hand-  book of econometrics, 4:2111-2245, 1994.  Samet Oymak and Babak Hassibi. New null space results and recovery thresholds for matrix rank  minimization. arXiv preprint arXiv:1011.6326, 2010.  Samet Oymak and Babak Hassibi. Sharp mse bounds for proximal denoising. arXiv preprint  arXiv:1305.2714, 2013.  Samet Oymak, Christos Thrampoulidis, and Babak Hassibi. The squared-error of generalized lasso:  A precise analysis. arXiv preprint arXiv:1311.0830, 2013.  Mert Pilanci and Martin J Wainwright. Randomized sketches of convex programs with sharp guar- antees. In Information Theory (ISIT), 2014 IEEE International Symposium on, pages 921-925. IEEE, 2014.  Calyampudi Radhakrishna Rao and Helge Toutenburg. Linear models. Springer, 1995. PRECISE ERROR ANALYSIS FOR REGULARIZED LINEAR REGRESSION  Garvesh Raskutti, Martin J Wainwright, and Bin Yu. Restricted eigenvalue properties for correlated  gaussian designs. The Journal of Machine Learning Research, 99:2241-2259, 2010.  R Tyrell Rockafellar. Convex analysis, volume 28. Princeton university press, 1997.  Mark Rudelson and Roman Vershynin. On sparse reconstruction from fourier and gaussian mea-  surements. Communications on Pure and Applied Mathematics, 61(8):1025-1045, 2008.  Maurice Sion et al. On general minimax theorems. Pacific Journal of Mathematics, 8(1):171-176,  Mihailo Stojnic. Various thresholds for (cid:96)1-optimization in compressed sensing. arXiv preprint  Mihailo Stojnic. A framework to characterize performance of lasso algorithms. arXiv preprint  Mihailo Stojnic. Meshes that trap random subspaces. arXiv preprint arXiv:1304.0003, 2013b.  Mihailo Stojnic. Spherical perceptron as a storage memory with limited errors. arXiv preprint  1958.  arXiv:0907.3666, 2009.  arXiv:1303.7291, 2013a.  arXiv:1306.3809, 2013c.  arXiv:1303.7289, 2013d.  Mihailo Stojnic.  Upper-bounding (cid:96)1-optimization weak thresholds.  arXiv preprint  Christos Thrampoulidis and Babak Hassibi. Estimating structured signals in sparse noise: A precise In Communication, Control, and Computing (Allerton), 2014 52nd  noise sensitivity analysis. Annual Allerton Conference on, pages 866-873. IEEE, 2014.  Christos Thrampoulidis and Babak Hassibi. Isotropically random orthogonal matrices: Performance of lasso and minimum conic singular values. arXiv preprint arXiv:1503.07236, accepted to ISIT 2015, 2015.  Christos Thrampoulidis, Ashkan Panahi, Daniel Guo, and Babak Hassibi. Precise error analysis of the lasso. In in 40th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2015, available on arXiv:1502.04977, 2015a.  Christos Thrampoulidis, Ashkan Panahi, and Babak Hassibi. Asymptotically exact error analysis  for the generalized (cid:96)2  2-lasso. arXiv preprint arXiv:1502.04977, accepted to ISIT 2015, 2015b.  Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical  Society. Series B (Methodological), pages 267-288, 1996.  Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv preprint  arXiv:1011.3027, 2010.  arXiv:1405.5103, 2014.  Roman Vershynin. Estimation in high dimensions: a geometric perspective.  arXiv preprint  Lie Wang. The l1 penalized lad estimator for high dimensional linear regression. Journal of Multi-  variate Analysis, 120:135-151, 2013. THRAMPOULIDIS OYMAK HASSIBI  John Wright and Yi Ma. Dense error correction via-minimization.  Information Theory, IEEE  Transactions on, 56(7):3540-3560, 2010.  Yihong Wu and Sergio Verd\u00b4u. Optimal phase transitions in compressed sensing. Information The-  ory, IEEE Transactions on, 58(10):6241-6263, 2012.  Ming Yuan and Yi Lin. Model selection and estimation in regression with grouped variables. Jour-  nal of the Royal Statistical Society: Series B (Statistical Methodology), 68(1):49-67, 2006.  Tong Zhang et al. Some sharp performance bounds for least squares regression with l1 regulariza-  tion. The Annals of Statistics, 37(5A):2109-2144, 2009."}