{"1": "Sanjeev Arora, Elad Hazan, and Satyen Kale. Fast algorithms for approximate semidefinite pro- gramming using the multiplicative weights update method. In Foundations of Computer Science, 2005. FOCS 2005. 46th Annual IEEE Symposium on, pages 339-348. IEEE, 2005.  12   ESTIMATING THE MIXING TIME OF ERGODIC MARKOV CHAINS  and applying Laplace \u03b1-smoothing. We then notice that (cid:98)\u03b3\u2020  k,r,\u03b1 = \u03b3  (cid:98)L  (cid:18)(cid:16)  (k,r,\u03b1)(cid:17)(cid:124)  (k,r,\u03b1)(cid:19)  (cid:98)L  , where  (cid:16)  (k,r,\u03b1)(cid:17)(cid:124)  (k,r,\u03b1)  (cid:98)L  (cid:98)L  (cid:16)  =  N(k,r,\u03b1) (cid:44)  (cid:17)\u22121/2 (cid:16)  D(k,r,\u03b1) N (cid:104) N (k,r)  ij + \u03b1  (cid:105)  N(k,r,\u03b1)(cid:17)(cid:124) (cid:16) , D(k,r,\u03b1) N  D(k,r,\u03b1) N (cid:16)  (cid:44) diag  (i,j)  (cid:17)\u22121  N(k,r,\u03b1) (cid:16)  D(k,r,\u03b1) N  (cid:17)\u22121/2  N (k,r) 1  + d\u03b1, . . . , N (k,r)  + d\u03b1  .  d  The derivation of the confidence intervals starts with an empirical version of the decomposition introduced for the point estimator. The subsequent analysis has two key components. The first is a perturbation bound for the stationary distribution in terms of the pseudo-spectral gap and the stability of the perturbation of matrix with respect to the (cid:107)\u00b7(cid:107)\u221e norm. More precisely, Lemma 19 guarantees that  (cid:107)(cid:98)\u03c0 \u2212 \u03c0(cid:107)\u221e \u2264 \u02dcO (1)  1 (cid:16)  (cid:13) (cid:13) (cid:13) (cid:99)M \u2212 M  (cid:13) (cid:13) (cid:13)\u221e  .  (cid:17)  \u03b3ps  (cid:99)M  The second component (Lemma 21) involves controlling the latter perturbation in terms of empiri- cally observable quantities. In particular,  ,  (cid:17)  (7.12)  (7.13)  (7.14)  (cid:13) (cid:13) (cid:13) (cid:99)M \u2212 M  (cid:13) (cid:13) (cid:13)\u221e  \u2264 \u02dcO (1)  (cid:114) d  Nmin  holds with high probability \u2014 which is an empirical version of the result of Wolfer and Kontorovich (2019, Theorem 1), achieved by constructing and analyzing appropriate row-martingales.  \u2020  \u221a  Reversible setting. Our analysis also yields improvements over the state of the art estimation procedure in the reversible setting, where Hsu et al. (2015) used the absolute spectral gap \u03b3(cid:63) of the additive reversiblization of the empirical transition matrix (cid:99)M as the estimator for the mixing time. Our analysis via row-martingales sharpens the confidence intervals roughly by a factor of O( d) over the previous method. The latter relied on entry-wise martingales together with the metric inequality (cid:107)A(cid:107)\u221e \u2264 d max(i,j)\u2208[d]2 |A(i, j)| , A \u2208 Rd\u00d7d. Additionally, we show that the computation complexity of the task can be reduced over non-trivial parameter regimes. We achieve this via iterative methods for computing the second largest eigenvalue, and by replacing an expen- sive pseudo-inverse computation by the already-computed estimator for \u03b3(cid:63) itself (Corollary 24). These computational improvements do not degrade the asymptotic behavior of the confidence inter- vals.  + (cid:99)M 2  We are thankful to Daniel Paulin for the insightful conversations, and to the anonymous referees for their valuable comments.  Acknowledgments  References  Sanjeev Arora, Elad Hazan, and Satyen Kale. Fast algorithms for approximate semidefinite pro- gramming using the multiplicative weights update method. In Foundations of Computer Science, 2005. FOCS 2005. 46th Annual IEEE Symposium on, pages 339-348. IEEE, 2005. ESTIMATING THE MIXING TIME OF ERGODIC MARKOV CHAINS  Tugkan Batu, Lance Fortnow, Ronitt Rubinfeld, Warren D Smith, and Patrick White. Testing that In Foundations of Computer Science, 2000. Proceedings. 41st Annual  distributions are close. Symposium on, pages 259-269. IEEE, 2000.  Tu\u02d8gkan Batu, Lance Fortnow, Ronitt Rubinfeld, Warren D Smith, and Patrick White. Testing close-  ness of discrete distributions. Journal of the ACM (JACM), 60(1):4, 2013.  Bhaswar Bhattacharya and Gregory Valiant. Testing closeness with unequal sized samples.  In  Advances in Neural Information Processing Systems, pages 2611-2619, 2015.  Olivier Bousquet, St\u00b4ephane Boucheron, and G\u00b4abor Lugosi. Introduction to statistical learning the-  ory. In Advanced lectures on machine learning, pages 169-207. Springer, 2004.  Fang Chen, L\u00b4aszl\u00b4o Lov\u00b4asz, and Igor Pak. Lifting markov chains to speed up mixing. In Proceedings of the thirty-first annual ACM symposium on Theory of computing, pages 275-281. ACM, 1999.  Ting-Li Chen and Chii-Ruey Hwang. Accelerating reversible markov chains. Statistics & Proba-  bility Letters, 83(9):1956-1962, 2013.  Grace E Cho and Carl D Meyer. Comparison of perturbation bounds for the stationary distribution  of a markov chain. Linear Algebra and its Applications, 335(1-3):137-150, 2001.  Richard Combes and Mikael Touati. Computationally efficient estimation of the spectral gap of a  markov chain. arXiv preprint arXiv:1806.06047, 2018.  Constantinos Daskalakis, Nishanth Dikkala, and Nick Gravin. Testing symmetric markov chains from a single trajectory. In S\u00b4ebastien Bubeck, Vianney Perchet, and Philippe Rigollet, editors, Proceedings of the 31st Conference On Learning Theory, volume 75 of Proceedings of Machine Learning Research, pages 385-409. PMLR, 06-09 Jul 2018. URL http://proceedings. mlr.press/v75/daskalakis18a.html.  Persi Diaconis, Susan Holmes, and Radford M Neal. Analysis of a nonreversible markov chain  sampler. Annals of Applied Probability, pages 726-752, 2000.  James Allen Fill. Eigenvalue bounds on convergence to stationarity for nonreversible markov chains, with an application to the exclusion process. The annals of applied probability, pages 62-87, 1991.  David Gamarnik. Extension of the pac framework to finite and countable markov chains. IEEE  Transactions on Information Theory, 49(1):338-345, 2003.  M Hildebrand. Rates of convergence for a non-reversible markov chain sampler. preprint, 1997.  Daniel J Hsu, Aryeh Kontorovich, and Csaba Szepesv\u00b4ari. Mixing time estimation in reversible markov chains from a single sample path. In Advances in neural information processing systems, pages 1459-1467, 2015.  Daniel J. Hsu, Aryeh Kontorovich, David A. Levin, Yuval Peres, Csaba Szepesv\u00b4ari, and Geoffrey Wolfer. Mixing time estimation in reversible markov chains from a single sample path. to appear in Annals of Applied Probability, 2018+. ESTIMATING THE MIXING TIME OF ERGODIC MARKOV CHAINS  Shmuel Kaniel. Estimates for some computational techniques in linear algebra. Mathematics of  Computation, 20(95):369-378, 1966.  Rajeeva L Karandikar and Mathukumalli Vidyasagar. Rates of uniform convergence of empirical  means with mixing processes. Statistics & probability letters, 58(3):297-307, 2002.  Dimitri Kazakos. The Bhattacharyya distance and detection between markov chains. IEEE Trans-  actions on Information Theory, 24(6):747-754, 1978.  Michael J. Kearns, Yishay Mansour, Dana Ron, Ronitt Rubinfeld, Robert E. Schapire, and Linda Sellie. On the learnability of discrete distributions. In Proceedings of the Twenty-Sixth Annual ACM Symposium on Theory of Computing, 23-25 May 1994, Montr\u00b4eal, Qu\u00b4ebec, Canada, pages 273-282, 1994. doi: 10.1145/195058.195155. URL http://doi.acm.org/10.1145/ 195058.195155.  Jacek Kuczy\u00b4nski and Henryk Wo\u00b4zniakowski. Estimating the largest eigenvalue by the power and lanczos algorithms with a random start. SIAM journal on matrix analysis and applications, 13 (4):1094-1122, 1992.  Franc\u00b8ois Le Gall. Powers of tensors and fast matrix multiplication.  In Proceedings of the 39th  international symposium on symbolic and algebraic computation, pages 296-303. ACM, 2014.  David A Levin and Yuval Peres. Estimating the spectral gap of a reversible markov chain from a  short trajectory. arXiv preprint arXiv:1612.05330, 2016.  David Asher Levin, Yuval Peres, and Elizabeth Lee Wilmer. Markov chains and mixing times,  second edition. American Mathematical Soc., 2009.  Carl D Meyer, Jr. The role of the group generalized inverse in the theory of finite markov chains.  Siam Review, 17(3):443-464, 1975.  Mehryar Mohri and Afshin Rostamizadeh. Stability bounds for non-iid processes. In Advances in  Neural Information Processing Systems, pages 1025-1032, 2008.  Mehryar Mohri and Afshin Rostamizadeh. Rademacher complexity bounds for non-iid processes.  In Advances in Neural Information Processing Systems, pages 1097-1104, 2009.  Ravi Montenegro and Prasad Tetali. Mathematical aspects of mixing times in markov chains. Foun-  dations and Trends R(cid:13) in Theoretical Computer Science, 1(3):237-354, 2006.  Radford M Neal. Improving asymptotic variance of mcmc estimators: Non-reversible chains are  better. arXiv preprint math/0407281, 2004.  Christopher Conway Paige. The computation of eigenvalues and eigenvectors of very large sparse  matrices. PhD thesis, University of London, 1971.  Daniel Paulin. Concentration inequalities for Markov chains by Marton couplings and spectral  methods. Electronic Journal of Probability, 20, 2015.  Qian Qin, James P Hobert, and Kshitij Khare. Estimating the spectral gap of a trace-class markov  operator. arXiv preprint arXiv:1704.00850, 2017. ESTIMATING THE MIXING TIME OF ERGODIC MARKOV CHAINS  Yousef Saad. On the rates of convergence of the lanczos and the block-lanczos methods. SIAM  Journal on Numerical Analysis, 17(5):687-706, 1980.  Cosma Rohilla Shalizi and Aryeh Kontorovich. Predictive PAC learning and process decomposi-  tions. In Neural Information Processing Systems (NIPS), 2013.  Ingo Steinwart and Andreas Christmann. Fast learning from non-iid observations. In Advances in  neural information processing systems, pages 1768-1776, 2009.  Ingo Steinwart, Don Hush, and Clint Scovel. Learning from dependent observations. Journal of  Multivariate Analysis, 100(1):175-194, 2009.  Yi Sun, J\u00a8urgen Schmidhuber, and Faustino J Gomez.  Improving the asymptotic performance of markov chain monte-carlo by inserting vortices. In Advances in Neural Information Processing Systems, pages 2235-2243, 2010.  Hidemaro Suwa and Synge Todo. Markov chain monte carlo method without detailed balance.  Physical review letters, 105(12):120603, 2010.  Joel Tropp. Freedman\u2019s inequality for matrix martingales. Electronic Communications in Probabil-  ity, 16:262-270, 2011.  Alexandre B. Tsybakov. Introduction to nonparametric estimation, 2009. URL https://doi. org/10.1007/b13794. Revised and extended from the 2004 French original, Translated by Vladimir Zaiats.  Konstantin S Turitsyn, Michael Chertkov, and Marija Vucelja. Irreversible monte carlo algorithms  for efficient sampling. Physica D: Nonlinear Phenomena, 240(4-5):410-414, 2011.  Marija Vucelja. Liftinga nonreversible markov chain monte carlo algorithm. American Journal of  Physics, 84(12):958-968, 2016.  Bo Waggoner. Lp testing and learning of discrete distributions.  In Proceedings of the 2015 Conference on Innovations in Theoretical Computer Science, ITCS 2015, Rehovot, Israel, Jan- doi: 10.1145/2688073.2688095. URL http: uary 11-13, 2015, pages 347-356, 2015. //doi.acm.org/10.1145/2688073.2688095.  Geoffrey Wolfer and Aryeh Kontorovich. Minimax learning of ergodic markov chains. In Aur\u00b4elien Garivier and Satyen Kale, editors, Proceedings of the 30th International Conference on Algorith- mic Learning Theory, volume 98 of Proceedings of Machine Learning Research, pages 904-930, Chicago, Illinois, 22-24 Mar 2019. PMLR. URL http://proceedings.mlr.press/ v98/wolfer19a.html.  Bin Yu. Rates of convergence for empirical processes of stationary mixing sequences. The Annals  of Probability, pages 94-116, 1994."}