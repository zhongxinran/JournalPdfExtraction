{"1": "Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An e\ufb03cient algorithm for bandit linear optimization. In Proceedings of the 21th Annual Conference on Computational Learning Theory, 2008.  104   Amin Kearns Syed  at xn and nowhere else; (3) For all n \u2208 N, if i = (cid:100)log2 n(cid:101) then fn(xn) \u2265 (cid:15)i and fm(xn) < (cid:15)i for all m (cid:54)= n.  For the remainder of the proof fix (cid:15) > 0 and the smallest i \u2208 N such that (cid:15)i \u2264 (cid:15). We  , which su\ufb03ces to prove the theorem.  will show that \u03b8\u2212((cid:15)) = 1 and \u03b8+((cid:15)) \u2264 4 N(cid:15)i First, we claim that \u03b8\u2212((cid:15)) = 1. Let F + = arg inf F \u2286C((cid:15)) supx\u2208X inf y\u2208R  . Let n be the smallest integer such that fn \u2208 F +. Then each fm \u2208 F + has a distinct value at xn, by property 1. So inf y\u2208R |F +((cid:104)xn, y(cid:105) , 0)| = |F +|. Next, we claim that \u03b8+((cid:15)) \u2264 4 . N(cid:15)i Let Fi = {fn \u2208 F : i = (cid:100)log2 n(cid:101)}, and note that Fi \u2286 C((cid:15)) and |Fi| = N(cid:15)i 2 . For any x \u2208 X we have |Fi(x, 0)| \u2264 1, by property 2, and inf y\u2208R |Fi((cid:104)x, y(cid:105) , (cid:15))| \u2264 1, by property 3.  |F (x,(cid:15))\u222aF ((cid:104)x,y(cid:105),0)| |F |  12. Computational Complexity  Our results have so far ignored computational complexity. In general a function class F, for which finding the optimal query is computationally intractable, might nevertheless have small haystack dimension, admitting algorithms with low query complexity. Consider the following simple example. Let X = X1\u222aX2\u222aX3 where X1, X2, X3 are disjoint, |X1| = |X2| = n and X3 = 2n. Each function in F will attain its maximum on some action in X3. The location of that maximum, as in Example 2, will be encoded by X1 and X2. However, we will now encode the location cryptographically, with a function\u2019s behavior on X1 representing a public key, and a function\u2019s behavior on X2 representing the encrypted location of its maximum.  More precisely, let z be an n-bit number. For a pair of n  2 -bit primes p and q, let Npq = pq.  Also let e(z, Npq) = z2 mod Npq be z encrypted with public key Npq.  Now let fz,p,q be the function that gives the ith bit of Npq as output to the ith input of X1 and the ith bit of e(z, Npq) as output to the ith input of X2. On the zth input of X3, fz,p,q outputs a 2. On all other inputs of X3, fz,p,q outputs 0. Let F be the function class consisting of all functions fz,p,q for every pair of n  2 -bit primes p, q and n-bit integer z.  There exists an algorithm with query complexity O(n) for any f \u2217 \u2208 F. That algorithm queries each action in X1 \u222a X2, retrieving the public key Npq and the cypher e(z, Npq). Information-theoretically, the maximum of f \u2217 can be found in a single additional query. The algorithm may simply test every n-bit z(cid:48), checking if e(z, Npq) = e(z(cid:48), Npq). However, computing z is as hard as factorization (Kearns and Vazirani, 1994).  We thank Alex Slivkins and the anonymous reviewers for their helpful comments.  Acknowledgments  References  Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An e\ufb03cient algorithm for bandit linear optimization. In Proceedings of the 21th Annual Conference on Computational Learning Theory, 2008. Haystack Dimension  Kareem Amin, Michael Kearns, and Umar Syed. Graphical models for bandit problems. In  Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence, 2011.  Dana Angluin. Queries and concept learning. Machine Learning, 2(4):319-342, 1988.  S\u00b4ebastien Bubeck, R\u00b4emi Munos, Gilles Stoltz, and Csaba Szepesv\u00b4ari. Online optimization in X-armed bandits. In Advances in Neural Information Processing Systems 21, 2008.  Varsha Dani and Thomas P. Hayes. Robbing the bandit: Less regret in online geometric In Proceedings of the 17th Annual ACM-  optimization against an adaptive adversary. SIAM Symposium on Discrete Algorithms, 2006.  Abraham Flaxman, Adam Tauman Kalai, and H. Brendan McMahan. Online convex op- timization in the bandit setting: Gradient descent without a gradient. In Proceeding of the 16th Annual ACM-SIAM Symposium on Discrete Algorithms, 2005.  Tibor Heged\u00a8us. Generalized teaching dimensions and the query complexity of learning. In Proceedings of the 8th Annual Conference on Computational Learning Theory, 1995.  Michael Kearns and Umesh Vazirani. An Introduction to Computational Learning Theory.  MIT Press, 1994.  Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal. Multi-armed bandits in metric spaces. In Proceedings of the 40th Annual ACM Symposium on Theory of Computing, 2008.  John Langford and Tong Zhang. The epoch-greedy algorithm for contextual multi-armed  bandits. In Advances in Neural Information Processing Systems 20, 2007.  Tyler Lu, D\u00b4avid P\u00b4al, and Martin P\u00b4al. Showing relevant ads via Lipschitz context multi- armed bandits. In Proceedings of the 13th International Conference on Artificial Intelli- gence and Statistics, 2010.  Adam J. Mersereau, Paat Rusmevichientong, and John N. Tsitsiklis. A structured multi- armed bandit problem and the greedy policy. IEEE Transactions on Automatic Control, 54(12):2787-2802, 2009.  Rob Nowak. Noisy generalized binary search. In Advances in Neural Information Processing  Systems 22, 2009.  Aleksandrs Slivkins. Contextual bandits with similarity information. In Proceedings of the  24th Annual Conference on Computational Learning Theory, 2011.  Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. In Proceedings of the 27th International Conference on Machine Learning, 2008.  William Thompson. On the likelihood that one unknown probability exceeds another in  view of the evidence of two samples. Biometrika, 25(3-4):285-294, 1933."}