{"1": "A popular approach in reinforcement learning is to use a model-based algorithm, i.e., an algorithm that utilizes a model learner to learn an approximate model to the  environment.It has been shown that  such a model-based learner is efficient  if the model learner is efficient  in the so-called \u201cknows what it knows\u201d  (KWIK)  framework.A major limitation of the standard KWIK framework is that, by its very definition, it covers only the case when the (model) learner can represent  the actual environment with no errors.In this paper, we study the agnostic KWIK learning model, where we relax this assumption by allowing nonzero approximation errors. We show that with the new definition  an efficient model learner still leads to an efficient reinforcement learning algorithm.At the same time, though, we find that learning within the new framework can be substantially slower as compared to the standard framework, even in the case of simple learning problems."}