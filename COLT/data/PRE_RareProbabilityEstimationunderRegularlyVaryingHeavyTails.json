{"1": "Wiley, 2004.  Cambridge, 1987.  This work was supported in part by NSF grant 6922470 and ONR grant 6918937.  J. Beirlant, Y. Goegebeur, J. Segers, and J. Teugels. Statistics of extremes: theory and applications.  N. H. Bingham, C. M. Goldie, and J. L. Teugels. Regular variation. Cambridge University Press,  S. F. Chen and J. Goodman. An empirical study of smoothing techniques for language modeling. Technical report, Center for Research in Computing Technology, Harvard University, Cambridge, Massachusetts, August 1998. TR-10-98.  H. Chernoff. A measure of the asymptotic efficiency of tests of a hypothesis based on the sum of  observations. Annals of Mathematical Statistics, 23:493-507, 1952.  21.12   OHANNESSIAN DAHLEH  quantity converges to one. We first showed that consistency is not to be taken for granted. In partic- ular, even in well-behaved distributions such as the geometric, the Good-Turing estimator may not be consistent. We then focused our attention to heavy-tailed distributions. To characterize these, we used Karamata\u2019s theory of regular variation Karamata (1933), following closely the early develop- ment of Karlin (1967) in the context of infinite urn schemes. We then used the McAllester and Ortiz (2003) method to extend their additive concentration results to all rare probabilities. Moreover, in the setting of regularly varying heavy-tailed distributions, we showed that one has multiplicative concentration.  We then used the multiplicative concentration to establish strong laws. These allowed us to show that regularly varying heavy tails are sufficient for the consistency of the Good-Turing estima- tor. We used the newly established strong laws, in addition to those established for the occupancy numbers by Karlin, to construct two new families of consistent rare probability estimators. These new estimators address some of the shortcomings of the Good-Turing estimator. In particular, they have built-in smoothing, and their structure follows closely the \u201cabsolute discounting\u201d form used extensively in computational language modeling heuristics, such as in the algorithm proposed by Kneser and Ney (1995) and extended by Chen and Goodman (1998) and others. As such, in addition to a systematic and principled estimation method, our results provide a justification to these algo- rithms and an interpretation of the discount as the regular variation index. Since our estimators can be split into two parts, first index estimation and then probability estimation, they are closely related to tail estimation techniques in extreme value theory (Beirlant et al. (2004)). This correspondence opens the door for modern semiparametric methods to be applied in the present framework.  Heavy tails are a very good model for natural language, as observed early on by Zipf (1949). As such, it is satisfying that we have shown here that this is a property that is sufficient for consis- tently estimating rare probabilities. The core multiplicative concentrations have room to generalize to heavy tails that are potentially not regularly varying, as long as the mean and variance growths balance out to yield a proper unbounded exponent. Naturally, to completely describe when rare probability estimation is possible in a meaningful manner, one ought to establish necessary condi- tions as well.  Acknowledgments  References  Wiley, 2004.  Cambridge, 1987.  This work was supported in part by NSF grant 6922470 and ONR grant 6918937.  J. Beirlant, Y. Goegebeur, J. Segers, and J. Teugels. Statistics of extremes: theory and applications.  N. H. Bingham, C. M. Goldie, and J. L. Teugels. Regular variation. Cambridge University Press,  S. F. Chen and J. Goodman. An empirical study of smoothing techniques for language modeling. Technical report, Center for Research in Computing Technology, Harvard University, Cambridge, Massachusetts, August 1998. TR-10-98.  H. Chernoff. A measure of the asymptotic efficiency of tests of a hypothesis based on the sum of  observations. Annals of Mathematical Statistics, 23:493-507, 1952.  21.12   RARE PROBABILITY ESTIMATION  A. Cohen and H. B. Sackrowitz. Admissibility of estimators of the probability of unobserved out-  comes. Annals of the Institute of Statistical Mathematics, 42(4):623-636, 1990.  D. Dubhasi and D. Ranjan. Balls and bins: A study in negative dependence. Random Structures  and Algorithms, 13(2):99-124, 1998.  W. W. Esty. A normal limit law for a nonparametric estimator of the coverage of a random sample.  The Annals of Statistics, 11(3):905-912, 1983.  W. A. Gale and G. Sampson. Good-Turing frequency estimation without tears. Journal of Quanti-  tative Linguistics, 2(3):217-237, 1995.  A. Gandolfi and C. C. A. Sastri. Nonparametric estimations about species not observed in a random  sample. Milan Journal of Mathematics, 72(1):81-105, 2004.  A. Gnedin, B. Hansen, and J. Pitman. Notes on the occupancy problem with infinitely many boxes:  general asymptotics and power laws. Probability Surveys, 4:146-171, 2007.  I. J. Good. The population frequencies of species and the estimation of population parameters.  Biometrika, 40(16):237-264, 1953.  J. Karamata. Sur un mode de croissance r\u00b4eguli`ere. Th\u00b4eor`emes fondamenteaux. Bulletin de la Soci\u00b4et\u00b4e  Math\u00b4ematique de France, 61:55-62, 1933.  S. Karlin. Central limit theorems for certain infinite urn schemes. Journal of Mathematics and  Mechanics, 17(4):373-401, 1967.  R. Kneser and H. Ney.  Improved smoothing for m-gram language modeling.  In International  Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 679-682, 1995.  D. MacKay and L. Peto. A hierarchical Dirichlet language model. Natural Language Engineering,  1(3):289-307, 1995.  D. McAllester and L. Ortiz. Concentration inequalities for the missing mass and for histogram rule  error. Journal of Machine Learning Research, 4:895-911, 2003.  D. McAllester and R .E. Schapire. On the convergence rate of Good-Turing estimators. In 13th  Annual Conference on Computational Learning Theory, 2000.  A. Orlitsky, N. P. Santhanam, and J. Zhang. Universal compression of memoryless sources over  unknown alphabets. IEEE Trans. on Information Theory, 50(7):1469-1481, 2004.  J. Pitman and M. Yor. The two-parameter Poisson-Dirichlet distribution derived from a stable sub-  ordinator. Annals of Probability, 25:855-900, 1997.  Y. W. Teh. A hierarchical Bayesian language model based on Pitman-Yor processes. In 21st Interna- tional Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics (ACL), pages 985-992, 2006.  G. Zipf. Human behavior and the principle of least effort: An introduction to human ecology.  Hafner, New York, 1949.  21.13   OHANNESSIAN DAHLEH"}