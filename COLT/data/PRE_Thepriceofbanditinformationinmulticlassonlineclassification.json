{"1": "P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2):235-256, 2002.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R.E. Schapire. The nonstochastic multiarmed  bandit problem. SICOMP: SIAM Journal on Computing, 32(1):48-77, 2003.  S. Ben-David, D. Pal, , and S. Shalev-Shwartz. Agnostic online learning. In COLT, 2009.  V. Dani, T. Hayes, and S.M. Kakade. The price of bandit information for online optimiza-  tion. Advances in Neural Information Processing Systems, 20:345-352, 2008.  11   The price of bandit information in multiclass online classification  4. Conclusion and future work  We have bounded the price of bandit information in the setting of hypothesis class based on-line learning and extended the results of Auer et al. (2003). We applied our results to estimate the bandit error rate of the class of large margin classifiers.  The focus of this paper is information theoretic. That is, we have ignored time com- plexity issues. It is of interest to study the computational price of bandit information - i.e. how the required runtime grows when moving from the full-info to the bandit scenario. It is instructive to consider the PAC setting. Given a learning algorithm, A, for a class H in the PAC full-info setting we can simply construct a bandit learning algorithm as follows - given a sample of unlabled instances, we guess, for each instance, a label from Y , uni- formly at random. Typically, we will be correct on about 1 k of the examples. Thus, we can generate a labeled i.i.d. sample whose size is 1 k -fraction of the original sample, and run the full-info algorithm A on this sample. Using this construction (see Daniely et al. (2011)), it easily follows that in the PAC setting, the price of bandit information, both information theoretic and computational, is O(k). Is this true in the on-line setting as well? We note that this question is open and interesting already for the class of large-margin multiclass linear separators.  There is still some room for improvements of the bounds in Theorems 2 and 3. We H (T ) = O(k \u00b7 L(H))  conjecture that the optimal bounds are that for every class H, B-Errr and B-Erra  H (T ) = O((cid:112)k \u00b7 L(H)T ).  \u221a  k).  Theorem 3 together with Theorem 1 characterize the bandit-agnostic error rate up to a factor of \u02dcO( It is of interest to find a tighter characterization. We note that Theorem 1 shows that the bandit Littlestone dimension characterizes the error rate in the bandit realizable case for deterministic algorithms. It is an open question to show that this dimension quantifies the error rate also in the agnostic case and for randomized algorithms in the realizable case.  Acknowledgements  We thank Nati Linial and Shai Shalev-Shwartz for many comments and suggestions regard- ing this work. Amit Daniely is a recipient of the Google Europe Fellowship in Learning Theory, and this research is supported in part by this Google Fellowship.  References  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2):235-256, 2002.  P. Auer, N. Cesa-Bianchi, Y. Freund, and R.E. Schapire. The nonstochastic multiarmed  bandit problem. SICOMP: SIAM Journal on Computing, 32(1):48-77, 2003.  S. Ben-David, D. Pal, , and S. Shalev-Shwartz. Agnostic online learning. In COLT, 2009.  V. Dani, T. Hayes, and S.M. Kakade. The price of bandit information for online optimiza-  tion. Advances in Neural Information Processing Systems, 20:345-352, 2008. Daniely Halbertal  A. Daniely, S. Sabato, S. Ben-David, and S. Shalev-Shwartz. Multiclass learnability and  the erm principle. In COLT, 2011.  R. O. Duda, P. E. Hart, and D. G. Stork. Pattern Classification. Wiley, 2 edition, 2001.  S.M. Kakade, S. Shalev-Shwartz, and A. Tewari. E\ufb03cient bandit algorithms for online  multiclass prediction. In International Conference on Machine Learning, 2008.  N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold  algorithm. Machine Learning, 2:285-318, 1988.  Nick Littlestone and Manfred Warmuth. The weighted majority algorithm. In FOCS, pages  256-261, October 1989.  A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Random averages, combinatorial  parameters, and learnability. In NIPS, 2010."}