{"1": "J-Y. Audibert, R. Munos, and C. Szepesvari. Exploration-exploitation trade-o\ufb00 using vari- ance estimates in multi-armed bandits. Theoretical Computer Science, 410:1876-1902, 2009.  J.Y. Audibert and S. Bubeck. Regret bounds and minimax policies under partial monitoring.  Journal of Machine Learning Research, 11:2635-2686, 2010.  P. Auer and R. Ortner. UCB revisited: Improved regret bounds for the stochastic multi-  armed bandit problem. Periodica Mathematica Hungarica, 61(1-2):55-65, 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite time analysis of the multiarmed bandit  problem. Machine Learning, 47(2-3):235-256, 2002.  A.N. Burnetas and M.N. Katehakis. Optimal adaptive policies for sequential allocation  problems. Advances in Applied Mathematics, 17(2):122-142, 1996.  Y. Chow and H. Teicher. Probability Theory. Springer, 1988.  I.H. Dinwoodie. Mesures dominantes et th\u00b4eor`eme de Sanov. Annales de l\u2019Institut Henri  Poincar\u00b4e - Probabilit\u00b4es et Statistiques, 28(3):365-373, 1992.  S. Filippi. Strat\u00b4egies optimistes en apprentissage par renforcement. PhD thesis, T\u00b4el\u00b4ecom  ParisTech, 2010.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and  beyond. In Proceedings of COLT, 2011.  A. Garivier and F. Leonardi. Context tree selection: A unifying view. Stochastic Processes  and their Applications, 2011. In press.  J. Honda and A. Takemura. An asymptotically optimal bandit algorithm for bounded  support models. In Proceedings of COLT, pages 67-79, 2010a.  J. Honda and A. Takemura. An asymptotically optimal policy for finite support models in  the multiarmed bandit problem. arXiv:0905.2776, 2010b.  T. L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6:4-22, 1985.  O.-A. Maillard, R. Munos, and G. Stoltz. A finite-time analysis of multi-armed bandits prob- lems with Kullback-Leibler divergences. 2011. URL http://hal.archives-ouvertes. fr/inria-00574987/.  H. Robbins. Some aspects of the sequential design of experiments. Bulletin of the American  Mathematics Society, 58:527-535, 1952.  514   Maillard Munos Stoltz  References  J-Y. Audibert, R. Munos, and C. Szepesvari. Exploration-exploitation trade-o\ufb00 using vari- ance estimates in multi-armed bandits. Theoretical Computer Science, 410:1876-1902, 2009.  J.Y. Audibert and S. Bubeck. Regret bounds and minimax policies under partial monitoring.  Journal of Machine Learning Research, 11:2635-2686, 2010.  P. Auer and R. Ortner. UCB revisited: Improved regret bounds for the stochastic multi-  armed bandit problem. Periodica Mathematica Hungarica, 61(1-2):55-65, 2010.  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite time analysis of the multiarmed bandit  problem. Machine Learning, 47(2-3):235-256, 2002.  A.N. Burnetas and M.N. Katehakis. Optimal adaptive policies for sequential allocation  problems. Advances in Applied Mathematics, 17(2):122-142, 1996.  Y. Chow and H. Teicher. Probability Theory. Springer, 1988.  I.H. Dinwoodie. Mesures dominantes et th\u00b4eor`eme de Sanov. Annales de l\u2019Institut Henri  Poincar\u00b4e - Probabilit\u00b4es et Statistiques, 28(3):365-373, 1992.  S. Filippi. Strat\u00b4egies optimistes en apprentissage par renforcement. PhD thesis, T\u00b4el\u00b4ecom  ParisTech, 2010.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and  beyond. In Proceedings of COLT, 2011.  A. Garivier and F. Leonardi. Context tree selection: A unifying view. Stochastic Processes  and their Applications, 2011. In press.  J. Honda and A. Takemura. An asymptotically optimal bandit algorithm for bounded  support models. In Proceedings of COLT, pages 67-79, 2010a.  J. Honda and A. Takemura. An asymptotically optimal policy for finite support models in  the multiarmed bandit problem. arXiv:0905.2776, 2010b.  T. L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in  Applied Mathematics, 6:4-22, 1985.  O.-A. Maillard, R. Munos, and G. Stoltz. A finite-time analysis of multi-armed bandits prob- lems with Kullback-Leibler divergences. 2011. URL http://hal.archives-ouvertes. fr/inria-00574987/.  H. Robbins. Some aspects of the sequential design of experiments. Bulletin of the American  Mathematics Society, 58:527-535, 1952."}