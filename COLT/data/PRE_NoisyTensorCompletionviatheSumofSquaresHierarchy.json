{"1": "Anima Anandkumar, Dean P. Foster, Daniel Hsu, Sham M. Kakade, and Yi-Kai Liu. A spectral algorithm for latent dirichlet allocation. Algorithmica, 72(1):193-214, 2015. doi: 10.1007/ s00453-014-9909-1.  Animashree Anandkumar, Rong Ge, Daniel Hsu, and Sham Kakade. A tensor spectral approach to learning mixed membership community models. In COLT 2013 - The 26th Annual Conference on Learning Theory, June 12-14, 2013, Princeton University, NJ, USA, pages 867-881, 2013.  Boaz Barak and David Steurer. Sum-of-squares proofs and the quest toward optimal algorithms.  CoRR, abs/1404.5236, 2014.  Boaz Barak, Fernando G. S. L. Brand\u02dcao, Aram Wettroth Harrow, Jonathan A. Kelner, David Steurer, and Yuan Zhou. Hypercontractivity, sum-of-squares proofs, and their applications. In Proceed- ings of the 44th Symposium on Theory of Computing Conference, STOC 2012, New York, NY, USA, May 19 - 22, 2012, pages 307-326, 2012. doi: 10.1145/2213977.2214006.  Boaz Barak, Jonathan A. Kelner, and David Steurer. Rounding sum-of-squares relaxations.  In Symposium on Theory of Computing, STOC 2014, New York, NY, USA, May 31 - June 03, 2014, pages 31-40, 2014. doi: 10.1145/2591796.2591886.  Boaz Barak, Jonathan A. Kelner, and David Steurer. Dictionary learning and tensor decomposition via the sum-of-squares method. In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, STOC 2015, Portland, OR, USA, June 14-17, 2015, pages 143-151, 2015. doi: 10.1145/2746539.2746605.  Peter L. Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and  structural results. J. Mach. Learn. Res., 3:463-482, March 2003. ISSN 1532-4435.  Quentin Berthet and Philippe Rigollet. Complexity theoretic lower bounds for sparse principal component detection. In COLT 2013 - The 26th Annual Conference on Learning Theory, June 12-14, 2013, Princeton University, NJ, USA, pages 1046-1066, 2013.  Srinadh Bhojanapalli and Sujay Sanghavi. A new sampling technique for tensors. CoRR,  abs/1502.05023, 2015.  Emmanuel J. Cand`es and Benjamin Recht. Exact matrix completion via convex optimization. Foun- dations of Computational Mathematics, 9(6):717-772, 2009. doi: 10.1007/s10208-009-9045-5.  Emmanuel J. Cand`es and Terence Tao. The power of convex relaxation: near-optimal ma- doi:  IEEE Transactions on Information Theory, 56(5):2053-2080, 2010.  trix completion. 10.1109/TIT.2010.2044061.  24   BARAK MOITRA  We would like to thank Aram Harrow for many helpful discussions. Part of this work was done while BB was at Microsoft Research, New England. AM is supposed by NSF CAREER Award CCF-1453261, a grant from the MIT NEC Corporation and a Google Faculty Research Award.  Acknowledgments  References  Anima Anandkumar, Dean P. Foster, Daniel Hsu, Sham M. Kakade, and Yi-Kai Liu. A spectral algorithm for latent dirichlet allocation. Algorithmica, 72(1):193-214, 2015. doi: 10.1007/ s00453-014-9909-1.  Animashree Anandkumar, Rong Ge, Daniel Hsu, and Sham Kakade. A tensor spectral approach to learning mixed membership community models. In COLT 2013 - The 26th Annual Conference on Learning Theory, June 12-14, 2013, Princeton University, NJ, USA, pages 867-881, 2013.  Boaz Barak and David Steurer. Sum-of-squares proofs and the quest toward optimal algorithms.  CoRR, abs/1404.5236, 2014.  Boaz Barak, Fernando G. S. L. Brand\u02dcao, Aram Wettroth Harrow, Jonathan A. Kelner, David Steurer, and Yuan Zhou. Hypercontractivity, sum-of-squares proofs, and their applications. In Proceed- ings of the 44th Symposium on Theory of Computing Conference, STOC 2012, New York, NY, USA, May 19 - 22, 2012, pages 307-326, 2012. doi: 10.1145/2213977.2214006.  Boaz Barak, Jonathan A. Kelner, and David Steurer. Rounding sum-of-squares relaxations.  In Symposium on Theory of Computing, STOC 2014, New York, NY, USA, May 31 - June 03, 2014, pages 31-40, 2014. doi: 10.1145/2591796.2591886.  Boaz Barak, Jonathan A. Kelner, and David Steurer. Dictionary learning and tensor decomposition via the sum-of-squares method. In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, STOC 2015, Portland, OR, USA, June 14-17, 2015, pages 143-151, 2015. doi: 10.1145/2746539.2746605.  Peter L. Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and  structural results. J. Mach. Learn. Res., 3:463-482, March 2003. ISSN 1532-4435.  Quentin Berthet and Philippe Rigollet. Complexity theoretic lower bounds for sparse principal component detection. In COLT 2013 - The 26th Annual Conference on Learning Theory, June 12-14, 2013, Princeton University, NJ, USA, pages 1046-1066, 2013.  Srinadh Bhojanapalli and Sujay Sanghavi. A new sampling technique for tensors. CoRR,  abs/1502.05023, 2015.  Emmanuel J. Cand`es and Benjamin Recht. Exact matrix completion via convex optimization. Foun- dations of Computational Mathematics, 9(6):717-772, 2009. doi: 10.1007/s10208-009-9045-5.  Emmanuel J. Cand`es and Terence Tao. The power of convex relaxation: near-optimal ma- doi:  IEEE Transactions on Information Theory, 56(5):2053-2080, 2010.  trix completion. 10.1109/TIT.2010.2044061. NOISY TENSOR COMPLETION  Anthony Carbery and James Wright. Distributional and l\u02c6 q norm inequalities for polynomials over  convex bodies in r\u02c6 n. Mathematical Research Letters, 8(3):233-248, 2001.  Venkat Chandrasekaran, Benjamin Recht, Pablo A. Parrilo, and Alan S. Willsky. The convex ge- ometry of linear inverse problems. Foundations of Computational Mathematics, 12(6):805-849, 2012. doi: 10.1007/s10208-012-9135-7.  Yudong Chen, Srinadh Bhojanapalli, Sujay Sanghavi, and Rachel Ward. Coherent matrix comple- tion. In Proceedings of the 31th International Conference on Machine Learning, ICML 2014, Beijing, China, 21-26 June 2014, pages 674-682, 2014.  Amin Coja-Oghlan, Andreas Goerdt, and Andr\u00b4e Lanka. Strong refutation heuristics for ran- doi: 10.1017/  dom k-sat. Combinatorics, Probability & Computing, 16(1):5-28, 2007. S096354830600784X.  Amit Daniely, Nati Linial, and Shai Shalev-Shwartz. More data speeds up training time in learning halfspaces over sparse vectors. In Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States., pages 145-153, 2013.  M. Fazel. Matrix Rank Minimization with Applications. PhD thesis, Stanford University, 2002.  Uriel Feige. Relations between average case complexity and approximation complexity. In Pro- ceedings on 34th Annual ACM Symposium on Theory of Computing, May 19-21, 2002, Montr\u00b4eal, Qu\u00b4ebec, Canada, pages 534-543, 2002. doi: 10.1145/509907.509985.  Uriel Feige and Eran Ofek. Easily refutable subformulas of large random 3cnf formulas. Theory of  Computing, 3(1):25-43, 2007. doi: 10.4086/toc.2007.v003a002.  Uriel Feige, Jeong Han Kim, and Eran Ofek. Witnesses for non-satisfiability of dense random 3cnf formulas. In 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2006), 21-24 October 2006, Berkeley, California, USA, Proceedings, pages 497-508, 2006. doi: 10.1109/FOCS.2006.78.  Joel Friedman, Jeff Kahn, and Endre Szemer\u00b4edi. On the second eigenvalue in random regular graphs. In Proceedings of the 21st Annual ACM Symposium on Theory of Computing, May 14- 17, 1989, Seattle, Washigton, USA, pages 587-598, 1989. doi: 10.1145/73007.73063.  Joel Friedman, Andreas Goerdt, and Michael Krivelevich. Recognizing more unsatisfiable ran- doi: 10.1137/  SIAM J. Comput., 35(2):408-430, 2005.  dom k-sat instances efficiently. S009753970444096X.  Silvia Gandy, Benjamin Recht, and Isao Yamada. Tensor completion and low-n-rank tensor recovery  via convex optimization. Inverse Problems, 27(2):025010, 2011.  Rong Ge and Tengyu Ma. Decomposing overcomplete 3rd order tensors using sum-of-squares algorithms. In Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques, APPROX/RANDOM 2015, August 24-26, 2015, Princeton, NJ, USA, pages 829-849, 2015. doi: 10.4230/LIPIcs.APPROX-RANDOM.2015.829. BARAK MOITRA  Andreas Goerdt and Michael Krivelevich. Efficient recognition of random unsatisfiable k-sat in- stances by spectral methods. In STACS 2001, 18th Annual Symposium on Theoretical Aspects of Computer Science, Dresden, Germany, February 15-17, 2001, Proceedings, pages 294-304, 2001. doi: 10.1007/3-540-44693-1 26.  Dima Grigoriev. Linear lower bound on degrees of positivstellensatz calculus proofs for the parity.  Theor. Comput. Sci., 259(1-2):613-622, 2001. doi: 10.1016/S0304-3975(00)00157-2.  Leonid Gurvits. Classical deterministic complexity of edmonds\u2019 problem and quantum entangle- ment. In Proceedings of the 35th Annual ACM Symposium on Theory of Computing, June 9-11, 2003, San Diego, CA, USA, pages 10-19, 2003. doi: 10.1145/780542.780545.  Moritz Hardt. Understanding alternating minimization for matrix completion. In 55th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2014, Philadelphia, PA, USA, October 18-21, 2014, pages 651-660, 2014. doi: 10.1109/FOCS.2014.75.  Aram Wettroth Harrow and Ashley Montanaro. Testing product states, quantum merlin-arthur  games and tensor optimization. J. ACM, 60(1):3, 2013. doi: 10.1145/2432622.2432625.  Samuel B Hopkins, Tselil Schramm, Jonathan Shi, and David Steurer. Speeding up sum-of-squares for tensor decomposition and planted sparse vectors. arXiv preprint arXiv:1512.02337, 2015.  Daniel Hsu and Sham M. Kakade. Learning mixtures of spherical gaussians: moment methods and spectral decompositions. In Innovations in Theoretical Computer Science, ITCS \u201913, Berkeley, CA, USA, January 9-12, 2013, pages 11-20, 2013. doi: 10.1145/2422436.2422439.  Prateek Jain and Sewoong Oh. Provable tensor factorization with missing data. In Advances in Neu- ral Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada, pages 1431-1439, 2014.  Prateek Jain, Praneeth Netrapalli, and Sujay Sanghavi. Low-rank matrix completion using alternat- ing minimization. In Symposium on Theory of Computing Conference, STOC\u201913, Palo Alto, CA, USA, June 1-4, 2013, pages 665-674, 2013. doi: 10.1145/2488608.2488693.  Raghunandan H. Keshavan, Andrea Montanari, and Sewoong Oh. Matrix completion from noisy  entries. Journal of Machine Learning Research, 11:2057-2078, 2010.  Daniel Kressner, Michael Steinlechner, and Bart Vandereycken. Low-rank tensor completion by  riemannian optimization. BIT Numerical Mathematics, 54(2):447-468, 2014.  Jean B Lasserre. Global optimization with polynomials and the problem of moments. SIAM Journal  on Optimization, 11(3):796-817, 2001.  Troy Lee and Adi Shraibman. Matrix completion from any given set of observations. In Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Pro- cessing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States., pages 1781-1787, 2013.  Ji Liu, Przemyslaw Musialski, Peter Wonka, and Jieping Ye. Tensor completion for estimating missing values in visual data. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(1):208-220, 2013. NOISY TENSOR COMPLETION  Ji\u02c7r\u00b4\u0131 Matou\u02c7sek. Lectures on discrete geometry, volume 212. Springer New York, 2002.  Elchanan Mossel and S\u00b4ebastien Roch. Learning nonsingular phylogenies and hidden markov mod- els. In Proceedings of the 37th Annual ACM Symposium on Theory of Computing, Baltimore, MD, USA, May 22-24, 2005, pages 366-375, 2005. doi: 10.1145/1060590.1060645.  Cun Mu, Bo Huang, John Wright, and Donald Goldfarb. Square deal: Lower bounds and improved relaxations for tensor recovery. In Proceedings of the 31th International Conference on Machine Learning, ICML 2014, Beijing, China, 21-26 June 2014, pages 73-81, 2014.  Yurii Nesterov. Squared functional systems and optimization problems. In High performance opti-  mization, pages 405-440. Springer, 2000.  Pablo A Parrilo. Structured semidefinite programs and semialgebraic geometry methods in robust-  ness and optimization. PhD thesis, California Institute of Technology, 2000.  Benjamin Recht, Maryam Fazel, and Pablo A. Parrilo. Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization. SIAM Review, 52(3):471-501, 2010. doi: 10.1137/070697835.  Grant Schoenebeck. Linear level lasserre lower bounds for certain k-csps. In 49th Annual IEEE Symposium on Foundations of Computer Science, FOCS 2008, October 25-28, 2008, Philadel- phia, PA, USA, pages 593-602, 2008. doi: 10.1109/FOCS.2008.74.  Naum Zuselevich Shor. An approach to obtaining global extremums in polynomial mathematical  programming problems. Cybernetics, 23(5):695-700, 1988.  Marco Signoretto, Lieven De Lathauwer, and Johan AK Suykens. Nuclear norms for tensors and  their use for convex multilinear estimation. Tech Report 10-186, K. U. Leuven, 2010.  Nathan Srebro and Adi Shraibman. Rank, trace-norm and max-norm. In Learning Theory, 18th Annual Conference on Learning Theory, COLT 2005, Bertinoro, Italy, June 27-30, 2005, Pro- ceedings, pages 545-560, 2005. doi: 10.1007/11503415 37.  Gongguo Tang, Badri Narayan Bhaskar, Parikshit Shah, and Benjamin Recht. Compressed sensing off the grid. IEEE Transactions on Information Theory, 59(11):7465-7490, 2013. doi: 10.1109/ TIT.2013.2277451.  Ming Yuan and Cun-Hui Zhang. On tensor completion via nuclear norm minimization. Foundations  of Computational Mathematics, pages 1-38, 2014."}