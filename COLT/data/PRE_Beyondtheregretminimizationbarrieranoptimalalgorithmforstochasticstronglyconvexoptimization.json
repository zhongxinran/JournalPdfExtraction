{"1": "Jacob Abernethy, Alekh Agarwal, Peter L. Bartlett, and Alexander Rakhlin. A stochastic  view of optimal regret through minimax duality. In COLT, 2009.  Alekh Agarwal, Peter L. Bartlett, Pradeep Ravikumar, and Martin J. Wainwright. Information-theoretic lower bounds on the oracle complexity of convex optimization. In arXiv:1009.0571v1, 2010.  Dimitri P. Bertsekas. Nonlinear Programming. Athena Scientific, 2nd edition, September  1999. ISBN 1886529000.  L\u00b4eon Bottou and Olivier Bousquet. The tradeo\ufb00s of large scale learning. In NIPS, 2007.  Nicol`o Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  Elad Hazan and Satyen Kale. An optimal algorithm for stochastic strongly-convex opti-  mization. June 2010. URL http://arxiv.org/abs/1006.2425.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online  convex optimization. Machine Learning, 69(2-3):169-192, 2007.  Anatoli Juditsky and Yuri Nesterov. Primal-dual subgradient methods for minimizing uni- formly convex functions. August 2010. URL http://hal.archives-ouvertes.fr/docs/ 00/50/89/33/PDF/Strong-hal.pdf.  Arkadi S. Nemirovski and David B. Yudin. Problem complexity and method e\ufb03ciency in  optimization. John Wiley UK/USA, 1983.  Erik Ordentlich and Thomas M. Cover. The cost of achieving the best portfolio in hindsight.  Math. Oper. Res., 23:960-982, November 1998.  Shai Shalev-Shwartz and Nathan Srebro. SVM optimization: inverse dependence on training  set size. In ICML, pages 928-935, 2008.  Shai Shalev-Shwartz, Ohad Shamir, Karthik Sridharan, and Nati Srebro. Stochastic convex  optimization. In COLT, 2009.  Eiji Takimoto and Manfred K. Warmuth. The minimax strategy for gaussian density esti-  mation. In COLT, pages 100-106, 2000.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.  In ICML, pages 928-936, 2003.  436   Hazan Kale  We thank an anonymous referee for several useful suggestions.  Acknowledgments  References  Jacob Abernethy, Alekh Agarwal, Peter L. Bartlett, and Alexander Rakhlin. A stochastic  view of optimal regret through minimax duality. In COLT, 2009.  Alekh Agarwal, Peter L. Bartlett, Pradeep Ravikumar, and Martin J. Wainwright. Information-theoretic lower bounds on the oracle complexity of convex optimization. In arXiv:1009.0571v1, 2010.  Dimitri P. Bertsekas. Nonlinear Programming. Athena Scientific, 2nd edition, September  1999. ISBN 1886529000.  L\u00b4eon Bottou and Olivier Bousquet. The tradeo\ufb00s of large scale learning. In NIPS, 2007.  Nicol`o Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge  University Press, 2006.  Elad Hazan and Satyen Kale. An optimal algorithm for stochastic strongly-convex opti-  mization. June 2010. URL http://arxiv.org/abs/1006.2425.  Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online  convex optimization. Machine Learning, 69(2-3):169-192, 2007.  Anatoli Juditsky and Yuri Nesterov. Primal-dual subgradient methods for minimizing uni- formly convex functions. August 2010. URL http://hal.archives-ouvertes.fr/docs/ 00/50/89/33/PDF/Strong-hal.pdf.  Arkadi S. Nemirovski and David B. Yudin. Problem complexity and method e\ufb03ciency in  optimization. John Wiley UK/USA, 1983.  Erik Ordentlich and Thomas M. Cover. The cost of achieving the best portfolio in hindsight.  Math. Oper. Res., 23:960-982, November 1998.  Shai Shalev-Shwartz and Nathan Srebro. SVM optimization: inverse dependence on training  set size. In ICML, pages 928-935, 2008.  Shai Shalev-Shwartz, Ohad Shamir, Karthik Sridharan, and Nati Srebro. Stochastic convex  optimization. In COLT, 2009.  Eiji Takimoto and Manfred K. Warmuth. The minimax strategy for gaussian density esti-  mation. In COLT, pages 100-106, 2000.  Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.  In ICML, pages 928-936, 2003."}