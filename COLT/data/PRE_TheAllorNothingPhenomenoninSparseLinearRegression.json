{"1": "Shuchin Aeron, Venkatesh Saligrama, and Manqi Zhao.  Information theoretic bounds for com- pressed sensing. IEEE Transactions on Information Theory, 56(10):5111-5130, October 2010. doi: 10.1109/TIT.2010.2059891.  Mehmet Akcakaya and Vahid Tarokh. Shannon-theoretic limits on noisy compressive sampling. IEEE Transactions on Information Theory, 56(1):492-504, December 2010. doi: 10.1109/TIT. 2009.2034796.  Ahmed El Alaoui, Florent Krzakala, and Michael I Jordan. Finite size corrections and likelihood  ratio \ufb02uctuations in the spiked Wigner model. arXiv preprint arXiv:1710.02903, 2017.  J. Barbier and F. Krzakala. Replica analysis and approximate message passing decoder for superpo- sition codes. In 2014 IEEE International Symposium on Information Theory, pages 1494-1498, June 2014. doi: 10.1109/ISIT.2014.6875082.  J. Barbier and F. Krzakala. Approximate message-passing decoder and capacity achieving sparse superposition codes. IEEE Transactions on Information Theory, 63(8):4894-4927, Aug 2017. ISSN 0018-9448. doi: 10.1109/TIT.2017.2713833.  Jean Barbier, Mohamad Dia, Nicolas Macris, and Florent Krzakala. The mutual information in random linear estimation. In Proceedings of the Allerton Conference on Communication, Control, and Computing, Monticello, IL, 2016.  A. R. Barron and S. Cho. High-rate sparse superposition codes with iteratively optimal estimates.  Proc. IEEE Int. Symp. Inf. Theory, 2012.  Emmanuel J Candes and Terence Tao. Decoding by linear programming. IEEE transactions on  information theory, 51(12):4203-4215, 2005.  Alan Miller. Chapman and Hall. Subset selection in regression. Chapman and Hall, 1990.  Scott Shaobing Chen, David L. Donoho, and Michael A. Saunders. Atomic decomposition by ISSN 0036-1445. doi: 10.1137/  basis pursuit. SIAM Rev., 43(1):129-159, January 2001. S003614450037906X. URL http://dx.doi.org/10.1137/S003614450037906X.  S. Cho. High-dimensional regression with random design, including sparse superposition codes.  Ph.D. dissertation, Dept. Statist., Yale Univ., New Haven, CT, USA, 2014.  David L Donoho. Compressed sensing. IEEE Transactions on information theory, 52(4):1289-  1306, 2006.  Alyson K. Fletcher, Sundeep Rangan, and Vivek K Goyal. Necessary and sufficient conditions IEEE Transactions on Information Theory, 55(12):5758-5772,  for sparsity pattern recovery. November 2009. doi: 10.1109/TIT.2009.2032726.  10   THE ALL-OR-NOTHING PHENOMENON IN SPARSE LINEAR REGRESSION  G. Reeves is supported by the NSF Grants CCF-1718494 and CCF-1750362. J. Xu is supported by the NSF Grants CCF-1850743, IIS-1838124, and CCF-1856424.  Acknowledgment  References  Shuchin Aeron, Venkatesh Saligrama, and Manqi Zhao.  Information theoretic bounds for com- pressed sensing. IEEE Transactions on Information Theory, 56(10):5111-5130, October 2010. doi: 10.1109/TIT.2010.2059891.  Mehmet Akcakaya and Vahid Tarokh. Shannon-theoretic limits on noisy compressive sampling. IEEE Transactions on Information Theory, 56(1):492-504, December 2010. doi: 10.1109/TIT. 2009.2034796.  Ahmed El Alaoui, Florent Krzakala, and Michael I Jordan. Finite size corrections and likelihood  ratio \ufb02uctuations in the spiked Wigner model. arXiv preprint arXiv:1710.02903, 2017.  J. Barbier and F. Krzakala. Replica analysis and approximate message passing decoder for superpo- sition codes. In 2014 IEEE International Symposium on Information Theory, pages 1494-1498, June 2014. doi: 10.1109/ISIT.2014.6875082.  J. Barbier and F. Krzakala. Approximate message-passing decoder and capacity achieving sparse superposition codes. IEEE Transactions on Information Theory, 63(8):4894-4927, Aug 2017. ISSN 0018-9448. doi: 10.1109/TIT.2017.2713833.  Jean Barbier, Mohamad Dia, Nicolas Macris, and Florent Krzakala. The mutual information in random linear estimation. In Proceedings of the Allerton Conference on Communication, Control, and Computing, Monticello, IL, 2016.  A. R. Barron and S. Cho. High-rate sparse superposition codes with iteratively optimal estimates.  Proc. IEEE Int. Symp. Inf. Theory, 2012.  Emmanuel J Candes and Terence Tao. Decoding by linear programming. IEEE transactions on  information theory, 51(12):4203-4215, 2005.  Alan Miller. Chapman and Hall. Subset selection in regression. Chapman and Hall, 1990.  Scott Shaobing Chen, David L. Donoho, and Michael A. Saunders. Atomic decomposition by ISSN 0036-1445. doi: 10.1137/  basis pursuit. SIAM Rev., 43(1):129-159, January 2001. S003614450037906X. URL http://dx.doi.org/10.1137/S003614450037906X.  S. Cho. High-dimensional regression with random design, including sparse superposition codes.  Ph.D. dissertation, Dept. Statist., Yale Univ., New Haven, CT, USA, 2014.  David L Donoho. Compressed sensing. IEEE Transactions on information theory, 52(4):1289-  1306, 2006.  Alyson K. Fletcher, Sundeep Rangan, and Vivek K Goyal. Necessary and sufficient conditions IEEE Transactions on Information Theory, 55(12):5758-5772,  for sparsity pattern recovery. November 2009. doi: 10.1109/TIT.2009.2032726. THE ALL-OR-NOTHING PHENOMENON IN SPARSE LINEAR REGRESSION  David Gamarnik and Ilias Zadik. High dimensional linear regression with binary coefficients: Mean squared error and a phase transition. Conference on Learning Theory (COLT), 2017a. URL https://arxiv.org/abs/1701.04455.  David Gamarnik and Ilias Zadik. Sparse high dimensional linear regression: Algorithmic barrier and a local search algorithm. arXiv Preprint, 2017b. URL https://arxiv.org/abs/ 1711.04952.  David Gamarnik and Ilias Zadik. High dimensional linear regression using lattice basis reduction.  In Advances in Neural Information Processing Systems (NIPS), 2018.  Dongning Guo and Sergio Verd\u00b4u. Randomly spread CDMA: Asymptotics via statistical physics.  IEEE Transactions on Information Theory, 51(6):1983-2010, June 2005.  Yuzhe Jin, Young-Han Kim, and Bhaskar D Rao. Limits on support recovery of sparse signals via multiple-access communication techniques. IEEE Transactions on Information Theory, 57(12): 7877-7892, 2011.  A. Joseph and A. R. Barron. Fast sparse superposition codes have near exponential error probability  for r \u00a1 c,. IEEE Trans. Inf. Theory, vol. 60, no. 2, pp. 919-942, 2014.  Antony Joseph and Andrew R. Barron. Least sqaures superposition codes of moderate dictionary-  size are reliable at rates up to capacity. IEEE Transactions on Information Theory, 2012.  Shrinivas Kudekar, Santhosh Kumar, Marco Mondelli, Henry D Pfister, Eren S\u00b8 as\u00b8o\u02c7glu, and IEEE Trans-  R\u00a8udiger L Urbanke. Reed-muller codes achieve capacity on erasure channels. actions on Information Theory, 63(7):4298-4316, 2017.  Cyril M\u00b4easson, Andrea Montanari, and R\u00a8udiger Urbanke. Maxwell construction: The hidden bridge between iterative and maximum a posteriori decoding. IEEE Transactions on Information Theory, 54(12):5277-5307, 2008.  Mohamed Ndaoud and Alexandre B Tsybakov. Optimal variable selection and adaptive noisy com-  pressed sensing. arXiv preprint arXiv:1809.03145, 2018.  Amelia Perry, Alexander S. Wein, and Afonso S. Bandeira. Statistical limits of spiked tensor mod-  els. arXiv:1612.07728, Dec. 2016.  K. Rahnama Rad. Nearly sharp sufficient conditions on exact sparsity pattern recovery.  IEEE Transactions on Information Theory, 57(7):4672-4679, July 2011. ISSN 0018-9448. doi: 10. 1109/TIT.2011.2145670.  Galen Reeves. Conditional central limit theorems for Gaussian projections.  In Proceedings of the IEEE International Symposium on Information Theory (ISIT), pages 3055-3059, Aachen, Germany, June 2017.  Galen Reeves and Michael Gastpar. The sampling rate-distortion tradeoff for sparsity pattern recov- ery in compressed sensing. IEEE Transactions on Information Theory, 58(5):3065-3092, May 2012. doi: 10.1109/TIT.2012.2184848. THE ALL-OR-NOTHING PHENOMENON IN SPARSE LINEAR REGRESSION  Galen Reeves and Michael Gastpar. Approximate sparsity pattern recovery: Information-theoretic IEEE Transactions on Information Theory, 59(6):3451-3465, June 2013. doi:  lower bounds. 10.1109/TIT.2013.2253852.  Galen Reeves and Henry D. Pfister. The replica-symmetric prediction for compressed sensing with Gaussian matrices is exact. In Proceedings of the IEEE International Symposium on Information Theory (ISIT), pages 665 - 669, Barcelona, Spain, July 2016. doi: 10.1109/ISIT.2016.7541382. arXiv. Available: https://arxiv.org/abs/1607.02524.  Galen Reeves, Jiaming Xu, and Ilias Zadik. The all-or-nothing phenomenon in sparse linear regres-  sion. arXiv Preprint arXiv:1903.05046, 2019.  C. Rush, A. Greig, and R. Venkataramanan. Capacity-achieving sparse superposition codes via approximate message passing decoding. IEEE Trans. Inf. Theory, vol. 63, pp. 1476-1500, 2017.  Jonathan Scarlett and Volkan Cevher. Limits on support recovery with probabilistic models: An IEEE Transactions on Information Theory, 63(1):593-620,  information-theoretic framework. September 2017. doi: 10.1109/TIT.2016.2606605.  T. Tanaka. A statistical-mechanics approach to large-system analysis of CDMA multiuser detectors.  IEEE Transactions on Information Theory, 48(11):2888-2910, November 2002.  Martin J Wainwright. Sharp thresholds for high-dimensional and noisy sparsity recovery using IEEE transactions on information theory, 55(5):  constrained quadratic programming (lasso). 2183-2202, 2009a.  Martin J. Wainwright. Information-theoretic limits on sparsity recovery in the high-dimensional and noisy setting. IEEE Transactions on Information Theory, 55(12):5728-5741, December 2009b.  Wei Wang, Martin J Wainwright, and Kannan Ramchandran. Information-theoretic limits on sparse signal recovery: Dense versus sparse measurement matrices. Information Theory, IEEE Trans- actions on, 56(6):2967-2979, 2010.  Yihong Wu and Jiaming Xu. Statistical problems with planted structures: Information-theoretical  and computational limits. arXiv preprint arXiv:1806.00118, 2018."}