{"1": "Pallavi Arora, Csaba Szepesv\u00e1ri, and Rong Zheng. Sequential learning for optimal monitoring of  multi-channel wireless networks. IEEE, 2011.  Jean-Yves Audibert, R\u00e9mi Munos, and Csaba Szepesv\u00e1ri. Exploration-exploitation tradeoff using variance estimates in multi-armed bandits. Theoretical Computer Science, 410(19):1876-1902, 2009.  Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2-3):235-256, 2002a.  Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. The nonstochastic multiarmed  bandit problem. SIAM journal on computing, 32(1):48-77, 2002b.  Marc Bellemare, Sriram Srinivasan, Georg Ostrovski, Tom Schaul, David Saxton, and Remi Munos. Unifying count-based exploration and intrinsic motivation. In Advances in Neural Information Processing Systems, pages 1471-1479, 2016.  S\u00e9bastien Bubeck, Nicolo Cesa-Bianchi, et al. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends R(cid:13) in Machine Learning, 5(1):1-122, 2012.  Felipe Caro and J\u00e9r\u00e9mie Gallien. Dynamic assortment with demand learning for seasonal consumer  goods. Management Science, 53(2):276-292, 2007.  Alexandra Carpentier and Michal Valko. Revealing graph bandits for maximizing local in\ufb02uence. In  International Conference on Artificial Intelligence and Statistics, 2016.  Nicolo Cesa-Bianchi and G\u00e1bor Lugosi. Combinatorial bandits. Journal of Computer and System  Sciences, 78(5):1404-1422, 2012.  Wei Chen, Yajun Wang, and Yang Yuan. Combinatorial multi-armed bandit: General framework and  applications. In International Conference on Machine Learning, pages 151-159, 2013.  Wei Chen, Yajun Wang, Yang Yuan, and Qinshi Wang. Combinatorial multi-armed bandit and its extension to probabilistically triggered arms. The Journal of Machine Learning Research, 17(1): 1746-1778, 2016a.  Wei Chen, Wei Hu, Fu Li, Jian Li, Yu Liu, and Pinyan Lu. Combinatorial multi-armed bandit with general reward functions. In Advances in Neural Information Processing Systems, pages 1659-1667, 2016b.  Richard Combes, Stefan Magureanu, Alexandre Proutiere, and Cyrille Laroche. Learning to rank: Regret lower bounds and efficient algorithms. ACM SIGMETRICS Performance Evaluation Review, 43(1):231-244, 2015a.  13   BATCH-SIZE INDEPENDENT REGRET BOUNDS FOR THE CMAB PROBLEM  The authors thank Asaf Cassel and Esther Derman for their helpful comments on the manuscript.  Acknowledgments  References  Pallavi Arora, Csaba Szepesv\u00e1ri, and Rong Zheng. Sequential learning for optimal monitoring of  multi-channel wireless networks. IEEE, 2011.  Jean-Yves Audibert, R\u00e9mi Munos, and Csaba Szepesv\u00e1ri. Exploration-exploitation tradeoff using variance estimates in multi-armed bandits. Theoretical Computer Science, 410(19):1876-1902, 2009.  Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2-3):235-256, 2002a.  Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. The nonstochastic multiarmed  bandit problem. SIAM journal on computing, 32(1):48-77, 2002b.  Marc Bellemare, Sriram Srinivasan, Georg Ostrovski, Tom Schaul, David Saxton, and Remi Munos. Unifying count-based exploration and intrinsic motivation. In Advances in Neural Information Processing Systems, pages 1471-1479, 2016.  S\u00e9bastien Bubeck, Nicolo Cesa-Bianchi, et al. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends R(cid:13) in Machine Learning, 5(1):1-122, 2012.  Felipe Caro and J\u00e9r\u00e9mie Gallien. Dynamic assortment with demand learning for seasonal consumer  goods. Management Science, 53(2):276-292, 2007.  Alexandra Carpentier and Michal Valko. Revealing graph bandits for maximizing local in\ufb02uence. In  International Conference on Artificial Intelligence and Statistics, 2016.  Nicolo Cesa-Bianchi and G\u00e1bor Lugosi. Combinatorial bandits. Journal of Computer and System  Sciences, 78(5):1404-1422, 2012.  Wei Chen, Yajun Wang, and Yang Yuan. Combinatorial multi-armed bandit: General framework and  applications. In International Conference on Machine Learning, pages 151-159, 2013.  Wei Chen, Yajun Wang, Yang Yuan, and Qinshi Wang. Combinatorial multi-armed bandit and its extension to probabilistically triggered arms. The Journal of Machine Learning Research, 17(1): 1746-1778, 2016a.  Wei Chen, Wei Hu, Fu Li, Jian Li, Yu Liu, and Pinyan Lu. Combinatorial multi-armed bandit with general reward functions. In Advances in Neural Information Processing Systems, pages 1659-1667, 2016b.  Richard Combes, Stefan Magureanu, Alexandre Proutiere, and Cyrille Laroche. Learning to rank: Regret lower bounds and efficient algorithms. ACM SIGMETRICS Performance Evaluation Review, 43(1):231-244, 2015a. BATCH-SIZE INDEPENDENT REGRET BOUNDS FOR THE CMAB PROBLEM  Richard Combes, Mohammad Sadegh Talebi Mazraeh Shahi, Alexandre Proutiere, et al. Combinato- rial bandits revisited. In Advances in Neural Information Processing Systems, pages 2116-2124, 2015b.  Imre Csisz\u00e1r and Zsolt Talata. Context tree estimation for not necessarily finite memory processes,  via bic and mdl. IEEE Transactions on Information theory, 52(3):1007-1016, 2006.  R\u00e9my Degenne and Vianney Perchet. Combinatorial semi-bandit with known covariance.  In  Advances in Neural Information Processing Systems, pages 2972-2980, 2016.  Yi Gai, Bhaskar Krishnamachari, and Rahul Jain. Learning multiuser channel allocations in cognitive radio networks: A combinatorial multi-armed bandit formulation. In New Frontiers in Dynamic Spectrum, 2010 IEEE Symposium on, pages 1-9. IEEE, 2010.  Yi Gai, Bhaskar Krishnamachari, and Rahul Jain. Combinatorial network optimization with unknown IEEE/ACM  variables: Multi-armed bandits with linear rewards and individual observations. Transactions on Networking (TON), 20(5):1466-1478, 2012.  Aur\u00e9lien Garivier and Olivier Capp\u00e9. The kl-ucb algorithm for bounded stochastic bandits and beyond. In Proceedings of the 24th annual Conference On Learning Theory, pages 359-376, 2011.  Thibault Gisselbrecht, Ludovic Denoyer, Patrick Gallinari, and Sylvain Lamprier. Whichstreams: A dynamic approach for focused data capture from large social media. In Ninth International AAAI Conference on Web and Social Media, 2015.  Aditya Gopalan and Shie Mannor. Thompson sampling for learning parameterized markov decision  processes. In Conference on Learning Theory, pages 861-898, 2015.  Aditya Gopalan, Shie Mannor, and Yishay Mansour. Thompson sampling for complex online  problems. In International Conference on Machine Learning, pages 100-108, 2014.  Dorit S Hochbaum. Approximation algorithms for NP-hard problems. PWS Publishing Co., 1996.  Alihan H\u00fcy\u00fck and Cem Tekin. Thompson sampling for combinatorial multi-armed bandit with  probabilistically triggered arms. arXiv preprint arXiv:1809.02707, 2018.  Thomas Jaksch, Ronald Ortner, and Peter Auer. Near-optimal regret bounds for reinforcement  learning. Journal of Machine Learning Research, 11(Apr):1563-1600, 2010.  Branislav Kveton, Zheng Wen, Azin Ashkan, Hoda Eydgahi, and Brian Eriksson. Matroid bandits: fast combinatorial optimization with learning. In Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence, pages 420-429. AUAI Press, 2014.  Branislav Kveton, Csaba Szepesvari, Zheng Wen, and Azin Ashkan. Cascading bandits: Learning to rank in the cascade model. In International Conference on Machine Learning, pages 767-776, 2015a.  Branislav Kveton, Zheng Wen, Azin Ashkan, and Csaba Szepesvari. Combinatorial cascading  bandits. In Advances in Neural Information Processing Systems, pages 1450-1458, 2015b. BATCH-SIZE INDEPENDENT REGRET BOUNDS FOR THE CMAB PROBLEM  Branislav Kveton, Zheng Wen, Azin Ashkan, and Csaba Szepesvari. Tight regret bounds for stochastic combinatorial semi-bandits. In Artificial Intelligence and Statistics, pages 535-543, 2015c.  Tze Leung Lai and Herbert Robbins. Asymptotically efficient adaptive allocation rules. Advances in  applied mathematics, 6(1):4-22, 1985.  Tor Lattimore and Csaba Szepesv\u00e1ri. Bandit algorithms. preprint, 2018.  Tor Lattimore, Branislav Kveton, Shuai Li, and Csaba Szepesvari. Toprank: A practical algorithm for online stochastic ranking. In Advances in Neural Information Processing Systems, pages 3949-3958, 2018.  Keqin Liu and Qing Zhao. Adaptive shortest-path routing under unknown and stochastically varying link states. In Modeling and Optimization in Mobile, Ad Hoc and Wireless Networks (WiOpt), 2012 10th International Symposium on, pages 232-237. IEEE, 2012.  Subhojyoti Mukherjee, KP Naveen, Nandan Sudarsanam, and Balaraman Ravindran. Efficient-ucbv: An almost optimal algorithm using variance estimates. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018.  George L Nemhauser, Laurence A Wolsey, and Marshall L Fisher. An analysis of approximations for maximizing submodular set functions\u2014i. Mathematical programming, 14(1):265-294, 1978.  Ian Osband, Daniel Russo, and Benjamin Van Roy. (more) efficient reinforcement learning via posterior sampling. In Advances in Neural Information Processing Systems, pages 3003-3011, 2013.  Pierre Perrault, Vianney Perchet, and Michal Valko. Finding the bandit in a graph: Sequential  search-and-stop. arXiv preprint arXiv:1806.02282, 2018.  Herbert Robbins. Some aspects of the sequential design of experiments. Bulletin of the American  Mathematical Society, 58(5):527-535, 1952.  William R Thompson. On the likelihood that one unknown probability exceeds another in view of  the evidence of two samples. Biometrika, 25(3/4):285-294, 1933.  Sharan Vaswani, Laks Lakshmanan, Mark Schmidt, et al. In\ufb02uence maximization with bandits.  arXiv preprint arXiv:1503.00024, 2015.  Qinshi Wang and Wei Chen. Improving regret bounds for combinatorial semi-bandits with proba- bilistically triggered arms and its applications. In Advances in Neural Information Processing Systems, pages 1161-1171, 2017.  Siwei Wang and Wei Chen. Thompson sampling for combinatorial semi-bandits. In International  Conference on Machine Learning, pages 5101-5109, 2018.  Zheng Wen, Branislav Kveton, Michal Valko, and Sharan Vaswani. Online in\ufb02uence maximiza- tion under independent cascade model with semi-bandit feedback. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 3026-3036. Curran Associates Inc., 2017. BATCH-SIZE INDEPENDENT REGRET BOUNDS FOR THE CMAB PROBLEM  (9)  (20)  (21)"}