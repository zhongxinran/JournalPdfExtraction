{"1": "P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem.  Machine Learning, 47(2-3):235-256, 2002.  O. Chapelle and L. Li. An empirical evaluation of thompson sampling. In NIPS, 2011.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and beyond. In  Conference on Learning Theory (COLT), 2011.  J. C. Gittins. Multi-armed Bandit Allocation Indices. Wiley Interscience Series in Systems and  Optimization. John Wiley and Son, 1989.  T. Graepel, J. Q. Candela, T. Borchert, and R. Herbrich. Web-scale bayesian click-through rate prediction for sponsored search advertising in microsoft\u2019s bing search engine. In ICML, pages 13-20, 2010.  O.-C. Granmo. Solving two-armed bernoulli bandit problems using a bayesian learning automaton. International Journal of Intelligent Computing and Cybernetics (IJICC), 3(2):207-234, 2010.  K. Jogdeo and S. M. Samuels. Monotone Convergence of Binomial Probabilities and A General- ization of Ramanujan\u2019s equation. The Annals of Mathematical Statistics, (4):1191-1195, 1968.  E. Kaufmann, O. Capp\u00b4e, and A. Garivier. On bayesian upper confidence bounds for bandit prob- In Fifteenth International Conference on Artificial Intelligence and Statistics (AISTAT),  lems. 2012.  T. L. Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Advances in Applied  Mathematics, 6:4-22, 1985.  O.-A. Maillard, R. Munos, and G. Stoltz. Finite-time analysis of multi-armed bandits problems with  kullback-leibler divergences. In Conference on Learning Theory (COLT), 2011.  B. C. May and D. S. Leslie. Simulation studies in optimistic bayesian sampling in contextual-bandit problems. Technical Report 11:02, Statistics Group, Department of Mathematics, University of Bristol, 2011.  B. C. May, N. Korda, A. Lee, and D. S. Leslie. Optimistic bayesian sampling in contextual-bandit problems. Technical Report 11:01, Statistics Group, Department of Mathematics, University of Bristol, 2011.  S. Scott. A modern bayesian look at the multi-armed bandit. Applied Stochastic Models in Business  and Industry, 26:639-658, 2010.  W. R. Thompson. On the likelihood that one unknown probability exceeds another in view of the  evidence of two samples. Biometrika, 25(3-4):285-294, 1933.  39.13   ANALYSIS OF THOMPSON SAMPLING  References  P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem.  Machine Learning, 47(2-3):235-256, 2002.  O. Chapelle and L. Li. An empirical evaluation of thompson sampling. In NIPS, 2011.  A. Garivier and O. Capp\u00b4e. The KL-UCB algorithm for bounded stochastic bandits and beyond. In  Conference on Learning Theory (COLT), 2011.  J. C. Gittins. Multi-armed Bandit Allocation Indices. Wiley Interscience Series in Systems and  Optimization. John Wiley and Son, 1989.  T. Graepel, J. Q. Candela, T. Borchert, and R. Herbrich. Web-scale bayesian click-through rate prediction for sponsored search advertising in microsoft\u2019s bing search engine. In ICML, pages 13-20, 2010.  O.-C. Granmo. Solving two-armed bernoulli bandit problems using a bayesian learning automaton. International Journal of Intelligent Computing and Cybernetics (IJICC), 3(2):207-234, 2010.  K. Jogdeo and S. M. Samuels. Monotone Convergence of Binomial Probabilities and A General- ization of Ramanujan\u2019s equation. The Annals of Mathematical Statistics, (4):1191-1195, 1968.  E. Kaufmann, O. Capp\u00b4e, and A. Garivier. On bayesian upper confidence bounds for bandit prob- In Fifteenth International Conference on Artificial Intelligence and Statistics (AISTAT),  lems. 2012.  T. L. Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Advances in Applied  Mathematics, 6:4-22, 1985.  O.-A. Maillard, R. Munos, and G. Stoltz. Finite-time analysis of multi-armed bandits problems with  kullback-leibler divergences. In Conference on Learning Theory (COLT), 2011.  B. C. May and D. S. Leslie. Simulation studies in optimistic bayesian sampling in contextual-bandit problems. Technical Report 11:02, Statistics Group, Department of Mathematics, University of Bristol, 2011.  B. C. May, N. Korda, A. Lee, and D. S. Leslie. Optimistic bayesian sampling in contextual-bandit problems. Technical Report 11:01, Statistics Group, Department of Mathematics, University of Bristol, 2011.  S. Scott. A modern bayesian look at the multi-armed bandit. Applied Stochastic Models in Business  and Industry, 26:639-658, 2010.  W. R. Thompson. On the likelihood that one unknown probability exceeds another in view of the  evidence of two samples. Biometrika, 25(3-4):285-294, 1933.  39.13   AGRAWAL GOYAL"}