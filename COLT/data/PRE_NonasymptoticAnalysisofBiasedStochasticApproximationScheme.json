{"1": "Yasin Abbasi-Yadkori, Nevena Lazic, and Csaba Szepesvari. Regret bounds for model-free linear  quadratic control. arXiv preprint arXiv:1804.06021, 2018.  Alekh Agarwal and John C Duchi. The generalization ability of online algorithms for dependent  data. IEEE Transactions on Information Theory, 59(1):573-587, 2013.  Sivaraman Balakrishnan, Martin J Wainwright, Bin Yu, et al. Statistical guarantees for the EM algorithm: From population to sample-based analysis. The Annals of Statistics, 45(1):77-120, 2017.  Jonathan Baxter and Peter L Bartlett. Infinite-horizon policy-gradient estimation. Journal of Artifi-  cial Intelligence Research, 15:319-350, 2001.  Albert Benveniste, Pierre Priouret, and Michel M\u00b4etivier. Adaptive Algorithms and Stochastic Ap-  proximation. 01 1990. ISBN 0-387-52894-6. doi: 10.1007/978-3-642-75894-2.  Jalaj Bhandari, Daniel Russo, and Raghav Singal. A finite time analysis of temporal difference learning with linear function approximation. In Conference On Learning Theory, pages 1691- 1692, 2018.  Vivek S Borkar. Stochastic approximation with two time scales. Systems & Control Letters, 29(5):  291-294, 1997.  2009.  17(9):142, 1998.  Vivek S Borkar. Stochastic approximation: a dynamical systems viewpoint, volume 48. Springer,  L\u00b4eon Bottou. Online learning and stochastic approximations. On-line learning in neural networks,  L\u00b4eon Bottou, Frank E Curtis, and Jorge Nocedal. Optimization methods for large-scale machine  learning. SIAM Review, 60(2):223-311, 2018.  Olivier Capp\u00b4e and Eric Moulines. On-line Expectation Maximization algorithm for latent data models. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 71(3):593- 613, 2009.  Jianfei Chen, Jun Zhu, Yee Whye Teh, and Tong Zhang. Stochastic Expectation Maximization with variance reduction. In Advances in Neural Information Processing Systems, pages 7978-7988, 2018.  Gal Dalal, Balazs Szorenyi, Gugan Thoppe, and Shie Mannor. Finite sample analysis of two- timescale stochastic approximation with applications to reinforcement learning. In Conference On Learning Theory, 2018a.  13   NON-ASYMPTOTIC ANALYSIS OF BIASED STOCHASTIC APPROXIMATION SCHEME  HTW\u2019s work is supported by the CUHK Direct Grant #4055113. The authors would like to thank the anonymous reviewers for valuable feedback.  Acknowledgement  References  Yasin Abbasi-Yadkori, Nevena Lazic, and Csaba Szepesvari. Regret bounds for model-free linear  quadratic control. arXiv preprint arXiv:1804.06021, 2018.  Alekh Agarwal and John C Duchi. The generalization ability of online algorithms for dependent  data. IEEE Transactions on Information Theory, 59(1):573-587, 2013.  Sivaraman Balakrishnan, Martin J Wainwright, Bin Yu, et al. Statistical guarantees for the EM algorithm: From population to sample-based analysis. The Annals of Statistics, 45(1):77-120, 2017.  Jonathan Baxter and Peter L Bartlett. Infinite-horizon policy-gradient estimation. Journal of Artifi-  cial Intelligence Research, 15:319-350, 2001.  Albert Benveniste, Pierre Priouret, and Michel M\u00b4etivier. Adaptive Algorithms and Stochastic Ap-  proximation. 01 1990. ISBN 0-387-52894-6. doi: 10.1007/978-3-642-75894-2.  Jalaj Bhandari, Daniel Russo, and Raghav Singal. A finite time analysis of temporal difference learning with linear function approximation. In Conference On Learning Theory, pages 1691- 1692, 2018.  Vivek S Borkar. Stochastic approximation with two time scales. Systems & Control Letters, 29(5):  291-294, 1997.  2009.  17(9):142, 1998.  Vivek S Borkar. Stochastic approximation: a dynamical systems viewpoint, volume 48. Springer,  L\u00b4eon Bottou. Online learning and stochastic approximations. On-line learning in neural networks,  L\u00b4eon Bottou, Frank E Curtis, and Jorge Nocedal. Optimization methods for large-scale machine  learning. SIAM Review, 60(2):223-311, 2018.  Olivier Capp\u00b4e and Eric Moulines. On-line Expectation Maximization algorithm for latent data models. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 71(3):593- 613, 2009.  Jianfei Chen, Jun Zhu, Yee Whye Teh, and Tong Zhang. Stochastic Expectation Maximization with variance reduction. In Advances in Neural Information Processing Systems, pages 7978-7988, 2018.  Gal Dalal, Balazs Szorenyi, Gugan Thoppe, and Shie Mannor. Finite sample analysis of two- timescale stochastic approximation with applications to reinforcement learning. In Conference On Learning Theory, 2018a. NON-ASYMPTOTIC ANALYSIS OF BIASED STOCHASTIC APPROXIMATION SCHEME  Gal Dalal, Bal\u00b4azs Sz\u00a8or\u00b4enyi, Gugan Thoppe, and Shie Mannor. Finite sample analyses for td (0) with function approximation. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018b.  Thomas Degris, Martha White, and Richard S Sutton. Off-policy actor-critic. arXiv preprint  arXiv:1205.4839, 2012.  Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society. Series B (methodological), pages 1-38, 1977.  Randal Douc, Eric Moulines, and David Stoffer. Nonlinear Time Series: Theory, Methods and  Applications with R examples. Chapman and Hall/CRC, 2014.  John C Duchi, Alekh Agarwal, Mikael Johansson, and Michael I Jordan. Ergodic mirror descent.  SIAM Journal on Optimization, 22(4):1549-1578, 2012.  Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator. In Advances in Neural Infor- mation Processing Systems, pages 687-697, 2018.  Maryam Fazel, Rong Ge, Sham Kakade, and Mehran Mesbahi. Global convergence of policy gradi- ent methods for the linear quadratic regulator. In International Conference on Machine Learning, pages 1466-1475, 2018.  Gersende Fort, Eric Moulines, and Pierre Priouret. Convergence of adaptive and interacting Markov  chain monte carlo algorithms. The Annals of Statistics, 39(6):3262-3289, 2011.  Saeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex  stochastic programming. SIAM Journal on Optimization, 23(4):2341-2368, 2013.  Tommi Jaakkola, Michael I Jordan, and Satinder P Singh. Convergence of stochastic iterative dy- namic programming algorithms. In Advances in Neural Information Processing Systems, pages 703-710, 1994.  Vijay R Konda and John N Tsitsiklis. On actor-critic algorithms. SIAM journal on Control and  Optimization, 42(4):1143-1166, 2003.  Harold Kushner and G George Yin. Stochastic approximation and recursive algorithms and appli-  cations, volume 35. Springer Science & Business Media, 2003.  Chandrashekar Lakshminarayanan and Csaba Szepesvari. Linear stochastic approximation: How far does constant step-size and iterate averaging go? In International Conference on Artificial Intelligence and Statistics, pages 1347-1355, 2018.  Julien Mairal. Incremental majorization-minimization optimization with application to large-scale  machine learning. SIAM Journal on Optimization, 25(2):829-855, 2015.  Eric Moulines and Francis R Bach. Non-asymptotic analysis of stochastic approximation algorithms for machine learning. In Advances in Neural Information Processing Systems, pages 451-459, 2011. NON-ASYMPTOTIC ANALYSIS OF BIASED STOCHASTIC APPROXIMATION SCHEME  Matteo Papini, Damiano Binaghi, Giuseppe Canonaco, Matteo Pirotta, and Marcello Restelli. Stochastic variance-reduced policy gradient. 80:4026-4035, 10-15 Jul 2018. URL http: //proceedings.mlr.press/v80/papini18a.html.  Jan Peters and Stefan Schaal. Natural actor-critic. Neurocomputing, 71(7-9):1180-1190, 2008.  Herbert Robbins and Sutton Monro. A stochastic approximation method. The Annals of Mathemat-  ical Statistics, 22(3):400-407, 1951.  Tao Sun, Yuejiao Sun, and Wotao Yin. On Markov chain gradient descent. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Infor- mation Processing Systems 31, pages 9918-9927. Curran Associates, Inc., 2018. URL http:// papers.nips.cc/paper/8195-on-markov-chain-gradient-descent.pdf.  Richard Sutton and Andrew Barto. Reinforcement Learning: An Introduction, 2nd Edition. MIT  Press, 2018.  Richard S Sutton, David A McAllester, Satinder P Singh, and Yishay Mansour. Policy gradient methods for reinforcement learning with function approximation. In Advances in Neural Infor- mation Processing Systems, pages 1057-1063, 2000.  Vladislav B Tadi\u00b4c and Arnaud Doucet. Asymptotic bias of stochastic gradient search. The Annals  of Applied Probability, 27(6):3255-3304, 2017.  Zhaoran Wang, Quanquan Gu, Yang Ning, and Han Liu. High dimensional em algorithm: Statistical optimization and asymptotic normality. In Advances in neural information processing systems, pages 2521-2529, 2015.  Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement  learning. Machine Learning, 8(3-4):229-256, 1992.  CF Jeff Wu. On the convergence properties of the EM algorithm. The Annals of Statistics, pages  Ji Xu, Daniel J Hsu, and Arian Maleki. Global analysis of Expectation Maximization for mixtures In Advances in Neural Information Processing Systems, pages 2676-2684,  95-103, 1983.  of two gaussians. 2016. NON-ASYMPTOTIC ANALYSIS OF BIASED STOCHASTIC APPROXIMATION SCHEME"}