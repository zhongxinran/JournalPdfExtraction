{"1": "Walid M. Abdelmoula, Benjamin Balluff, Sonja Englert, Jouke Dijkstra, Marcel J. T. Reinders, Axel Walch, Liam A. McDonnell, and Boudewijn P. F. Lelieveldt. Data-driven identification of prognostic tumor subpopulations using spatially mapped t-sne of mass spectrometry imaging data. Proceedings of the National Academy of Sciences, 113(43):12244-12249, 2016.  Dimitris Achlioptas and Frank McSherry. On spectral learning of mixtures of distributions. In 18th  Annual Conference on Learning Theory, pages 458-469, 2005.  6   ARORA HU KOTHARI  We show that the t-SNE heuristic can visualize clusters under assumptions similar to the more sophisticated methods in previous theoretical work.  Finally, we show that even when the conditions in Definition 1.4 are not met, t-SNE can still provably visualize at least one cluster in the original data in some cases. As an example, using a more fine-grained analysis, we show that t-SNE computes a partial visualization for data obtained from a mixture of two concentric (thus, no mean separation at all!) spherical Gaussians with vari- ances differing by a constant factor.  Theorem 1.7 (Informal) Let X be generated from an equal-weighted mixture of two Gaussians N (0, \u03c32 2) such that 1.5 \u2264 \u03c32/\u03c31 \u2264 10. Then t-SNE with early exaggeration on input X outputs a (1 \u2212 d\u2212\u2126(1))-partial visualization of X where C1 is (1 \u2212 d\u2212\u2126(1))-visible.  1) and N (0, \u03c32  1.2. Related Work  This paper continues the line of work focused on analyzing gradient descent and related heuristics for non-convex optimization problems, examples of which we have discussed before. Theoretically analyzing t-SNE, in particular, was recently considered in a work of Linderman and Steinerberger (2017) who showed that running t-SNE with early exaggeration causes points from the same cluster to move towards each other (i.e., embedding of any cluster shrinks). As discussed before, however, this does not imply that t-SNE ends up with a visualization as all the clusters could potentially collapse into each other. Another work by Shaham and Steinerberger (2017) derived a theoretical property of SNE, but their result is only nontrivial when the number of clusters is significantly larger than the number of points per cluster, which is an unrealistic assumption.  Mixture models are natural average-case generative models for clusterable data which have been studied as benchmarks for analyzing various clustering algorithms and have a long history of theo- retical work. By now, a sequence of results (Dasgupta et al., 2007, 2006; Arora and Kannan, 2005; Vempala and Wang, 2004; Achlioptas and McSherry, 2005; Kannan et al., 2005; Vempala, 2007; Hsu and Kakade, 2013; Ge et al., 2015b; Kalai et al., 2012; Belkin and Sinha, 2010; Kalai et al., 2010; Kothari and Steinhardt, 2017; Hopkins and Li, 2017; Diakonikolas et al., 2017) have identified efficient algorithms for clustering data from such models under various natural assumptions.  This research was done with support from NSF, ONR, Simons Foundation, Mozilla Research, and Schmidt Foundation.  Acknowledgments  References  Walid M. Abdelmoula, Benjamin Balluff, Sonja Englert, Jouke Dijkstra, Marcel J. T. Reinders, Axel Walch, Liam A. McDonnell, and Boudewijn P. F. Lelieveldt. Data-driven identification of prognostic tumor subpopulations using spatially mapped t-sne of mass spectrometry imaging data. Proceedings of the National Academy of Sciences, 113(43):12244-12249, 2016.  Dimitris Achlioptas and Frank McSherry. On spectral learning of mixtures of distributions. In 18th  Annual Conference on Learning Theory, pages 458-469, 2005. AN ANALYSIS OF THE T-SNE ALGORITHM FOR DATA VISUALIZATION  Sanjeev Arora and Ravi Kannan. Learning mixtures of separated nonspherical gaussians. The  Annals of Applied Probability, 15(1A):69-92, 2005.  Sanjeev Arora, Rong Ge, and Ankur Moitra. Learning topic models\u2014going beyond SVD. In 2012 IEEE 53rd Annual Symposium on Foundations of Computer Science\u2014FOCS 2012, pages 1-10. IEEE Computer Soc., Los Alamitos, CA, 2012.  Sanjeev Arora, Rong Ge, and Ankur Moitra. New algorithms for learning incoherent and overcom- plete dictionaries. In COLT, volume 35 of JMLR Workshop and Conference Proceedings, pages 779-806. JMLR.org, 2014.  Mikhail Belkin and Kaushik Sinha. Polynomial learning of distribution families. In FOCS, pages  103-112. IEEE Computer Society, 2010.  Srinadh Bhojanapalli, Behnam Neyshabur, and Nathan Srebro. Global optimality of local search  for low rank matrix recovery. In NIPS, pages 3873-3881, 2016.  Anirban Dasgupta, John E. Hopcroft, Ravi Kannan, and Pradipta Prometheus Mitra. Spectral clus- tering by recursive partitioning. In ESA, volume 4168 of Lecture Notes in Computer Science, pages 256-267. Springer, 2006.  Anirban Dasgupta, John E. Hopcroft, Ravi Kannan, and Pradipta Prometheus Mitra. Spectral clus-  tering with limited independence. In SODA, pages 1036-1045. SIAM, 2007.  Sanjoy Dasgupta. Learning mixtures of gaussians. In FOCS, pages 634-644, 1999.  Ilias Diakonikolas, Daniel M. Kane, and Alistair Stewart. List-decodable robust mean estimation  and learning mixtures of spherical gaussians. CoRR, abs/1711.07211, 2017.  Ilir Gashi, Vladimir Stankovic, Corrado Leita, and Olivier Thonnard. An experimental study of diversity with off-the-shelf antivirus engines. In Proceedings of The Eighth IEEE International Symposium on Networking Computing and Applications, NCA 2009, July 9-11, 2009, Cambridge, Massachusetts, USA, pages 4-11, 2009.  Rong Ge, Furong Huang, Chi Jin, and Yang Yuan. Escaping from saddle points - online stochastic In COLT, volume 40 of JMLR Workshop and Conference  gradient for tensor decomposition. Proceedings, pages 797-842. JMLR.org, 2015a.  Rong Ge, Qingqing Huang, and Sham M. Kakade. Learning mixtures of gaussians in high dimen-  sions. In STOC, pages 761-770. ACM, 2015b.  Rong Ge, Jason D. Lee, and Tengyu Ma. Matrix completion has no spurious local minimum. CoRR,  abs/1605.07272, 2016.  Rong Ge, Chi Jin, and Yi Zheng. No spurious local minima in nonconvex low rank problems: A  unified geometric analysis. In ICML, pages 1233-1242, 2017.  Philippe Hamel and Douglas Eck. Learning features from music audio with deep belief networks.  In ISMIR, pages 339-344. International Society for Music Information Retrieval, 2010. ARORA HU KOTHARI  Geoffrey E. Hinton and Sam T. Roweis. Stochastic neighbor embedding. In NIPS, pages 833-840,  Samuel B. Hopkins and Jerry Li. Mixture models, robustness, and sum of squares proofs. CoRR,  2002.  abs/1711.07454, 2017.  Daniel Hsu and Sham M. Kakade. Learning mixtures of spherical Gaussians: moment methods and spectral decompositions. In ITCS\u201913\u2014Proceedings of the 2013 ACM Conference on Innovations in Theoretical Computer Science, pages 11-19. ACM, New York, 2013.  Adam Tauman Kalai, Ankur Moitra, and Gregory Valiant. Efficiently learning mixtures of two  gaussians. In STOC, pages 553-562. ACM, 2010.  Adam Tauman Kalai, Ankur Moitra, and Gregory Valiant. Disentangling gaussians. Commun.  ACM, 55(2):113-120, 2012.  Ravindran Kannan, Hadi Salmasian, and Santosh Vempala. The spectral method for general mix-  ture models. In COLT, pages 444-457, 2005.  Jon M. Kleinberg. An impossibility theorem for clustering. In NIPS, pages 446-453, 2002.  Pravesh K. Kothari and Jacob Steinhardt. Better agnostic clustering via relaxed tensor norms. CoRR,  abs/1711.07465, 2017.  arXiv:1706.02582, 2017.  George C Linderman and Stefan Steinerberger. Clustering with t-sne, provably. arXiv preprint  Dohyung Park, Anastasios Kyrillidis, Constantine Caramanis, and Sujay Sanghavi. Non-square In AISTATS,  matrix sensing without spurious local minima via the burer-monteiro approach. pages 65-74, 2017.  Uri Shaham and Stefan Steinerberger. Stochastic neighbor embedding separates well-separated  clusters. arXiv preprint arXiv:1702.02670, 2017.  Ju Sun, Qing Qu, and John Wright. Complete dictionary recovery over the sphere I: overview and  the geometric picture. IEEE Trans. Information Theory, 63(2):853-884, 2017.  Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine  learning research, 9(Nov):2579-2605, 2008.  Santosh Vempala. Spectral algorithms for learning and clustering. In COLT, volume 4539 of Lecture  Notes in Computer Science, pages 3-4. Springer, 2007.  Santosh Vempala and Grant Wang. A spectral algorithm for learning mixture models. Journal of  Computer and System Sciences, 68(4):841-860, 2004.  Izhar Wallach and Ryan Lilien. The protein-small-molecule database (psmdb), a non-redundant structural resource for the analysis of protein-ligand binding. Bioinformatics, 25(5):615-20, 2009."}