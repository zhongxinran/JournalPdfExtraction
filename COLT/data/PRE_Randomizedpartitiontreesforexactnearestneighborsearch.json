{"1": "N. Ailon and B. Chazelle. The fast Johnson-Lindenstrauss transform and approximate  nearest neighbors. SIAM Journal on Computing, 39:302-322, 2009.  13   Randomized trees for NN search  The overall distribution is thus a mixture \u00b5 = w1\u00b51 + a Bernoulli product distribution \u00b5j = B(p for the distribution on 0 < p  + wt\u00b5t whose jth component is (j) N ). Here B(p) is a shorthand with expected value p. It will simplify things to assume that  (j) i < 1/2; this is not a huge assumption if, say, stopwords have been removed.  0, 1 {  \u00d7 \u00b7 \u00b7 \u00b7 \u00d7  \u00b7 \u00b7 \u00b7 B(p  (j) 1 )  }  For the purposes of bounding \u03a6, we are interested in the distribution of dH (q, X), where X is chosen from \u00b5 and dH denotes Hamming distance. This is a sum of small independent quantities, and it is customary to approximate such sums by a Poisson distribution. In the current context, however, this approximation is rather poor, and we instead use counting arguments to directly bound how rapidly the distribution grows. The results stand in stark contrast to those we obtained for doubling measures, and reveal this to be a substantially more di\ufb03cult setting for nearest neighbor search. For a doubling measure, the probability mass of a ball B(q, r) doubles whenever r is multiplied by a constant. In our present setting, it doubles whenever r is increased by an additive constant:  Theorem 10 Suppose that all p of words in a document from topic j, and let L = min(L1, . . . , Lt). Pick any query q 0, 1 }  N , and draw X  denote the expected number  \u00b5. For any (cid:96)  i p  0,  \u223c  \u2208  {  (0, 1/2). Let Lj = (cid:80)  (j) i \u2208  (j) i  \u2265 Pr(dH (q, X) = (cid:96) + 1) Pr(dH (q, X) = (cid:96))  L  (cid:96)/2  \u2212 (cid:96) + 1  .  \u2265  Now, fix a particular query q  0, 1  N , and draw x1, . . . , xn from distribution \u00b5.  \u2208 {  }  Lemma 11 There is an absolute constant co for which the following holds. Pick any 0 < \u03b4 < 1 and any k v) for any m  1, and let v denote the smallest integer for which PrX\u223c\u00b5(dH (q, X)  (8/n) max(k, ln 1/\u03b4). Then with probability at least 1  \u2264 3\u03b4 over the choice of x1, . . . , xn,  n,  \u2265  \u2265  \u2212  \u2264  \u03a6k,m(q,  x1, . . . , xn  )  {  }  \u2264  coL  log2(n/m)  .  (cid:114) 4  v  \u2212  The implication of this lemma is that for any of the three tree data structures, the (cid:112) v/L. This means that the tree can only be  failure probability at a single level is roughly  (cid:112)  grown to depth O(  L/v), and thus the query time is dominated by no = n  When n is large, we expect v to be small, and thus the query time improves over L.  exhaustive search by a factor of roughly 2\u2212  \u221a  2\u2212O(\u221aL/v).  \u00b7  We thank the National Science Foundation for support under grant IIS-1162581.  Acknowledgments  References  N. Ailon and B. Chazelle. The fast Johnson-Lindenstrauss transform and approximate  nearest neighbors. SIAM Journal on Computing, 39:302-322, 2009. Dasgupta Sinha  A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor  in high dimensions. Communications of the ACM, 51(1):117-122, 2008.  S. Arya, D.M. Mount, N.S. Netanyahu, R. Silverman, and A.Y. Wu. An optimal algorithm for approximate nearest neighbor searching. Journal of the ACM, 45:891-923, 1998.  J.L. Bentley. Multidimensional binary search trees used for associative searching. Commu-  nications of the ACM, 18(9):509-517, 1975.  A. Beygelzimer, S. Kakade, and J. Langford. Cover trees for nearest neighbor.  In 23rd  International Conference on Machine Learning, 2006.  S. Dasgupta and Y. Freund. Random projection trees and low dimensional manifolds. In  ACM Symposium on Theory of Computing, pages 537-546, 2008.  D.R. Karger and M. Ruhl. Finding nearest neighbors in growth-restricted metrics. In ACM  Symposium on Theory of Computing, pages 741-750, 2002.  J. Kleinberg. Two algorithms for nearest-neighbor search in high dimensions. In 29th ACM  Symposium on Theory of Computing, 1997.  R. Krauthgamer and J.R. Lee. Navigating nets: simple algorithms for proximity search. In  ACM-SIAM Symposium on Discrete Algorithms, 2004.  T. Liu, A.W. Moore, A. Gray, and K. Yang. An investigation of practical approximate  nearest neighbor algorithms. In Neural Information Processing Systems, 2004.  S. Maneewongvatana and D.M. Mount. The analysis of a probabilistic approach to nearest neighbor searching. In Seventh International Worshop on Algorithms and Data Struc- tures, pages 276-286, 2001."}