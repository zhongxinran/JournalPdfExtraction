{"1": "Yasin Abbasi-Yadkori, Csaba Szepesv\u00b4ari, and David Tax. Improved algorithms for linear stochastic  bandits. In Advances in Neural Information Processing Systems, pages 2312-2320, 2011.  Jean-Yves Audibert, S\u00b4ebastien Bubeck, and R\u00b4emi Munos. Best arm identification in multi-armed  bandits. COLT 2010-Proceedings, 2010.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2-3):235-256, 2002.  Robert E Bechhofer. A sequential multiple-decision procedure for selecting the best one of several normal populations with a common unknown variance, and its use with various experimental designs. Biometrics, 14(3):408-429, 1958.  S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in multi-armed bandits problems. In Pro- ceedings of the 20th International Conference on Algorithmic Learning Theory (ALT), 2009.  S\u00b4ebastien Bubeck, Tengyao Wang, and Nitin Viswanathan. Multiple identifications in multi-armed  bandits. arXiv preprint arXiv:1205.3181, 2012.  DA Darling and Herbert Robbins.  Iterated logarithm inequalities.  In Herbert Robbins Selected  Papers, pages 254-258. Springer, 1985.  Eyal Even-Dar, Shie Mannor, and Yishay Mansour. PAC bounds for multi-armed bandit and markov  decision processes. In Computational Learning Theory, pages 255-270. Springer, 2002.  R. H. Farrell. Asymptotic behavior of expected sample size in certain one sided tests. The Annals  of Mathematical Statistics, 35(1):pp. 36-72, 1964. ISSN 00034851.  Victor Gabillon, Mohammad Ghavamzadeh, Alessandro Lazaric, and Team SequeL. Best arm iden- tification: A unified approach to fixed budget and fixed confidence. In NIPS, pages 3221-3229, 2012.  Kevin Jamieson, Matthew Malloy, Robert Nowak, and Sebastien Bubeck. On finding the largest  mean among many. arXiv preprint arXiv:1306.3917, 2013.  Shivaram Kalyanakrishnan, Ambuj Tewari, Peter Auer, and Peter Stone. PAC subset selection in stochastic multi-armed bandits. In Proceedings of the 29th International Conference on Machine Learning (ICML-12), pages 655-662, 2012.  Zohar Karnin, Tomer Koren, and Oren Somekh. Almost optimal exploration in multi-armed bandits.  In Proceedings of the 30th International Conference on Machine Learning, 2013.  Emilie Kaufmann and Shivaram Kalyanakrishnan. Information complexity in bandit subset selec-  tion. COLT, 2013.  Shie Mannor and John N Tsitsiklis. The sample complexity of exploration in the multi-armed bandit  problem. The Journal of Machine Learning Research, 5:623-648, 2004.  Edward Paulson. A sequential procedure for selecting the population with the largest mean from k  normal populations. The Annals of Mathematical Statistics, 35(1):174-180, 1964.  14   JAMIESON MALLOY NOWAK BUBECK  References  Yasin Abbasi-Yadkori, Csaba Szepesv\u00b4ari, and David Tax. Improved algorithms for linear stochastic  bandits. In Advances in Neural Information Processing Systems, pages 2312-2320, 2011.  Jean-Yves Audibert, S\u00b4ebastien Bubeck, and R\u00b4emi Munos. Best arm identification in multi-armed  bandits. COLT 2010-Proceedings, 2010.  Peter Auer, Nicol`o Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit  problem. Machine learning, 47(2-3):235-256, 2002.  Robert E Bechhofer. A sequential multiple-decision procedure for selecting the best one of several normal populations with a common unknown variance, and its use with various experimental designs. Biometrics, 14(3):408-429, 1958.  S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in multi-armed bandits problems. In Pro- ceedings of the 20th International Conference on Algorithmic Learning Theory (ALT), 2009.  S\u00b4ebastien Bubeck, Tengyao Wang, and Nitin Viswanathan. Multiple identifications in multi-armed  bandits. arXiv preprint arXiv:1205.3181, 2012.  DA Darling and Herbert Robbins.  Iterated logarithm inequalities.  In Herbert Robbins Selected  Papers, pages 254-258. Springer, 1985.  Eyal Even-Dar, Shie Mannor, and Yishay Mansour. PAC bounds for multi-armed bandit and markov  decision processes. In Computational Learning Theory, pages 255-270. Springer, 2002.  R. H. Farrell. Asymptotic behavior of expected sample size in certain one sided tests. The Annals  of Mathematical Statistics, 35(1):pp. 36-72, 1964. ISSN 00034851.  Victor Gabillon, Mohammad Ghavamzadeh, Alessandro Lazaric, and Team SequeL. Best arm iden- tification: A unified approach to fixed budget and fixed confidence. In NIPS, pages 3221-3229, 2012.  Kevin Jamieson, Matthew Malloy, Robert Nowak, and Sebastien Bubeck. On finding the largest  mean among many. arXiv preprint arXiv:1306.3917, 2013.  Shivaram Kalyanakrishnan, Ambuj Tewari, Peter Auer, and Peter Stone. PAC subset selection in stochastic multi-armed bandits. In Proceedings of the 29th International Conference on Machine Learning (ICML-12), pages 655-662, 2012.  Zohar Karnin, Tomer Koren, and Oren Somekh. Almost optimal exploration in multi-armed bandits.  In Proceedings of the 30th International Conference on Machine Learning, 2013.  Emilie Kaufmann and Shivaram Kalyanakrishnan. Information complexity in bandit subset selec-  tion. COLT, 2013.  Shie Mannor and John N Tsitsiklis. The sample complexity of exploration in the multi-armed bandit  problem. The Journal of Machine Learning Research, 5:623-648, 2004.  Edward Paulson. A sequential procedure for selecting the population with the largest mean from k  normal populations. The Annals of Mathematical Statistics, 35(1):174-180, 1964. LIL\u2019 UCB : AN OPTIMAL EXPLORATION ALGORITHM FOR MULTI-ARMED BANDITS"}